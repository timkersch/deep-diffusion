Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		4.430009E-02
  validation loss:		9.715251E-04
Epoch took 9.040s

Epoch 2 of 100
  training loss:		4.976114E-04
  validation loss:		2.631487E-04
Epoch took 8.578s

Epoch 3 of 100
  training loss:		1.638173E-04
  validation loss:		1.146923E-04
Epoch took 9.834s

Epoch 4 of 100
  training loss:		8.079121E-05
  validation loss:		6.742118E-05
Epoch took 8.833s

Epoch 5 of 100
  training loss:		4.764526E-05
  validation loss:		4.059969E-05
Epoch took 9.602s

Epoch 6 of 100
  training loss:		3.349479E-05
  validation loss:		3.100223E-05
Epoch took 10.221s

Epoch 7 of 100
  training loss:		2.217246E-05
  validation loss:		1.819004E-05
Epoch took 10.018s

Epoch 8 of 100
  training loss:		1.583488E-05
  validation loss:		1.488149E-05
Epoch took 10.322s

Epoch 9 of 100
  training loss:		1.152060E-05
  validation loss:		1.026688E-05
Epoch took 9.714s

Epoch 10 of 100
  training loss:		8.976911E-06
  validation loss:		7.871588E-06
Epoch took 8.657s

Epoch 11 of 100
  training loss:		6.517572E-06
  validation loss:		5.669446E-06
Epoch took 9.537s

Epoch 12 of 100
  training loss:		5.288816E-06
  validation loss:		4.407224E-06
Epoch took 9.836s

Epoch 13 of 100
  training loss:		3.986288E-06
  validation loss:		3.410601E-06
Epoch took 9.079s

Epoch 14 of 100
  training loss:		3.529558E-06
  validation loss:		2.658647E-06
Epoch took 9.274s

Epoch 15 of 100
  training loss:		2.918262E-06
  validation loss:		2.193966E-06
Epoch took 9.478s

Epoch 16 of 100
  training loss:		2.597207E-06
  validation loss:		5.402541E-06
Epoch took 8.688s

Epoch 17 of 100
  training loss:		2.186422E-06
  validation loss:		1.480852E-06
Epoch took 9.593s

Epoch 18 of 100
  training loss:		1.610751E-06
  validation loss:		1.748572E-06
Epoch took 9.410s

Epoch 19 of 100
  training loss:		1.631709E-06
  validation loss:		9.043115E-07
Epoch took 8.666s

Epoch 20 of 100
  training loss:		2.197932E-06
  validation loss:		1.443147E-06
Epoch took 9.016s

Epoch 21 of 100
  training loss:		3.263308E-06
  validation loss:		1.473310E-06
Epoch took 9.353s

Epoch 22 of 100
  training loss:		5.835906E-06
  validation loss:		9.484877E-07
Epoch took 8.950s

Epoch 23 of 100
  training loss:		2.696312E-04
  validation loss:		1.499036E-04
Epoch took 8.297s

Epoch 24 of 100
  training loss:		1.410070E-05
  validation loss:		3.518820E-06
Epoch took 9.701s

Epoch 25 of 100
  training loss:		6.894302E-06
  validation loss:		4.481370E-06
Epoch took 10.064s

Epoch 26 of 100
  training loss:		8.584509E-06
  validation loss:		2.002191E-06
Epoch took 9.444s

Epoch 27 of 100
  training loss:		4.657244E-05
  validation loss:		1.359540E-05
Epoch took 9.834s

Epoch 28 of 100
  training loss:		9.534172E-05
  validation loss:		3.406925E-04
Epoch took 9.374s

Epoch 29 of 100
  training loss:		3.024959E-04
  validation loss:		1.888117E-06
Epoch took 10.209s

Epoch 30 of 100
  training loss:		3.584316E-06
  validation loss:		5.805696E-07
Epoch took 10.101s

Epoch 31 of 100
  training loss:		1.564280E-06
  validation loss:		3.980229E-06
Epoch took 9.800s

Epoch 32 of 100
  training loss:		3.835769E-05
  validation loss:		6.613096E-05
Epoch took 9.809s

Epoch 33 of 100
  training loss:		3.303647E-04
  validation loss:		6.816500E-06
Epoch took 9.297s

Epoch 34 of 100
  training loss:		5.276114E-06
  validation loss:		1.244176E-06
Epoch took 9.070s

Epoch 35 of 100
  training loss:		1.077399E-05
  validation loss:		1.650667E-04
Epoch took 9.021s

Epoch 36 of 100
  training loss:		1.093971E-04
  validation loss:		2.991447E-05
Epoch took 9.422s

Epoch 37 of 100
  training loss:		8.362824E-06
  validation loss:		2.073211E-05
Epoch took 9.419s

Epoch 38 of 100
  training loss:		9.741501E-05
  validation loss:		1.084004E-05
Epoch took 9.894s

Epoch 39 of 100
  training loss:		3.810947E-05
  validation loss:		2.392010E-06
Epoch took 10.446s

Epoch 40 of 100
  training loss:		3.476468E-04
  validation loss:		5.053609E-06
Epoch took 8.800s

Epoch 41 of 100
  training loss:		2.562972E-06
  validation loss:		1.771574E-06
Epoch took 7.908s

Epoch 42 of 100
  training loss:		1.491375E-06
  validation loss:		5.625183E-07
Epoch took 9.346s

Epoch 43 of 100
  training loss:		2.113020E-06
  validation loss:		1.080246E-06
Epoch took 8.945s

Epoch 44 of 100
  training loss:		8.947316E-05
  validation loss:		1.198574E-05
Epoch took 9.026s

Epoch 45 of 100
  training loss:		6.733765E-05
  validation loss:		4.450395E-04
Epoch took 9.807s

Epoch 46 of 100
  training loss:		8.099412E-05
  validation loss:		8.792078E-06
Epoch took 8.906s

Epoch 47 of 100
  training loss:		6.256899E-06
  validation loss:		3.065180E-06
Epoch took 8.331s

Epoch 48 of 100
  training loss:		1.260385E-04
  validation loss:		4.715681E-06
Epoch took 9.516s

Epoch 49 of 100
  training loss:		4.557147E-06
  validation loss:		3.996129E-07
Epoch took 8.586s

Epoch 50 of 100
  training loss:		3.768318E-04
  validation loss:		2.691442E-04
Epoch took 10.467s

Epoch 51 of 100
  training loss:		3.444843E-05
  validation loss:		1.207942E-06
Epoch took 8.307s

Epoch 52 of 100
  training loss:		9.687765E-07
  validation loss:		4.185238E-07
Epoch took 8.350s

Epoch 53 of 100
  training loss:		2.830265E-07
  validation loss:		1.468853E-07
Epoch took 8.653s

Epoch 54 of 100
  training loss:		1.821474E-07
  validation loss:		3.985540E-07
Epoch took 9.363s

Epoch 55 of 100
  training loss:		1.338333E-06
  validation loss:		1.896946E-07
Epoch took 9.682s

Epoch 56 of 100
  training loss:		1.380533E-06
  validation loss:		3.661300E-06
Epoch took 9.113s

Epoch 57 of 100
  training loss:		4.061470E-05
  validation loss:		5.618001E-05
Epoch took 9.542s

Epoch 58 of 100
  training loss:		8.395961E-05
  validation loss:		1.903318E-06
Epoch took 8.918s

Epoch 59 of 100
  training loss:		8.463299E-07
  validation loss:		3.445214E-07
Epoch took 9.588s

Epoch 60 of 100
  training loss:		1.840500E-04
  validation loss:		6.197883E-05
Epoch took 9.628s

Epoch 61 of 100
  training loss:		4.722155E-06
  validation loss:		1.729005E-07
Epoch took 9.729s

Epoch 62 of 100
  training loss:		1.214714E-07
  validation loss:		6.440350E-08
Epoch took 10.151s

Epoch 63 of 100
  training loss:		7.817131E-08
  validation loss:		4.479465E-08
Epoch took 9.060s

Epoch 64 of 100
  training loss:		9.814034E-08
  validation loss:		4.439503E-08
Epoch took 9.524s

Epoch 65 of 100
  training loss:		7.537817E-05
  validation loss:		4.610454E-05
Epoch took 9.706s

Epoch 66 of 100
  training loss:		4.412109E-05
  validation loss:		7.496204E-06
Epoch took 9.623s

Epoch 67 of 100
  training loss:		1.045566E-06
  validation loss:		8.045204E-08
Epoch took 9.660s

Epoch 68 of 100
  training loss:		1.380831E-06
  validation loss:		4.353896E-06
Epoch took 10.104s

Epoch 69 of 100
  training loss:		9.735263E-05
  validation loss:		1.518611E-06
Epoch took 10.749s

Epoch 70 of 100
  training loss:		5.837905E-07
  validation loss:		1.415420E-07
Epoch took 9.005s

Epoch 71 of 100
  training loss:		9.080260E-07
  validation loss:		2.435125E-06
Epoch took 10.508s

Epoch 72 of 100
  training loss:		9.684895E-05
  validation loss:		6.194888E-05
Epoch took 11.393s

Epoch 73 of 100
  training loss:		8.345246E-06
  validation loss:		6.021432E-07
Epoch took 9.673s

Epoch 74 of 100
  training loss:		9.340310E-07
  validation loss:		3.124988E-07
Epoch took 10.113s

Epoch 75 of 100
  training loss:		1.775454E-05
  validation loss:		6.779956E-05
Epoch took 10.450s

Epoch 76 of 100
  training loss:		2.842419E-05
  validation loss:		1.556084E-06
Epoch took 10.131s

Epoch 77 of 100
  training loss:		2.593939E-05
  validation loss:		7.835744E-05
Epoch took 9.535s

Epoch 78 of 100
  training loss:		2.107540E-05
  validation loss:		6.857832E-06
Epoch took 9.432s

Epoch 79 of 100
  training loss:		1.264746E-05
  validation loss:		4.547952E-06
Epoch took 8.724s

Epoch 80 of 100
  training loss:		3.614828E-05
  validation loss:		7.573701E-06
Epoch took 8.562s

Epoch 81 of 100
  training loss:		2.612473E-06
  validation loss:		4.185101E-07
Epoch took 10.347s

Epoch 82 of 100
  training loss:		2.716036E-05
  validation loss:		2.559274E-05
Epoch took 9.731s

Epoch 83 of 100
  training loss:		2.946230E-05
  validation loss:		1.156219E-05
Epoch took 9.410s

Epoch 84 of 100
  training loss:		4.890286E-06
  validation loss:		7.587404E-06
Epoch took 9.026s

Epoch 85 of 100
  training loss:		1.652287E-05
  validation loss:		1.159367E-06
Epoch took 8.948s

Epoch 86 of 100
  training loss:		4.190139E-05
  validation loss:		2.692111E-05
Epoch took 9.094s

Epoch 87 of 100
  training loss:		6.126099E-06
  validation loss:		2.482634E-07
Epoch took 8.914s

Epoch 88 of 100
  training loss:		1.203093E-06
  validation loss:		3.542445E-06
Epoch took 9.581s

Epoch 89 of 100
  training loss:		9.162345E-05
  validation loss:		2.836289E-06
Epoch took 9.227s

Epoch 90 of 100
  training loss:		9.530387E-07
  validation loss:		4.575127E-08
Epoch took 10.732s

Epoch 91 of 100
  training loss:		3.305462E-08
  validation loss:		1.808551E-08
Epoch took 10.489s

Epoch 92 of 100
  training loss:		6.970914E-09
  validation loss:		2.390135E-09
Epoch took 10.135s

Epoch 93 of 100
  training loss:		2.125649E-09
  validation loss:		6.881051E-09
Epoch took 10.560s

Epoch 94 of 100
  training loss:		4.554791E-05
  validation loss:		1.395585E-05
Epoch took 9.645s

Epoch 95 of 100
  training loss:		3.228270E-06
  validation loss:		2.464751E-07
Epoch took 10.183s

Epoch 96 of 100
  training loss:		2.799122E-07
  validation loss:		5.487376E-07
Epoch took 9.659s

Epoch 97 of 100
  training loss:		4.373396E-05
  validation loss:		3.934850E-04
Epoch took 10.436s

Epoch 98 of 100
  training loss:		4.023329E-05
  validation loss:		5.518259E-07
Epoch took 8.938s

Epoch 99 of 100
  training loss:		1.416876E-07
  validation loss:		1.185588E-08
Epoch took 8.075s

Epoch 100 of 100
  training loss:		4.652139E-09
  validation loss:		4.934178E-09
Epoch took 9.721s

Training RMSE: 7.03941485069e-05
Validation RMSE: 7.01510483779e-05
