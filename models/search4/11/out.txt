Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.086907E-02
  validation loss:		8.955937E-04
Epoch took 9.581s

Epoch 2 of 100
  training loss:		4.935465E-04
  validation loss:		2.479143E-04
Epoch took 9.234s

Epoch 3 of 100
  training loss:		1.556217E-04
  validation loss:		9.580182E-05
Epoch took 9.378s

Epoch 4 of 100
  training loss:		6.755761E-05
  validation loss:		4.441564E-05
Epoch took 9.537s

Epoch 5 of 100
  training loss:		3.398257E-05
  validation loss:		2.500808E-05
Epoch took 9.439s

Epoch 6 of 100
  training loss:		1.979810E-05
  validation loss:		1.674988E-05
Epoch took 9.078s

Epoch 7 of 100
  training loss:		1.254066E-05
  validation loss:		1.024757E-05
Epoch took 10.001s

Epoch 8 of 100
  training loss:		9.508833E-06
  validation loss:		8.277625E-06
Epoch took 9.442s

Epoch 9 of 100
  training loss:		6.468436E-06
  validation loss:		4.922047E-06
Epoch took 8.707s

Epoch 10 of 100
  training loss:		4.838799E-06
  validation loss:		3.116958E-06
Epoch took 9.126s

Epoch 11 of 100
  training loss:		2.795578E-06
  validation loss:		2.108071E-06
Epoch took 10.023s

Epoch 12 of 100
  training loss:		2.171942E-06
  validation loss:		2.757048E-06
Epoch took 10.041s

Epoch 13 of 100
  training loss:		1.586737E-06
  validation loss:		2.584534E-06
Epoch took 9.730s

Epoch 14 of 100
  training loss:		1.188035E-06
  validation loss:		1.026881E-06
Epoch took 10.129s

Epoch 15 of 100
  training loss:		9.902847E-07
  validation loss:		6.525324E-07
Epoch took 9.543s

Epoch 16 of 100
  training loss:		6.797014E-07
  validation loss:		3.871156E-07
Epoch took 9.191s

Epoch 17 of 100
  training loss:		1.415656E-06
  validation loss:		6.649919E-07
Epoch took 9.069s

Epoch 18 of 100
  training loss:		2.510678E-05
  validation loss:		2.597862E-06
Epoch took 9.613s

Epoch 19 of 100
  training loss:		1.801421E-05
  validation loss:		3.143084E-06
Epoch took 8.920s

Epoch 20 of 100
  training loss:		7.084459E-05
  validation loss:		3.226015E-06
Epoch took 9.700s

Epoch 21 of 100
  training loss:		1.561395E-06
  validation loss:		6.466346E-07
Epoch took 9.197s

Epoch 22 of 100
  training loss:		5.848583E-05
  validation loss:		4.047986E-05
Epoch took 8.637s

Epoch 23 of 100
  training loss:		4.021585E-05
  validation loss:		3.767037E-07
Epoch took 9.317s

Epoch 24 of 100
  training loss:		7.507860E-05
  validation loss:		1.181143E-05
Epoch took 9.918s

Epoch 25 of 100
  training loss:		1.353810E-06
  validation loss:		1.559977E-07
Epoch took 10.468s

Epoch 26 of 100
  training loss:		4.254817E-07
  validation loss:		4.466585E-06
Epoch took 9.553s

Epoch 27 of 100
  training loss:		4.762257E-05
  validation loss:		9.769880E-05
Epoch took 9.513s

Epoch 28 of 100
  training loss:		7.892194E-05
  validation loss:		1.223851E-06
Epoch took 9.154s

Epoch 29 of 100
  training loss:		1.467612E-06
  validation loss:		2.253003E-07
Epoch took 9.788s

Epoch 30 of 100
  training loss:		3.941203E-05
  validation loss:		2.782617E-04
Epoch took 9.121s

Epoch 31 of 100
  training loss:		5.690928E-05
  validation loss:		2.613683E-05
Epoch took 8.689s

Epoch 32 of 100
  training loss:		2.203583E-05
  validation loss:		4.772438E-05
Epoch took 9.573s

Epoch 33 of 100
  training loss:		4.540665E-05
  validation loss:		7.418740E-05
Epoch took 9.970s

Epoch 34 of 100
  training loss:		2.998717E-05
  validation loss:		2.408130E-06
Epoch took 9.492s

Epoch 35 of 100
  training loss:		7.838863E-05
  validation loss:		3.935204E-05
Epoch took 8.783s

Epoch 36 of 100
  training loss:		8.313112E-06
  validation loss:		4.570278E-05
Epoch took 9.873s

Epoch 37 of 100
  training loss:		2.766140E-05
  validation loss:		1.516945E-06
Epoch took 9.285s

Epoch 38 of 100
  training loss:		3.701605E-04
  validation loss:		1.421860E-03
Epoch took 9.028s

Epoch 39 of 100
  training loss:		1.239048E-04
  validation loss:		1.835408E-06
Epoch took 10.184s

Epoch 40 of 100
  training loss:		1.075891E-06
  validation loss:		1.351076E-06
Epoch took 9.865s

Epoch 41 of 100
  training loss:		3.950102E-07
  validation loss:		3.886321E-07
Epoch took 9.858s

Epoch 42 of 100
  training loss:		2.554653E-07
  validation loss:		1.082261E-07
Epoch took 9.472s

Epoch 43 of 100
  training loss:		1.298128E-07
  validation loss:		5.861500E-08
Epoch took 9.561s

Epoch 44 of 100
  training loss:		6.730179E-08
  validation loss:		5.598699E-08
Epoch took 9.787s

Epoch 45 of 100
  training loss:		3.719620E-08
  validation loss:		7.713526E-08
Epoch took 8.967s

Epoch 46 of 100
  training loss:		3.276064E-07
  validation loss:		1.273734E-05
Epoch took 9.160s

Epoch 47 of 100
  training loss:		1.462950E-04
  validation loss:		3.823786E-06
Epoch took 10.077s

Epoch 48 of 100
  training loss:		1.010283E-06
  validation loss:		7.102980E-07
Epoch took 10.064s

Epoch 49 of 100
  training loss:		3.369876E-07
  validation loss:		1.344824E-07
Epoch took 9.474s

Epoch 50 of 100
  training loss:		2.276123E-07
  validation loss:		2.684048E-07
Epoch took 9.448s

Epoch 51 of 100
  training loss:		3.287446E-05
  validation loss:		4.785255E-05
Epoch took 9.323s

Epoch 52 of 100
  training loss:		1.114025E-04
  validation loss:		2.384520E-06
Epoch took 9.009s

Epoch 53 of 100
  training loss:		4.332962E-07
  validation loss:		6.510765E-08
Epoch took 10.170s

Epoch 54 of 100
  training loss:		1.080583E-07
  validation loss:		6.183496E-08
Epoch took 9.402s

Epoch 55 of 100
  training loss:		1.409461E-07
  validation loss:		3.623220E-08
Epoch took 9.750s

Epoch 56 of 100
  training loss:		3.597400E-05
  validation loss:		1.280112E-04
Epoch took 9.046s

Epoch 57 of 100
  training loss:		2.002187E-05
  validation loss:		2.578039E-06
Epoch took 9.122s

Epoch 58 of 100
  training loss:		8.038261E-05
  validation loss:		2.023305E-04
Epoch took 9.032s

Epoch 59 of 100
  training loss:		4.074863E-05
  validation loss:		2.888645E-07
Epoch took 9.604s

Epoch 60 of 100
  training loss:		2.007542E-07
  validation loss:		1.120622E-07
Epoch took 9.244s

Epoch 61 of 100
  training loss:		1.759796E-07
  validation loss:		9.153100E-08
Epoch took 8.861s

Epoch 62 of 100
  training loss:		8.319478E-06
  validation loss:		9.120908E-04
Epoch took 9.398s

Epoch 63 of 100
  training loss:		1.180462E-04
  validation loss:		4.532166E-07
Epoch took 9.730s

Epoch 64 of 100
  training loss:		4.209514E-07
  validation loss:		7.887224E-08
Epoch took 9.462s

Epoch 65 of 100
  training loss:		7.969729E-08
  validation loss:		4.866561E-08
Epoch took 9.992s

Epoch 66 of 100
  training loss:		1.028586E-06
  validation loss:		5.074144E-07
Epoch took 8.668s

Epoch 67 of 100
  training loss:		1.163887E-04
  validation loss:		8.223971E-04
Epoch took 9.055s

Epoch 68 of 100
  training loss:		5.960379E-05
  validation loss:		1.815475E-07
Epoch took 8.954s

Epoch 69 of 100
  training loss:		1.250260E-07
  validation loss:		3.573897E-08
Epoch took 9.450s

Epoch 70 of 100
  training loss:		1.960151E-08
  validation loss:		1.002660E-08
Epoch took 9.567s

Epoch 71 of 100
  training loss:		3.991446E-09
  validation loss:		1.534773E-09
Epoch took 9.278s

Epoch 72 of 100
  training loss:		3.036962E-09
  validation loss:		2.881796E-09
Epoch took 8.804s

Epoch 73 of 100
  training loss:		3.441736E-05
  validation loss:		4.103362E-04
Epoch took 10.269s

Epoch 74 of 100
  training loss:		8.038942E-05
  validation loss:		3.576719E-07
Epoch took 9.617s

Epoch 75 of 100
  training loss:		1.536358E-07
  validation loss:		8.270066E-08
Epoch took 9.780s

Epoch 76 of 100
  training loss:		4.396819E-08
  validation loss:		2.486312E-08
Epoch took 9.725s

Epoch 77 of 100
  training loss:		1.824120E-07
  validation loss:		3.040762E-07
Epoch took 9.930s

Epoch 78 of 100
  training loss:		9.370408E-05
  validation loss:		3.346846E-04
Epoch took 10.605s

Epoch 79 of 100
  training loss:		2.255325E-05
  validation loss:		3.399318E-07
Epoch took 9.334s

Epoch 80 of 100
  training loss:		2.012726E-07
  validation loss:		7.019719E-08
Epoch took 9.172s

Epoch 81 of 100
  training loss:		4.659080E-08
  validation loss:		1.614537E-08
Epoch took 9.947s

Epoch 82 of 100
  training loss:		1.979532E-08
  validation loss:		5.929362E-09
Epoch took 9.217s

Epoch 83 of 100
  training loss:		2.985340E-05
  validation loss:		1.068124E-05
Epoch took 9.134s

Epoch 84 of 100
  training loss:		8.143671E-06
  validation loss:		5.167981E-07
Epoch took 8.968s

Epoch 85 of 100
  training loss:		2.114123E-05
  validation loss:		2.205108E-05
Epoch took 8.827s

Epoch 86 of 100
  training loss:		4.219939E-05
  validation loss:		3.624357E-07
Epoch took 9.008s

Epoch 87 of 100
  training loss:		1.032371E-07
  validation loss:		2.958757E-08
Epoch took 9.720s

Epoch 88 of 100
  training loss:		3.802929E-08
  validation loss:		4.670538E-08
Epoch took 9.001s

Epoch 89 of 100
  training loss:		5.075041E-05
  validation loss:		1.260554E-06
Epoch took 8.925s

Epoch 90 of 100
  training loss:		1.808176E-06
  validation loss:		4.201614E-06
Epoch took 10.235s

Epoch 91 of 100
  training loss:		7.097586E-06
  validation loss:		2.071847E-05
Epoch took 9.316s

Epoch 92 of 100
  training loss:		2.183172E-05
  validation loss:		7.113730E-07
Epoch took 9.466s

Epoch 93 of 100
  training loss:		3.903447E-05
  validation loss:		3.956562E-05
Epoch took 9.691s

Epoch 94 of 100
  training loss:		1.788075E-05
  validation loss:		2.720344E-07
Epoch took 9.149s

Epoch 95 of 100
  training loss:		1.340683E-07
  validation loss:		1.929301E-06
Epoch took 8.742s

Epoch 96 of 100
  training loss:		3.702461E-05
  validation loss:		1.156312E-04
Epoch took 9.732s

Epoch 97 of 100
  training loss:		1.786286E-05
  validation loss:		4.413141E-07
Epoch took 8.761s

Epoch 98 of 100
  training loss:		1.887729E-07
  validation loss:		6.906337E-09
Epoch took 9.868s

Epoch 99 of 100
  training loss:		2.570064E-05
  validation loss:		2.395832E-04
Epoch took 9.444s

Epoch 100 of 100
  training loss:		2.967030E-05
  validation loss:		5.251029E-06
Epoch took 9.067s

Training RMSE: 0.00229551362641
Validation RMSE: 0.00229234921174
