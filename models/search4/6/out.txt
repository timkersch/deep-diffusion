Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		8.658755E-02
  validation loss:		8.734253E-03
Epoch took 10.671s

Epoch 2 of 100
  training loss:		5.426299E-03
  validation loss:		3.458518E-03
Epoch took 9.536s

Epoch 3 of 100
  training loss:		2.591282E-03
  validation loss:		1.962104E-03
Epoch took 10.445s

Epoch 4 of 100
  training loss:		1.547327E-03
  validation loss:		1.217799E-03
Epoch took 10.141s

Epoch 5 of 100
  training loss:		9.774669E-04
  validation loss:		7.901953E-04
Epoch took 9.907s

Epoch 6 of 100
  training loss:		6.428300E-04
  validation loss:		5.365590E-04
Epoch took 10.184s

Epoch 7 of 100
  training loss:		4.391428E-04
  validation loss:		3.739826E-04
Epoch took 10.604s

Epoch 8 of 100
  training loss:		3.079145E-04
  validation loss:		2.656266E-04
Epoch took 10.475s

Epoch 9 of 100
  training loss:		2.168889E-04
  validation loss:		1.961478E-04
Epoch took 10.956s

Epoch 10 of 100
  training loss:		1.549721E-04
  validation loss:		1.429413E-04
Epoch took 9.573s

Epoch 11 of 100
  training loss:		1.122098E-04
  validation loss:		1.000780E-04
Epoch took 9.590s

Epoch 12 of 100
  training loss:		8.150982E-05
  validation loss:		7.385667E-05
Epoch took 10.710s

Epoch 13 of 100
  training loss:		6.030631E-05
  validation loss:		5.689555E-05
Epoch took 10.202s

Epoch 14 of 100
  training loss:		4.487429E-05
  validation loss:		4.129764E-05
Epoch took 9.683s

Epoch 15 of 100
  training loss:		3.336701E-05
  validation loss:		3.096310E-05
Epoch took 10.344s

Epoch 16 of 100
  training loss:		2.573350E-05
  validation loss:		2.382126E-05
Epoch took 10.794s

Epoch 17 of 100
  training loss:		1.857737E-05
  validation loss:		1.909047E-05
Epoch took 10.410s

Epoch 18 of 100
  training loss:		1.421906E-05
  validation loss:		1.285886E-05
Epoch took 10.759s

Epoch 19 of 100
  training loss:		1.047242E-05
  validation loss:		1.012209E-05
Epoch took 10.096s

Epoch 20 of 100
  training loss:		8.316541E-06
  validation loss:		7.076208E-06
Epoch took 10.970s

Epoch 21 of 100
  training loss:		6.662996E-06
  validation loss:		5.457458E-06
Epoch took 11.066s

Epoch 22 of 100
  training loss:		5.317203E-06
  validation loss:		4.282121E-06
Epoch took 10.158s

Epoch 23 of 100
  training loss:		5.017774E-06
  validation loss:		3.199444E-06
Epoch took 10.544s

Epoch 24 of 100
  training loss:		3.122584E-06
  validation loss:		2.370494E-06
Epoch took 9.584s

Epoch 25 of 100
  training loss:		2.733436E-06
  validation loss:		2.615369E-06
Epoch took 9.508s

Epoch 26 of 100
  training loss:		1.698115E-06
  validation loss:		1.478202E-06
Epoch took 10.077s

Epoch 27 of 100
  training loss:		1.433689E-06
  validation loss:		9.944533E-07
Epoch took 9.088s

Epoch 28 of 100
  training loss:		1.616278E-06
  validation loss:		3.038941E-06
Epoch took 9.004s

Epoch 29 of 100
  training loss:		2.666984E-06
  validation loss:		4.342553E-07
Epoch took 10.355s

Epoch 30 of 100
  training loss:		1.098743E-05
  validation loss:		3.095921E-07
Epoch took 10.168s

Epoch 31 of 100
  training loss:		5.454026E-07
  validation loss:		2.699390E-07
Epoch took 9.399s

Epoch 32 of 100
  training loss:		1.115789E-06
  validation loss:		1.053884E-05
Epoch took 10.526s

Epoch 33 of 100
  training loss:		8.410184E-06
  validation loss:		1.332804E-06
Epoch took 9.183s

Epoch 34 of 100
  training loss:		6.896707E-07
  validation loss:		6.963369E-07
Epoch took 9.456s

Epoch 35 of 100
  training loss:		5.192679E-06
  validation loss:		6.004041E-07
Epoch took 11.516s

Epoch 36 of 100
  training loss:		1.644518E-06
  validation loss:		1.180131E-05
Epoch took 10.634s

Epoch 37 of 100
  training loss:		8.103055E-06
  validation loss:		6.658625E-05
Epoch took 9.033s

Epoch 38 of 100
  training loss:		9.848830E-06
  validation loss:		1.645728E-08
Epoch took 9.526s

Epoch 39 of 100
  training loss:		2.641431E-08
  validation loss:		1.600855E-08
Epoch took 10.324s

Epoch 40 of 100
  training loss:		1.098869E-05
  validation loss:		3.431628E-06
Epoch took 10.240s

Epoch 41 of 100
  training loss:		4.884517E-07
  validation loss:		6.435239E-09
Epoch took 9.500s

Epoch 42 of 100
  training loss:		1.799234E-08
  validation loss:		5.568219E-08
Epoch took 9.817s

Epoch 43 of 100
  training loss:		6.496971E-06
  validation loss:		9.715865E-08
Epoch took 9.305s

Epoch 44 of 100
  training loss:		1.853199E-05
  validation loss:		2.054607E-07
Epoch took 10.109s

Epoch 45 of 100
  training loss:		4.273553E-08
  validation loss:		1.233252E-08
Epoch took 10.385s

Epoch 46 of 100
  training loss:		7.787464E-09
  validation loss:		8.116162E-09
Epoch took 10.477s

Epoch 47 of 100
  training loss:		1.534156E-06
  validation loss:		7.974586E-07
Epoch took 9.601s

Epoch 48 of 100
  training loss:		1.405973E-05
  validation loss:		1.564812E-08
Epoch took 10.069s

Epoch 49 of 100
  training loss:		1.430874E-08
  validation loss:		3.621910E-09
Epoch took 9.954s

Epoch 50 of 100
  training loss:		1.045091E-05
  validation loss:		1.121680E-06
Epoch took 10.684s

Epoch 51 of 100
  training loss:		1.867437E-07
  validation loss:		1.508335E-08
Epoch took 10.120s

Epoch 52 of 100
  training loss:		1.384981E-06
  validation loss:		6.607740E-07
Epoch took 10.156s

Epoch 53 of 100
  training loss:		1.149968E-05
  validation loss:		1.726114E-07
Epoch took 10.248s

Epoch 54 of 100
  training loss:		3.736804E-08
  validation loss:		1.096100E-08
Epoch took 10.414s

Epoch 55 of 100
  training loss:		6.546285E-06
  validation loss:		1.454841E-05
Epoch took 11.151s

Epoch 56 of 100
  training loss:		3.517470E-06
  validation loss:		1.026274E-08
Epoch took 10.718s

Epoch 57 of 100
  training loss:		8.736796E-06
  validation loss:		2.585523E-04
Epoch took 11.192s

Epoch 58 of 100
  training loss:		9.014421E-06
  validation loss:		1.291364E-08
Epoch took 10.201s

Epoch 59 of 100
  training loss:		1.668903E-08
  validation loss:		4.684482E-09
Epoch took 10.722s

Epoch 60 of 100
  training loss:		2.535077E-08
  validation loss:		4.320110E-06
Epoch took 11.064s

Epoch 61 of 100
  training loss:		1.447085E-05
  validation loss:		6.910097E-08
Epoch took 10.082s

Epoch 62 of 100
  training loss:		2.985391E-08
  validation loss:		1.459636E-07
Epoch took 10.007s

Epoch 63 of 100
  training loss:		8.990183E-06
  validation loss:		1.731107E-05
Epoch took 9.112s

Epoch 64 of 100
  training loss:		1.150104E-06
  validation loss:		3.687049E-08
Epoch took 9.302s

Epoch 65 of 100
  training loss:		5.688932E-06
  validation loss:		1.401009E-05
Epoch took 10.996s

Epoch 66 of 100
  training loss:		1.138856E-06
  validation loss:		1.672853E-08
Epoch took 10.481s

Epoch 67 of 100
  training loss:		1.693817E-05
  validation loss:		7.443265E-07
Epoch took 10.836s

Epoch 68 of 100
  training loss:		1.215516E-07
  validation loss:		2.386014E-08
Epoch took 10.690s

Epoch 69 of 100
  training loss:		9.778493E-09
  validation loss:		2.463390E-08
Epoch took 11.361s

Epoch 70 of 100
  training loss:		9.361697E-06
  validation loss:		2.980432E-06
Epoch took 10.152s

Epoch 71 of 100
  training loss:		3.944746E-06
  validation loss:		7.360440E-08
Epoch took 9.423s

Epoch 72 of 100
  training loss:		1.867441E-08
  validation loss:		5.623316E-09
Epoch took 10.112s

Epoch 73 of 100
  training loss:		6.025028E-06
  validation loss:		1.057101E-06
Epoch took 10.208s

Epoch 74 of 100
  training loss:		5.623562E-07
  validation loss:		2.683475E-07
Epoch took 9.821s

Epoch 75 of 100
  training loss:		6.183092E-06
  validation loss:		8.606032E-08
Epoch took 10.285s

Epoch 76 of 100
  training loss:		3.020686E-06
  validation loss:		3.015837E-07
Epoch took 10.479s

Epoch 77 of 100
  training loss:		6.533328E-06
  validation loss:		9.223445E-07
Epoch took 10.476s

Epoch 78 of 100
  training loss:		1.107131E-05
  validation loss:		7.441109E-07
Epoch took 9.959s

Epoch 79 of 100
  training loss:		7.279065E-08
  validation loss:		1.860114E-08
Epoch took 9.269s

Epoch 80 of 100
  training loss:		9.963685E-08
  validation loss:		7.058112E-08
Epoch took 9.142s

Epoch 81 of 100
  training loss:		7.807595E-06
  validation loss:		8.858502E-08
Epoch took 10.447s

Epoch 82 of 100
  training loss:		6.513062E-07
  validation loss:		5.936984E-07
Epoch took 10.715s

Epoch 83 of 100
  training loss:		1.346270E-05
  validation loss:		2.097075E-08
Epoch took 10.102s

Epoch 84 of 100
  training loss:		6.636754E-08
  validation loss:		1.822901E-08
Epoch took 10.359s

Epoch 85 of 100
  training loss:		4.597190E-06
  validation loss:		2.400395E-05
Epoch took 9.593s

Epoch 86 of 100
  training loss:		1.793368E-06
  validation loss:		7.085532E-09
Epoch took 10.631s

Epoch 87 of 100
  training loss:		4.760248E-06
  validation loss:		3.006814E-07
Epoch took 10.123s

Epoch 88 of 100
  training loss:		1.273269E-05
  validation loss:		2.159564E-06
Epoch took 10.383s

Epoch 89 of 100
  training loss:		1.085057E-07
  validation loss:		5.415935E-08
Epoch took 9.793s

Epoch 90 of 100
  training loss:		1.618191E-08
  validation loss:		5.136879E-07
Epoch took 11.483s

Epoch 91 of 100
  training loss:		6.427717E-06
  validation loss:		1.152572E-07
Epoch took 10.658s

Epoch 92 of 100
  training loss:		9.725117E-06
  validation loss:		2.005467E-06
Epoch took 9.662s

Epoch 93 of 100
  training loss:		3.746255E-07
  validation loss:		2.186562E-08
Epoch took 10.066s

Epoch 94 of 100
  training loss:		2.099384E-06
  validation loss:		2.372659E-05
Epoch took 10.186s

Epoch 95 of 100
  training loss:		9.524906E-06
  validation loss:		1.750749E-08
Epoch took 10.410s

Epoch 96 of 100
  training loss:		3.541727E-08
  validation loss:		1.122806E-07
Epoch took 8.954s

Epoch 97 of 100
  training loss:		6.012983E-06
  validation loss:		2.650142E-06
Epoch took 10.768s

Epoch 98 of 100
  training loss:		7.155509E-06
  validation loss:		1.993838E-07
Epoch took 11.237s

Epoch 99 of 100
  training loss:		1.020926E-07
  validation loss:		1.426858E-07
Epoch took 10.136s

Epoch 100 of 100
  training loss:		4.549958E-06
  validation loss:		7.843421E-08
Epoch took 10.228s

Training RMSE: 0.000280466148196
Validation RMSE: 0.000280030904059
