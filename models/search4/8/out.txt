Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.207905E-02
  validation loss:		1.625865E-04
Epoch took 10.782s

Epoch 2 of 100
  training loss:		7.143895E-05
  validation loss:		3.177592E-05
Epoch took 9.850s

Epoch 3 of 100
  training loss:		2.073953E-05
  validation loss:		1.526081E-05
Epoch took 10.255s

Epoch 4 of 100
  training loss:		1.126259E-05
  validation loss:		9.602636E-06
Epoch took 8.683s

Epoch 5 of 100
  training loss:		6.851163E-06
  validation loss:		4.337642E-06
Epoch took 10.219s

Epoch 6 of 100
  training loss:		4.321519E-06
  validation loss:		7.468244E-06
Epoch took 10.247s

Epoch 7 of 100
  training loss:		4.820090E-06
  validation loss:		4.181906E-06
Epoch took 10.929s

Epoch 8 of 100
  training loss:		4.774682E-06
  validation loss:		5.009220E-06
Epoch took 11.256s

Epoch 9 of 100
  training loss:		1.877116E-05
  validation loss:		3.979424E-05
Epoch took 10.190s

Epoch 10 of 100
  training loss:		2.043167E-04
  validation loss:		7.471987E-06
Epoch took 9.884s

Epoch 11 of 100
  training loss:		1.284917E-05
  validation loss:		6.241214E-05
Epoch took 10.680s

Epoch 12 of 100
  training loss:		1.104593E-04
  validation loss:		9.288682E-06
Epoch took 9.792s

Epoch 13 of 100
  training loss:		2.098891E-04
  validation loss:		6.646739E-04
Epoch took 10.436s

Epoch 14 of 100
  training loss:		9.360104E-05
  validation loss:		1.409990E-06
Epoch took 9.785s

Epoch 15 of 100
  training loss:		7.853785E-05
  validation loss:		5.265881E-04
Epoch took 9.245s

Epoch 16 of 100
  training loss:		7.848510E-05
  validation loss:		5.337081E-06
Epoch took 9.956s

Epoch 17 of 100
  training loss:		1.003614E-04
  validation loss:		5.186997E-06
Epoch took 9.549s

Epoch 18 of 100
  training loss:		1.149686E-04
  validation loss:		8.143374E-05
Epoch took 12.062s

Epoch 19 of 100
  training loss:		3.714021E-05
  validation loss:		2.769890E-06
Epoch took 10.575s

Epoch 20 of 100
  training loss:		8.881732E-05
  validation loss:		5.483948E-06
Epoch took 10.330s

Epoch 21 of 100
  training loss:		3.093561E-05
  validation loss:		1.994550E-04
Epoch took 10.641s

Epoch 22 of 100
  training loss:		2.235881E-04
  validation loss:		1.384847E-05
Epoch took 12.069s

Epoch 23 of 100
  training loss:		4.361358E-06
  validation loss:		4.907951E-06
Epoch took 11.304s

Epoch 24 of 100
  training loss:		4.134560E-05
  validation loss:		1.453802E-03
Epoch took 11.165s

Epoch 25 of 100
  training loss:		8.802075E-05
  validation loss:		6.059753E-06
Epoch took 9.861s

Epoch 26 of 100
  training loss:		5.181482E-06
  validation loss:		8.682510E-06
Epoch took 9.448s

Epoch 27 of 100
  training loss:		1.353418E-04
  validation loss:		6.553236E-05
Epoch took 10.973s

Epoch 28 of 100
  training loss:		5.884254E-06
  validation loss:		9.727203E-07
Epoch took 10.498s

Epoch 29 of 100
  training loss:		4.849077E-07
  validation loss:		4.284037E-07
Epoch took 10.642s

Epoch 30 of 100
  training loss:		3.778453E-05
  validation loss:		2.584250E-04
Epoch took 9.947s

Epoch 31 of 100
  training loss:		6.360634E-05
  validation loss:		6.950674E-07
Epoch took 10.393s

Epoch 32 of 100
  training loss:		1.435654E-06
  validation loss:		6.021813E-07
Epoch took 9.444s

Epoch 33 of 100
  training loss:		5.283052E-05
  validation loss:		2.453810E-04
Epoch took 10.663s

Epoch 34 of 100
  training loss:		3.288260E-05
  validation loss:		2.195961E-06
Epoch took 9.650s

Epoch 35 of 100
  training loss:		1.799162E-05
  validation loss:		1.336605E-06
Epoch took 10.454s

Epoch 36 of 100
  training loss:		2.676014E-05
  validation loss:		4.569703E-06
Epoch took 9.643s

Epoch 37 of 100
  training loss:		5.078763E-05
  validation loss:		1.042778E-05
Epoch took 10.005s

Epoch 38 of 100
  training loss:		9.826829E-06
  validation loss:		7.388864E-07
Epoch took 9.943s

Epoch 39 of 100
  training loss:		3.086837E-07
  validation loss:		2.650463E-07
Epoch took 10.200s

Epoch 40 of 100
  training loss:		5.638641E-05
  validation loss:		2.423249E-05
Epoch took 10.101s

Epoch 41 of 100
  training loss:		2.747357E-06
  validation loss:		1.770553E-07
Epoch took 9.519s

Epoch 42 of 100
  training loss:		2.426303E-06
  validation loss:		2.279125E-05
Epoch took 9.874s

Epoch 43 of 100
  training loss:		4.308576E-05
  validation loss:		6.823257E-07
Epoch took 10.267s

Epoch 44 of 100
  training loss:		5.135995E-07
  validation loss:		5.787550E-07
Epoch took 10.285s

Epoch 45 of 100
  training loss:		4.092680E-05
  validation loss:		2.311996E-05
Epoch took 10.767s

Epoch 46 of 100
  training loss:		2.859402E-06
  validation loss:		6.199220E-08
Epoch took 9.887s

Epoch 47 of 100
  training loss:		3.450119E-08
  validation loss:		3.231318E-08
Epoch took 10.207s

Epoch 48 of 100
  training loss:		8.509766E-08
  validation loss:		7.927191E-07
Epoch took 10.030s

Epoch 49 of 100
  training loss:		1.313635E-05
  validation loss:		1.828195E-05
Epoch took 10.170s

Epoch 50 of 100
  training loss:		2.691182E-05
  validation loss:		2.905720E-06
Epoch took 10.415s

Epoch 51 of 100
  training loss:		1.048885E-05
  validation loss:		9.129374E-06
Epoch took 10.213s

Epoch 52 of 100
  training loss:		1.773003E-06
  validation loss:		3.129924E-06
Epoch took 10.039s

Epoch 53 of 100
  training loss:		8.741157E-06
  validation loss:		1.322352E-05
Epoch took 10.587s

Epoch 54 of 100
  training loss:		9.096139E-06
  validation loss:		1.027557E-05
Epoch took 10.491s

Epoch 55 of 100
  training loss:		2.462600E-05
  validation loss:		4.044444E-06
Epoch took 10.227s

Epoch 56 of 100
  training loss:		7.766572E-07
  validation loss:		1.767572E-08
Epoch took 10.535s

Epoch 57 of 100
  training loss:		2.004574E-08
  validation loss:		1.167413E-07
Epoch took 9.884s

Epoch 58 of 100
  training loss:		1.914935E-05
  validation loss:		2.744304E-05
Epoch took 10.775s

Epoch 59 of 100
  training loss:		6.736405E-06
  validation loss:		1.453531E-06
Epoch took 10.387s

Epoch 60 of 100
  training loss:		2.101768E-07
  validation loss:		3.754192E-08
Epoch took 10.184s

Epoch 61 of 100
  training loss:		6.255138E-05
  validation loss:		1.230989E-04
Epoch took 11.237s

Epoch 62 of 100
  training loss:		8.996355E-06
  validation loss:		3.648790E-08
Epoch took 11.537s

Epoch 63 of 100
  training loss:		7.407177E-09
  validation loss:		3.305892E-10
Epoch took 10.609s

Epoch 64 of 100
  training loss:		1.274071E-10
  validation loss:		2.912734E-11
Epoch took 10.506s

Epoch 65 of 100
  training loss:		1.398657E-11
  validation loss:		9.069189E-13
Epoch took 10.194s

Epoch 66 of 100
  training loss:		1.183492E-13
  validation loss:		3.802692E-14
Epoch took 11.239s

Epoch 67 of 100
  training loss:		4.550331E-14
  validation loss:		4.570861E-14
Epoch took 9.871s

Epoch 68 of 100
  training loss:		5.291337E-14
  validation loss:		1.033870E-13
Epoch took 10.192s

Epoch 69 of 100
  training loss:		2.152084E-05
  validation loss:		1.541008E-06
Epoch took 10.102s

Epoch 70 of 100
  training loss:		2.363320E-07
  validation loss:		5.899712E-09
Epoch took 9.532s

Epoch 71 of 100
  training loss:		2.842010E-09
  validation loss:		3.729157E-10
Epoch took 10.647s

Epoch 72 of 100
  training loss:		1.867936E-10
  validation loss:		1.625129E-10
Epoch took 10.184s

Epoch 73 of 100
  training loss:		2.099223E-07
  validation loss:		2.199761E-06
Epoch took 9.919s

Epoch 74 of 100
  training loss:		9.365401E-06
  validation loss:		3.273969E-06
Epoch took 10.580s

Epoch 75 of 100
  training loss:		4.542954E-07
  validation loss:		1.339144E-08
Epoch took 9.860s

Epoch 76 of 100
  training loss:		5.315019E-09
  validation loss:		7.587432E-09
Epoch took 9.372s

Epoch 77 of 100
  training loss:		3.733752E-07
  validation loss:		1.166275E-06
Epoch took 9.834s

Epoch 78 of 100
  training loss:		7.408206E-06
  validation loss:		2.865795E-06
Epoch took 10.652s

Epoch 79 of 100
  training loss:		4.987713E-07
  validation loss:		1.049922E-07
Epoch took 10.561s

Epoch 80 of 100
  training loss:		7.474508E-08
  validation loss:		1.680207E-07
Epoch took 10.424s

Epoch 81 of 100
  training loss:		7.781579E-06
  validation loss:		1.687637E-06
Epoch took 11.298s

Epoch 82 of 100
  training loss:		2.637553E-07
  validation loss:		6.309623E-08
Epoch took 10.958s

Epoch 83 of 100
  training loss:		3.746087E-08
  validation loss:		2.640657E-08
Epoch took 10.256s

Epoch 84 of 100
  training loss:		1.229359E-06
  validation loss:		7.326791E-06
Epoch took 10.083s

Epoch 85 of 100
  training loss:		2.988773E-06
  validation loss:		1.191457E-06
Epoch took 9.729s

Epoch 86 of 100
  training loss:		2.920589E-07
  validation loss:		1.102486E-07
Epoch took 9.974s

Epoch 87 of 100
  training loss:		4.847880E-07
  validation loss:		2.910536E-06
Epoch took 9.862s

Epoch 88 of 100
  training loss:		4.308452E-06
  validation loss:		2.512483E-06
Epoch took 10.793s

Epoch 89 of 100
  training loss:		6.231955E-07
  validation loss:		1.104478E-07
Epoch took 10.057s

Epoch 90 of 100
  training loss:		8.422924E-07
  validation loss:		1.386251E-06
Epoch took 9.113s

Epoch 91 of 100
  training loss:		1.510236E-06
  validation loss:		7.135320E-07
Epoch took 10.233s

Epoch 92 of 100
  training loss:		5.990582E-07
  validation loss:		2.131036E-07
Epoch took 11.067s

Epoch 93 of 100
  training loss:		1.944769E-07
  validation loss:		2.743176E-07
Epoch took 9.749s

Epoch 94 of 100
  training loss:		1.905021E-06
  validation loss:		7.447398E-06
Epoch took 9.972s

Epoch 95 of 100
  training loss:		4.037461E-06
  validation loss:		5.316077E-08
Epoch took 10.403s

Epoch 96 of 100
  training loss:		1.068884E-08
  validation loss:		2.681077E-10
Epoch took 10.757s

Epoch 97 of 100
  training loss:		1.158491E-10
  validation loss:		4.346252E-11
Epoch took 10.435s

Epoch 98 of 100
  training loss:		2.166951E-08
  validation loss:		3.431779E-07
Epoch took 9.706s

Epoch 99 of 100
  training loss:		2.002925E-06
  validation loss:		2.870925E-07
Epoch took 11.354s

Epoch 100 of 100
  training loss:		7.794168E-08
  validation loss:		7.671055E-08
Epoch took 9.641s

Training RMSE: 0.000269777459562
Validation RMSE: 0.000276945938721
