Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		7.472556E-02
  validation loss:		5.030891E-02
Epoch took 13.276s

Epoch 2 of 100
  training loss:		4.423871E-02
  validation loss:		4.221975E-02
Epoch took 13.049s

Epoch 3 of 100
  training loss:		3.820520E-02
  validation loss:		3.666119E-02
Epoch took 13.638s

Epoch 4 of 100
  training loss:		3.522825E-02
  validation loss:		3.320130E-02
Epoch took 12.876s

Epoch 5 of 100
  training loss:		3.306424E-02
  validation loss:		3.285310E-02
Epoch took 11.970s

Epoch 6 of 100
  training loss:		3.178893E-02
  validation loss:		3.073281E-02
Epoch took 12.883s

Epoch 7 of 100
  training loss:		3.136660E-02
  validation loss:		3.452974E-02
Epoch took 13.549s

Epoch 8 of 100
  training loss:		3.062953E-02
  validation loss:		3.008588E-02
Epoch took 13.526s

Epoch 9 of 100
  training loss:		3.040358E-02
  validation loss:		3.089866E-02
Epoch took 12.473s

Epoch 10 of 100
  training loss:		2.956976E-02
  validation loss:		2.924791E-02
Epoch took 12.930s

Epoch 11 of 100
  training loss:		2.884521E-02
  validation loss:		2.865168E-02
Epoch took 11.802s

Epoch 12 of 100
  training loss:		2.935878E-02
  validation loss:		2.808229E-02
Epoch took 13.594s

Epoch 13 of 100
  training loss:		2.831526E-02
  validation loss:		2.897667E-02
Epoch took 13.164s

Epoch 14 of 100
  training loss:		2.849871E-02
  validation loss:		2.829485E-02
Epoch took 13.404s

Epoch 15 of 100
  training loss:		2.849350E-02
  validation loss:		2.790609E-02
Epoch took 12.652s

Epoch 16 of 100
  training loss:		2.840007E-02
  validation loss:		2.757671E-02
Epoch took 11.830s

Epoch 17 of 100
  training loss:		2.794718E-02
  validation loss:		2.764102E-02
Epoch took 13.103s

Epoch 18 of 100
  training loss:		2.807820E-02
  validation loss:		2.777345E-02
Epoch took 12.772s

Epoch 19 of 100
  training loss:		2.788621E-02
  validation loss:		2.857463E-02
Epoch took 13.084s

Epoch 20 of 100
  training loss:		2.747971E-02
  validation loss:		2.752194E-02
Epoch took 12.254s

Epoch 21 of 100
  training loss:		2.787964E-02
  validation loss:		2.774313E-02
Epoch took 10.975s

Epoch 22 of 100
  training loss:		2.785242E-02
  validation loss:		2.739642E-02
Epoch took 11.780s

Epoch 23 of 100
  training loss:		2.765653E-02
  validation loss:		2.830997E-02
Epoch took 13.762s

Epoch 24 of 100
  training loss:		2.735281E-02
  validation loss:		2.773943E-02
Epoch took 12.559s

Epoch 25 of 100
  training loss:		2.746679E-02
  validation loss:		2.826550E-02
Epoch took 12.631s

Epoch 26 of 100
  training loss:		2.740011E-02
  validation loss:		2.757424E-02
Epoch took 13.174s

Epoch 27 of 100
  training loss:		2.749186E-02
  validation loss:		2.843214E-02
Epoch took 12.852s

Epoch 28 of 100
  training loss:		2.701417E-02
  validation loss:		2.708959E-02
Epoch took 12.530s

Epoch 29 of 100
  training loss:		2.727419E-02
  validation loss:		2.823124E-02
Epoch took 11.638s

Epoch 30 of 100
  training loss:		2.728604E-02
  validation loss:		2.779465E-02
Epoch took 11.741s

Epoch 31 of 100
  training loss:		2.718707E-02
  validation loss:		2.749423E-02
Epoch took 13.297s

Epoch 32 of 100
  training loss:		2.709328E-02
  validation loss:		2.802117E-02
Epoch took 12.412s

Epoch 33 of 100
  training loss:		2.713772E-02
  validation loss:		2.819946E-02
Epoch took 12.368s

Epoch 34 of 100
  training loss:		2.731268E-02
  validation loss:		2.712690E-02
Epoch took 12.608s

Epoch 35 of 100
  training loss:		2.710975E-02
  validation loss:		2.791043E-02
Epoch took 12.504s

Epoch 36 of 100
  training loss:		2.686263E-02
  validation loss:		2.785472E-02
Epoch took 12.041s

Epoch 37 of 100
  training loss:		2.711283E-02
  validation loss:		2.940753E-02
Epoch took 12.203s

Epoch 38 of 100
  training loss:		2.697961E-02
  validation loss:		2.698006E-02
Epoch took 11.807s

Epoch 39 of 100
  training loss:		2.691714E-02
  validation loss:		2.745790E-02
Epoch took 13.654s

Epoch 40 of 100
  training loss:		2.696600E-02
  validation loss:		2.711517E-02
Epoch took 13.450s

Epoch 41 of 100
  training loss:		2.713382E-02
  validation loss:		2.669392E-02
Epoch took 13.704s

Epoch 42 of 100
  training loss:		2.717667E-02
  validation loss:		2.697322E-02
Epoch took 12.805s

Epoch 43 of 100
  training loss:		2.682660E-02
  validation loss:		2.694444E-02
Epoch took 12.536s

Epoch 44 of 100
  training loss:		2.672154E-02
  validation loss:		2.709182E-02
Epoch took 12.703s

Epoch 45 of 100
  training loss:		2.692250E-02
  validation loss:		2.730214E-02
Epoch took 13.244s

Epoch 46 of 100
  training loss:		2.703455E-02
  validation loss:		2.691542E-02
Epoch took 12.618s

Epoch 47 of 100
  training loss:		2.685652E-02
  validation loss:		2.690055E-02
Epoch took 13.575s

Epoch 48 of 100
  training loss:		2.688266E-02
  validation loss:		2.654412E-02
Epoch took 13.016s

Epoch 49 of 100
  training loss:		2.692150E-02
  validation loss:		2.695311E-02
Epoch took 13.477s

Epoch 50 of 100
  training loss:		2.662737E-02
  validation loss:		2.740065E-02
Epoch took 12.510s

Epoch 51 of 100
  training loss:		2.679751E-02
  validation loss:		2.729441E-02
Epoch took 11.348s

Epoch 52 of 100
  training loss:		2.682487E-02
  validation loss:		2.692735E-02
Epoch took 13.955s

Epoch 53 of 100
  training loss:		2.697952E-02
  validation loss:		2.739663E-02
Epoch took 13.020s

Epoch 54 of 100
  training loss:		2.669245E-02
  validation loss:		2.694969E-02
Epoch took 12.366s

Epoch 55 of 100
  training loss:		2.670799E-02
  validation loss:		2.727680E-02
Epoch took 12.063s

Epoch 56 of 100
  training loss:		2.695995E-02
  validation loss:		2.690544E-02
Epoch took 12.556s

Epoch 57 of 100
  training loss:		2.689610E-02
  validation loss:		2.642393E-02
Epoch took 13.090s

Epoch 58 of 100
  training loss:		2.663421E-02
  validation loss:		2.728443E-02
Epoch took 12.521s

Epoch 59 of 100
  training loss:		2.652935E-02
  validation loss:		2.701053E-02
Epoch took 12.339s

Epoch 60 of 100
  training loss:		2.671260E-02
  validation loss:		2.649516E-02
Epoch took 12.624s

Early stopping, val-loss increased over the last 10 epochs from 0.0269719393758 to 0.0269964372095
Training RMSE: 1.61170186161e-07
Validation RMSE: 1.61970457417e-07
