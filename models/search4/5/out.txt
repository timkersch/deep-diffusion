Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		6.253586E-02
  validation loss:		1.078982E-02
Epoch took 10.114s

Epoch 2 of 100
  training loss:		7.223567E-03
  validation loss:		4.995858E-03
Epoch took 9.091s

Epoch 3 of 100
  training loss:		3.732538E-03
  validation loss:		2.891988E-03
Epoch took 10.720s

Epoch 4 of 100
  training loss:		2.212917E-03
  validation loss:		1.707798E-03
Epoch took 9.988s

Epoch 5 of 100
  training loss:		1.323818E-03
  validation loss:		1.056403E-03
Epoch took 10.192s

Epoch 6 of 100
  training loss:		8.612862E-04
  validation loss:		7.029380E-04
Epoch took 10.947s

Epoch 7 of 100
  training loss:		5.783724E-04
  validation loss:		4.724713E-04
Epoch took 10.000s

Epoch 8 of 100
  training loss:		3.907944E-04
  validation loss:		3.232354E-04
Epoch took 9.621s

Epoch 9 of 100
  training loss:		2.666551E-04
  validation loss:		2.204553E-04
Epoch took 11.641s

Epoch 10 of 100
  training loss:		1.813829E-04
  validation loss:		1.483049E-04
Epoch took 10.625s

Epoch 11 of 100
  training loss:		1.239558E-04
  validation loss:		1.024060E-04
Epoch took 10.527s

Epoch 12 of 100
  training loss:		8.355113E-05
  validation loss:		6.821156E-05
Epoch took 10.894s

Epoch 13 of 100
  training loss:		5.583961E-05
  validation loss:		5.147665E-05
Epoch took 10.593s

Epoch 14 of 100
  training loss:		3.699233E-05
  validation loss:		3.058942E-05
Epoch took 10.058s

Epoch 15 of 100
  training loss:		2.353451E-05
  validation loss:		1.859876E-05
Epoch took 9.988s

Epoch 16 of 100
  training loss:		1.533053E-05
  validation loss:		1.235564E-05
Epoch took 10.076s

Epoch 17 of 100
  training loss:		1.011417E-05
  validation loss:		7.335852E-06
Epoch took 10.807s

Epoch 18 of 100
  training loss:		6.790125E-06
  validation loss:		4.497038E-06
Epoch took 11.696s

Epoch 19 of 100
  training loss:		3.859646E-06
  validation loss:		2.657464E-06
Epoch took 9.816s

Epoch 20 of 100
  training loss:		2.687822E-06
  validation loss:		2.010824E-06
Epoch took 10.332s

Epoch 21 of 100
  training loss:		1.601546E-06
  validation loss:		1.433527E-06
Epoch took 10.953s

Epoch 22 of 100
  training loss:		1.410244E-06
  validation loss:		6.938578E-07
Epoch took 10.567s

Epoch 23 of 100
  training loss:		1.466355E-06
  validation loss:		6.237090E-07
Epoch took 10.236s

Epoch 24 of 100
  training loss:		7.882810E-07
  validation loss:		2.012944E-06
Epoch took 8.337s

Epoch 25 of 100
  training loss:		6.464885E-07
  validation loss:		2.958776E-07
Epoch took 11.212s

Epoch 26 of 100
  training loss:		1.179234E-06
  validation loss:		7.422533E-07
Epoch took 10.876s

Epoch 27 of 100
  training loss:		2.787745E-06
  validation loss:		4.628009E-07
Epoch took 11.520s

Epoch 28 of 100
  training loss:		2.179279E-07
  validation loss:		5.055476E-07
Epoch took 9.608s

Epoch 29 of 100
  training loss:		2.466113E-07
  validation loss:		4.332867E-08
Epoch took 9.680s

Epoch 30 of 100
  training loss:		1.177572E-06
  validation loss:		7.970942E-06
Epoch took 10.645s

Epoch 31 of 100
  training loss:		1.145664E-06
  validation loss:		6.813727E-07
Epoch took 9.698s

Epoch 32 of 100
  training loss:		4.823789E-06
  validation loss:		5.083531E-08
Epoch took 11.173s

Epoch 33 of 100
  training loss:		9.360315E-08
  validation loss:		8.825054E-09
Epoch took 8.768s

Epoch 34 of 100
  training loss:		1.485166E-07
  validation loss:		1.381583E-07
Epoch took 10.396s

Epoch 35 of 100
  training loss:		1.286612E-06
  validation loss:		4.856450E-06
Epoch took 9.429s

Epoch 36 of 100
  training loss:		4.579549E-06
  validation loss:		5.545626E-06
Epoch took 10.376s

Epoch 37 of 100
  training loss:		3.564968E-07
  validation loss:		3.715100E-08
Epoch took 9.764s

Epoch 38 of 100
  training loss:		6.687459E-07
  validation loss:		2.934386E-06
Epoch took 10.539s

Epoch 39 of 100
  training loss:		1.624205E-06
  validation loss:		2.847211E-05
Epoch took 10.364s

Epoch 40 of 100
  training loss:		1.437281E-06
  validation loss:		1.649893E-07
Epoch took 10.133s

Epoch 41 of 100
  training loss:		6.041391E-06
  validation loss:		9.140499E-09
Epoch took 9.810s

Epoch 42 of 100
  training loss:		4.883381E-09
  validation loss:		3.199715E-09
Epoch took 10.602s

Epoch 43 of 100
  training loss:		1.997220E-08
  validation loss:		8.671828E-08
Epoch took 10.780s

Epoch 44 of 100
  training loss:		2.060659E-06
  validation loss:		1.477448E-06
Epoch took 10.450s

Epoch 45 of 100
  training loss:		6.217850E-07
  validation loss:		6.012849E-07
Epoch took 10.452s

Epoch 46 of 100
  training loss:		5.353060E-06
  validation loss:		6.983378E-09
Epoch took 10.596s

Epoch 47 of 100
  training loss:		5.982837E-09
  validation loss:		1.157360E-09
Epoch took 10.677s

Epoch 48 of 100
  training loss:		7.231381E-06
  validation loss:		7.372194E-07
Epoch took 10.336s

Epoch 49 of 100
  training loss:		1.342471E-07
  validation loss:		2.261501E-09
Epoch took 9.832s

Epoch 50 of 100
  training loss:		1.985909E-09
  validation loss:		6.897783E-10
Epoch took 9.545s

Epoch 51 of 100
  training loss:		5.710006E-10
  validation loss:		3.350865E-09
Epoch took 10.659s

Epoch 52 of 100
  training loss:		3.366313E-06
  validation loss:		1.721278E-07
Epoch took 10.747s

Epoch 53 of 100
  training loss:		9.932851E-07
  validation loss:		1.126376E-06
Epoch took 10.129s

Epoch 54 of 100
  training loss:		2.770960E-06
  validation loss:		2.596425E-06
Epoch took 9.271s

Epoch 55 of 100
  training loss:		2.116286E-06
  validation loss:		1.335750E-06
Epoch took 9.443s

Epoch 56 of 100
  training loss:		4.815764E-07
  validation loss:		2.180885E-06
Epoch took 9.641s

Epoch 57 of 100
  training loss:		3.296158E-06
  validation loss:		4.123413E-07
Epoch took 11.351s

Epoch 58 of 100
  training loss:		6.722805E-07
  validation loss:		5.615947E-07
Epoch took 10.676s

Epoch 59 of 100
  training loss:		3.142565E-06
  validation loss:		5.129236E-06
Epoch took 10.024s

Epoch 60 of 100
  training loss:		4.439765E-07
  validation loss:		9.615442E-08
Epoch took 10.061s

Epoch 61 of 100
  training loss:		3.910953E-06
  validation loss:		1.471894E-08
Epoch took 11.606s

Epoch 62 of 100
  training loss:		7.894508E-09
  validation loss:		1.647375E-08
Epoch took 9.531s

Epoch 63 of 100
  training loss:		8.662277E-08
  validation loss:		3.445385E-06
Epoch took 9.776s

Epoch 64 of 100
  training loss:		6.526080E-06
  validation loss:		1.994805E-08
Epoch took 10.311s

Epoch 65 of 100
  training loss:		1.551470E-08
  validation loss:		4.221063E-10
Epoch took 10.542s

Epoch 66 of 100
  training loss:		2.599108E-07
  validation loss:		7.029079E-06
Epoch took 10.042s

Epoch 67 of 100
  training loss:		2.340902E-06
  validation loss:		1.155102E-07
Epoch took 10.138s

Epoch 68 of 100
  training loss:		2.503683E-06
  validation loss:		1.080783E-06
Epoch took 10.809s

Epoch 69 of 100
  training loss:		2.352021E-06
  validation loss:		3.222787E-07
Epoch took 10.688s

Epoch 70 of 100
  training loss:		3.020685E-07
  validation loss:		2.177442E-07
Epoch took 11.032s

Epoch 71 of 100
  training loss:		1.810860E-06
  validation loss:		1.537731E-07
Epoch took 10.155s

Epoch 72 of 100
  training loss:		3.791336E-06
  validation loss:		4.519438E-08
Epoch took 9.767s

Epoch 73 of 100
  training loss:		1.533268E-08
  validation loss:		8.982670E-09
Epoch took 9.161s

Epoch 74 of 100
  training loss:		6.337358E-06
  validation loss:		1.022431E-05
Epoch took 8.143s

Epoch 75 of 100
  training loss:		4.183153E-07
  validation loss:		3.432378E-09
Epoch took 8.120s

Epoch 76 of 100
  training loss:		1.405546E-09
  validation loss:		2.215237E-09
Epoch took 9.071s

Epoch 77 of 100
  training loss:		1.426868E-06
  validation loss:		1.745340E-05
Epoch took 10.354s

Epoch 78 of 100
  training loss:		2.021057E-06
  validation loss:		9.747897E-08
Epoch took 10.275s

Epoch 79 of 100
  training loss:		1.205188E-06
  validation loss:		3.534021E-05
Epoch took 10.619s

Epoch 80 of 100
  training loss:		3.394945E-06
  validation loss:		3.691608E-09
Epoch took 9.885s

Epoch 81 of 100
  training loss:		1.980389E-09
  validation loss:		2.261037E-09
Epoch took 10.695s

Epoch 82 of 100
  training loss:		6.630163E-06
  validation loss:		1.961783E-06
Epoch took 10.932s

Epoch 83 of 100
  training loss:		6.704117E-08
  validation loss:		6.158719E-09
Epoch took 11.022s

Epoch 84 of 100
  training loss:		3.503089E-09
  validation loss:		5.631407E-10
Epoch took 11.288s

Epoch 85 of 100
  training loss:		1.378522E-06
  validation loss:		8.651824E-06
Epoch took 10.013s

Epoch 86 of 100
  training loss:		3.613906E-06
  validation loss:		4.543333E-09
Epoch took 10.796s

Epoch 87 of 100
  training loss:		2.257708E-09
  validation loss:		4.788156E-10
Epoch took 10.033s

Epoch 88 of 100
  training loss:		9.141046E-06
  validation loss:		1.976953E-07
Epoch took 9.770s

Epoch 89 of 100
  training loss:		2.522594E-08
  validation loss:		8.015876E-09
Epoch took 10.338s

Epoch 90 of 100
  training loss:		1.868299E-09
  validation loss:		1.786387E-09
Epoch took 9.731s

Epoch 91 of 100
  training loss:		7.814722E-10
  validation loss:		4.212638E-09
Epoch took 10.513s

Epoch 92 of 100
  training loss:		2.771787E-06
  validation loss:		1.673131E-07
Epoch took 10.841s

Epoch 93 of 100
  training loss:		8.410593E-08
  validation loss:		2.519941E-08
Epoch took 9.573s

Epoch 94 of 100
  training loss:		4.960446E-06
  validation loss:		9.291082E-08
Epoch took 9.729s

Epoch 95 of 100
  training loss:		1.332682E-08
  validation loss:		1.867832E-09
Epoch took 9.831s

Epoch 96 of 100
  training loss:		4.338579E-06
  validation loss:		2.608242E-06
Epoch took 10.591s

Epoch 97 of 100
  training loss:		8.230192E-07
  validation loss:		1.865396E-09
Epoch took 10.949s

Epoch 98 of 100
  training loss:		1.204059E-09
  validation loss:		7.299131E-10
Epoch took 9.749s

Epoch 99 of 100
  training loss:		3.304844E-06
  validation loss:		6.720473E-07
Epoch took 10.722s

Epoch 100 of 100
  training loss:		2.424405E-07
  validation loss:		3.583371E-08
Epoch took 10.302s

Training RMSE: 0.00018783333032
Validation RMSE: 0.000189297196614
