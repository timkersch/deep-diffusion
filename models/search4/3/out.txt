Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.476425E-02
  validation loss:		1.983570E-04
Epoch took 11.577s

Epoch 2 of 100
  training loss:		8.581511E-05
  validation loss:		3.538305E-05
Epoch took 9.776s

Epoch 3 of 100
  training loss:		2.087648E-05
  validation loss:		1.131585E-05
Epoch took 11.089s

Epoch 4 of 100
  training loss:		9.101124E-06
  validation loss:		5.854679E-06
Epoch took 11.972s

Epoch 5 of 100
  training loss:		4.951200E-06
  validation loss:		1.472932E-05
Epoch took 11.563s

Epoch 6 of 100
  training loss:		3.373161E-06
  validation loss:		1.707710E-06
Epoch took 11.344s

Epoch 7 of 100
  training loss:		2.914755E-05
  validation loss:		1.990114E-05
Epoch took 10.673s

Epoch 8 of 100
  training loss:		1.867543E-05
  validation loss:		3.526590E-05
Epoch took 11.145s

Epoch 9 of 100
  training loss:		1.003155E-04
  validation loss:		2.505400E-05
Epoch took 11.413s

Epoch 10 of 100
  training loss:		9.573752E-05
  validation loss:		5.709815E-06
Epoch took 11.438s

Epoch 11 of 100
  training loss:		6.146209E-05
  validation loss:		3.729722E-05
Epoch took 11.479s

Epoch 12 of 100
  training loss:		1.272915E-04
  validation loss:		2.456861E-05
Epoch took 11.606s

Epoch 13 of 100
  training loss:		1.300037E-04
  validation loss:		1.153962E-05
Epoch took 11.817s

Epoch 14 of 100
  training loss:		8.257028E-06
  validation loss:		4.101678E-05
Epoch took 12.272s

Epoch 15 of 100
  training loss:		1.282706E-04
  validation loss:		6.003337E-06
Epoch took 11.021s

Epoch 16 of 100
  training loss:		3.634073E-06
  validation loss:		1.079448E-06
Epoch took 11.440s

Epoch 17 of 100
  training loss:		9.387143E-05
  validation loss:		2.555719E-05
Epoch took 10.802s

Epoch 18 of 100
  training loss:		6.451815E-05
  validation loss:		3.979767E-06
Epoch took 11.713s

Epoch 19 of 100
  training loss:		5.651439E-05
  validation loss:		2.227106E-05
Epoch took 11.761s

Epoch 20 of 100
  training loss:		3.613953E-05
  validation loss:		3.663232E-05
Epoch took 11.592s

Epoch 21 of 100
  training loss:		6.748175E-05
  validation loss:		2.005151E-06
Epoch took 10.965s

Epoch 22 of 100
  training loss:		1.818123E-04
  validation loss:		4.385824E-06
Epoch took 10.936s

Epoch 23 of 100
  training loss:		2.464563E-06
  validation loss:		1.225418E-06
Epoch took 11.452s

Epoch 24 of 100
  training loss:		4.687111E-05
  validation loss:		1.818885E-05
Epoch took 10.650s

Epoch 25 of 100
  training loss:		3.863314E-05
  validation loss:		6.086815E-05
Epoch took 12.173s

Epoch 26 of 100
  training loss:		1.231994E-05
  validation loss:		2.229689E-05
Epoch took 12.211s

Epoch 27 of 100
  training loss:		5.209664E-05
  validation loss:		5.465972E-06
Epoch took 11.218s

Epoch 28 of 100
  training loss:		2.586030E-05
  validation loss:		8.225136E-06
Epoch took 12.567s

Epoch 29 of 100
  training loss:		3.491967E-05
  validation loss:		8.754594E-06
Epoch took 11.682s

Epoch 30 of 100
  training loss:		9.755764E-05
  validation loss:		9.381545E-06
Epoch took 12.201s

Epoch 31 of 100
  training loss:		3.030938E-06
  validation loss:		3.559704E-07
Epoch took 10.890s

Epoch 32 of 100
  training loss:		1.476254E-05
  validation loss:		2.030820E-05
Epoch took 12.561s

Epoch 33 of 100
  training loss:		2.859336E-05
  validation loss:		2.552106E-06
Epoch took 10.432s

Epoch 34 of 100
  training loss:		4.188689E-05
  validation loss:		3.776310E-06
Epoch took 12.082s

Epoch 35 of 100
  training loss:		2.974188E-06
  validation loss:		9.689871E-06
Epoch took 11.328s

Epoch 36 of 100
  training loss:		2.544340E-05
  validation loss:		2.260686E-05
Epoch took 12.762s

Epoch 37 of 100
  training loss:		1.323609E-05
  validation loss:		1.038393E-04
Epoch took 11.452s

Epoch 38 of 100
  training loss:		5.184796E-05
  validation loss:		9.163606E-07
Epoch took 10.966s

Epoch 39 of 100
  training loss:		4.174049E-07
  validation loss:		7.364994E-07
Epoch took 12.523s

Epoch 40 of 100
  training loss:		2.878810E-05
  validation loss:		1.853890E-06
Epoch took 12.310s

Epoch 41 of 100
  training loss:		8.336476E-06
  validation loss:		1.186922E-05
Epoch took 11.007s

Epoch 42 of 100
  training loss:		1.803251E-05
  validation loss:		3.717811E-06
Epoch took 11.823s

Epoch 43 of 100
  training loss:		1.756184E-05
  validation loss:		2.057863E-06
Epoch took 11.149s

Epoch 44 of 100
  training loss:		6.260791E-06
  validation loss:		1.621380E-05
Epoch took 11.602s

Epoch 45 of 100
  training loss:		2.498885E-05
  validation loss:		3.165355E-05
Epoch took 11.469s

Epoch 46 of 100
  training loss:		5.599428E-06
  validation loss:		8.372550E-07
Epoch took 11.655s

Epoch 47 of 100
  training loss:		1.033903E-05
  validation loss:		6.553392E-06
Epoch took 11.686s

Epoch 48 of 100
  training loss:		9.540589E-06
  validation loss:		1.287599E-05
Epoch took 11.219s

Epoch 49 of 100
  training loss:		9.080202E-06
  validation loss:		1.282023E-05
Epoch took 12.806s

Epoch 50 of 100
  training loss:		2.077710E-05
  validation loss:		2.157544E-05
Epoch took 11.513s

Epoch 51 of 100
  training loss:		1.862394E-06
  validation loss:		2.402104E-06
Epoch took 12.003s

Epoch 52 of 100
  training loss:		1.457733E-05
  validation loss:		1.174997E-06
Epoch took 10.862s

Epoch 53 of 100
  training loss:		5.044119E-06
  validation loss:		2.992982E-05
Epoch took 11.741s

Epoch 54 of 100
  training loss:		1.123758E-05
  validation loss:		8.085749E-07
Epoch took 11.155s

Epoch 55 of 100
  training loss:		1.198049E-05
  validation loss:		3.455032E-05
Epoch took 11.338s

Epoch 56 of 100
  training loss:		3.778673E-06
  validation loss:		1.004394E-07
Epoch took 11.832s

Epoch 57 of 100
  training loss:		9.115042E-06
  validation loss:		4.159082E-06
Epoch took 11.443s

Epoch 58 of 100
  training loss:		2.324699E-06
  validation loss:		1.245633E-05
Epoch took 11.155s

Epoch 59 of 100
  training loss:		9.262584E-06
  validation loss:		9.218603E-08
Epoch took 11.222s

Epoch 60 of 100
  training loss:		7.613418E-06
  validation loss:		3.181053E-06
Epoch took 11.957s

Epoch 61 of 100
  training loss:		5.177100E-06
  validation loss:		6.787801E-06
Epoch took 10.598s

Epoch 62 of 100
  training loss:		2.716087E-06
  validation loss:		5.144186E-07
Epoch took 11.685s

Epoch 63 of 100
  training loss:		5.639761E-06
  validation loss:		6.076517E-06
Epoch took 12.124s

Epoch 64 of 100
  training loss:		5.723372E-06
  validation loss:		4.993902E-06
Epoch took 11.660s

Epoch 65 of 100
  training loss:		3.466278E-06
  validation loss:		2.776252E-06
Epoch took 11.934s

Epoch 66 of 100
  training loss:		5.066311E-06
  validation loss:		1.306469E-06
Epoch took 11.609s

Epoch 67 of 100
  training loss:		3.327029E-06
  validation loss:		8.528671E-06
Epoch took 11.325s

Epoch 68 of 100
  training loss:		9.762981E-06
  validation loss:		4.842194E-08
Epoch took 11.542s

Epoch 69 of 100
  training loss:		5.430567E-07
  validation loss:		3.887410E-06
Epoch took 10.313s

Epoch 70 of 100
  training loss:		6.212526E-06
  validation loss:		6.035124E-08
Epoch took 12.031s

Epoch 71 of 100
  training loss:		2.405447E-07
  validation loss:		1.554361E-06
Epoch took 11.568s

Epoch 72 of 100
  training loss:		4.304795E-06
  validation loss:		1.051372E-06
Epoch took 11.365s

Epoch 73 of 100
  training loss:		5.366053E-06
  validation loss:		9.426057E-06
Epoch took 11.900s

Epoch 74 of 100
  training loss:		1.134666E-06
  validation loss:		4.060478E-08
Epoch took 11.053s

Epoch 75 of 100
  training loss:		3.122709E-06
  validation loss:		9.625259E-06
Epoch took 11.220s

Epoch 76 of 100
  training loss:		1.852509E-06
  validation loss:		3.220119E-07
Epoch took 12.082s

Epoch 77 of 100
  training loss:		2.543163E-06
  validation loss:		3.807078E-06
Epoch took 11.949s

Epoch 78 of 100
  training loss:		3.200442E-06
  validation loss:		2.247257E-07
Epoch took 12.119s

Epoch 79 of 100
  training loss:		7.320243E-07
  validation loss:		3.418260E-06
Epoch took 11.312s

Epoch 80 of 100
  training loss:		4.990608E-06
  validation loss:		8.409541E-08
Epoch took 12.804s

Epoch 81 of 100
  training loss:		6.100123E-08
  validation loss:		5.984547E-07
Epoch took 10.614s

Epoch 82 of 100
  training loss:		2.375693E-06
  validation loss:		4.984091E-07
Epoch took 10.943s

Epoch 83 of 100
  training loss:		1.468813E-06
  validation loss:		3.346554E-06
Epoch took 11.909s

Epoch 84 of 100
  training loss:		1.657140E-06
  validation loss:		2.468972E-06
Epoch took 11.212s

Epoch 85 of 100
  training loss:		3.500451E-06
  validation loss:		3.672216E-08
Epoch took 10.788s

Epoch 86 of 100
  training loss:		8.635198E-09
  validation loss:		1.806827E-08
Epoch took 12.331s

Epoch 87 of 100
  training loss:		2.596452E-06
  validation loss:		9.832285E-07
Epoch took 11.750s

Epoch 88 of 100
  training loss:		2.766845E-07
  validation loss:		6.181394E-08
Epoch took 11.988s

Epoch 89 of 100
  training loss:		1.700912E-06
  validation loss:		8.663816E-07
Epoch took 12.034s

Epoch 90 of 100
  training loss:		9.190171E-07
  validation loss:		1.998058E-06
Epoch took 12.076s

Epoch 91 of 100
  training loss:		1.287755E-06
  validation loss:		1.559656E-06
Epoch took 11.361s

Epoch 92 of 100
  training loss:		8.085465E-07
  validation loss:		5.721098E-07
Epoch took 11.489s

Epoch 93 of 100
  training loss:		1.776738E-06
  validation loss:		7.785824E-07
Epoch took 12.385s

Epoch 94 of 100
  training loss:		2.961008E-07
  validation loss:		3.527356E-06
Epoch took 11.099s

Epoch 95 of 100
  training loss:		1.416600E-06
  validation loss:		9.916826E-09
Epoch took 11.021s

Epoch 96 of 100
  training loss:		5.859228E-07
  validation loss:		2.548457E-06
Epoch took 11.875s

Epoch 97 of 100
  training loss:		1.306095E-06
  validation loss:		2.318531E-07
Epoch took 11.559s

Epoch 98 of 100
  training loss:		4.266841E-07
  validation loss:		2.010661E-06
Epoch took 12.456s

Epoch 99 of 100
  training loss:		1.116374E-06
  validation loss:		6.523706E-08
Epoch took 12.074s

Epoch 100 of 100
  training loss:		9.944232E-07
  validation loss:		2.252667E-06
Epoch took 11.577s

Training RMSE: 0.00149961833037
Validation RMSE: 0.00150089797293
