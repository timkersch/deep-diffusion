Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		7.177981E-02
  validation loss:		5.758167E-02
Epoch took 14.716s

Epoch 2 of 100
  training loss:		4.262914E-02
  validation loss:		3.837810E-02
Epoch took 13.858s

Epoch 3 of 100
  training loss:		3.614989E-02
  validation loss:		3.433213E-02
Epoch took 15.493s

Epoch 4 of 100
  training loss:		3.392007E-02
  validation loss:		3.295444E-02
Epoch took 14.860s

Epoch 5 of 100
  training loss:		3.189782E-02
  validation loss:		3.118820E-02
Epoch took 15.070s

Epoch 6 of 100
  training loss:		3.109862E-02
  validation loss:		3.089943E-02
Epoch took 14.640s

Epoch 7 of 100
  training loss:		3.048348E-02
  validation loss:		3.179882E-02
Epoch took 14.418s

Epoch 8 of 100
  training loss:		2.974075E-02
  validation loss:		2.934326E-02
Epoch took 13.568s

Epoch 9 of 100
  training loss:		2.923275E-02
  validation loss:		3.192364E-02
Epoch took 15.027s

Epoch 10 of 100
  training loss:		2.909727E-02
  validation loss:		2.863133E-02
Epoch took 13.340s

Epoch 11 of 100
  training loss:		2.870785E-02
  validation loss:		2.838521E-02
Epoch took 15.091s

Epoch 12 of 100
  training loss:		2.889686E-02
  validation loss:		2.923551E-02
Epoch took 13.797s

Epoch 13 of 100
  training loss:		2.845330E-02
  validation loss:		2.762592E-02
Epoch took 14.332s

Epoch 14 of 100
  training loss:		2.855898E-02
  validation loss:		2.791353E-02
Epoch took 14.819s

Epoch 15 of 100
  training loss:		2.823838E-02
  validation loss:		2.851234E-02
Epoch took 15.084s

Epoch 16 of 100
  training loss:		2.817769E-02
  validation loss:		2.759529E-02
Epoch took 15.465s

Epoch 17 of 100
  training loss:		2.810719E-02
  validation loss:		2.728418E-02
Epoch took 13.941s

Epoch 18 of 100
  training loss:		2.776421E-02
  validation loss:		3.092590E-02
Epoch took 13.448s

Epoch 19 of 100
  training loss:		2.759223E-02
  validation loss:		2.791049E-02
Epoch took 15.164s

Epoch 20 of 100
  training loss:		2.761001E-02
  validation loss:		2.740925E-02
Epoch took 14.143s

Epoch 21 of 100
  training loss:		2.805761E-02
  validation loss:		2.741827E-02
Epoch took 11.925s

Epoch 22 of 100
  training loss:		2.776806E-02
  validation loss:		2.782105E-02
Epoch took 14.323s

Epoch 23 of 100
  training loss:		2.758923E-02
  validation loss:		2.769505E-02
Epoch took 15.026s

Epoch 24 of 100
  training loss:		2.765434E-02
  validation loss:		2.807233E-02
Epoch took 14.298s

Epoch 25 of 100
  training loss:		2.744307E-02
  validation loss:		2.753250E-02
Epoch took 13.042s

Epoch 26 of 100
  training loss:		2.756819E-02
  validation loss:		2.912919E-02
Epoch took 14.481s

Epoch 27 of 100
  training loss:		2.728235E-02
  validation loss:		2.810644E-02
Epoch took 14.781s

Epoch 28 of 100
  training loss:		2.749229E-02
  validation loss:		2.806605E-02
Epoch took 14.775s

Epoch 29 of 100
  training loss:		2.750248E-02
  validation loss:		2.763008E-02
Epoch took 14.038s

Epoch 30 of 100
  training loss:		2.726648E-02
  validation loss:		2.691044E-02
Epoch took 15.708s

Epoch 31 of 100
  training loss:		2.727098E-02
  validation loss:		2.702428E-02
Epoch took 13.001s

Epoch 32 of 100
  training loss:		2.758423E-02
  validation loss:		2.713779E-02
Epoch took 13.287s

Epoch 33 of 100
  training loss:		2.722905E-02
  validation loss:		2.710021E-02
Epoch took 13.130s

Epoch 34 of 100
  training loss:		2.723442E-02
  validation loss:		2.705092E-02
Epoch took 12.639s

Epoch 35 of 100
  training loss:		2.715964E-02
  validation loss:		2.687095E-02
Epoch took 14.829s

Epoch 36 of 100
  training loss:		2.732655E-02
  validation loss:		2.772300E-02
Epoch took 13.855s

Epoch 37 of 100
  training loss:		2.715521E-02
  validation loss:		2.679722E-02
Epoch took 12.353s

Epoch 38 of 100
  training loss:		2.710764E-02
  validation loss:		2.682568E-02
Epoch took 14.185s

Epoch 39 of 100
  training loss:		2.703764E-02
  validation loss:		2.787059E-02
Epoch took 13.505s

Epoch 40 of 100
  training loss:		2.725810E-02
  validation loss:		2.697800E-02
Epoch took 14.733s

Epoch 41 of 100
  training loss:		2.717102E-02
  validation loss:		2.706353E-02
Epoch took 13.603s

Epoch 42 of 100
  training loss:		2.718880E-02
  validation loss:		2.738386E-02
Epoch took 13.015s

Epoch 43 of 100
  training loss:		2.695756E-02
  validation loss:		2.705474E-02
Epoch took 13.414s

Epoch 44 of 100
  training loss:		2.716482E-02
  validation loss:		2.737804E-02
Epoch took 14.803s

Epoch 45 of 100
  training loss:		2.694829E-02
  validation loss:		2.688357E-02
Epoch took 14.841s

Epoch 46 of 100
  training loss:		2.695848E-02
  validation loss:		2.667977E-02
Epoch took 12.855s

Epoch 47 of 100
  training loss:		2.700300E-02
  validation loss:		2.732018E-02
Epoch took 14.878s

Epoch 48 of 100
  training loss:		2.683386E-02
  validation loss:		2.656345E-02
Epoch took 14.184s

Epoch 49 of 100
  training loss:		2.704997E-02
  validation loss:		2.732407E-02
Epoch took 14.266s

Epoch 50 of 100
  training loss:		2.669410E-02
  validation loss:		2.687207E-02
Epoch took 14.597s

Epoch 51 of 100
  training loss:		2.701885E-02
  validation loss:		2.667506E-02
Epoch took 14.245s

Epoch 52 of 100
  training loss:		2.704061E-02
  validation loss:		2.658402E-02
Epoch took 14.894s

Epoch 53 of 100
  training loss:		2.701240E-02
  validation loss:		2.740989E-02
Epoch took 14.372s

Epoch 54 of 100
  training loss:		2.700272E-02
  validation loss:		2.723342E-02
Epoch took 15.676s

Epoch 55 of 100
  training loss:		2.679546E-02
  validation loss:		2.725827E-02
Epoch took 14.697s

Epoch 56 of 100
  training loss:		2.676644E-02
  validation loss:		2.667468E-02
Epoch took 14.137s

Epoch 57 of 100
  training loss:		2.690096E-02
  validation loss:		2.687060E-02
Epoch took 13.780s

Epoch 58 of 100
  training loss:		2.685697E-02
  validation loss:		2.696015E-02
Epoch took 14.992s

Epoch 59 of 100
  training loss:		2.681414E-02
  validation loss:		2.655711E-02
Epoch took 15.125s

Epoch 60 of 100
  training loss:		2.701194E-02
  validation loss:		2.690414E-02
Epoch took 14.297s

Epoch 61 of 100
  training loss:		2.682246E-02
  validation loss:		2.692775E-02
Epoch took 14.347s

Epoch 62 of 100
  training loss:		2.679669E-02
  validation loss:		2.642221E-02
Epoch took 15.080s

Epoch 63 of 100
  training loss:		2.670118E-02
  validation loss:		2.678445E-02
Epoch took 15.305s

Epoch 64 of 100
  training loss:		2.684244E-02
  validation loss:		2.688965E-02
Epoch took 14.191s

Epoch 65 of 100
  training loss:		2.680033E-02
  validation loss:		2.656807E-02
Epoch took 14.865s

Epoch 66 of 100
  training loss:		2.657500E-02
  validation loss:		2.673726E-02
Epoch took 15.132s

Epoch 67 of 100
  training loss:		2.661293E-02
  validation loss:		2.761178E-02
Epoch took 12.861s

Epoch 68 of 100
  training loss:		2.672279E-02
  validation loss:		2.683763E-02
Epoch took 14.335s

Epoch 69 of 100
  training loss:		2.667304E-02
  validation loss:		2.662753E-02
Epoch took 13.680s

Epoch 70 of 100
  training loss:		2.676769E-02
  validation loss:		2.711650E-02
Epoch took 13.407s

Epoch 71 of 100
  training loss:		2.658628E-02
  validation loss:		2.649148E-02
Epoch took 14.544s

Epoch 72 of 100
  training loss:		2.645521E-02
  validation loss:		2.700382E-02
Epoch took 14.807s

Epoch 73 of 100
  training loss:		2.673857E-02
  validation loss:		2.658946E-02
Epoch took 14.472s

Epoch 74 of 100
  training loss:		2.659939E-02
  validation loss:		2.841968E-02
Epoch took 14.287s

Epoch 75 of 100
  training loss:		2.674172E-02
  validation loss:		2.679357E-02
Epoch took 14.324s

Epoch 76 of 100
  training loss:		2.651661E-02
  validation loss:		2.653173E-02
Epoch took 16.034s

Epoch 77 of 100
  training loss:		2.659410E-02
  validation loss:		2.644820E-02
Epoch took 13.972s

Epoch 78 of 100
  training loss:		2.647532E-02
  validation loss:		2.660777E-02
Epoch took 14.280s

Epoch 79 of 100
  training loss:		2.654760E-02
  validation loss:		2.660275E-02
Epoch took 14.670s

Epoch 80 of 100
  training loss:		2.660913E-02
  validation loss:		2.722986E-02
Epoch took 13.889s

Early stopping, val-loss increased over the last 10 epochs from 0.0268522828603 to 0.0268718323393
Training RMSE: 1.60653943864e-07
Validation RMSE: 1.61356405269e-07
