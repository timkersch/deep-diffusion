Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		3.504723E-01
  validation loss:		8.516059E-02
Epoch took 16.874s

Epoch 2 of 100
  training loss:		7.227223E-02
  validation loss:		6.709800E-02
Epoch took 15.331s

Epoch 3 of 100
  training loss:		5.942465E-02
  validation loss:		5.649077E-02
Epoch took 15.253s

Epoch 4 of 100
  training loss:		5.199910E-02
  validation loss:		5.006606E-02
Epoch took 16.830s

Epoch 5 of 100
  training loss:		4.701404E-02
  validation loss:		4.584577E-02
Epoch took 16.526s

Epoch 6 of 100
  training loss:		4.344128E-02
  validation loss:		4.297264E-02
Epoch took 16.500s

Epoch 7 of 100
  training loss:		4.100944E-02
  validation loss:		4.100658E-02
Epoch took 15.501s

Epoch 8 of 100
  training loss:		3.908666E-02
  validation loss:		3.953392E-02
Epoch took 17.974s

Epoch 9 of 100
  training loss:		3.773511E-02
  validation loss:		3.759544E-02
Epoch took 15.827s

Epoch 10 of 100
  training loss:		3.652635E-02
  validation loss:		3.795363E-02
Epoch took 15.677s

Epoch 11 of 100
  training loss:		3.567712E-02
  validation loss:		3.552423E-02
Epoch took 15.716s

Epoch 12 of 100
  training loss:		3.505643E-02
  validation loss:		3.461345E-02
Epoch took 16.940s

Epoch 13 of 100
  training loss:		3.414207E-02
  validation loss:		3.398058E-02
Epoch took 17.017s

Epoch 14 of 100
  training loss:		3.360713E-02
  validation loss:		3.366764E-02
Epoch took 16.671s

Epoch 15 of 100
  training loss:		3.315453E-02
  validation loss:		3.311193E-02
Epoch took 16.373s

Epoch 16 of 100
  training loss:		3.252500E-02
  validation loss:		3.234950E-02
Epoch took 16.209s

Epoch 17 of 100
  training loss:		3.237954E-02
  validation loss:		3.371563E-02
Epoch took 15.009s

Epoch 18 of 100
  training loss:		3.167978E-02
  validation loss:		3.299552E-02
Epoch took 13.639s

Epoch 19 of 100
  training loss:		3.140416E-02
  validation loss:		3.538426E-02
Epoch took 17.381s

Epoch 20 of 100
  training loss:		3.119228E-02
  validation loss:		3.130952E-02
Epoch took 16.693s

Epoch 21 of 100
  training loss:		3.070775E-02
  validation loss:		3.077081E-02
Epoch took 15.023s

Epoch 22 of 100
  training loss:		3.050826E-02
  validation loss:		3.127709E-02
Epoch took 15.958s

Epoch 23 of 100
  training loss:		3.016179E-02
  validation loss:		3.174380E-02
Epoch took 16.286s

Epoch 24 of 100
  training loss:		3.017835E-02
  validation loss:		2.987728E-02
Epoch took 15.930s

Epoch 25 of 100
  training loss:		2.988363E-02
  validation loss:		3.068931E-02
Epoch took 15.813s

Epoch 26 of 100
  training loss:		2.966815E-02
  validation loss:		3.069285E-02
Epoch took 16.551s

Epoch 27 of 100
  training loss:		2.942908E-02
  validation loss:		2.937682E-02
Epoch took 15.371s

Epoch 28 of 100
  training loss:		2.923509E-02
  validation loss:		3.175081E-02
Epoch took 17.331s

Epoch 29 of 100
  training loss:		2.911328E-02
  validation loss:		2.915828E-02
Epoch took 15.465s

Epoch 30 of 100
  training loss:		2.903847E-02
  validation loss:		2.982211E-02
Epoch took 16.382s

Epoch 31 of 100
  training loss:		2.884673E-02
  validation loss:		2.891916E-02
Epoch took 16.366s

Epoch 32 of 100
  training loss:		2.887964E-02
  validation loss:		2.880747E-02
Epoch took 15.312s

Epoch 33 of 100
  training loss:		2.859667E-02
  validation loss:		2.857944E-02
Epoch took 16.443s

Epoch 34 of 100
  training loss:		2.845880E-02
  validation loss:		2.866568E-02
Epoch took 16.222s

Epoch 35 of 100
  training loss:		2.831524E-02
  validation loss:		2.819329E-02
Epoch took 15.295s

Epoch 36 of 100
  training loss:		2.834002E-02
  validation loss:		2.844568E-02
Epoch took 16.862s

Epoch 37 of 100
  training loss:		2.812465E-02
  validation loss:		2.866691E-02
Epoch took 16.494s

Epoch 38 of 100
  training loss:		2.814794E-02
  validation loss:		2.868257E-02
Epoch took 16.177s

Epoch 39 of 100
  training loss:		2.814083E-02
  validation loss:		2.778764E-02
Epoch took 17.411s

Epoch 40 of 100
  training loss:		2.799529E-02
  validation loss:		2.883250E-02
Epoch took 17.782s

Epoch 41 of 100
  training loss:		2.791597E-02
  validation loss:		2.829507E-02
Epoch took 15.805s

Epoch 42 of 100
  training loss:		2.783073E-02
  validation loss:		2.766161E-02
Epoch took 15.252s

Epoch 43 of 100
  training loss:		2.768521E-02
  validation loss:		2.779892E-02
Epoch took 16.791s

Epoch 44 of 100
  training loss:		2.765352E-02
  validation loss:		2.940906E-02
Epoch took 15.672s

Epoch 45 of 100
  training loss:		2.753157E-02
  validation loss:		2.825524E-02
Epoch took 17.002s

Epoch 46 of 100
  training loss:		2.764826E-02
  validation loss:		2.776886E-02
Epoch took 16.249s

Epoch 47 of 100
  training loss:		2.744451E-02
  validation loss:		2.779475E-02
Epoch took 16.411s

Epoch 48 of 100
  training loss:		2.745403E-02
  validation loss:		2.752972E-02
Epoch took 15.634s

Epoch 49 of 100
  training loss:		2.740889E-02
  validation loss:		2.711944E-02
Epoch took 16.181s

Epoch 50 of 100
  training loss:		2.729534E-02
  validation loss:		2.757729E-02
Epoch took 14.068s

Epoch 51 of 100
  training loss:		2.738286E-02
  validation loss:		2.721332E-02
Epoch took 16.973s

Epoch 52 of 100
  training loss:		2.727353E-02
  validation loss:		2.736398E-02
Epoch took 14.989s

Epoch 53 of 100
  training loss:		2.728705E-02
  validation loss:		2.738152E-02
Epoch took 16.630s

Epoch 54 of 100
  training loss:		2.715294E-02
  validation loss:		2.721218E-02
Epoch took 13.051s

Epoch 55 of 100
  training loss:		2.723815E-02
  validation loss:		2.713363E-02
Epoch took 14.996s

Epoch 56 of 100
  training loss:		2.710193E-02
  validation loss:		2.783389E-02
Epoch took 15.323s

Epoch 57 of 100
  training loss:		2.703382E-02
  validation loss:		2.732069E-02
Epoch took 16.380s

Epoch 58 of 100
  training loss:		2.695512E-02
  validation loss:		2.799936E-02
Epoch took 17.407s

Epoch 59 of 100
  training loss:		2.704244E-02
  validation loss:		2.743577E-02
Epoch took 15.893s

Epoch 60 of 100
  training loss:		2.693591E-02
  validation loss:		2.754942E-02
Epoch took 16.451s

Epoch 61 of 100
  training loss:		2.706973E-02
  validation loss:		2.728718E-02
Epoch took 17.229s

Epoch 62 of 100
  training loss:		2.709498E-02
  validation loss:		2.706018E-02
Epoch took 14.294s

Epoch 63 of 100
  training loss:		2.693968E-02
  validation loss:		2.751458E-02
Epoch took 16.254s

Epoch 64 of 100
  training loss:		2.697629E-02
  validation loss:		2.653888E-02
Epoch took 14.991s

Epoch 65 of 100
  training loss:		2.672584E-02
  validation loss:		2.721011E-02
Epoch took 15.961s

Epoch 66 of 100
  training loss:		2.680556E-02
  validation loss:		2.662679E-02
Epoch took 17.541s

Epoch 67 of 100
  training loss:		2.679423E-02
  validation loss:		2.756354E-02
Epoch took 16.721s

Epoch 68 of 100
  training loss:		2.673607E-02
  validation loss:		2.656465E-02
Epoch took 16.368s

Epoch 69 of 100
  training loss:		2.664706E-02
  validation loss:		2.690255E-02
Epoch took 15.493s

Epoch 70 of 100
  training loss:		2.681750E-02
  validation loss:		2.655953E-02
Epoch took 16.564s

Epoch 71 of 100
  training loss:		2.688907E-02
  validation loss:		2.677470E-02
Epoch took 16.099s

Epoch 72 of 100
  training loss:		2.673966E-02
  validation loss:		2.657107E-02
Epoch took 16.998s

Epoch 73 of 100
  training loss:		2.666028E-02
  validation loss:		2.657903E-02
Epoch took 15.179s

Epoch 74 of 100
  training loss:		2.677553E-02
  validation loss:		2.750101E-02
Epoch took 16.542s

Epoch 75 of 100
  training loss:		2.668212E-02
  validation loss:		2.646514E-02
Epoch took 17.041s

Epoch 76 of 100
  training loss:		2.676017E-02
  validation loss:		2.673900E-02
Epoch took 15.867s

Epoch 77 of 100
  training loss:		2.684458E-02
  validation loss:		2.641409E-02
Epoch took 17.530s

Epoch 78 of 100
  training loss:		2.662096E-02
  validation loss:		2.671030E-02
Epoch took 16.633s

Epoch 79 of 100
  training loss:		2.658473E-02
  validation loss:		2.651716E-02
Epoch took 16.072s

Epoch 80 of 100
  training loss:		2.661949E-02
  validation loss:		2.634424E-02
Epoch took 14.160s

Epoch 81 of 100
  training loss:		2.669945E-02
  validation loss:		2.709406E-02
Epoch took 17.133s

Epoch 82 of 100
  training loss:		2.668829E-02
  validation loss:		2.677610E-02
Epoch took 15.441s

Epoch 83 of 100
  training loss:		2.658662E-02
  validation loss:		2.707547E-02
Epoch took 16.524s

Epoch 84 of 100
  training loss:		2.659056E-02
  validation loss:		2.675651E-02
Epoch took 17.216s

Epoch 85 of 100
  training loss:		2.672392E-02
  validation loss:		2.627225E-02
Epoch took 15.632s

Epoch 86 of 100
  training loss:		2.651297E-02
  validation loss:		2.688112E-02
Epoch took 15.394s

Epoch 87 of 100
  training loss:		2.662432E-02
  validation loss:		2.749188E-02
Epoch took 17.920s

Epoch 88 of 100
  training loss:		2.651522E-02
  validation loss:		2.673168E-02
Epoch took 16.774s

Epoch 89 of 100
  training loss:		2.658857E-02
  validation loss:		2.625935E-02
Epoch took 18.140s

Epoch 90 of 100
  training loss:		2.657898E-02
  validation loss:		2.644812E-02
Epoch took 15.427s

Early stopping, val-loss increased over the last 10 epochs from 0.0266615731937 to 0.0267786526329
Training RMSE: 1.58170463136e-07
Validation RMSE: 1.59120216759e-07
