Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.325857E-02
  validation loss:		2.807488E-03
Epoch took 9.879s

Epoch 2 of 100
  training loss:		1.732226E-03
  validation loss:		1.118407E-03
Epoch took 9.364s

Epoch 3 of 100
  training loss:		7.319044E-04
  validation loss:		4.923746E-04
Epoch took 9.764s

Epoch 4 of 100
  training loss:		3.348586E-04
  validation loss:		2.367266E-04
Epoch took 10.479s

Epoch 5 of 100
  training loss:		1.654440E-04
  validation loss:		1.193122E-04
Epoch took 10.080s

Epoch 6 of 100
  training loss:		8.882847E-05
  validation loss:		6.627625E-05
Epoch took 10.061s

Epoch 7 of 100
  training loss:		5.114190E-05
  validation loss:		4.480195E-05
Epoch took 10.921s

Epoch 8 of 100
  training loss:		3.256554E-05
  validation loss:		2.502903E-05
Epoch took 10.725s

Epoch 9 of 100
  training loss:		2.096102E-05
  validation loss:		1.757236E-05
Epoch took 9.397s

Epoch 10 of 100
  training loss:		1.580507E-05
  validation loss:		1.324984E-05
Epoch took 10.266s

Epoch 11 of 100
  training loss:		1.170022E-05
  validation loss:		1.003021E-05
Epoch took 10.582s

Epoch 12 of 100
  training loss:		9.648382E-06
  validation loss:		7.163801E-06
Epoch took 10.395s

Epoch 13 of 100
  training loss:		8.732576E-06
  validation loss:		8.989044E-06
Epoch took 9.659s

Epoch 14 of 100
  training loss:		6.500790E-06
  validation loss:		4.848976E-06
Epoch took 9.509s

Epoch 15 of 100
  training loss:		6.654418E-06
  validation loss:		5.347730E-06
Epoch took 9.716s

Epoch 16 of 100
  training loss:		6.787469E-06
  validation loss:		4.820332E-06
Epoch took 10.462s

Epoch 17 of 100
  training loss:		6.993912E-06
  validation loss:		2.101027E-06
Epoch took 10.841s

Epoch 18 of 100
  training loss:		3.985271E-06
  validation loss:		1.598400E-06
Epoch took 10.540s

Epoch 19 of 100
  training loss:		7.962873E-06
  validation loss:		1.303647E-06
Epoch took 10.508s

Epoch 20 of 100
  training loss:		8.633925E-06
  validation loss:		9.335328E-07
Epoch took 9.966s

Epoch 21 of 100
  training loss:		2.592706E-06
  validation loss:		1.192319E-06
Epoch took 10.445s

Epoch 22 of 100
  training loss:		4.090366E-06
  validation loss:		3.957946E-06
Epoch took 10.085s

Epoch 23 of 100
  training loss:		3.559594E-06
  validation loss:		5.183166E-05
Epoch took 10.783s

Epoch 24 of 100
  training loss:		8.956318E-06
  validation loss:		1.779997E-05
Epoch took 9.788s

Epoch 25 of 100
  training loss:		9.521604E-06
  validation loss:		9.272234E-07
Epoch took 11.046s

Early stopping, val-loss increased over the last 5 epochs from 2.15138767991e-06 to 1.51418241617e-05
Training RMSE: 0.000935000668386
Validation RMSE: 0.000966036779438
