Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.137212E-01
  validation loss:		1.927749E-02
Epoch took 8.830s

Epoch 2 of 100
  training loss:		1.203926E-02
  validation loss:		7.454403E-03
Epoch took 9.249s

Epoch 3 of 100
  training loss:		5.557262E-03
  validation loss:		4.154111E-03
Epoch took 9.799s

Epoch 4 of 100
  training loss:		3.310011E-03
  validation loss:		2.732207E-03
Epoch took 10.338s

Epoch 5 of 100
  training loss:		2.210763E-03
  validation loss:		1.862879E-03
Epoch took 9.234s

Epoch 6 of 100
  training loss:		1.548091E-03
  validation loss:		1.339980E-03
Epoch took 9.589s

Epoch 7 of 100
  training loss:		1.111362E-03
  validation loss:		9.741134E-04
Epoch took 9.524s

Epoch 8 of 100
  training loss:		8.145891E-04
  validation loss:		7.231891E-04
Epoch took 9.515s

Epoch 9 of 100
  training loss:		6.040085E-04
  validation loss:		5.408923E-04
Epoch took 10.186s

Epoch 10 of 100
  training loss:		4.483432E-04
  validation loss:		3.994406E-04
Epoch took 9.570s

Epoch 11 of 100
  training loss:		3.336093E-04
  validation loss:		2.986558E-04
Epoch took 8.955s

Epoch 12 of 100
  training loss:		2.504136E-04
  validation loss:		2.282255E-04
Epoch took 9.653s

Epoch 13 of 100
  training loss:		1.919809E-04
  validation loss:		1.769438E-04
Epoch took 9.081s

Epoch 14 of 100
  training loss:		1.477179E-04
  validation loss:		1.351135E-04
Epoch took 9.551s

Epoch 15 of 100
  training loss:		1.138707E-04
  validation loss:		1.040282E-04
Epoch took 8.544s

Epoch 16 of 100
  training loss:		8.792344E-05
  validation loss:		8.093772E-05
Epoch took 10.053s

Epoch 17 of 100
  training loss:		6.827311E-05
  validation loss:		6.341750E-05
Epoch took 10.032s

Epoch 18 of 100
  training loss:		5.241857E-05
  validation loss:		4.795024E-05
Epoch took 9.562s

Epoch 19 of 100
  training loss:		4.090549E-05
  validation loss:		3.736083E-05
Epoch took 9.926s

Epoch 20 of 100
  training loss:		3.206706E-05
  validation loss:		3.120784E-05
Epoch took 9.232s

Epoch 21 of 100
  training loss:		2.462637E-05
  validation loss:		2.233639E-05
Epoch took 8.915s

Epoch 22 of 100
  training loss:		1.879344E-05
  validation loss:		1.777167E-05
Epoch took 10.096s

Epoch 23 of 100
  training loss:		1.478158E-05
  validation loss:		1.628502E-05
Epoch took 9.194s

Epoch 24 of 100
  training loss:		1.170952E-05
  validation loss:		1.154343E-05
Epoch took 9.407s

Epoch 25 of 100
  training loss:		9.477672E-06
  validation loss:		8.500715E-06
Epoch took 9.034s

Epoch 26 of 100
  training loss:		7.040702E-06
  validation loss:		6.535515E-06
Epoch took 9.400s

Epoch 27 of 100
  training loss:		5.678899E-06
  validation loss:		5.015207E-06
Epoch took 9.342s

Epoch 28 of 100
  training loss:		4.422991E-06
  validation loss:		3.926752E-06
Epoch took 9.173s

Epoch 29 of 100
  training loss:		3.526095E-06
  validation loss:		3.153680E-06
Epoch took 9.221s

Epoch 30 of 100
  training loss:		2.987475E-06
  validation loss:		2.498066E-06
Epoch took 9.360s

Epoch 31 of 100
  training loss:		2.425416E-06
  validation loss:		1.868123E-06
Epoch took 8.970s

Epoch 32 of 100
  training loss:		1.790653E-06
  validation loss:		2.625121E-06
Epoch took 9.670s

Epoch 33 of 100
  training loss:		1.488641E-06
  validation loss:		1.172416E-06
Epoch took 9.426s

Epoch 34 of 100
  training loss:		1.289272E-06
  validation loss:		1.055606E-06
Epoch took 9.567s

Epoch 35 of 100
  training loss:		9.628875E-07
  validation loss:		2.540762E-06
Epoch took 10.052s

Epoch 36 of 100
  training loss:		3.392189E-06
  validation loss:		1.215085E-06
Epoch took 9.226s

Epoch 37 of 100
  training loss:		1.226573E-06
  validation loss:		9.423296E-07
Epoch took 9.373s

Epoch 38 of 100
  training loss:		6.998869E-07
  validation loss:		2.850977E-07
Epoch took 9.459s

Epoch 39 of 100
  training loss:		1.242193E-05
  validation loss:		5.014651E-04
Epoch took 9.291s

Epoch 40 of 100
  training loss:		2.137233E-05
  validation loss:		4.395488E-07
Epoch took 9.118s

Early stopping, val-loss increased over the last 5 epochs from 1.85240541713e-06 to 0.000100869428946
Training RMSE: 0.00157261039042
Validation RMSE: 0.00159532566436
