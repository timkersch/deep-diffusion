Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		9.501501E-02
  validation loss:		7.163905E-02
Epoch took 15.827s

Epoch 2 of 100
  training loss:		6.486029E-02
  validation loss:		6.089790E-02
Epoch took 16.269s

Epoch 3 of 100
  training loss:		5.631743E-02
  validation loss:		5.407767E-02
Epoch took 16.056s

Epoch 4 of 100
  training loss:		5.107971E-02
  validation loss:		5.004635E-02
Epoch took 13.926s

Epoch 5 of 100
  training loss:		4.742624E-02
  validation loss:		4.660886E-02
Epoch took 15.603s

Epoch 6 of 100
  training loss:		4.451108E-02
  validation loss:		4.446308E-02
Epoch took 15.578s

Epoch 7 of 100
  training loss:		4.210738E-02
  validation loss:		4.153851E-02
Epoch took 17.506s

Epoch 8 of 100
  training loss:		4.002304E-02
  validation loss:		3.991152E-02
Epoch took 16.837s

Epoch 9 of 100
  training loss:		3.845854E-02
  validation loss:		3.820047E-02
Epoch took 14.279s

Epoch 10 of 100
  training loss:		3.703765E-02
  validation loss:		3.707151E-02
Epoch took 17.575s

Epoch 11 of 100
  training loss:		3.594929E-02
  validation loss:		3.599516E-02
Epoch took 16.530s

Epoch 12 of 100
  training loss:		3.500144E-02
  validation loss:		3.531059E-02
Epoch took 13.700s

Epoch 13 of 100
  training loss:		3.413467E-02
  validation loss:		3.419772E-02
Epoch took 17.220s

Epoch 14 of 100
  training loss:		3.346251E-02
  validation loss:		3.333694E-02
Epoch took 15.227s

Epoch 15 of 100
  training loss:		3.275759E-02
  validation loss:		3.330323E-02
Epoch took 16.927s

Epoch 16 of 100
  training loss:		3.222260E-02
  validation loss:		3.263820E-02
Epoch took 17.014s

Epoch 17 of 100
  training loss:		3.184114E-02
  validation loss:		3.242197E-02
Epoch took 16.430s

Epoch 18 of 100
  training loss:		3.141911E-02
  validation loss:		3.143269E-02
Epoch took 16.524s

Epoch 19 of 100
  training loss:		3.096678E-02
  validation loss:		3.161514E-02
Epoch took 16.989s

Epoch 20 of 100
  training loss:		3.062668E-02
  validation loss:		3.095477E-02
Epoch took 16.477s

Epoch 21 of 100
  training loss:		3.034354E-02
  validation loss:		3.045224E-02
Epoch took 14.083s

Epoch 22 of 100
  training loss:		3.005473E-02
  validation loss:		3.013071E-02
Epoch took 16.644s

Epoch 23 of 100
  training loss:		2.984685E-02
  validation loss:		3.029358E-02
Epoch took 15.892s

Epoch 24 of 100
  training loss:		2.958587E-02
  validation loss:		2.973546E-02
Epoch took 16.313s

Epoch 25 of 100
  training loss:		2.937251E-02
  validation loss:		2.965325E-02
Epoch took 17.472s

Epoch 26 of 100
  training loss:		2.919677E-02
  validation loss:		2.981290E-02
Epoch took 16.512s

Epoch 27 of 100
  training loss:		2.901072E-02
  validation loss:		2.955542E-02
Epoch took 16.881s

Epoch 28 of 100
  training loss:		2.884199E-02
  validation loss:		2.897823E-02
Epoch took 18.056s

Epoch 29 of 100
  training loss:		2.872199E-02
  validation loss:		2.987534E-02
Epoch took 17.294s

Epoch 30 of 100
  training loss:		2.862666E-02
  validation loss:		2.885550E-02
Epoch took 16.586s

Epoch 31 of 100
  training loss:		2.843241E-02
  validation loss:		2.891406E-02
Epoch took 16.646s

Epoch 32 of 100
  training loss:		2.827169E-02
  validation loss:		2.848061E-02
Epoch took 16.708s

Epoch 33 of 100
  training loss:		2.821903E-02
  validation loss:		2.839254E-02
Epoch took 15.595s

Epoch 34 of 100
  training loss:		2.810594E-02
  validation loss:		2.833154E-02
Epoch took 16.358s

Epoch 35 of 100
  training loss:		2.800556E-02
  validation loss:		2.822172E-02
Epoch took 16.705s

Epoch 36 of 100
  training loss:		2.780094E-02
  validation loss:		2.799114E-02
Epoch took 15.652s

Epoch 37 of 100
  training loss:		2.774447E-02
  validation loss:		2.789441E-02
Epoch took 15.656s

Epoch 38 of 100
  training loss:		2.775431E-02
  validation loss:		2.866950E-02
Epoch took 16.968s

Epoch 39 of 100
  training loss:		2.763224E-02
  validation loss:		2.819791E-02
Epoch took 17.050s

Epoch 40 of 100
  training loss:		2.754217E-02
  validation loss:		2.757429E-02
Epoch took 15.897s

Epoch 41 of 100
  training loss:		2.749460E-02
  validation loss:		2.756757E-02
Epoch took 17.680s

Epoch 42 of 100
  training loss:		2.752830E-02
  validation loss:		2.852599E-02
Epoch took 16.637s

Epoch 43 of 100
  training loss:		2.726596E-02
  validation loss:		2.754656E-02
Epoch took 15.683s

Epoch 44 of 100
  training loss:		2.722809E-02
  validation loss:		2.744811E-02
Epoch took 16.514s

Epoch 45 of 100
  training loss:		2.723871E-02
  validation loss:		2.827485E-02
Epoch took 18.576s

Epoch 46 of 100
  training loss:		2.714046E-02
  validation loss:		2.725832E-02
Epoch took 14.964s

Epoch 47 of 100
  training loss:		2.710567E-02
  validation loss:		2.765817E-02
Epoch took 15.976s

Epoch 48 of 100
  training loss:		2.709724E-02
  validation loss:		2.716809E-02
Epoch took 17.075s

Epoch 49 of 100
  training loss:		2.703582E-02
  validation loss:		2.792781E-02
Epoch took 16.345s

Epoch 50 of 100
  training loss:		2.695951E-02
  validation loss:		2.727777E-02
Epoch took 16.621s

Epoch 51 of 100
  training loss:		2.693666E-02
  validation loss:		2.717344E-02
Epoch took 16.489s

Epoch 52 of 100
  training loss:		2.693932E-02
  validation loss:		2.731011E-02
Epoch took 17.320s

Epoch 53 of 100
  training loss:		2.681268E-02
  validation loss:		2.688998E-02
Epoch took 15.468s

Epoch 54 of 100
  training loss:		2.675787E-02
  validation loss:		2.689970E-02
Epoch took 15.427s

Epoch 55 of 100
  training loss:		2.679110E-02
  validation loss:		2.731261E-02
Epoch took 16.574s

Epoch 56 of 100
  training loss:		2.669458E-02
  validation loss:		2.676100E-02
Epoch took 16.520s

Epoch 57 of 100
  training loss:		2.669487E-02
  validation loss:		2.697321E-02
Epoch took 16.709s

Epoch 58 of 100
  training loss:		2.676763E-02
  validation loss:		2.685534E-02
Epoch took 15.687s

Epoch 59 of 100
  training loss:		2.661738E-02
  validation loss:		2.685577E-02
Epoch took 15.690s

Epoch 60 of 100
  training loss:		2.664960E-02
  validation loss:		2.734890E-02
Epoch took 16.350s

Epoch 61 of 100
  training loss:		2.658126E-02
  validation loss:		2.664903E-02
Epoch took 16.209s

Epoch 62 of 100
  training loss:		2.656457E-02
  validation loss:		2.674128E-02
Epoch took 16.968s

Epoch 63 of 100
  training loss:		2.651631E-02
  validation loss:		2.658911E-02
Epoch took 15.611s

Epoch 64 of 100
  training loss:		2.652155E-02
  validation loss:		2.656737E-02
Epoch took 15.544s

Epoch 65 of 100
  training loss:		2.654830E-02
  validation loss:		2.691351E-02
Epoch took 15.523s

Epoch 66 of 100
  training loss:		2.650565E-02
  validation loss:		2.730320E-02
Epoch took 14.837s

Epoch 67 of 100
  training loss:		2.646958E-02
  validation loss:		2.689546E-02
Epoch took 17.024s

Epoch 68 of 100
  training loss:		2.644922E-02
  validation loss:		2.676320E-02
Epoch took 14.475s

Epoch 69 of 100
  training loss:		2.643458E-02
  validation loss:		2.671180E-02
Epoch took 15.467s

Epoch 70 of 100
  training loss:		2.640236E-02
  validation loss:		2.662083E-02
Epoch took 16.807s

Epoch 71 of 100
  training loss:		2.636405E-02
  validation loss:		2.657874E-02
Epoch took 17.331s

Epoch 72 of 100
  training loss:		2.643504E-02
  validation loss:		2.631952E-02
Epoch took 16.392s

Epoch 73 of 100
  training loss:		2.636974E-02
  validation loss:		2.786445E-02
Epoch took 15.594s

Epoch 74 of 100
  training loss:		2.637205E-02
  validation loss:		2.699276E-02
Epoch took 16.788s

Epoch 75 of 100
  training loss:		2.636311E-02
  validation loss:		2.639898E-02
Epoch took 17.396s

Epoch 76 of 100
  training loss:		2.635145E-02
  validation loss:		2.718155E-02
Epoch took 16.973s

Epoch 77 of 100
  training loss:		2.630832E-02
  validation loss:		2.719442E-02
Epoch took 15.513s

Epoch 78 of 100
  training loss:		2.636897E-02
  validation loss:		2.649088E-02
Epoch took 17.470s

Epoch 79 of 100
  training loss:		2.629166E-02
  validation loss:		2.654724E-02
Epoch took 16.240s

Epoch 80 of 100
  training loss:		2.628268E-02
  validation loss:		2.670965E-02
Epoch took 16.367s

Early stopping, val-loss increased over the last 10 epochs from 0.0267754796088 to 0.0268278198965
Training RMSE: 1.58791808566e-07
Validation RMSE: 1.59866346827e-07
