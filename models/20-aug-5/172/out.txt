Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 200
  training loss:		6.865527E-02
  validation loss:		5.014559E-02
Epoch took 0.939s

Epoch 2 of 200
  training loss:		4.878130E-02
  validation loss:		4.088960E-02
Epoch took 0.882s

Epoch 3 of 200
  training loss:		4.158240E-02
  validation loss:		3.665174E-02
Epoch took 0.881s

Epoch 4 of 200
  training loss:		3.741628E-02
  validation loss:		3.402793E-02
Epoch took 0.882s

Epoch 5 of 200
  training loss:		3.509574E-02
  validation loss:		3.379089E-02
Epoch took 0.882s

Epoch 6 of 200
  training loss:		3.321779E-02
  validation loss:		3.058956E-02
Epoch took 0.882s

Epoch 7 of 200
  training loss:		3.148989E-02
  validation loss:		3.070253E-02
Epoch took 0.882s

Epoch 8 of 200
  training loss:		3.102073E-02
  validation loss:		2.938580E-02
Epoch took 0.881s

Epoch 9 of 200
  training loss:		3.078335E-02
  validation loss:		2.809735E-02
Epoch took 0.882s

Epoch 10 of 200
  training loss:		3.038692E-02
  validation loss:		2.805526E-02
Epoch took 0.881s

Epoch 11 of 200
  training loss:		2.998438E-02
  validation loss:		2.736745E-02
Epoch took 0.881s

Epoch 12 of 200
  training loss:		2.939128E-02
  validation loss:		2.971769E-02
Epoch took 0.881s

Epoch 13 of 200
  training loss:		2.897948E-02
  validation loss:		2.887239E-02
Epoch took 0.881s

Epoch 14 of 200
  training loss:		2.901420E-02
  validation loss:		2.794456E-02
Epoch took 0.881s

Epoch 15 of 200
  training loss:		2.865513E-02
  validation loss:		2.812398E-02
Epoch took 0.881s

Epoch 16 of 200
  training loss:		2.843395E-02
  validation loss:		2.768502E-02
Epoch took 0.881s

Epoch 17 of 200
  training loss:		2.819747E-02
  validation loss:		2.933268E-02
Epoch took 0.880s

Epoch 18 of 200
  training loss:		2.860487E-02
  validation loss:		2.830517E-02
Epoch took 0.880s

Epoch 19 of 200
  training loss:		2.822609E-02
  validation loss:		2.793956E-02
Epoch took 0.880s

Epoch 20 of 200
  training loss:		2.850600E-02
  validation loss:		2.749372E-02
Epoch took 0.880s

Epoch 21 of 200
  training loss:		2.796102E-02
  validation loss:		2.743586E-02
Epoch took 0.880s

Epoch 22 of 200
  training loss:		2.791884E-02
  validation loss:		2.729123E-02
Epoch took 0.880s

Epoch 23 of 200
  training loss:		2.783142E-02
  validation loss:		2.924494E-02
Epoch took 0.880s

Epoch 24 of 200
  training loss:		2.782961E-02
  validation loss:		2.730933E-02
Epoch took 0.880s

Epoch 25 of 200
  training loss:		2.752438E-02
  validation loss:		2.701046E-02
Epoch took 0.880s

Epoch 26 of 200
  training loss:		2.738232E-02
  validation loss:		2.715116E-02
Epoch took 0.880s

Epoch 27 of 200
  training loss:		2.736007E-02
  validation loss:		2.710721E-02
Epoch took 0.880s

Epoch 28 of 200
  training loss:		2.751271E-02
  validation loss:		2.787820E-02
Epoch took 0.880s

Epoch 29 of 200
  training loss:		2.731296E-02
  validation loss:		2.753776E-02
Epoch took 0.880s

Epoch 30 of 200
  training loss:		2.730670E-02
  validation loss:		2.756868E-02
Epoch took 0.880s

Epoch 31 of 200
  training loss:		2.724510E-02
  validation loss:		2.680274E-02
Epoch took 0.879s

Epoch 32 of 200
  training loss:		2.734703E-02
  validation loss:		2.728323E-02
Epoch took 0.879s

Epoch 33 of 200
  training loss:		2.699736E-02
  validation loss:		2.649976E-02
Epoch took 0.882s

Epoch 34 of 200
  training loss:		2.726230E-02
  validation loss:		2.698508E-02
Epoch took 0.879s

Epoch 35 of 200
  training loss:		2.699745E-02
  validation loss:		2.660902E-02
Epoch took 0.878s

Epoch 36 of 200
  training loss:		2.703202E-02
  validation loss:		2.658775E-02
Epoch took 0.879s

Epoch 37 of 200
  training loss:		2.706481E-02
  validation loss:		2.741828E-02
Epoch took 0.880s

Epoch 38 of 200
  training loss:		2.692634E-02
  validation loss:		2.659206E-02
Epoch took 0.879s

Epoch 39 of 200
  training loss:		2.695337E-02
  validation loss:		2.687497E-02
Epoch took 0.880s

Epoch 40 of 200
  training loss:		2.681877E-02
  validation loss:		2.665210E-02
Epoch took 0.879s

Epoch 41 of 200
  training loss:		2.693377E-02
  validation loss:		2.648684E-02
Epoch took 0.878s

Epoch 42 of 200
  training loss:		2.685517E-02
  validation loss:		2.645896E-02
Epoch took 0.880s

Epoch 43 of 200
  training loss:		2.670144E-02
  validation loss:		2.658469E-02
Epoch took 0.879s

Epoch 44 of 200
  training loss:		2.662508E-02
  validation loss:		2.676576E-02
Epoch took 0.878s

Epoch 45 of 200
  training loss:		2.674559E-02
  validation loss:		2.674396E-02
Epoch took 0.878s

Epoch 46 of 200
  training loss:		2.669566E-02
  validation loss:		2.640003E-02
Epoch took 0.879s

Epoch 47 of 200
  training loss:		2.679228E-02
  validation loss:		2.660294E-02
Epoch took 0.879s

Epoch 48 of 200
  training loss:		2.662416E-02
  validation loss:		2.640563E-02
Epoch took 0.879s

Epoch 49 of 200
  training loss:		2.692681E-02
  validation loss:		2.622173E-02
Epoch took 0.880s

Epoch 50 of 200
  training loss:		2.663290E-02
  validation loss:		2.640603E-02
Epoch took 0.879s

Epoch 51 of 200
  training loss:		2.660814E-02
  validation loss:		2.658474E-02
Epoch took 0.878s

Epoch 52 of 200
  training loss:		2.658687E-02
  validation loss:		2.640393E-02
Epoch took 0.879s

Epoch 53 of 200
  training loss:		2.659103E-02
  validation loss:		2.660659E-02
Epoch took 0.878s

Epoch 54 of 200
  training loss:		2.662739E-02
  validation loss:		2.635319E-02
Epoch took 0.878s

Epoch 55 of 200
  training loss:		2.651179E-02
  validation loss:		2.662149E-02
Epoch took 0.879s

Epoch 56 of 200
  training loss:		2.654558E-02
  validation loss:		2.648673E-02
Epoch took 0.878s

Epoch 57 of 200
  training loss:		2.645546E-02
  validation loss:		2.639881E-02
Epoch took 0.879s

Epoch 58 of 200
  training loss:		2.648726E-02
  validation loss:		2.625304E-02
Epoch took 0.879s

Epoch 59 of 200
  training loss:		2.647914E-02
  validation loss:		2.643413E-02
Epoch took 0.878s

Epoch 60 of 200
  training loss:		2.658245E-02
  validation loss:		2.642781E-02
Epoch took 0.879s

Epoch 61 of 200
  training loss:		2.637578E-02
  validation loss:		2.609150E-02
Epoch took 0.879s

Epoch 62 of 200
  training loss:		2.658071E-02
  validation loss:		2.649251E-02
Epoch took 0.878s

Epoch 63 of 200
  training loss:		2.643477E-02
  validation loss:		2.617164E-02
Epoch took 0.879s

Epoch 64 of 200
  training loss:		2.636400E-02
  validation loss:		2.618430E-02
Epoch took 0.880s

Epoch 65 of 200
  training loss:		2.635130E-02
  validation loss:		2.625274E-02
Epoch took 0.879s

Epoch 66 of 200
  training loss:		2.645166E-02
  validation loss:		2.610503E-02
Epoch took 0.878s

Epoch 67 of 200
  training loss:		2.639364E-02
  validation loss:		2.614093E-02
Epoch took 0.878s

Epoch 68 of 200
  training loss:		2.639870E-02
  validation loss:		2.629761E-02
Epoch took 0.879s

Epoch 69 of 200
  training loss:		2.635605E-02
  validation loss:		2.608592E-02
Epoch took 0.878s

Epoch 70 of 200
  training loss:		2.634420E-02
  validation loss:		2.612064E-02
Epoch took 0.878s

Epoch 71 of 200
  training loss:		2.640878E-02
  validation loss:		2.598366E-02
Epoch took 0.878s

Epoch 72 of 200
  training loss:		2.636093E-02
  validation loss:		2.621538E-02
Epoch took 0.879s

Epoch 73 of 200
  training loss:		2.625830E-02
  validation loss:		2.612497E-02
Epoch took 0.878s

Epoch 74 of 200
  training loss:		2.629113E-02
  validation loss:		2.604528E-02
Epoch took 0.878s

Epoch 75 of 200
  training loss:		2.630064E-02
  validation loss:		2.612141E-02
Epoch took 0.878s

Epoch 76 of 200
  training loss:		2.639152E-02
  validation loss:		2.604775E-02
Epoch took 0.879s

Epoch 77 of 200
  training loss:		2.630150E-02
  validation loss:		2.607680E-02
Epoch took 0.878s

Epoch 78 of 200
  training loss:		2.626221E-02
  validation loss:		2.611052E-02
Epoch took 0.878s

Epoch 79 of 200
  training loss:		2.637491E-02
  validation loss:		2.627522E-02
Epoch took 0.878s

Epoch 80 of 200
  training loss:		2.644470E-02
  validation loss:		2.601330E-02
Epoch took 0.878s

Epoch 81 of 200
  training loss:		2.625642E-02
  validation loss:		2.598798E-02
Epoch took 0.879s

Epoch 82 of 200
  training loss:		2.622238E-02
  validation loss:		2.594098E-02
Epoch took 0.878s

Epoch 83 of 200
  training loss:		2.624030E-02
  validation loss:		2.594339E-02
Epoch took 0.878s

Epoch 84 of 200
  training loss:		2.618892E-02
  validation loss:		2.614121E-02
Epoch took 0.879s

Epoch 85 of 200
  training loss:		2.623285E-02
  validation loss:		2.610938E-02
Epoch took 0.878s

Epoch 86 of 200
  training loss:		2.636082E-02
  validation loss:		2.617097E-02
Epoch took 0.878s

Epoch 87 of 200
  training loss:		2.621473E-02
  validation loss:		2.625540E-02
Epoch took 0.879s

Epoch 88 of 200
  training loss:		2.617655E-02
  validation loss:		2.605650E-02
Epoch took 0.878s

Epoch 89 of 200
  training loss:		2.626526E-02
  validation loss:		2.619152E-02
Epoch took 0.878s

Epoch 90 of 200
  training loss:		2.625404E-02
  validation loss:		2.604116E-02
Epoch took 0.878s

Epoch 91 of 200
  training loss:		2.623191E-02
  validation loss:		2.604139E-02
Epoch took 0.879s

Epoch 92 of 200
  training loss:		2.625794E-02
  validation loss:		2.617588E-02
Epoch took 0.878s

Epoch 93 of 200
  training loss:		2.619689E-02
  validation loss:		2.594424E-02
Epoch took 0.879s

Epoch 94 of 200
  training loss:		2.630438E-02
  validation loss:		2.611407E-02
Epoch took 0.878s

Epoch 95 of 200
  training loss:		2.618265E-02
  validation loss:		2.600645E-02
Epoch took 0.878s

Epoch 96 of 200
  training loss:		2.616940E-02
  validation loss:		2.593716E-02
Epoch took 0.878s

Epoch 97 of 200
  training loss:		2.625901E-02
  validation loss:		2.628514E-02
Epoch took 0.878s

Epoch 98 of 200
  training loss:		2.617052E-02
  validation loss:		2.596898E-02
Epoch took 0.879s

Epoch 99 of 200
  training loss:		2.613521E-02
  validation loss:		2.615439E-02
Epoch took 0.878s

Epoch 100 of 200
  training loss:		2.613154E-02
  validation loss:		2.593887E-02
Epoch took 0.878s

Epoch 101 of 200
  training loss:		2.615921E-02
  validation loss:		2.648839E-02
Epoch took 0.878s

Epoch 102 of 200
  training loss:		2.617877E-02
  validation loss:		2.635751E-02
Epoch took 0.879s

Epoch 103 of 200
  training loss:		2.613602E-02
  validation loss:		2.591421E-02
Epoch took 0.878s

Epoch 104 of 200
  training loss:		2.615055E-02
  validation loss:		2.603217E-02
Epoch took 0.878s

Epoch 105 of 200
  training loss:		2.615207E-02
  validation loss:		2.594171E-02
Epoch took 0.878s

Epoch 106 of 200
  training loss:		2.608135E-02
  validation loss:		2.615440E-02
Epoch took 0.879s

Epoch 107 of 200
  training loss:		2.625602E-02
  validation loss:		2.688523E-02
Epoch took 0.879s

Epoch 108 of 200
  training loss:		2.620045E-02
  validation loss:		2.596274E-02
Epoch took 0.878s

Epoch 109 of 200
  training loss:		2.612674E-02
  validation loss:		2.619846E-02
Epoch took 0.879s

Epoch 110 of 200
  training loss:		2.609555E-02
  validation loss:		2.593137E-02
Epoch took 0.878s

Epoch 111 of 200
  training loss:		2.611190E-02
  validation loss:		2.593963E-02
Epoch took 0.878s

Epoch 112 of 200
  training loss:		2.608531E-02
  validation loss:		2.572366E-02
Epoch took 0.880s

Epoch 113 of 200
  training loss:		2.612298E-02
  validation loss:		2.589159E-02
Epoch took 0.880s

Epoch 114 of 200
  training loss:		2.610876E-02
  validation loss:		2.599405E-02
Epoch took 0.879s

Epoch 115 of 200
  training loss:		2.622264E-02
  validation loss:		2.594142E-02
Epoch took 0.879s

Epoch 116 of 200
  training loss:		2.606643E-02
  validation loss:		2.593210E-02
Epoch took 0.879s

Epoch 117 of 200
  training loss:		2.607334E-02
  validation loss:		2.596031E-02
Epoch took 0.879s

Epoch 118 of 200
  training loss:		2.606500E-02
  validation loss:		2.587419E-02
Epoch took 0.879s

Epoch 119 of 200
  training loss:		2.608455E-02
  validation loss:		2.599374E-02
Epoch took 0.879s

Epoch 120 of 200
  training loss:		2.607498E-02
  validation loss:		2.590648E-02
Epoch took 0.878s

Epoch 121 of 200
  training loss:		2.606088E-02
  validation loss:		2.595481E-02
Epoch took 0.879s

Epoch 122 of 200
  training loss:		2.607707E-02
  validation loss:		2.630160E-02
Epoch took 0.879s

Epoch 123 of 200
  training loss:		2.628596E-02
  validation loss:		2.598579E-02
Epoch took 0.878s

Epoch 124 of 200
  training loss:		2.601888E-02
  validation loss:		2.581677E-02
Epoch took 0.879s

Epoch 125 of 200
  training loss:		2.606593E-02
  validation loss:		2.588118E-02
Epoch took 0.878s

Epoch 126 of 200
  training loss:		2.604420E-02
  validation loss:		2.593005E-02
Epoch took 0.878s

Epoch 127 of 200
  training loss:		2.603822E-02
  validation loss:		2.607745E-02
Epoch took 0.879s

Epoch 128 of 200
  training loss:		2.625786E-02
  validation loss:		2.599335E-02
Epoch took 0.878s

Epoch 129 of 200
  training loss:		2.603925E-02
  validation loss:		2.593795E-02
Epoch took 0.879s

Epoch 130 of 200
  training loss:		2.604402E-02
  validation loss:		2.591273E-02
Epoch took 0.880s

Epoch 131 of 200
  training loss:		2.600038E-02
  validation loss:		2.584178E-02
Epoch took 0.878s

Epoch 132 of 200
  training loss:		2.608980E-02
  validation loss:		2.590679E-02
Epoch took 0.878s

Epoch 133 of 200
  training loss:		2.604497E-02
  validation loss:		2.592690E-02
Epoch took 0.879s

Epoch 134 of 200
  training loss:		2.603202E-02
  validation loss:		2.592858E-02
Epoch took 0.878s

Epoch 135 of 200
  training loss:		2.604445E-02
  validation loss:		2.592388E-02
Epoch took 0.878s

Epoch 136 of 200
  training loss:		2.601844E-02
  validation loss:		2.583410E-02
Epoch took 0.879s

Epoch 137 of 200
  training loss:		2.615678E-02
  validation loss:		2.589459E-02
Epoch took 0.878s

Epoch 138 of 200
  training loss:		2.606452E-02
  validation loss:		2.581579E-02
Epoch took 0.879s

Epoch 139 of 200
  training loss:		2.601924E-02
  validation loss:		2.596533E-02
Epoch took 0.878s

Epoch 140 of 200
  training loss:		2.601092E-02
  validation loss:		2.585118E-02
Epoch took 0.878s

Epoch 141 of 200
  training loss:		2.596182E-02
  validation loss:		2.585340E-02
Epoch took 0.878s

Epoch 142 of 200
  training loss:		2.612413E-02
  validation loss:		2.592533E-02
Epoch took 0.878s

Epoch 143 of 200
  training loss:		2.599113E-02
  validation loss:		2.587482E-02
Epoch took 0.879s

Epoch 144 of 200
  training loss:		2.597796E-02
  validation loss:		2.574506E-02
Epoch took 0.878s

Epoch 145 of 200
  training loss:		2.600657E-02
  validation loss:		2.572676E-02
Epoch took 0.878s

Epoch 146 of 200
  training loss:		2.599050E-02
  validation loss:		2.587292E-02
Epoch took 0.878s

Epoch 147 of 200
  training loss:		2.602912E-02
  validation loss:		2.572853E-02
Epoch took 0.879s

Epoch 148 of 200
  training loss:		2.608087E-02
  validation loss:		2.587034E-02
Epoch took 0.878s

Epoch 149 of 200
  training loss:		2.597933E-02
  validation loss:		2.589938E-02
Epoch took 0.878s

Epoch 150 of 200
  training loss:		2.599405E-02
  validation loss:		2.578009E-02
Epoch took 0.879s

Epoch 151 of 200
  training loss:		2.594343E-02
  validation loss:		2.586110E-02
Epoch took 0.879s

Epoch 152 of 200
  training loss:		2.598639E-02
  validation loss:		2.580975E-02
Epoch took 0.878s

Epoch 153 of 200
  training loss:		2.597701E-02
  validation loss:		2.601065E-02
Epoch took 0.878s

Epoch 154 of 200
  training loss:		2.603236E-02
  validation loss:		2.597879E-02
Epoch took 0.879s

Epoch 155 of 200
  training loss:		2.597551E-02
  validation loss:		2.580461E-02
Epoch took 0.879s

Epoch 156 of 200
  training loss:		2.601763E-02
  validation loss:		2.576380E-02
Epoch took 0.879s

Epoch 157 of 200
  training loss:		2.597265E-02
  validation loss:		2.591415E-02
Epoch took 0.880s

Epoch 158 of 200
  training loss:		2.602042E-02
  validation loss:		2.577245E-02
Epoch took 0.879s

Epoch 159 of 200
  training loss:		2.605125E-02
  validation loss:		2.585242E-02
Epoch took 0.880s

Epoch 160 of 200
  training loss:		2.596377E-02
  validation loss:		2.594861E-02
Epoch took 0.880s

Epoch 161 of 200
  training loss:		2.599022E-02
  validation loss:		2.582565E-02
Epoch took 0.880s

Epoch 162 of 200
  training loss:		2.595190E-02
  validation loss:		2.585737E-02
Epoch took 0.880s

Epoch 163 of 200
  training loss:		2.597788E-02
  validation loss:		2.583948E-02
Epoch took 0.879s

Epoch 164 of 200
  training loss:		2.597508E-02
  validation loss:		2.580049E-02
Epoch took 0.879s

Epoch 165 of 200
  training loss:		2.596204E-02
  validation loss:		2.677442E-02
Epoch took 0.880s

Early stopping, val-loss increased over the last 15 epochs from 0.0258425072537 to 0.0259209160017
Saving model from epoch 150
Training MSE: 2.48165e-14
Validation MSE: 2.47499e-14
Training R2: 0.736884642952
Validation R2: 0.737696620614
