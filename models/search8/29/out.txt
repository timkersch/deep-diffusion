Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		3.993990E-01
  validation loss:		2.153502E-01
Epoch took 2.020s

Epoch 2 of 500
  training loss:		2.248673E-01
  validation loss:		1.304128E-01
Epoch took 2.013s

Epoch 3 of 500
  training loss:		1.843380E-01
  validation loss:		1.063067E-01
Epoch took 2.013s

Epoch 4 of 500
  training loss:		1.642259E-01
  validation loss:		8.619035E-02
Epoch took 2.013s

Epoch 5 of 500
  training loss:		1.503618E-01
  validation loss:		8.782110E-02
Epoch took 2.013s

Epoch 6 of 500
  training loss:		1.398378E-01
  validation loss:		7.762489E-02
Epoch took 2.013s

Epoch 7 of 500
  training loss:		1.319943E-01
  validation loss:		7.547284E-02
Epoch took 2.014s

Epoch 8 of 500
  training loss:		1.246951E-01
  validation loss:		6.574534E-02
Epoch took 2.013s

Epoch 9 of 500
  training loss:		1.181753E-01
  validation loss:		6.337116E-02
Epoch took 2.013s

Epoch 10 of 500
  training loss:		1.126723E-01
  validation loss:		5.991655E-02
Epoch took 2.013s

Epoch 11 of 500
  training loss:		1.071538E-01
  validation loss:		6.214540E-02
Epoch took 2.013s

Epoch 12 of 500
  training loss:		1.038717E-01
  validation loss:		5.220981E-02
Epoch took 2.013s

Epoch 13 of 500
  training loss:		9.813083E-02
  validation loss:		5.410574E-02
Epoch took 2.013s

Epoch 14 of 500
  training loss:		9.598138E-02
  validation loss:		5.027922E-02
Epoch took 2.013s

Epoch 15 of 500
  training loss:		9.193073E-02
  validation loss:		4.870466E-02
Epoch took 2.013s

Epoch 16 of 500
  training loss:		8.969418E-02
  validation loss:		4.674392E-02
Epoch took 2.013s

Epoch 17 of 500
  training loss:		8.712979E-02
  validation loss:		4.345315E-02
Epoch took 2.013s

Epoch 18 of 500
  training loss:		8.403253E-02
  validation loss:		4.177067E-02
Epoch took 2.013s

Epoch 19 of 500
  training loss:		8.089991E-02
  validation loss:		3.973282E-02
Epoch took 2.013s

Epoch 20 of 500
  training loss:		7.903383E-02
  validation loss:		4.170274E-02
Epoch took 2.013s

Epoch 21 of 500
  training loss:		7.598937E-02
  validation loss:		4.188910E-02
Epoch took 2.013s

Epoch 22 of 500
  training loss:		7.412510E-02
  validation loss:		3.849095E-02
Epoch took 2.013s

Epoch 23 of 500
  training loss:		7.249338E-02
  validation loss:		3.586892E-02
Epoch took 2.013s

Epoch 24 of 500
  training loss:		7.016592E-02
  validation loss:		3.649339E-02
Epoch took 2.013s

Epoch 25 of 500
  training loss:		6.828496E-02
  validation loss:		3.424050E-02
Epoch took 2.013s

Epoch 26 of 500
  training loss:		6.597188E-02
  validation loss:		3.387733E-02
Epoch took 2.013s

Epoch 27 of 500
  training loss:		6.378063E-02
  validation loss:		3.118173E-02
Epoch took 2.014s

Epoch 28 of 500
  training loss:		6.291828E-02
  validation loss:		3.330919E-02
Epoch took 2.014s

Epoch 29 of 500
  training loss:		6.170268E-02
  validation loss:		3.396751E-02
Epoch took 2.014s

Epoch 30 of 500
  training loss:		5.951421E-02
  validation loss:		3.399620E-02
Epoch took 2.013s

Epoch 31 of 500
  training loss:		5.795206E-02
  validation loss:		2.893470E-02
Epoch took 2.014s

Epoch 32 of 500
  training loss:		5.697299E-02
  validation loss:		2.920060E-02
Epoch took 2.014s

Epoch 33 of 500
  training loss:		5.548298E-02
  validation loss:		2.824171E-02
Epoch took 2.014s

Epoch 34 of 500
  training loss:		5.456597E-02
  validation loss:		2.772719E-02
Epoch took 2.014s

Epoch 35 of 500
  training loss:		5.198634E-02
  validation loss:		2.731192E-02
Epoch took 2.014s

Epoch 36 of 500
  training loss:		5.107216E-02
  validation loss:		2.932503E-02
Epoch took 2.013s

Epoch 37 of 500
  training loss:		4.976698E-02
  validation loss:		2.733102E-02
Epoch took 2.013s

Epoch 38 of 500
  training loss:		4.873958E-02
  validation loss:		2.535645E-02
Epoch took 2.014s

Epoch 39 of 500
  training loss:		4.794589E-02
  validation loss:		2.446652E-02
Epoch took 2.013s

Epoch 40 of 500
  training loss:		4.581907E-02
  validation loss:		2.615775E-02
Epoch took 2.013s

Epoch 41 of 500
  training loss:		4.538122E-02
  validation loss:		2.439945E-02
Epoch took 2.014s

Epoch 42 of 500
  training loss:		4.347121E-02
  validation loss:		2.496198E-02
Epoch took 2.014s

Epoch 43 of 500
  training loss:		4.248190E-02
  validation loss:		2.173258E-02
Epoch took 2.015s

Epoch 44 of 500
  training loss:		4.134261E-02
  validation loss:		2.257488E-02
Epoch took 2.013s

Epoch 45 of 500
  training loss:		4.011089E-02
  validation loss:		2.118051E-02
Epoch took 2.014s

Epoch 46 of 500
  training loss:		3.956691E-02
  validation loss:		2.077663E-02
Epoch took 2.013s

Epoch 47 of 500
  training loss:		3.856357E-02
  validation loss:		2.321796E-02
Epoch took 2.013s

Epoch 48 of 500
  training loss:		3.738220E-02
  validation loss:		2.247166E-02
Epoch took 2.013s

Epoch 49 of 500
  training loss:		3.685657E-02
  validation loss:		2.062038E-02
Epoch took 2.013s

Epoch 50 of 500
  training loss:		3.581861E-02
  validation loss:		1.854041E-02
Epoch took 2.013s

Epoch 51 of 500
  training loss:		3.505439E-02
  validation loss:		2.052310E-02
Epoch took 2.013s

Epoch 52 of 500
  training loss:		3.444185E-02
  validation loss:		1.846351E-02
Epoch took 2.013s

Epoch 53 of 500
  training loss:		3.343230E-02
  validation loss:		1.918045E-02
Epoch took 2.014s

Epoch 54 of 500
  training loss:		3.241085E-02
  validation loss:		1.842947E-02
Epoch took 2.013s

Epoch 55 of 500
  training loss:		3.193706E-02
  validation loss:		1.829350E-02
Epoch took 2.013s

Epoch 56 of 500
  training loss:		3.122464E-02
  validation loss:		1.962529E-02
Epoch took 2.013s

Epoch 57 of 500
  training loss:		2.988013E-02
  validation loss:		1.750405E-02
Epoch took 2.013s

Epoch 58 of 500
  training loss:		2.974525E-02
  validation loss:		1.878008E-02
Epoch took 2.013s

Epoch 59 of 500
  training loss:		2.901197E-02
  validation loss:		1.491661E-02
Epoch took 2.013s

Epoch 60 of 500
  training loss:		2.852836E-02
  validation loss:		1.773793E-02
Epoch took 2.013s

Epoch 61 of 500
  training loss:		2.788180E-02
  validation loss:		1.592324E-02
Epoch took 2.013s

Epoch 62 of 500
  training loss:		2.729315E-02
  validation loss:		1.627782E-02
Epoch took 2.013s

Epoch 63 of 500
  training loss:		2.669573E-02
  validation loss:		1.833993E-02
Epoch took 2.013s

Epoch 64 of 500
  training loss:		2.582566E-02
  validation loss:		1.430850E-02
Epoch took 2.013s

Epoch 65 of 500
  training loss:		2.539248E-02
  validation loss:		1.780609E-02
Epoch took 2.013s

Epoch 66 of 500
  training loss:		2.462779E-02
  validation loss:		1.557721E-02
Epoch took 2.013s

Epoch 67 of 500
  training loss:		2.414321E-02
  validation loss:		1.571441E-02
Epoch took 2.013s

Epoch 68 of 500
  training loss:		2.324857E-02
  validation loss:		1.538117E-02
Epoch took 2.013s

Epoch 69 of 500
  training loss:		2.264493E-02
  validation loss:		1.549540E-02
Epoch took 2.013s

Epoch 70 of 500
  training loss:		2.230780E-02
  validation loss:		1.323939E-02
Epoch took 2.013s

Epoch 71 of 500
  training loss:		2.163019E-02
  validation loss:		1.515514E-02
Epoch took 2.013s

Epoch 72 of 500
  training loss:		2.161177E-02
  validation loss:		1.118130E-02
Epoch took 2.016s

Epoch 73 of 500
  training loss:		2.102976E-02
  validation loss:		1.273682E-02
Epoch took 2.014s

Epoch 74 of 500
  training loss:		2.076628E-02
  validation loss:		1.286176E-02
Epoch took 2.013s

Epoch 75 of 500
  training loss:		2.005318E-02
  validation loss:		1.268678E-02
Epoch took 2.013s

Epoch 76 of 500
  training loss:		1.981431E-02
  validation loss:		1.045101E-02
Epoch took 2.013s

Epoch 77 of 500
  training loss:		1.937217E-02
  validation loss:		1.328925E-02
Epoch took 2.013s

Epoch 78 of 500
  training loss:		1.943065E-02
  validation loss:		1.383348E-02
Epoch took 2.013s

Epoch 79 of 500
  training loss:		1.875506E-02
  validation loss:		1.257792E-02
Epoch took 2.013s

Epoch 80 of 500
  training loss:		1.798385E-02
  validation loss:		1.130220E-02
Epoch took 2.013s

Epoch 81 of 500
  training loss:		1.804571E-02
  validation loss:		1.145585E-02
Epoch took 2.013s

Epoch 82 of 500
  training loss:		1.748860E-02
  validation loss:		1.156404E-02
Epoch took 2.013s

Epoch 83 of 500
  training loss:		1.756172E-02
  validation loss:		1.264157E-02
Epoch took 2.013s

Epoch 84 of 500
  training loss:		1.696993E-02
  validation loss:		1.029631E-02
Epoch took 2.014s

Epoch 85 of 500
  training loss:		1.685346E-02
  validation loss:		1.175909E-02
Epoch took 2.013s

Epoch 86 of 500
  training loss:		1.629460E-02
  validation loss:		1.076323E-02
Epoch took 2.013s

Epoch 87 of 500
  training loss:		1.605174E-02
  validation loss:		1.249978E-02
Epoch took 2.013s

Epoch 88 of 500
  training loss:		1.583370E-02
  validation loss:		9.082018E-03
Epoch took 2.013s

Epoch 89 of 500
  training loss:		1.552497E-02
  validation loss:		9.761397E-03
Epoch took 2.013s

Epoch 90 of 500
  training loss:		1.530539E-02
  validation loss:		1.056128E-02
Epoch took 2.013s

Epoch 91 of 500
  training loss:		1.497653E-02
  validation loss:		1.124798E-02
Epoch took 2.014s

Epoch 92 of 500
  training loss:		1.468386E-02
  validation loss:		1.110490E-02
Epoch took 2.014s

Epoch 93 of 500
  training loss:		1.456468E-02
  validation loss:		8.834248E-03
Epoch took 2.014s

Epoch 94 of 500
  training loss:		1.435969E-02
  validation loss:		9.021817E-03
Epoch took 2.013s

Epoch 95 of 500
  training loss:		1.415848E-02
  validation loss:		9.355312E-03
Epoch took 2.013s

Epoch 96 of 500
  training loss:		1.389288E-02
  validation loss:		9.938799E-03
Epoch took 2.013s

Epoch 97 of 500
  training loss:		1.399426E-02
  validation loss:		8.496599E-03
Epoch took 2.014s

Epoch 98 of 500
  training loss:		1.331673E-02
  validation loss:		9.250245E-03
Epoch took 2.013s

Epoch 99 of 500
  training loss:		1.322585E-02
  validation loss:		8.932998E-03
Epoch took 2.014s

Epoch 100 of 500
  training loss:		1.307882E-02
  validation loss:		7.862481E-03
Epoch took 2.013s

Epoch 101 of 500
  training loss:		1.297738E-02
  validation loss:		8.006959E-03
Epoch took 2.013s

Epoch 102 of 500
  training loss:		1.264678E-02
  validation loss:		9.481108E-03
Epoch took 2.013s

Epoch 103 of 500
  training loss:		1.284671E-02
  validation loss:		7.896820E-03
Epoch took 2.013s

Epoch 104 of 500
  training loss:		1.232836E-02
  validation loss:		7.877459E-03
Epoch took 2.013s

Epoch 105 of 500
  training loss:		1.231480E-02
  validation loss:		9.385120E-03
Epoch took 2.014s

Epoch 106 of 500
  training loss:		1.213832E-02
  validation loss:		9.833498E-03
Epoch took 2.013s

Epoch 107 of 500
  training loss:		1.193473E-02
  validation loss:		7.730198E-03
Epoch took 2.013s

Epoch 108 of 500
  training loss:		1.188577E-02
  validation loss:		8.558756E-03
Epoch took 2.012s

Epoch 109 of 500
  training loss:		1.160173E-02
  validation loss:		6.688848E-03
Epoch took 2.013s

Epoch 110 of 500
  training loss:		1.159400E-02
  validation loss:		1.056337E-02
Epoch took 2.013s

Epoch 111 of 500
  training loss:		1.152225E-02
  validation loss:		7.136061E-03
Epoch took 2.013s

Epoch 112 of 500
  training loss:		1.115110E-02
  validation loss:		7.937796E-03
Epoch took 2.013s

Epoch 113 of 500
  training loss:		1.108992E-02
  validation loss:		6.672607E-03
Epoch took 2.013s

Epoch 114 of 500
  training loss:		1.097055E-02
  validation loss:		6.911443E-03
Epoch took 2.013s

Epoch 115 of 500
  training loss:		1.092037E-02
  validation loss:		7.621717E-03
Epoch took 2.013s

Epoch 116 of 500
  training loss:		1.089186E-02
  validation loss:		6.375268E-03
Epoch took 2.013s

Epoch 117 of 500
  training loss:		1.081389E-02
  validation loss:		8.633790E-03
Epoch took 2.013s

Epoch 118 of 500
  training loss:		1.055915E-02
  validation loss:		9.659116E-03
Epoch took 2.013s

Epoch 119 of 500
  training loss:		1.037944E-02
  validation loss:		7.169759E-03
Epoch took 2.013s

Epoch 120 of 500
  training loss:		1.021452E-02
  validation loss:		7.115951E-03
Epoch took 2.013s

Epoch 121 of 500
  training loss:		1.024369E-02
  validation loss:		7.006983E-03
Epoch took 2.013s

Epoch 122 of 500
  training loss:		1.005788E-02
  validation loss:		6.943671E-03
Epoch took 2.013s

Epoch 123 of 500
  training loss:		9.954070E-03
  validation loss:		8.103477E-03
Epoch took 2.013s

Epoch 124 of 500
  training loss:		9.818091E-03
  validation loss:		7.164678E-03
Epoch took 2.013s

Epoch 125 of 500
  training loss:		9.896790E-03
  validation loss:		8.049627E-03
Epoch took 2.013s

Epoch 126 of 500
  training loss:		9.671086E-03
  validation loss:		6.456913E-03
Epoch took 2.013s

Epoch 127 of 500
  training loss:		9.679328E-03
  validation loss:		5.853641E-03
Epoch took 2.013s

Epoch 128 of 500
  training loss:		9.341298E-03
  validation loss:		6.255993E-03
Epoch took 2.013s

Epoch 129 of 500
  training loss:		9.548114E-03
  validation loss:		9.091027E-03
Epoch took 2.014s

Epoch 130 of 500
  training loss:		9.384896E-03
  validation loss:		7.350110E-03
Epoch took 2.013s

Epoch 131 of 500
  training loss:		9.185058E-03
  validation loss:		5.757888E-03
Epoch took 2.012s

Epoch 132 of 500
  training loss:		9.216509E-03
  validation loss:		6.895751E-03
Epoch took 2.013s

Epoch 133 of 500
  training loss:		9.182680E-03
  validation loss:		7.555263E-03
Epoch took 2.013s

Epoch 134 of 500
  training loss:		8.959851E-03
  validation loss:		7.225616E-03
Epoch took 2.012s

Epoch 135 of 500
  training loss:		8.923703E-03
  validation loss:		5.849367E-03
Epoch took 2.013s

Epoch 136 of 500
  training loss:		8.813650E-03
  validation loss:		7.325641E-03
Epoch took 2.013s

Epoch 137 of 500
  training loss:		8.783775E-03
  validation loss:		6.881683E-03
Epoch took 2.014s

Epoch 138 of 500
  training loss:		8.831244E-03
  validation loss:		6.988435E-03
Epoch took 2.013s

Epoch 139 of 500
  training loss:		8.552403E-03
  validation loss:		7.204702E-03
Epoch took 2.014s

Epoch 140 of 500
  training loss:		8.486854E-03
  validation loss:		6.386099E-03
Epoch took 2.012s

Epoch 141 of 500
  training loss:		8.617918E-03
  validation loss:		8.066003E-03
Epoch took 2.014s

Epoch 142 of 500
  training loss:		8.471048E-03
  validation loss:		9.292948E-03
Epoch took 2.013s

Epoch 143 of 500
  training loss:		8.569786E-03
  validation loss:		6.640418E-03
Epoch took 2.014s

Epoch 144 of 500
  training loss:		8.122110E-03
  validation loss:		6.751285E-03
Epoch took 2.013s

Epoch 145 of 500
  training loss:		8.268287E-03
  validation loss:		6.761080E-03
Epoch took 2.013s

Epoch 146 of 500
  training loss:		8.246491E-03
  validation loss:		5.836083E-03
Epoch took 2.013s

Epoch 147 of 500
  training loss:		8.111669E-03
  validation loss:		6.426920E-03
Epoch took 2.013s

Epoch 148 of 500
  training loss:		8.123828E-03
  validation loss:		6.744360E-03
Epoch took 2.014s

Epoch 149 of 500
  training loss:		7.944268E-03
  validation loss:		7.747087E-03
Epoch took 2.013s

Epoch 150 of 500
  training loss:		7.952006E-03
  validation loss:		8.773392E-03
Epoch took 2.013s

Early stopping, val-loss increased over the last 15 epochs from 0.00703733366611 to 0.00718840908215
Saving model from epoch 135
Training RMSE: 0.00583257
Validation RMSE: 0.00587371
Test RMSE: 0.00588130159304
Test MSE: 3.4589706047e-05
Test MAE: 0.0045837839134
Test R2: -368235743.647 

