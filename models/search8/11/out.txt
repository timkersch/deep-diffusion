Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.379464E-01
  validation loss:		9.024397E-02
Epoch took 0.909s

Epoch 2 of 500
  training loss:		7.453847E-02
  validation loss:		5.804686E-02
Epoch took 0.872s

Epoch 3 of 500
  training loss:		5.646132E-02
  validation loss:		4.921906E-02
Epoch took 0.872s

Epoch 4 of 500
  training loss:		4.866572E-02
  validation loss:		4.142269E-02
Epoch took 0.872s

Epoch 5 of 500
  training loss:		4.057425E-02
  validation loss:		2.795629E-02
Epoch took 0.878s

Epoch 6 of 500
  training loss:		3.607903E-02
  validation loss:		3.652819E-02
Epoch took 0.878s

Epoch 7 of 500
  training loss:		3.164669E-02
  validation loss:		2.015945E-02
Epoch took 0.879s

Epoch 8 of 500
  training loss:		2.736266E-02
  validation loss:		2.250176E-02
Epoch took 0.878s

Epoch 9 of 500
  training loss:		2.637303E-02
  validation loss:		2.936778E-02
Epoch took 0.878s

Epoch 10 of 500
  training loss:		2.375012E-02
  validation loss:		1.917543E-02
Epoch took 0.878s

Epoch 11 of 500
  training loss:		2.255401E-02
  validation loss:		3.376333E-02
Epoch took 0.878s

Epoch 12 of 500
  training loss:		2.133995E-02
  validation loss:		2.946182E-02
Epoch took 0.878s

Epoch 13 of 500
  training loss:		1.960574E-02
  validation loss:		9.480851E-03
Epoch took 0.878s

Epoch 14 of 500
  training loss:		1.941472E-02
  validation loss:		1.957450E-02
Epoch took 0.878s

Epoch 15 of 500
  training loss:		1.842090E-02
  validation loss:		3.598635E-02
Epoch took 0.878s

Epoch 16 of 500
  training loss:		1.728266E-02
  validation loss:		1.852519E-02
Epoch took 0.878s

Epoch 17 of 500
  training loss:		1.667846E-02
  validation loss:		1.431540E-02
Epoch took 0.878s

Epoch 18 of 500
  training loss:		1.550167E-02
  validation loss:		1.395412E-02
Epoch took 0.878s

Epoch 19 of 500
  training loss:		1.688867E-02
  validation loss:		2.243268E-02
Epoch took 0.878s

Epoch 20 of 500
  training loss:		1.489132E-02
  validation loss:		1.354850E-02
Epoch took 0.878s

Epoch 21 of 500
  training loss:		1.343932E-02
  validation loss:		8.378541E-03
Epoch took 0.878s

Epoch 22 of 500
  training loss:		1.290058E-02
  validation loss:		7.165055E-03
Epoch took 0.878s

Epoch 23 of 500
  training loss:		1.442388E-02
  validation loss:		1.601326E-02
Epoch took 0.878s

Epoch 24 of 500
  training loss:		1.317908E-02
  validation loss:		8.442832E-03
Epoch took 0.878s

Epoch 25 of 500
  training loss:		1.230983E-02
  validation loss:		6.530097E-03
Epoch took 0.878s

Epoch 26 of 500
  training loss:		1.215143E-02
  validation loss:		9.964765E-03
Epoch took 0.878s

Epoch 27 of 500
  training loss:		1.247711E-02
  validation loss:		9.593951E-03
Epoch took 0.878s

Epoch 28 of 500
  training loss:		1.224296E-02
  validation loss:		1.122959E-02
Epoch took 0.878s

Epoch 29 of 500
  training loss:		1.126786E-02
  validation loss:		1.729892E-02
Epoch took 0.878s

Epoch 30 of 500
  training loss:		1.143277E-02
  validation loss:		1.115558E-02
Epoch took 0.878s

Epoch 31 of 500
  training loss:		1.042019E-02
  validation loss:		1.272744E-02
Epoch took 0.878s

Epoch 32 of 500
  training loss:		1.014347E-02
  validation loss:		4.779227E-03
Epoch took 0.878s

Epoch 33 of 500
  training loss:		9.691651E-03
  validation loss:		7.838562E-03
Epoch took 0.878s

Epoch 34 of 500
  training loss:		9.878669E-03
  validation loss:		8.205008E-03
Epoch took 0.878s

Epoch 35 of 500
  training loss:		9.997026E-03
  validation loss:		1.518238E-02
Epoch took 0.878s

Epoch 36 of 500
  training loss:		9.767646E-03
  validation loss:		9.638916E-03
Epoch took 0.878s

Epoch 37 of 500
  training loss:		1.050774E-02
  validation loss:		5.419152E-03
Epoch took 0.878s

Epoch 38 of 500
  training loss:		9.561796E-03
  validation loss:		1.128813E-02
Epoch took 0.878s

Epoch 39 of 500
  training loss:		9.926436E-03
  validation loss:		2.039399E-02
Epoch took 0.878s

Epoch 40 of 500
  training loss:		9.972254E-03
  validation loss:		1.143417E-02
Epoch took 0.878s

Early stopping, val-loss increased over the last 10 epochs from 0.0105772594283 to 0.0106906972985
Saving model from epoch 30
Training RMSE: 0.0111616
Validation RMSE: 0.0111686
Test RMSE: 0.0110654328018
Test MSE: 0.000122443801956
Test MAE: 0.00912398565561
Test R2: -1303514538.0 

