Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.009837E-01
  validation loss:		3.255506E-02
Epoch took 2.061s

Epoch 2 of 500
  training loss:		3.664737E-02
  validation loss:		1.555941E-02
Epoch took 2.015s

Epoch 3 of 500
  training loss:		2.700059E-02
  validation loss:		2.167308E-02
Epoch took 2.014s

Epoch 4 of 500
  training loss:		2.103188E-02
  validation loss:		1.309756E-02
Epoch took 2.012s

Epoch 5 of 500
  training loss:		1.935286E-02
  validation loss:		2.026636E-02
Epoch took 2.012s

Epoch 6 of 500
  training loss:		1.740329E-02
  validation loss:		8.445796E-03
Epoch took 2.012s

Epoch 7 of 500
  training loss:		1.495100E-02
  validation loss:		1.104923E-02
Epoch took 2.014s

Epoch 8 of 500
  training loss:		1.385022E-02
  validation loss:		2.436643E-02
Epoch took 2.012s

Epoch 9 of 500
  training loss:		1.247783E-02
  validation loss:		9.170803E-03
Epoch took 2.013s

Epoch 10 of 500
  training loss:		1.252542E-02
  validation loss:		8.302767E-03
Epoch took 2.012s

Epoch 11 of 500
  training loss:		1.080511E-02
  validation loss:		1.279616E-02
Epoch took 2.012s

Epoch 12 of 500
  training loss:		9.727517E-03
  validation loss:		1.448509E-02
Epoch took 2.012s

Epoch 13 of 500
  training loss:		9.034486E-03
  validation loss:		6.193666E-03
Epoch took 2.012s

Epoch 14 of 500
  training loss:		8.944102E-03
  validation loss:		1.344083E-02
Epoch took 2.012s

Epoch 15 of 500
  training loss:		8.872686E-03
  validation loss:		6.893015E-03
Epoch took 2.012s

Epoch 16 of 500
  training loss:		8.007893E-03
  validation loss:		1.035443E-02
Epoch took 2.012s

Epoch 17 of 500
  training loss:		7.616027E-03
  validation loss:		1.213684E-02
Epoch took 2.012s

Epoch 18 of 500
  training loss:		7.460695E-03
  validation loss:		1.502905E-02
Epoch took 2.012s

Epoch 19 of 500
  training loss:		6.802358E-03
  validation loss:		6.654809E-03
Epoch took 2.012s

Epoch 20 of 500
  training loss:		7.816797E-03
  validation loss:		1.047504E-02
Epoch took 2.012s

Epoch 21 of 500
  training loss:		6.976524E-03
  validation loss:		4.878768E-03
Epoch took 2.013s

Epoch 22 of 500
  training loss:		6.441137E-03
  validation loss:		3.766085E-03
Epoch took 2.012s

Epoch 23 of 500
  training loss:		6.573939E-03
  validation loss:		1.301318E-02
Epoch took 2.013s

Epoch 24 of 500
  training loss:		6.420635E-03
  validation loss:		8.623772E-03
Epoch took 2.013s

Epoch 25 of 500
  training loss:		6.460089E-03
  validation loss:		4.330897E-03
Epoch took 2.012s

Epoch 26 of 500
  training loss:		6.083475E-03
  validation loss:		8.585254E-03
Epoch took 2.012s

Epoch 27 of 500
  training loss:		5.967885E-03
  validation loss:		9.359385E-03
Epoch took 2.012s

Epoch 28 of 500
  training loss:		5.759426E-03
  validation loss:		8.150027E-03
Epoch took 2.013s

Epoch 29 of 500
  training loss:		5.371409E-03
  validation loss:		1.199032E-02
Epoch took 2.012s

Epoch 30 of 500
  training loss:		5.299688E-03
  validation loss:		5.636459E-03
Epoch took 2.012s

Epoch 31 of 500
  training loss:		5.522139E-03
  validation loss:		1.372710E-02
Epoch took 2.012s

Epoch 32 of 500
  training loss:		5.495531E-03
  validation loss:		3.134125E-03
Epoch took 2.012s

Epoch 33 of 500
  training loss:		5.322892E-03
  validation loss:		1.802797E-02
Epoch took 2.013s

Epoch 34 of 500
  training loss:		5.350043E-03
  validation loss:		7.285003E-03
Epoch took 2.012s

Epoch 35 of 500
  training loss:		4.752702E-03
  validation loss:		3.316350E-03
Epoch took 2.013s

Epoch 36 of 500
  training loss:		5.503609E-03
  validation loss:		2.023520E-03
Epoch took 2.013s

Epoch 37 of 500
  training loss:		4.907245E-03
  validation loss:		2.543746E-02
Epoch took 2.013s

Epoch 38 of 500
  training loss:		4.785650E-03
  validation loss:		8.875558E-03
Epoch took 2.013s

Epoch 39 of 500
  training loss:		4.778978E-03
  validation loss:		9.641444E-03
Epoch took 2.013s

Epoch 40 of 500
  training loss:		4.731941E-03
  validation loss:		4.070299E-03
Epoch took 2.013s

Early stopping, val-loss increased over the last 10 epochs from 0.0078334145565 to 0.00955388320295
Saving model from epoch 30
Training RMSE: 0.00565673
Validation RMSE: 0.00566788
Test RMSE: 0.00556480558589
Test MSE: 3.09670613206e-05
Test MAE: 0.00437929481268
Test R2: -329669740.602 

