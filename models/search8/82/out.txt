Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.896008E-01
  validation loss:		7.629532E+01
Epoch took 0.749s

Epoch 2 of 500
  training loss:		8.323182E-02
  validation loss:		2.810487E-01
Epoch took 0.701s

Epoch 3 of 500
  training loss:		6.640696E-02
  validation loss:		8.594861E-02
Epoch took 0.701s

Epoch 4 of 500
  training loss:		6.189802E-02
  validation loss:		7.142860E-02
Epoch took 0.701s

Epoch 5 of 500
  training loss:		5.569154E-02
  validation loss:		6.030396E-02
Epoch took 0.701s

Epoch 6 of 500
  training loss:		5.251249E-02
  validation loss:		7.446726E-02
Epoch took 0.701s

Epoch 7 of 500
  training loss:		5.499502E-02
  validation loss:		7.739589E-02
Epoch took 0.701s

Epoch 8 of 500
  training loss:		4.275890E-02
  validation loss:		5.315939E-02
Epoch took 0.702s

Epoch 9 of 500
  training loss:		4.144035E-02
  validation loss:		5.270843E-02
Epoch took 0.701s

Epoch 10 of 500
  training loss:		3.967193E-02
  validation loss:		4.055761E-02
Epoch took 0.701s

Epoch 11 of 500
  training loss:		4.124410E-02
  validation loss:		5.496989E-02
Epoch took 0.701s

Epoch 12 of 500
  training loss:		4.676802E-02
  validation loss:		3.836403E-02
Epoch took 0.701s

Epoch 13 of 500
  training loss:		4.087719E-02
  validation loss:		4.555413E-02
Epoch took 0.700s

Epoch 14 of 500
  training loss:		3.538500E-02
  validation loss:		2.943338E-02
Epoch took 0.701s

Epoch 15 of 500
  training loss:		2.913371E-02
  validation loss:		5.020314E-02
Epoch took 0.701s

Epoch 16 of 500
  training loss:		3.504780E-02
  validation loss:		4.392402E-02
Epoch took 0.701s

Epoch 17 of 500
  training loss:		3.811457E-02
  validation loss:		4.268895E-02
Epoch took 0.700s

Epoch 18 of 500
  training loss:		3.449818E-02
  validation loss:		4.253143E-02
Epoch took 0.700s

Epoch 19 of 500
  training loss:		3.690606E-02
  validation loss:		4.388366E-02
Epoch took 0.701s

Epoch 20 of 500
  training loss:		2.738825E-02
  validation loss:		3.411798E-02
Epoch took 0.700s

Epoch 21 of 500
  training loss:		2.815689E-02
  validation loss:		2.658416E-02
Epoch took 0.701s

Epoch 22 of 500
  training loss:		2.701155E-02
  validation loss:		2.319276E-02
Epoch took 0.701s

Epoch 23 of 500
  training loss:		2.719722E-02
  validation loss:		2.982877E-02
Epoch took 0.700s

Epoch 24 of 500
  training loss:		2.394780E-02
  validation loss:		2.418747E-02
Epoch took 0.703s

Epoch 25 of 500
  training loss:		2.356760E-02
  validation loss:		2.217611E-02
Epoch took 0.703s

Epoch 26 of 500
  training loss:		2.383305E-02
  validation loss:		3.900055E-02
Epoch took 0.703s

Epoch 27 of 500
  training loss:		2.670918E-02
  validation loss:		2.462516E-02
Epoch took 0.703s

Epoch 28 of 500
  training loss:		2.233116E-02
  validation loss:		3.293597E-02
Epoch took 0.703s

Epoch 29 of 500
  training loss:		2.339569E-02
  validation loss:		2.039585E-02
Epoch took 0.703s

Epoch 30 of 500
  training loss:		2.264653E-02
  validation loss:		3.931351E-02
Epoch took 0.703s

Epoch 31 of 500
  training loss:		2.304497E-02
  validation loss:		2.256193E-02
Epoch took 0.702s

Epoch 32 of 500
  training loss:		2.459353E-02
  validation loss:		2.419830E-02
Epoch took 0.703s

Epoch 33 of 500
  training loss:		2.130447E-02
  validation loss:		2.545250E-02
Epoch took 0.703s

Epoch 34 of 500
  training loss:		1.859579E-02
  validation loss:		2.970339E-02
Epoch took 0.703s

Epoch 35 of 500
  training loss:		2.025540E-02
  validation loss:		2.825292E-02
Epoch took 0.703s

Epoch 36 of 500
  training loss:		1.823309E-02
  validation loss:		1.738037E-02
Epoch took 0.703s

Epoch 37 of 500
  training loss:		1.890228E-02
  validation loss:		1.838169E-02
Epoch took 0.703s

Epoch 38 of 500
  training loss:		2.131315E-02
  validation loss:		1.804224E-02
Epoch took 0.703s

Epoch 39 of 500
  training loss:		1.661840E-02
  validation loss:		1.817311E-02
Epoch took 0.703s

Epoch 40 of 500
  training loss:		1.800090E-02
  validation loss:		2.613440E-02
Epoch took 0.703s

Epoch 41 of 500
  training loss:		2.067148E-02
  validation loss:		2.774083E-02
Epoch took 0.703s

Epoch 42 of 500
  training loss:		1.702611E-02
  validation loss:		2.011665E-02
Epoch took 0.703s

Epoch 43 of 500
  training loss:		1.915863E-02
  validation loss:		2.431987E-02
Epoch took 0.703s

Epoch 44 of 500
  training loss:		1.662571E-02
  validation loss:		3.029527E-02
Epoch took 0.703s

Epoch 45 of 500
  training loss:		1.867505E-02
  validation loss:		1.083150E-02
Epoch took 0.703s

Epoch 46 of 500
  training loss:		1.632657E-02
  validation loss:		1.328914E-02
Epoch took 0.703s

Epoch 47 of 500
  training loss:		1.549248E-02
  validation loss:		1.650766E-02
Epoch took 0.703s

Epoch 48 of 500
  training loss:		1.643398E-02
  validation loss:		1.322307E-02
Epoch took 0.703s

Epoch 49 of 500
  training loss:		1.835672E-02
  validation loss:		1.584362E-02
Epoch took 0.703s

Epoch 50 of 500
  training loss:		1.713770E-02
  validation loss:		1.179606E-02
Epoch took 0.704s

Epoch 51 of 500
  training loss:		1.493317E-02
  validation loss:		1.279619E-02
Epoch took 0.703s

Epoch 52 of 500
  training loss:		1.778272E-02
  validation loss:		1.606105E-02
Epoch took 0.703s

Epoch 53 of 500
  training loss:		1.460190E-02
  validation loss:		1.337326E-02
Epoch took 0.703s

Epoch 54 of 500
  training loss:		1.530698E-02
  validation loss:		1.650610E-02
Epoch took 0.703s

Epoch 55 of 500
  training loss:		1.510832E-02
  validation loss:		1.834850E-02
Epoch took 0.703s

Epoch 56 of 500
  training loss:		1.653733E-02
  validation loss:		2.116574E-02
Epoch took 0.703s

Epoch 57 of 500
  training loss:		1.743151E-02
  validation loss:		2.201030E-02
Epoch took 0.703s

Epoch 58 of 500
  training loss:		1.614114E-02
  validation loss:		1.965937E-02
Epoch took 0.704s

Epoch 59 of 500
  training loss:		1.538892E-02
  validation loss:		1.639233E-02
Epoch took 0.703s

Epoch 60 of 500
  training loss:		1.520323E-02
  validation loss:		1.195608E-02
Epoch took 0.703s

Epoch 61 of 500
  training loss:		1.558415E-02
  validation loss:		1.938123E-02
Epoch took 0.703s

Epoch 62 of 500
  training loss:		1.475229E-02
  validation loss:		1.690662E-02
Epoch took 0.703s

Epoch 63 of 500
  training loss:		1.562889E-02
  validation loss:		6.605001E-03
Epoch took 0.702s

Epoch 64 of 500
  training loss:		1.549786E-02
  validation loss:		1.298772E-02
Epoch took 0.704s

Epoch 65 of 500
  training loss:		1.234074E-02
  validation loss:		1.545139E-02
Epoch took 0.703s

Epoch 66 of 500
  training loss:		1.379914E-02
  validation loss:		1.024033E-02
Epoch took 0.703s

Epoch 67 of 500
  training loss:		1.410260E-02
  validation loss:		1.914371E-02
Epoch took 0.703s

Epoch 68 of 500
  training loss:		1.371843E-02
  validation loss:		1.271406E-02
Epoch took 0.703s

Epoch 69 of 500
  training loss:		1.283038E-02
  validation loss:		7.679943E-03
Epoch took 0.704s

Epoch 70 of 500
  training loss:		1.365303E-02
  validation loss:		1.076199E-02
Epoch took 0.703s

Epoch 71 of 500
  training loss:		1.307424E-02
  validation loss:		1.284417E-02
Epoch took 0.703s

Epoch 72 of 500
  training loss:		1.277637E-02
  validation loss:		1.474271E-02
Epoch took 0.703s

Epoch 73 of 500
  training loss:		1.320410E-02
  validation loss:		1.264230E-02
Epoch took 0.703s

Epoch 74 of 500
  training loss:		1.192594E-02
  validation loss:		9.786653E-03
Epoch took 0.704s

Epoch 75 of 500
  training loss:		1.323793E-02
  validation loss:		1.945974E-02
Epoch took 0.703s

Epoch 76 of 500
  training loss:		1.445845E-02
  validation loss:		1.457291E-02
Epoch took 0.703s

Epoch 77 of 500
  training loss:		1.211131E-02
  validation loss:		1.919207E-02
Epoch took 0.703s

Epoch 78 of 500
  training loss:		1.195447E-02
  validation loss:		8.261585E-03
Epoch took 0.703s

Epoch 79 of 500
  training loss:		1.493812E-02
  validation loss:		1.451913E-02
Epoch took 0.702s

Epoch 80 of 500
  training loss:		1.240617E-02
  validation loss:		7.193726E-03
Epoch took 0.702s

Epoch 81 of 500
  training loss:		1.128285E-02
  validation loss:		1.536110E-02
Epoch took 0.703s

Epoch 82 of 500
  training loss:		1.093429E-02
  validation loss:		7.134615E-03
Epoch took 0.703s

Epoch 83 of 500
  training loss:		1.167581E-02
  validation loss:		1.468712E-02
Epoch took 0.702s

Epoch 84 of 500
  training loss:		1.100886E-02
  validation loss:		6.288206E-03
Epoch took 0.703s

Epoch 85 of 500
  training loss:		1.124103E-02
  validation loss:		1.132622E-02
Epoch took 0.703s

Epoch 86 of 500
  training loss:		1.333115E-02
  validation loss:		1.284476E-02
Epoch took 0.703s

Epoch 87 of 500
  training loss:		1.348083E-02
  validation loss:		1.411066E-02
Epoch took 0.703s

Epoch 88 of 500
  training loss:		1.285357E-02
  validation loss:		1.383340E-02
Epoch took 0.702s

Epoch 89 of 500
  training loss:		1.277141E-02
  validation loss:		1.360022E-02
Epoch took 0.703s

Epoch 90 of 500
  training loss:		1.226704E-02
  validation loss:		1.670125E-02
Epoch took 0.703s

Epoch 91 of 500
  training loss:		1.081595E-02
  validation loss:		1.365176E-02
Epoch took 0.703s

Epoch 92 of 500
  training loss:		1.217538E-02
  validation loss:		1.718804E-02
Epoch took 0.703s

Epoch 93 of 500
  training loss:		1.144100E-02
  validation loss:		1.561273E-02
Epoch took 0.703s

Epoch 94 of 500
  training loss:		1.160687E-02
  validation loss:		9.024689E-03
Epoch took 0.703s

Epoch 95 of 500
  training loss:		1.067381E-02
  validation loss:		1.317432E-02
Epoch took 0.703s

Epoch 96 of 500
  training loss:		1.097618E-02
  validation loss:		7.239621E-03
Epoch took 0.703s

Epoch 97 of 500
  training loss:		1.212106E-02
  validation loss:		5.460223E-03
Epoch took 0.703s

Epoch 98 of 500
  training loss:		1.166138E-02
  validation loss:		1.260573E-02
Epoch took 0.703s

Epoch 99 of 500
  training loss:		1.108227E-02
  validation loss:		1.120771E-02
Epoch took 0.703s

Epoch 100 of 500
  training loss:		1.325230E-02
  validation loss:		1.077130E-02
Epoch took 0.703s

Epoch 101 of 500
  training loss:		1.063874E-02
  validation loss:		1.096193E-02
Epoch took 0.703s

Epoch 102 of 500
  training loss:		9.454535E-03
  validation loss:		1.169553E-02
Epoch took 0.703s

Epoch 103 of 500
  training loss:		1.097962E-02
  validation loss:		9.998136E-03
Epoch took 0.703s

Epoch 104 of 500
  training loss:		9.680399E-03
  validation loss:		1.338364E-02
Epoch took 0.703s

Epoch 105 of 500
  training loss:		1.048895E-02
  validation loss:		1.347668E-02
Epoch took 0.702s

Epoch 106 of 500
  training loss:		1.059292E-02
  validation loss:		9.000923E-03
Epoch took 0.703s

Epoch 107 of 500
  training loss:		1.225325E-02
  validation loss:		8.136074E-03
Epoch took 0.703s

Epoch 108 of 500
  training loss:		1.193863E-02
  validation loss:		1.254151E-02
Epoch took 0.703s

Epoch 109 of 500
  training loss:		1.473980E-02
  validation loss:		1.443273E-02
Epoch took 0.704s

Epoch 110 of 500
  training loss:		9.968404E-03
  validation loss:		9.945277E-03
Epoch took 0.702s

Epoch 111 of 500
  training loss:		1.080163E-02
  validation loss:		1.015508E-02
Epoch took 0.703s

Epoch 112 of 500
  training loss:		1.075902E-02
  validation loss:		4.958606E-03
Epoch took 0.703s

Epoch 113 of 500
  training loss:		9.970248E-03
  validation loss:		7.385865E-03
Epoch took 0.703s

Epoch 114 of 500
  training loss:		9.962115E-03
  validation loss:		1.148439E-02
Epoch took 0.702s

Epoch 115 of 500
  training loss:		1.005130E-02
  validation loss:		6.626127E-03
Epoch took 0.703s

Epoch 116 of 500
  training loss:		1.026282E-02
  validation loss:		5.817512E-03
Epoch took 0.703s

Epoch 117 of 500
  training loss:		9.558793E-03
  validation loss:		7.559083E-03
Epoch took 0.703s

Epoch 118 of 500
  training loss:		1.109360E-02
  validation loss:		1.469319E-02
Epoch took 0.703s

Epoch 119 of 500
  training loss:		9.476167E-03
  validation loss:		1.129048E-02
Epoch took 0.703s

Epoch 120 of 500
  training loss:		9.831440E-03
  validation loss:		9.545575E-03
Epoch took 0.703s

Epoch 121 of 500
  training loss:		9.678585E-03
  validation loss:		1.107533E-02
Epoch took 0.704s

Epoch 122 of 500
  training loss:		9.073708E-03
  validation loss:		6.314479E-03
Epoch took 0.703s

Epoch 123 of 500
  training loss:		1.027104E-02
  validation loss:		9.911561E-03
Epoch took 0.703s

Epoch 124 of 500
  training loss:		8.699268E-03
  validation loss:		8.565271E-03
Epoch took 0.704s

Epoch 125 of 500
  training loss:		9.800410E-03
  validation loss:		1.706413E-02
Epoch took 0.703s

Epoch 126 of 500
  training loss:		1.191516E-02
  validation loss:		7.836242E-03
Epoch took 0.703s

Epoch 127 of 500
  training loss:		9.850389E-03
  validation loss:		1.128714E-02
Epoch took 0.703s

Epoch 128 of 500
  training loss:		9.748433E-03
  validation loss:		5.847286E-03
Epoch took 0.703s

Epoch 129 of 500
  training loss:		7.660317E-03
  validation loss:		1.014308E-02
Epoch took 0.703s

Epoch 130 of 500
  training loss:		9.395739E-03
  validation loss:		7.347599E-03
Epoch took 0.703s

Epoch 131 of 500
  training loss:		9.282614E-03
  validation loss:		9.989865E-03
Epoch took 0.703s

Epoch 132 of 500
  training loss:		8.927568E-03
  validation loss:		7.389603E-03
Epoch took 0.703s

Epoch 133 of 500
  training loss:		8.711601E-03
  validation loss:		1.002408E-02
Epoch took 0.704s

Epoch 134 of 500
  training loss:		9.760528E-03
  validation loss:		7.970502E-03
Epoch took 0.703s

Epoch 135 of 500
  training loss:		9.792135E-03
  validation loss:		1.337033E-02
Epoch took 0.704s

Epoch 136 of 500
  training loss:		1.005233E-02
  validation loss:		8.789381E-03
Epoch took 0.703s

Epoch 137 of 500
  training loss:		9.675863E-03
  validation loss:		1.014471E-02
Epoch took 0.703s

Epoch 138 of 500
  training loss:		8.778382E-03
  validation loss:		1.153045E-02
Epoch took 0.703s

Epoch 139 of 500
  training loss:		8.642436E-03
  validation loss:		1.584046E-02
Epoch took 0.702s

Epoch 140 of 500
  training loss:		8.309902E-03
  validation loss:		1.093814E-02
Epoch took 0.703s

Epoch 141 of 500
  training loss:		8.452745E-03
  validation loss:		9.411518E-03
Epoch took 0.703s

Epoch 142 of 500
  training loss:		8.518296E-03
  validation loss:		6.227012E-03
Epoch took 0.703s

Epoch 143 of 500
  training loss:		9.178600E-03
  validation loss:		1.090053E-02
Epoch took 0.703s

Epoch 144 of 500
  training loss:		8.498159E-03
  validation loss:		8.088213E-03
Epoch took 0.703s

Epoch 145 of 500
  training loss:		9.460955E-03
  validation loss:		1.034827E-02
Epoch took 0.703s

Epoch 146 of 500
  training loss:		1.097676E-02
  validation loss:		7.768786E-03
Epoch took 0.702s

Epoch 147 of 500
  training loss:		8.354713E-03
  validation loss:		5.311150E-03
Epoch took 0.703s

Epoch 148 of 500
  training loss:		7.291679E-03
  validation loss:		5.454826E-03
Epoch took 0.703s

Epoch 149 of 500
  training loss:		8.484950E-03
  validation loss:		1.451473E-02
Epoch took 0.703s

Epoch 150 of 500
  training loss:		1.265162E-02
  validation loss:		7.167167E-03
Epoch took 0.703s

Epoch 151 of 500
  training loss:		9.308493E-03
  validation loss:		1.389489E-02
Epoch took 0.703s

Epoch 152 of 500
  training loss:		8.835491E-03
  validation loss:		6.955815E-03
Epoch took 0.702s

Epoch 153 of 500
  training loss:		8.699081E-03
  validation loss:		1.375480E-02
Epoch took 0.703s

Epoch 154 of 500
  training loss:		8.894406E-03
  validation loss:		8.076590E-03
Epoch took 0.703s

Epoch 155 of 500
  training loss:		6.865969E-03
  validation loss:		1.381562E-02
Epoch took 0.703s

Epoch 156 of 500
  training loss:		8.737384E-03
  validation loss:		4.068884E-03
Epoch took 0.703s

Epoch 157 of 500
  training loss:		8.895217E-03
  validation loss:		6.011183E-03
Epoch took 0.703s

Epoch 158 of 500
  training loss:		8.541134E-03
  validation loss:		6.763542E-03
Epoch took 0.703s

Epoch 159 of 500
  training loss:		8.002105E-03
  validation loss:		1.041910E-02
Epoch took 0.703s

Epoch 160 of 500
  training loss:		8.386021E-03
  validation loss:		1.202917E-02
Epoch took 0.703s

Epoch 161 of 500
  training loss:		8.430455E-03
  validation loss:		6.943862E-03
Epoch took 0.703s

Epoch 162 of 500
  training loss:		7.474721E-03
  validation loss:		1.226766E-02
Epoch took 0.703s

Epoch 163 of 500
  training loss:		7.749692E-03
  validation loss:		3.741817E-03
Epoch took 0.703s

Epoch 164 of 500
  training loss:		8.619844E-03
  validation loss:		7.810334E-03
Epoch took 0.703s

Epoch 165 of 500
  training loss:		8.869538E-03
  validation loss:		8.919152E-03
Epoch took 0.703s

Epoch 166 of 500
  training loss:		1.049481E-02
  validation loss:		1.360866E-02
Epoch took 0.703s

Epoch 167 of 500
  training loss:		7.114691E-03
  validation loss:		7.248935E-03
Epoch took 0.703s

Epoch 168 of 500
  training loss:		7.022660E-03
  validation loss:		9.302459E-03
Epoch took 0.703s

Epoch 169 of 500
  training loss:		8.875452E-03
  validation loss:		5.833782E-03
Epoch took 0.702s

Epoch 170 of 500
  training loss:		7.646934E-03
  validation loss:		9.790915E-03
Epoch took 0.703s

Epoch 171 of 500
  training loss:		8.061357E-03
  validation loss:		6.138193E-03
Epoch took 0.703s

Epoch 172 of 500
  training loss:		7.118574E-03
  validation loss:		3.514482E-03
Epoch took 0.704s

Epoch 173 of 500
  training loss:		9.461810E-03
  validation loss:		7.514517E-03
Epoch took 0.702s

Epoch 174 of 500
  training loss:		8.014098E-03
  validation loss:		8.142611E-03
Epoch took 0.703s

Epoch 175 of 500
  training loss:		7.156543E-03
  validation loss:		5.358341E-03
Epoch took 0.703s

Epoch 176 of 500
  training loss:		6.895325E-03
  validation loss:		8.384517E-03
Epoch took 0.703s

Epoch 177 of 500
  training loss:		7.427615E-03
  validation loss:		5.161458E-03
Epoch took 0.703s

Epoch 178 of 500
  training loss:		7.739025E-03
  validation loss:		6.953951E-03
Epoch took 0.703s

Epoch 179 of 500
  training loss:		7.707297E-03
  validation loss:		5.330543E-03
Epoch took 0.703s

Epoch 180 of 500
  training loss:		7.804264E-03
  validation loss:		5.518448E-03
Epoch took 0.703s

Epoch 181 of 500
  training loss:		8.890516E-03
  validation loss:		5.632785E-03
Epoch took 0.703s

Epoch 182 of 500
  training loss:		7.586416E-03
  validation loss:		9.187869E-03
Epoch took 0.703s

Epoch 183 of 500
  training loss:		7.199661E-03
  validation loss:		4.805344E-03
Epoch took 0.703s

Epoch 184 of 500
  training loss:		7.739842E-03
  validation loss:		8.477618E-03
Epoch took 0.703s

Epoch 185 of 500
  training loss:		8.415987E-03
  validation loss:		8.524112E-03
Epoch took 0.703s

Epoch 186 of 500
  training loss:		7.952506E-03
  validation loss:		5.034623E-03
Epoch took 0.703s

Epoch 187 of 500
  training loss:		6.802020E-03
  validation loss:		7.080765E-03
Epoch took 0.703s

Epoch 188 of 500
  training loss:		8.349820E-03
  validation loss:		5.706433E-03
Epoch took 0.703s

Epoch 189 of 500
  training loss:		6.900538E-03
  validation loss:		6.180638E-03
Epoch took 0.702s

Epoch 190 of 500
  training loss:		7.514307E-03
  validation loss:		7.992397E-03
Epoch took 0.703s

Epoch 191 of 500
  training loss:		7.588487E-03
  validation loss:		1.201968E-02
Epoch took 0.703s

Epoch 192 of 500
  training loss:		7.637244E-03
  validation loss:		5.988894E-03
Epoch took 0.703s

Epoch 193 of 500
  training loss:		7.919567E-03
  validation loss:		1.099120E-02
Epoch took 0.703s

Epoch 194 of 500
  training loss:		7.481351E-03
  validation loss:		9.376571E-03
Epoch took 0.703s

Epoch 195 of 500
  training loss:		8.341380E-03
  validation loss:		1.061735E-02
Epoch took 0.703s

Epoch 196 of 500
  training loss:		7.055506E-03
  validation loss:		5.206919E-03
Epoch took 0.703s

Epoch 197 of 500
  training loss:		6.980041E-03
  validation loss:		5.770950E-03
Epoch took 0.705s

Epoch 198 of 500
  training loss:		6.957907E-03
  validation loss:		1.041337E-02
Epoch took 0.704s

Epoch 199 of 500
  training loss:		7.239216E-03
  validation loss:		4.933687E-03
Epoch took 0.704s

Epoch 200 of 500
  training loss:		9.720854E-03
  validation loss:		1.308989E-02
Epoch took 0.703s

Early stopping, val-loss increased over the last 20 epochs from 0.00737423192542 to 0.00785155469785
Saving model from epoch 180
Training RMSE: 0.00555434
Validation RMSE: 0.00551572
Test RMSE: 0.00552009185776
Test MSE: 3.04714121739e-05
Test MAE: 0.00375228980556
Test R2: -324393125.908 

