Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.029388E-01
  validation loss:		2.282389E-02
Epoch took 2.058s

Epoch 2 of 500
  training loss:		3.545455E-02
  validation loss:		2.066521E-02
Epoch took 2.012s

Epoch 3 of 500
  training loss:		2.448019E-02
  validation loss:		3.757616E-02
Epoch took 2.012s

Epoch 4 of 500
  training loss:		2.183965E-02
  validation loss:		2.249077E-02
Epoch took 2.011s

Epoch 5 of 500
  training loss:		1.849729E-02
  validation loss:		2.194989E-02
Epoch took 2.011s

Epoch 6 of 500
  training loss:		1.674586E-02
  validation loss:		6.886478E-03
Epoch took 2.011s

Epoch 7 of 500
  training loss:		1.517143E-02
  validation loss:		1.309902E-02
Epoch took 2.011s

Epoch 8 of 500
  training loss:		1.344447E-02
  validation loss:		1.394723E-02
Epoch took 2.011s

Epoch 9 of 500
  training loss:		1.275604E-02
  validation loss:		4.126405E-03
Epoch took 2.012s

Epoch 10 of 500
  training loss:		1.192227E-02
  validation loss:		9.211382E-03
Epoch took 2.010s

Epoch 11 of 500
  training loss:		1.155597E-02
  validation loss:		1.031474E-02
Epoch took 2.011s

Epoch 12 of 500
  training loss:		1.002083E-02
  validation loss:		1.249376E-02
Epoch took 2.011s

Epoch 13 of 500
  training loss:		9.612904E-03
  validation loss:		1.148979E-02
Epoch took 2.011s

Epoch 14 of 500
  training loss:		9.025631E-03
  validation loss:		1.157518E-02
Epoch took 2.011s

Epoch 15 of 500
  training loss:		9.174970E-03
  validation loss:		8.317769E-03
Epoch took 2.011s

Epoch 16 of 500
  training loss:		9.156037E-03
  validation loss:		1.267043E-02
Epoch took 2.011s

Epoch 17 of 500
  training loss:		8.406209E-03
  validation loss:		1.115560E-02
Epoch took 2.012s

Epoch 18 of 500
  training loss:		7.589625E-03
  validation loss:		6.056700E-03
Epoch took 2.011s

Epoch 19 of 500
  training loss:		7.762675E-03
  validation loss:		8.620464E-03
Epoch took 2.011s

Epoch 20 of 500
  training loss:		7.192850E-03
  validation loss:		1.295853E-02
Epoch took 2.011s

Epoch 21 of 500
  training loss:		7.424034E-03
  validation loss:		8.160779E-03
Epoch took 2.011s

Epoch 22 of 500
  training loss:		6.138183E-03
  validation loss:		9.556969E-03
Epoch took 2.011s

Epoch 23 of 500
  training loss:		6.334173E-03
  validation loss:		1.397119E-02
Epoch took 2.011s

Epoch 24 of 500
  training loss:		7.020594E-03
  validation loss:		8.207142E-03
Epoch took 2.011s

Epoch 25 of 500
  training loss:		5.606936E-03
  validation loss:		7.382342E-03
Epoch took 2.011s

Epoch 26 of 500
  training loss:		5.529917E-03
  validation loss:		5.813044E-03
Epoch took 2.011s

Epoch 27 of 500
  training loss:		6.278673E-03
  validation loss:		7.992643E-03
Epoch took 2.011s

Epoch 28 of 500
  training loss:		5.631331E-03
  validation loss:		9.890389E-03
Epoch took 2.012s

Epoch 29 of 500
  training loss:		6.010984E-03
  validation loss:		1.068617E-02
Epoch took 2.012s

Epoch 30 of 500
  training loss:		6.103354E-03
  validation loss:		9.231557E-03
Epoch took 2.012s

Epoch 31 of 500
  training loss:		5.175520E-03
  validation loss:		3.028806E-03
Epoch took 2.012s

Epoch 32 of 500
  training loss:		5.297298E-03
  validation loss:		4.875769E-03
Epoch took 2.012s

Epoch 33 of 500
  training loss:		5.686359E-03
  validation loss:		7.733072E-03
Epoch took 2.012s

Epoch 34 of 500
  training loss:		5.453367E-03
  validation loss:		1.017953E-02
Epoch took 2.011s

Epoch 35 of 500
  training loss:		5.512581E-03
  validation loss:		8.090466E-03
Epoch took 2.012s

Epoch 36 of 500
  training loss:		4.931112E-03
  validation loss:		1.235559E-02
Epoch took 2.012s

Epoch 37 of 500
  training loss:		5.001481E-03
  validation loss:		1.179910E-02
Epoch took 2.012s

Epoch 38 of 500
  training loss:		5.213416E-03
  validation loss:		7.121118E-03
Epoch took 2.012s

Epoch 39 of 500
  training loss:		4.511049E-03
  validation loss:		8.758530E-03
Epoch took 2.012s

Epoch 40 of 500
  training loss:		5.128366E-03
  validation loss:		1.537721E-02
Epoch took 2.012s

Epoch 41 of 500
  training loss:		4.443605E-03
  validation loss:		1.424810E-02
Epoch took 2.013s

Epoch 42 of 500
  training loss:		4.852158E-03
  validation loss:		8.243081E-03
Epoch took 2.013s

Epoch 43 of 500
  training loss:		4.891054E-03
  validation loss:		3.288295E-03
Epoch took 2.013s

Epoch 44 of 500
  training loss:		4.349280E-03
  validation loss:		4.940825E-03
Epoch took 2.012s

Epoch 45 of 500
  training loss:		4.318963E-03
  validation loss:		1.303372E-02
Epoch took 2.012s

Epoch 46 of 500
  training loss:		4.632676E-03
  validation loss:		6.348534E-03
Epoch took 2.012s

Epoch 47 of 500
  training loss:		4.388495E-03
  validation loss:		9.847896E-03
Epoch took 2.012s

Epoch 48 of 500
  training loss:		4.181544E-03
  validation loss:		9.351689E-03
Epoch took 2.012s

Epoch 49 of 500
  training loss:		4.371258E-03
  validation loss:		1.235490E-02
Epoch took 2.012s

Epoch 50 of 500
  training loss:		3.800963E-03
  validation loss:		4.935257E-03
Epoch took 2.012s

Epoch 51 of 500
  training loss:		3.914984E-03
  validation loss:		3.385925E-03
Epoch took 2.012s

Epoch 52 of 500
  training loss:		3.871014E-03
  validation loss:		3.472550E-03
Epoch took 2.013s

Epoch 53 of 500
  training loss:		4.223733E-03
  validation loss:		5.386740E-03
Epoch took 2.012s

Epoch 54 of 500
  training loss:		4.062393E-03
  validation loss:		3.199840E-03
Epoch took 2.012s

Epoch 55 of 500
  training loss:		4.055768E-03
  validation loss:		4.974122E-03
Epoch took 2.012s

Epoch 56 of 500
  training loss:		3.762993E-03
  validation loss:		3.498662E-03
Epoch took 2.013s

Epoch 57 of 500
  training loss:		4.106354E-03
  validation loss:		9.166569E-03
Epoch took 2.013s

Epoch 58 of 500
  training loss:		3.448552E-03
  validation loss:		7.152636E-03
Epoch took 2.013s

Epoch 59 of 500
  training loss:		3.861956E-03
  validation loss:		1.038225E-02
Epoch took 2.013s

Epoch 60 of 500
  training loss:		3.592758E-03
  validation loss:		7.719920E-03
Epoch took 2.013s

Epoch 61 of 500
  training loss:		3.998898E-03
  validation loss:		9.770686E-03
Epoch took 2.014s

Epoch 62 of 500
  training loss:		3.516727E-03
  validation loss:		4.516385E-03
Epoch took 2.014s

Epoch 63 of 500
  training loss:		3.723626E-03
  validation loss:		6.326906E-03
Epoch took 2.016s

Epoch 64 of 500
  training loss:		3.755826E-03
  validation loss:		1.209755E-02
Epoch took 2.013s

Epoch 65 of 500
  training loss:		3.726458E-03
  validation loss:		1.183743E-02
Epoch took 2.012s

Epoch 66 of 500
  training loss:		3.375685E-03
  validation loss:		7.644023E-03
Epoch took 2.013s

Epoch 67 of 500
  training loss:		3.486230E-03
  validation loss:		7.990381E-03
Epoch took 2.013s

Epoch 68 of 500
  training loss:		3.794170E-03
  validation loss:		4.502894E-03
Epoch took 2.016s

Epoch 69 of 500
  training loss:		3.769479E-03
  validation loss:		5.483017E-03
Epoch took 2.012s

Epoch 70 of 500
  training loss:		3.302136E-03
  validation loss:		7.535005E-03
Epoch took 2.012s

Epoch 71 of 500
  training loss:		3.465552E-03
  validation loss:		2.298733E-03
Epoch took 2.013s

Epoch 72 of 500
  training loss:		3.151815E-03
  validation loss:		2.547392E-03
Epoch took 2.018s

Epoch 73 of 500
  training loss:		3.308613E-03
  validation loss:		8.794055E-03
Epoch took 2.018s

Epoch 74 of 500
  training loss:		3.385712E-03
  validation loss:		7.338622E-03
Epoch took 2.017s

Epoch 75 of 500
  training loss:		3.356449E-03
  validation loss:		1.048787E-02
Epoch took 2.015s

Epoch 76 of 500
  training loss:		3.027076E-03
  validation loss:		1.121344E-02
Epoch took 2.017s

Epoch 77 of 500
  training loss:		3.572380E-03
  validation loss:		4.983638E-03
Epoch took 2.018s

Epoch 78 of 500
  training loss:		3.185545E-03
  validation loss:		1.111409E-02
Epoch took 2.017s

Epoch 79 of 500
  training loss:		3.548905E-03
  validation loss:		6.122864E-03
Epoch took 2.016s

Epoch 80 of 500
  training loss:		3.218443E-03
  validation loss:		9.909291E-03
Epoch took 2.012s

Early stopping, val-loss increased over the last 20 epochs from 0.00724657552333 to 0.00762571324231
Saving model from epoch 60
Training RMSE: 0.00779304
Validation RMSE: 0.00778157
Test RMSE: 0.00762619497254
Test MSE: 5.81588465138e-05
Test MAE: 0.00606189621612
Test R2: -619148540.876 

