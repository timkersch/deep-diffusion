Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.217222E-01
  validation loss:		4.256252E-02
Epoch took 2.060s

Epoch 2 of 500
  training loss:		4.118587E-02
  validation loss:		2.480258E-02
Epoch took 2.017s

Epoch 3 of 500
  training loss:		2.710925E-02
  validation loss:		1.768142E-02
Epoch took 2.016s

Epoch 4 of 500
  training loss:		2.088805E-02
  validation loss:		1.698138E-02
Epoch took 2.017s

Epoch 5 of 500
  training loss:		1.757972E-02
  validation loss:		1.250704E-02
Epoch took 2.017s

Epoch 6 of 500
  training loss:		1.601033E-02
  validation loss:		2.765744E-02
Epoch took 2.016s

Epoch 7 of 500
  training loss:		1.482646E-02
  validation loss:		5.927463E-03
Epoch took 2.016s

Epoch 8 of 500
  training loss:		1.302089E-02
  validation loss:		1.270698E-02
Epoch took 2.016s

Epoch 9 of 500
  training loss:		1.155689E-02
  validation loss:		5.887942E-03
Epoch took 2.017s

Epoch 10 of 500
  training loss:		1.153681E-02
  validation loss:		1.318478E-02
Epoch took 2.016s

Epoch 11 of 500
  training loss:		1.001233E-02
  validation loss:		5.772004E-03
Epoch took 2.016s

Epoch 12 of 500
  training loss:		1.046839E-02
  validation loss:		1.114689E-02
Epoch took 2.016s

Epoch 13 of 500
  training loss:		9.245189E-03
  validation loss:		6.538771E-03
Epoch took 2.017s

Epoch 14 of 500
  training loss:		8.655061E-03
  validation loss:		4.680462E-03
Epoch took 2.016s

Epoch 15 of 500
  training loss:		8.044436E-03
  validation loss:		5.639419E-03
Epoch took 2.016s

Epoch 16 of 500
  training loss:		8.183958E-03
  validation loss:		5.947120E-03
Epoch took 2.016s

Epoch 17 of 500
  training loss:		7.428420E-03
  validation loss:		7.987450E-03
Epoch took 2.017s

Epoch 18 of 500
  training loss:		7.169912E-03
  validation loss:		9.341276E-03
Epoch took 2.017s

Epoch 19 of 500
  training loss:		6.777305E-03
  validation loss:		3.292887E-03
Epoch took 2.016s

Epoch 20 of 500
  training loss:		6.901788E-03
  validation loss:		6.372806E-03
Epoch took 2.016s

Epoch 21 of 500
  training loss:		6.887128E-03
  validation loss:		7.597027E-03
Epoch took 2.017s

Epoch 22 of 500
  training loss:		6.343839E-03
  validation loss:		5.846470E-03
Epoch took 2.016s

Epoch 23 of 500
  training loss:		6.208469E-03
  validation loss:		4.117821E-03
Epoch took 2.016s

Epoch 24 of 500
  training loss:		5.986007E-03
  validation loss:		5.362929E-03
Epoch took 2.016s

Epoch 25 of 500
  training loss:		6.278284E-03
  validation loss:		6.156848E-03
Epoch took 2.017s

Epoch 26 of 500
  training loss:		5.276754E-03
  validation loss:		1.038803E-02
Epoch took 2.016s

Epoch 27 of 500
  training loss:		5.688295E-03
  validation loss:		5.273172E-03
Epoch took 2.016s

Epoch 28 of 500
  training loss:		5.272624E-03
  validation loss:		1.205326E-02
Epoch took 2.017s

Epoch 29 of 500
  training loss:		5.539736E-03
  validation loss:		4.530927E-03
Epoch took 2.016s

Epoch 30 of 500
  training loss:		4.926916E-03
  validation loss:		3.943423E-03
Epoch took 2.017s

Epoch 31 of 500
  training loss:		5.425937E-03
  validation loss:		1.902070E-03
Epoch took 2.016s

Epoch 32 of 500
  training loss:		5.080560E-03
  validation loss:		6.962143E-03
Epoch took 2.016s

Epoch 33 of 500
  training loss:		4.670366E-03
  validation loss:		4.874502E-03
Epoch took 2.016s

Epoch 34 of 500
  training loss:		4.912098E-03
  validation loss:		6.017653E-03
Epoch took 2.016s

Epoch 35 of 500
  training loss:		4.714655E-03
  validation loss:		3.610057E-03
Epoch took 2.017s

Epoch 36 of 500
  training loss:		4.163225E-03
  validation loss:		2.927640E-03
Epoch took 2.016s

Epoch 37 of 500
  training loss:		4.723139E-03
  validation loss:		8.433355E-03
Epoch took 2.017s

Epoch 38 of 500
  training loss:		4.551588E-03
  validation loss:		7.363391E-03
Epoch took 2.016s

Epoch 39 of 500
  training loss:		4.574684E-03
  validation loss:		8.122368E-03
Epoch took 2.017s

Epoch 40 of 500
  training loss:		4.194010E-03
  validation loss:		4.120562E-03
Epoch took 2.017s

Epoch 41 of 500
  training loss:		4.177157E-03
  validation loss:		2.104421E-03
Epoch took 2.017s

Epoch 42 of 500
  training loss:		4.675088E-03
  validation loss:		4.315736E-03
Epoch took 2.017s

Epoch 43 of 500
  training loss:		4.329508E-03
  validation loss:		7.024206E-03
Epoch took 2.016s

Epoch 44 of 500
  training loss:		4.413522E-03
  validation loss:		4.893369E-03
Epoch took 2.016s

Epoch 45 of 500
  training loss:		4.101860E-03
  validation loss:		4.410089E-03
Epoch took 2.017s

Epoch 46 of 500
  training loss:		3.823867E-03
  validation loss:		6.663335E-03
Epoch took 2.017s

Epoch 47 of 500
  training loss:		4.250057E-03
  validation loss:		9.842116E-03
Epoch took 2.017s

Epoch 48 of 500
  training loss:		3.774894E-03
  validation loss:		2.321595E-03
Epoch took 2.016s

Epoch 49 of 500
  training loss:		3.841430E-03
  validation loss:		7.091844E-03
Epoch took 2.017s

Epoch 50 of 500
  training loss:		3.945731E-03
  validation loss:		3.683646E-03
Epoch took 2.016s

Epoch 51 of 500
  training loss:		3.885220E-03
  validation loss:		5.077783E-03
Epoch took 2.016s

Epoch 52 of 500
  training loss:		3.834374E-03
  validation loss:		1.012222E-02
Epoch took 2.016s

Epoch 53 of 500
  training loss:		3.874966E-03
  validation loss:		1.283463E-02
Epoch took 2.017s

Epoch 54 of 500
  training loss:		3.579218E-03
  validation loss:		6.473704E-03
Epoch took 2.016s

Epoch 55 of 500
  training loss:		4.084293E-03
  validation loss:		3.151410E-03
Epoch took 2.017s

Epoch 56 of 500
  training loss:		3.451794E-03
  validation loss:		6.714935E-03
Epoch took 2.017s

Epoch 57 of 500
  training loss:		3.413233E-03
  validation loss:		2.798115E-03
Epoch took 2.019s

Epoch 58 of 500
  training loss:		3.546153E-03
  validation loss:		3.095708E-03
Epoch took 2.018s

Epoch 59 of 500
  training loss:		3.732681E-03
  validation loss:		4.099908E-03
Epoch took 2.017s

Epoch 60 of 500
  training loss:		3.394297E-03
  validation loss:		5.726250E-03
Epoch took 2.017s

Early stopping, val-loss increased over the last 15 epochs from 0.00513877073913 to 0.00597981328655
Saving model from epoch 45
Training RMSE: 0.00442476
Validation RMSE: 0.0044128
Test RMSE: 0.00442997086793
Test MSE: 1.96246419364e-05
Test MAE: 0.004222325515
Test R2: -208920378.183 

