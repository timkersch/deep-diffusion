Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		2.510502E-01
  validation loss:		9.670772E-02
Epoch took 2.063s

Epoch 2 of 500
  training loss:		1.451585E-01
  validation loss:		7.003380E-02
Epoch took 2.020s

Epoch 3 of 500
  training loss:		1.172483E-01
  validation loss:		6.150129E-02
Epoch took 2.020s

Epoch 4 of 500
  training loss:		9.954692E-02
  validation loss:		5.620327E-02
Epoch took 2.020s

Epoch 5 of 500
  training loss:		8.445801E-02
  validation loss:		4.438326E-02
Epoch took 2.020s

Epoch 6 of 500
  training loss:		7.459860E-02
  validation loss:		4.411086E-02
Epoch took 2.020s

Epoch 7 of 500
  training loss:		6.642830E-02
  validation loss:		4.339137E-02
Epoch took 2.020s

Epoch 8 of 500
  training loss:		5.893229E-02
  validation loss:		3.547719E-02
Epoch took 2.033s

Epoch 9 of 500
  training loss:		5.173757E-02
  validation loss:		2.935317E-02
Epoch took 2.020s

Epoch 10 of 500
  training loss:		4.613019E-02
  validation loss:		2.533211E-02
Epoch took 2.020s

Epoch 11 of 500
  training loss:		4.056616E-02
  validation loss:		2.405816E-02
Epoch took 2.020s

Epoch 12 of 500
  training loss:		3.598269E-02
  validation loss:		2.140038E-02
Epoch took 2.020s

Epoch 13 of 500
  training loss:		3.150287E-02
  validation loss:		1.742476E-02
Epoch took 2.022s

Epoch 14 of 500
  training loss:		2.866692E-02
  validation loss:		2.156976E-02
Epoch took 2.020s

Epoch 15 of 500
  training loss:		2.624144E-02
  validation loss:		1.573766E-02
Epoch took 2.020s

Epoch 16 of 500
  training loss:		2.361641E-02
  validation loss:		1.481583E-02
Epoch took 2.020s

Epoch 17 of 500
  training loss:		2.172442E-02
  validation loss:		1.609923E-02
Epoch took 2.020s

Epoch 18 of 500
  training loss:		2.037822E-02
  validation loss:		1.353673E-02
Epoch took 2.020s

Epoch 19 of 500
  training loss:		1.888206E-02
  validation loss:		1.064221E-02
Epoch took 2.020s

Epoch 20 of 500
  training loss:		1.729735E-02
  validation loss:		1.270998E-02
Epoch took 2.018s

Epoch 21 of 500
  training loss:		1.640629E-02
  validation loss:		8.531516E-03
Epoch took 2.017s

Epoch 22 of 500
  training loss:		1.532582E-02
  validation loss:		9.128294E-03
Epoch took 2.016s

Epoch 23 of 500
  training loss:		1.453353E-02
  validation loss:		1.121245E-02
Epoch took 2.016s

Epoch 24 of 500
  training loss:		1.404801E-02
  validation loss:		8.771025E-03
Epoch took 2.016s

Epoch 25 of 500
  training loss:		1.325991E-02
  validation loss:		9.348485E-03
Epoch took 2.017s

Epoch 26 of 500
  training loss:		1.278255E-02
  validation loss:		9.298426E-03
Epoch took 2.016s

Epoch 27 of 500
  training loss:		1.226720E-02
  validation loss:		1.006742E-02
Epoch took 2.018s

Epoch 28 of 500
  training loss:		1.152640E-02
  validation loss:		8.621230E-03
Epoch took 2.016s

Epoch 29 of 500
  training loss:		1.129038E-02
  validation loss:		7.739072E-03
Epoch took 2.017s

Epoch 30 of 500
  training loss:		1.106616E-02
  validation loss:		6.498633E-03
Epoch took 2.017s

Epoch 31 of 500
  training loss:		1.067185E-02
  validation loss:		7.133456E-03
Epoch took 2.017s

Epoch 32 of 500
  training loss:		1.012885E-02
  validation loss:		6.390978E-03
Epoch took 2.017s

Epoch 33 of 500
  training loss:		1.009941E-02
  validation loss:		1.039082E-02
Epoch took 2.017s

Epoch 34 of 500
  training loss:		9.824681E-03
  validation loss:		5.832786E-03
Epoch took 2.017s

Epoch 35 of 500
  training loss:		9.582303E-03
  validation loss:		5.314664E-03
Epoch took 2.017s

Epoch 36 of 500
  training loss:		9.254975E-03
  validation loss:		1.370899E-02
Epoch took 2.017s

Epoch 37 of 500
  training loss:		9.371903E-03
  validation loss:		5.411781E-03
Epoch took 2.017s

Epoch 38 of 500
  training loss:		8.867187E-03
  validation loss:		1.010029E-02
Epoch took 2.016s

Epoch 39 of 500
  training loss:		8.559805E-03
  validation loss:		1.036083E-02
Epoch took 2.016s

Epoch 40 of 500
  training loss:		8.857431E-03
  validation loss:		7.725383E-03
Epoch took 2.017s

Epoch 41 of 500
  training loss:		8.628094E-03
  validation loss:		5.968395E-03
Epoch took 2.016s

Epoch 42 of 500
  training loss:		8.531594E-03
  validation loss:		5.107418E-03
Epoch took 2.016s

Epoch 43 of 500
  training loss:		8.047100E-03
  validation loss:		7.224406E-03
Epoch took 2.016s

Epoch 44 of 500
  training loss:		7.843623E-03
  validation loss:		4.047910E-03
Epoch took 2.017s

Epoch 45 of 500
  training loss:		7.663683E-03
  validation loss:		5.722570E-03
Epoch took 2.017s

Epoch 46 of 500
  training loss:		7.873323E-03
  validation loss:		5.444346E-03
Epoch took 2.017s

Epoch 47 of 500
  training loss:		7.672009E-03
  validation loss:		7.294477E-03
Epoch took 2.017s

Epoch 48 of 500
  training loss:		7.478152E-03
  validation loss:		4.330879E-03
Epoch took 2.017s

Epoch 49 of 500
  training loss:		7.364459E-03
  validation loss:		4.428308E-03
Epoch took 2.016s

Epoch 50 of 500
  training loss:		7.150087E-03
  validation loss:		4.165884E-03
Epoch took 2.016s

Epoch 51 of 500
  training loss:		7.100341E-03
  validation loss:		3.362591E-03
Epoch took 2.016s

Epoch 52 of 500
  training loss:		6.889181E-03
  validation loss:		8.228226E-03
Epoch took 2.017s

Epoch 53 of 500
  training loss:		6.826034E-03
  validation loss:		7.805739E-03
Epoch took 2.017s

Epoch 54 of 500
  training loss:		6.918009E-03
  validation loss:		4.565745E-03
Epoch took 2.016s

Epoch 55 of 500
  training loss:		6.824992E-03
  validation loss:		9.552049E-03
Epoch took 2.017s

Epoch 56 of 500
  training loss:		6.627948E-03
  validation loss:		5.953093E-03
Epoch took 2.016s

Epoch 57 of 500
  training loss:		6.547426E-03
  validation loss:		4.094398E-03
Epoch took 2.016s

Epoch 58 of 500
  training loss:		6.781372E-03
  validation loss:		6.044532E-03
Epoch took 2.016s

Epoch 59 of 500
  training loss:		6.596008E-03
  validation loss:		4.453826E-03
Epoch took 2.017s

Epoch 60 of 500
  training loss:		6.268102E-03
  validation loss:		5.909267E-03
Epoch took 2.016s

Epoch 61 of 500
  training loss:		6.175767E-03
  validation loss:		8.256707E-03
Epoch took 2.017s

Epoch 62 of 500
  training loss:		6.255771E-03
  validation loss:		3.168691E-03
Epoch took 2.017s

Epoch 63 of 500
  training loss:		6.053521E-03
  validation loss:		4.077132E-03
Epoch took 2.017s

Epoch 64 of 500
  training loss:		6.268549E-03
  validation loss:		7.309898E-03
Epoch took 2.016s

Epoch 65 of 500
  training loss:		6.219143E-03
  validation loss:		3.365229E-03
Epoch took 2.016s

Epoch 66 of 500
  training loss:		6.165211E-03
  validation loss:		5.587868E-03
Epoch took 2.016s

Epoch 67 of 500
  training loss:		5.887770E-03
  validation loss:		3.757624E-03
Epoch took 2.018s

Epoch 68 of 500
  training loss:		5.889953E-03
  validation loss:		3.499778E-03
Epoch took 2.017s

Epoch 69 of 500
  training loss:		5.775243E-03
  validation loss:		3.785730E-03
Epoch took 2.016s

Epoch 70 of 500
  training loss:		5.930780E-03
  validation loss:		2.633466E-03
Epoch took 2.016s

Epoch 71 of 500
  training loss:		5.824974E-03
  validation loss:		5.436674E-03
Epoch took 2.016s

Epoch 72 of 500
  training loss:		5.675880E-03
  validation loss:		4.870310E-03
Epoch took 2.016s

Epoch 73 of 500
  training loss:		5.853532E-03
  validation loss:		3.525025E-03
Epoch took 2.016s

Epoch 74 of 500
  training loss:		5.616683E-03
  validation loss:		5.477598E-03
Epoch took 2.016s

Epoch 75 of 500
  training loss:		5.506364E-03
  validation loss:		5.978633E-03
Epoch took 2.017s

Epoch 76 of 500
  training loss:		5.510464E-03
  validation loss:		4.804467E-03
Epoch took 2.016s

Epoch 77 of 500
  training loss:		5.564112E-03
  validation loss:		3.657657E-03
Epoch took 2.016s

Epoch 78 of 500
  training loss:		5.276127E-03
  validation loss:		4.470462E-03
Epoch took 2.016s

Epoch 79 of 500
  training loss:		5.441323E-03
  validation loss:		4.641820E-03
Epoch took 2.017s

Epoch 80 of 500
  training loss:		5.321063E-03
  validation loss:		3.528777E-03
Epoch took 2.016s

Epoch 81 of 500
  training loss:		5.272777E-03
  validation loss:		4.147190E-03
Epoch took 2.016s

Epoch 82 of 500
  training loss:		5.338726E-03
  validation loss:		4.348964E-03
Epoch took 2.016s

Epoch 83 of 500
  training loss:		5.299921E-03
  validation loss:		4.143870E-03
Epoch took 2.017s

Epoch 84 of 500
  training loss:		5.196462E-03
  validation loss:		5.185622E-03
Epoch took 2.016s

Epoch 85 of 500
  training loss:		5.232484E-03
  validation loss:		4.037707E-03
Epoch took 2.016s

Epoch 86 of 500
  training loss:		5.123233E-03
  validation loss:		3.658096E-03
Epoch took 2.016s

Epoch 87 of 500
  training loss:		5.202254E-03
  validation loss:		6.115998E-03
Epoch took 2.017s

Epoch 88 of 500
  training loss:		5.113009E-03
  validation loss:		2.901452E-03
Epoch took 2.016s

Epoch 89 of 500
  training loss:		5.122516E-03
  validation loss:		2.822125E-03
Epoch took 2.017s

Epoch 90 of 500
  training loss:		5.126326E-03
  validation loss:		4.870179E-03
Epoch took 2.016s

Epoch 91 of 500
  training loss:		4.952924E-03
  validation loss:		2.664726E-03
Epoch took 2.017s

Epoch 92 of 500
  training loss:		5.021347E-03
  validation loss:		3.634871E-03
Epoch took 2.017s

Epoch 93 of 500
  training loss:		5.090414E-03
  validation loss:		5.137755E-03
Epoch took 2.017s

Epoch 94 of 500
  training loss:		4.891511E-03
  validation loss:		4.878754E-03
Epoch took 2.016s

Epoch 95 of 500
  training loss:		4.880565E-03
  validation loss:		3.672308E-03
Epoch took 2.017s

Epoch 96 of 500
  training loss:		4.973700E-03
  validation loss:		5.480316E-03
Epoch took 2.017s

Epoch 97 of 500
  training loss:		4.838934E-03
  validation loss:		3.972324E-03
Epoch took 2.017s

Epoch 98 of 500
  training loss:		4.796924E-03
  validation loss:		4.141026E-03
Epoch took 2.016s

Epoch 99 of 500
  training loss:		5.036150E-03
  validation loss:		4.916234E-03
Epoch took 2.017s

Epoch 100 of 500
  training loss:		4.799958E-03
  validation loss:		2.989998E-03
Epoch took 2.017s

Epoch 101 of 500
  training loss:		4.709062E-03
  validation loss:		3.156273E-03
Epoch took 2.016s

Epoch 102 of 500
  training loss:		4.702869E-03
  validation loss:		3.737068E-03
Epoch took 2.017s

Epoch 103 of 500
  training loss:		4.681026E-03
  validation loss:		5.194145E-03
Epoch took 2.017s

Epoch 104 of 500
  training loss:		4.752104E-03
  validation loss:		2.857431E-03
Epoch took 2.016s

Epoch 105 of 500
  training loss:		4.538936E-03
  validation loss:		3.247038E-03
Epoch took 2.017s

Epoch 106 of 500
  training loss:		4.596017E-03
  validation loss:		3.059499E-03
Epoch took 2.016s

Epoch 107 of 500
  training loss:		4.642613E-03
  validation loss:		2.970647E-03
Epoch took 2.016s

Epoch 108 of 500
  training loss:		4.513420E-03
  validation loss:		1.983861E-03
Epoch took 2.017s

Epoch 109 of 500
  training loss:		4.565554E-03
  validation loss:		4.603127E-03
Epoch took 2.017s

Epoch 110 of 500
  training loss:		4.385639E-03
  validation loss:		4.700621E-03
Epoch took 2.017s

Epoch 111 of 500
  training loss:		4.453750E-03
  validation loss:		3.389550E-03
Epoch took 2.017s

Epoch 112 of 500
  training loss:		4.445995E-03
  validation loss:		7.498278E-03
Epoch took 2.017s

Epoch 113 of 500
  training loss:		4.576923E-03
  validation loss:		3.014035E-03
Epoch took 2.017s

Epoch 114 of 500
  training loss:		4.611423E-03
  validation loss:		4.380828E-03
Epoch took 2.017s

Epoch 115 of 500
  training loss:		4.322054E-03
  validation loss:		4.732900E-03
Epoch took 2.016s

Epoch 116 of 500
  training loss:		4.469614E-03
  validation loss:		3.069783E-03
Epoch took 2.016s

Epoch 117 of 500
  training loss:		4.500882E-03
  validation loss:		5.560053E-03
Epoch took 2.016s

Epoch 118 of 500
  training loss:		4.308661E-03
  validation loss:		5.790692E-03
Epoch took 2.016s

Epoch 119 of 500
  training loss:		4.284449E-03
  validation loss:		4.133655E-03
Epoch took 2.017s

Epoch 120 of 500
  training loss:		4.443652E-03
  validation loss:		4.268475E-03
Epoch took 2.016s

Early stopping, val-loss increased over the last 15 epochs from 0.00397868439607 to 0.00421040022109
Saving model from epoch 105
Training RMSE: 0.00324031
Validation RMSE: 0.00325496
Test RMSE: 0.00322669418529
Test MSE: 1.04115551949e-05
Test MAE: 0.00277181924321
Test R2: -110839534.359 

