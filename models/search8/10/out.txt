Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.775553E-01
  validation loss:		9.070580E-02
Epoch took 0.921s

Epoch 2 of 500
  training loss:		1.024620E-01
  validation loss:		7.750807E-02
Epoch took 0.871s

Epoch 3 of 500
  training loss:		8.622827E-02
  validation loss:		4.826713E-02
Epoch took 0.871s

Epoch 4 of 500
  training loss:		8.168944E-02
  validation loss:		6.175332E-02
Epoch took 0.877s

Epoch 5 of 500
  training loss:		7.462132E-02
  validation loss:		5.888409E-02
Epoch took 0.877s

Epoch 6 of 500
  training loss:		7.109577E-02
  validation loss:		5.073496E-02
Epoch took 0.877s

Epoch 7 of 500
  training loss:		6.670332E-02
  validation loss:		4.559402E-02
Epoch took 0.877s

Epoch 8 of 500
  training loss:		6.167623E-02
  validation loss:		5.989171E-02
Epoch took 0.877s

Epoch 9 of 500
  training loss:		6.132469E-02
  validation loss:		3.478464E-02
Epoch took 0.877s

Epoch 10 of 500
  training loss:		5.898872E-02
  validation loss:		3.539064E-02
Epoch took 0.877s

Epoch 11 of 500
  training loss:		5.720009E-02
  validation loss:		6.162654E-02
Epoch took 0.877s

Epoch 12 of 500
  training loss:		5.419389E-02
  validation loss:		3.509844E-02
Epoch took 0.877s

Epoch 13 of 500
  training loss:		5.259233E-02
  validation loss:		4.153265E-02
Epoch took 0.877s

Epoch 14 of 500
  training loss:		5.074373E-02
  validation loss:		3.082787E-02
Epoch took 0.877s

Epoch 15 of 500
  training loss:		4.993155E-02
  validation loss:		3.316564E-02
Epoch took 0.877s

Epoch 16 of 500
  training loss:		4.822455E-02
  validation loss:		3.542441E-02
Epoch took 0.877s

Epoch 17 of 500
  training loss:		4.675543E-02
  validation loss:		3.613901E-02
Epoch took 0.877s

Epoch 18 of 500
  training loss:		4.553500E-02
  validation loss:		3.713910E-02
Epoch took 0.877s

Epoch 19 of 500
  training loss:		4.402338E-02
  validation loss:		3.301690E-02
Epoch took 0.877s

Epoch 20 of 500
  training loss:		4.355281E-02
  validation loss:		2.439377E-02
Epoch took 0.877s

Epoch 21 of 500
  training loss:		4.141594E-02
  validation loss:		2.855302E-02
Epoch took 0.877s

Epoch 22 of 500
  training loss:		4.117735E-02
  validation loss:		2.622040E-02
Epoch took 0.877s

Epoch 23 of 500
  training loss:		3.944613E-02
  validation loss:		2.969371E-02
Epoch took 0.877s

Epoch 24 of 500
  training loss:		3.871403E-02
  validation loss:		1.978075E-02
Epoch took 0.877s

Epoch 25 of 500
  training loss:		3.837851E-02
  validation loss:		3.746470E-02
Epoch took 0.877s

Epoch 26 of 500
  training loss:		3.665608E-02
  validation loss:		2.585786E-02
Epoch took 0.877s

Epoch 27 of 500
  training loss:		3.689764E-02
  validation loss:		2.301185E-02
Epoch took 0.877s

Epoch 28 of 500
  training loss:		3.508687E-02
  validation loss:		2.593695E-02
Epoch took 0.877s

Epoch 29 of 500
  training loss:		3.531719E-02
  validation loss:		2.425234E-02
Epoch took 0.877s

Epoch 30 of 500
  training loss:		3.462001E-02
  validation loss:		2.253215E-02
Epoch took 0.877s

Epoch 31 of 500
  training loss:		3.445103E-02
  validation loss:		2.438210E-02
Epoch took 0.877s

Epoch 32 of 500
  training loss:		3.238553E-02
  validation loss:		2.175457E-02
Epoch took 0.877s

Epoch 33 of 500
  training loss:		3.258325E-02
  validation loss:		2.532852E-02
Epoch took 0.877s

Epoch 34 of 500
  training loss:		3.200817E-02
  validation loss:		1.765458E-02
Epoch took 0.877s

Epoch 35 of 500
  training loss:		3.131750E-02
  validation loss:		1.983093E-02
Epoch took 0.877s

Epoch 36 of 500
  training loss:		3.043410E-02
  validation loss:		1.963212E-02
Epoch took 0.877s

Epoch 37 of 500
  training loss:		2.922555E-02
  validation loss:		1.726912E-02
Epoch took 0.877s

Epoch 38 of 500
  training loss:		2.855816E-02
  validation loss:		1.857244E-02
Epoch took 0.877s

Epoch 39 of 500
  training loss:		2.883522E-02
  validation loss:		1.996927E-02
Epoch took 0.877s

Epoch 40 of 500
  training loss:		2.853499E-02
  validation loss:		1.618324E-02
Epoch took 0.877s

Epoch 41 of 500
  training loss:		2.754938E-02
  validation loss:		1.814195E-02
Epoch took 0.877s

Epoch 42 of 500
  training loss:		2.685254E-02
  validation loss:		1.474993E-02
Epoch took 0.877s

Epoch 43 of 500
  training loss:		2.671420E-02
  validation loss:		1.994872E-02
Epoch took 0.877s

Epoch 44 of 500
  training loss:		2.628341E-02
  validation loss:		1.948204E-02
Epoch took 0.877s

Epoch 45 of 500
  training loss:		2.599514E-02
  validation loss:		1.877045E-02
Epoch took 0.877s

Epoch 46 of 500
  training loss:		2.507162E-02
  validation loss:		1.954645E-02
Epoch took 0.877s

Epoch 47 of 500
  training loss:		2.524268E-02
  validation loss:		2.037502E-02
Epoch took 0.877s

Epoch 48 of 500
  training loss:		2.495380E-02
  validation loss:		1.859989E-02
Epoch took 0.877s

Epoch 49 of 500
  training loss:		2.365922E-02
  validation loss:		1.643467E-02
Epoch took 0.877s

Epoch 50 of 500
  training loss:		2.434059E-02
  validation loss:		1.666779E-02
Epoch took 0.877s

Epoch 51 of 500
  training loss:		2.365828E-02
  validation loss:		1.518635E-02
Epoch took 0.877s

Epoch 52 of 500
  training loss:		2.286612E-02
  validation loss:		1.502269E-02
Epoch took 0.877s

Epoch 53 of 500
  training loss:		2.236580E-02
  validation loss:		1.663215E-02
Epoch took 0.877s

Epoch 54 of 500
  training loss:		2.251177E-02
  validation loss:		1.610734E-02
Epoch took 0.877s

Epoch 55 of 500
  training loss:		2.208753E-02
  validation loss:		1.244051E-02
Epoch took 0.877s

Epoch 56 of 500
  training loss:		2.158626E-02
  validation loss:		1.574660E-02
Epoch took 0.877s

Epoch 57 of 500
  training loss:		2.129496E-02
  validation loss:		1.582144E-02
Epoch took 0.877s

Epoch 58 of 500
  training loss:		2.148926E-02
  validation loss:		1.650611E-02
Epoch took 0.877s

Epoch 59 of 500
  training loss:		2.133343E-02
  validation loss:		1.173150E-02
Epoch took 0.877s

Epoch 60 of 500
  training loss:		2.089025E-02
  validation loss:		1.535083E-02
Epoch took 0.877s

Epoch 61 of 500
  training loss:		2.056231E-02
  validation loss:		1.474642E-02
Epoch took 0.877s

Epoch 62 of 500
  training loss:		1.988854E-02
  validation loss:		1.308883E-02
Epoch took 0.877s

Epoch 63 of 500
  training loss:		1.937918E-02
  validation loss:		1.149707E-02
Epoch took 0.877s

Epoch 64 of 500
  training loss:		1.879583E-02
  validation loss:		1.232462E-02
Epoch took 0.877s

Epoch 65 of 500
  training loss:		1.879750E-02
  validation loss:		1.363735E-02
Epoch took 0.877s

Epoch 66 of 500
  training loss:		1.856532E-02
  validation loss:		1.210754E-02
Epoch took 0.877s

Epoch 67 of 500
  training loss:		1.922550E-02
  validation loss:		1.262197E-02
Epoch took 0.877s

Epoch 68 of 500
  training loss:		1.853261E-02
  validation loss:		1.294376E-02
Epoch took 0.877s

Epoch 69 of 500
  training loss:		1.835360E-02
  validation loss:		1.171845E-02
Epoch took 0.877s

Epoch 70 of 500
  training loss:		1.793104E-02
  validation loss:		1.243344E-02
Epoch took 0.877s

Epoch 71 of 500
  training loss:		1.780164E-02
  validation loss:		1.483596E-02
Epoch took 0.877s

Epoch 72 of 500
  training loss:		1.765068E-02
  validation loss:		1.195283E-02
Epoch took 0.877s

Epoch 73 of 500
  training loss:		1.736549E-02
  validation loss:		1.059968E-02
Epoch took 0.877s

Epoch 74 of 500
  training loss:		1.736505E-02
  validation loss:		9.966010E-03
Epoch took 0.877s

Epoch 75 of 500
  training loss:		1.648704E-02
  validation loss:		1.441409E-02
Epoch took 0.877s

Epoch 76 of 500
  training loss:		1.669338E-02
  validation loss:		9.508462E-03
Epoch took 0.877s

Epoch 77 of 500
  training loss:		1.645139E-02
  validation loss:		1.086232E-02
Epoch took 0.877s

Epoch 78 of 500
  training loss:		1.660693E-02
  validation loss:		9.322962E-03
Epoch took 0.877s

Epoch 79 of 500
  training loss:		1.610044E-02
  validation loss:		1.105812E-02
Epoch took 0.877s

Epoch 80 of 500
  training loss:		1.588756E-02
  validation loss:		1.358003E-02
Epoch took 0.877s

Epoch 81 of 500
  training loss:		1.653906E-02
  validation loss:		1.422476E-02
Epoch took 0.877s

Epoch 82 of 500
  training loss:		1.546786E-02
  validation loss:		9.476059E-03
Epoch took 0.877s

Epoch 83 of 500
  training loss:		1.566788E-02
  validation loss:		1.341392E-02
Epoch took 0.877s

Epoch 84 of 500
  training loss:		1.481394E-02
  validation loss:		9.385026E-03
Epoch took 0.877s

Epoch 85 of 500
  training loss:		1.488833E-02
  validation loss:		9.662714E-03
Epoch took 0.877s

Epoch 86 of 500
  training loss:		1.483785E-02
  validation loss:		1.048634E-02
Epoch took 0.877s

Epoch 87 of 500
  training loss:		1.483875E-02
  validation loss:		9.295877E-03
Epoch took 0.877s

Epoch 88 of 500
  training loss:		1.477525E-02
  validation loss:		9.228174E-03
Epoch took 0.877s

Epoch 89 of 500
  training loss:		1.429455E-02
  validation loss:		1.029112E-02
Epoch took 0.877s

Epoch 90 of 500
  training loss:		1.401957E-02
  validation loss:		1.397388E-02
Epoch took 0.877s

Epoch 91 of 500
  training loss:		1.406222E-02
  validation loss:		9.862770E-03
Epoch took 0.877s

Epoch 92 of 500
  training loss:		1.389112E-02
  validation loss:		7.524973E-03
Epoch took 0.877s

Epoch 93 of 500
  training loss:		1.380200E-02
  validation loss:		9.536638E-03
Epoch took 0.877s

Epoch 94 of 500
  training loss:		1.347650E-02
  validation loss:		1.030509E-02
Epoch took 0.877s

Epoch 95 of 500
  training loss:		1.347216E-02
  validation loss:		9.100511E-03
Epoch took 0.877s

Epoch 96 of 500
  training loss:		1.352759E-02
  validation loss:		9.850780E-03
Epoch took 0.877s

Epoch 97 of 500
  training loss:		1.322614E-02
  validation loss:		1.179174E-02
Epoch took 0.877s

Epoch 98 of 500
  training loss:		1.334073E-02
  validation loss:		1.430236E-02
Epoch took 0.877s

Epoch 99 of 500
  training loss:		1.292441E-02
  validation loss:		9.499280E-03
Epoch took 0.877s

Epoch 100 of 500
  training loss:		1.272462E-02
  validation loss:		9.499062E-03
Epoch took 0.877s

Epoch 101 of 500
  training loss:		1.324128E-02
  validation loss:		8.577901E-03
Epoch took 0.877s

Epoch 102 of 500
  training loss:		1.262177E-02
  validation loss:		8.549662E-03
Epoch took 0.877s

Epoch 103 of 500
  training loss:		1.202709E-02
  validation loss:		8.499706E-03
Epoch took 0.877s

Epoch 104 of 500
  training loss:		1.204126E-02
  validation loss:		1.008239E-02
Epoch took 0.877s

Epoch 105 of 500
  training loss:		1.205615E-02
  validation loss:		7.397003E-03
Epoch took 0.877s

Epoch 106 of 500
  training loss:		1.215390E-02
  validation loss:		7.534860E-03
Epoch took 0.877s

Epoch 107 of 500
  training loss:		1.183852E-02
  validation loss:		8.281279E-03
Epoch took 0.877s

Epoch 108 of 500
  training loss:		1.154442E-02
  validation loss:		1.202998E-02
Epoch took 0.877s

Epoch 109 of 500
  training loss:		1.172381E-02
  validation loss:		8.703423E-03
Epoch took 0.877s

Epoch 110 of 500
  training loss:		1.165824E-02
  validation loss:		7.560452E-03
Epoch took 0.877s

Epoch 111 of 500
  training loss:		1.184050E-02
  validation loss:		9.730402E-03
Epoch took 0.877s

Epoch 112 of 500
  training loss:		1.166636E-02
  validation loss:		9.789019E-03
Epoch took 0.877s

Epoch 113 of 500
  training loss:		1.173888E-02
  validation loss:		7.688235E-03
Epoch took 0.877s

Epoch 114 of 500
  training loss:		1.123288E-02
  validation loss:		8.313015E-03
Epoch took 0.877s

Epoch 115 of 500
  training loss:		1.097101E-02
  validation loss:		8.045394E-03
Epoch took 0.878s

Epoch 116 of 500
  training loss:		1.145446E-02
  validation loss:		8.612652E-03
Epoch took 0.879s

Epoch 117 of 500
  training loss:		1.133381E-02
  validation loss:		8.018864E-03
Epoch took 0.877s

Epoch 118 of 500
  training loss:		1.069791E-02
  validation loss:		6.701363E-03
Epoch took 0.877s

Epoch 119 of 500
  training loss:		1.078095E-02
  validation loss:		8.999590E-03
Epoch took 0.877s

Epoch 120 of 500
  training loss:		1.074769E-02
  validation loss:		6.322608E-03
Epoch took 0.877s

Epoch 121 of 500
  training loss:		1.052393E-02
  validation loss:		8.059377E-03
Epoch took 0.877s

Epoch 122 of 500
  training loss:		1.049137E-02
  validation loss:		6.783041E-03
Epoch took 0.877s

Epoch 123 of 500
  training loss:		1.001918E-02
  validation loss:		6.580443E-03
Epoch took 0.877s

Epoch 124 of 500
  training loss:		1.062302E-02
  validation loss:		1.379524E-02
Epoch took 0.877s

Epoch 125 of 500
  training loss:		1.038530E-02
  validation loss:		8.308076E-03
Epoch took 0.877s

Epoch 126 of 500
  training loss:		1.026661E-02
  validation loss:		6.347912E-03
Epoch took 0.877s

Epoch 127 of 500
  training loss:		1.024579E-02
  validation loss:		9.100852E-03
Epoch took 0.877s

Epoch 128 of 500
  training loss:		1.008133E-02
  validation loss:		5.557199E-03
Epoch took 0.877s

Epoch 129 of 500
  training loss:		9.679973E-03
  validation loss:		8.627106E-03
Epoch took 0.877s

Epoch 130 of 500
  training loss:		9.987433E-03
  validation loss:		7.748581E-03
Epoch took 0.877s

Epoch 131 of 500
  training loss:		9.764818E-03
  validation loss:		6.134450E-03
Epoch took 0.877s

Epoch 132 of 500
  training loss:		9.323369E-03
  validation loss:		5.953780E-03
Epoch took 0.877s

Epoch 133 of 500
  training loss:		9.564976E-03
  validation loss:		8.014813E-03
Epoch took 0.877s

Epoch 134 of 500
  training loss:		9.542072E-03
  validation loss:		6.465910E-03
Epoch took 0.877s

Epoch 135 of 500
  training loss:		9.376913E-03
  validation loss:		7.398913E-03
Epoch took 0.877s

Epoch 136 of 500
  training loss:		8.949818E-03
  validation loss:		6.623002E-03
Epoch took 0.877s

Epoch 137 of 500
  training loss:		9.512460E-03
  validation loss:		9.024394E-03
Epoch took 0.877s

Epoch 138 of 500
  training loss:		9.180593E-03
  validation loss:		7.985560E-03
Epoch took 0.877s

Epoch 139 of 500
  training loss:		1.053824E-02
  validation loss:		6.638110E-03
Epoch took 0.877s

Epoch 140 of 500
  training loss:		9.140987E-03
  validation loss:		6.703816E-03
Epoch took 0.877s

Epoch 141 of 500
  training loss:		9.113417E-03
  validation loss:		7.030638E-03
Epoch took 0.877s

Epoch 142 of 500
  training loss:		8.896844E-03
  validation loss:		6.650595E-03
Epoch took 0.877s

Epoch 143 of 500
  training loss:		8.944596E-03
  validation loss:		5.928981E-03
Epoch took 0.877s

Epoch 144 of 500
  training loss:		8.915307E-03
  validation loss:		8.486570E-03
Epoch took 0.877s

Epoch 145 of 500
  training loss:		8.839487E-03
  validation loss:		6.341873E-03
Epoch took 0.877s

Epoch 146 of 500
  training loss:		9.018930E-03
  validation loss:		4.909375E-03
Epoch took 0.877s

Epoch 147 of 500
  training loss:		8.443017E-03
  validation loss:		5.609765E-03
Epoch took 0.877s

Epoch 148 of 500
  training loss:		8.236455E-03
  validation loss:		7.022939E-03
Epoch took 0.877s

Epoch 149 of 500
  training loss:		8.811675E-03
  validation loss:		5.149344E-03
Epoch took 0.877s

Epoch 150 of 500
  training loss:		8.906529E-03
  validation loss:		5.068009E-03
Epoch took 0.877s

Epoch 151 of 500
  training loss:		8.458720E-03
  validation loss:		5.940617E-03
Epoch took 0.877s

Epoch 152 of 500
  training loss:		8.159203E-03
  validation loss:		6.279038E-03
Epoch took 0.877s

Epoch 153 of 500
  training loss:		8.591284E-03
  validation loss:		6.172187E-03
Epoch took 0.877s

Epoch 154 of 500
  training loss:		8.151516E-03
  validation loss:		4.975334E-03
Epoch took 0.877s

Epoch 155 of 500
  training loss:		8.169058E-03
  validation loss:		4.904736E-03
Epoch took 0.877s

Epoch 156 of 500
  training loss:		8.004874E-03
  validation loss:		5.230249E-03
Epoch took 0.877s

Epoch 157 of 500
  training loss:		7.720388E-03
  validation loss:		4.901550E-03
Epoch took 0.877s

Epoch 158 of 500
  training loss:		8.368081E-03
  validation loss:		5.492270E-03
Epoch took 0.877s

Epoch 159 of 500
  training loss:		7.726035E-03
  validation loss:		5.884966E-03
Epoch took 0.877s

Epoch 160 of 500
  training loss:		8.001844E-03
  validation loss:		4.529556E-03
Epoch took 0.877s

Epoch 161 of 500
  training loss:		7.514541E-03
  validation loss:		4.903862E-03
Epoch took 0.877s

Epoch 162 of 500
  training loss:		7.646542E-03
  validation loss:		5.804192E-03
Epoch took 0.877s

Epoch 163 of 500
  training loss:		7.456474E-03
  validation loss:		7.804942E-03
Epoch took 0.877s

Epoch 164 of 500
  training loss:		7.901472E-03
  validation loss:		5.083729E-03
Epoch took 0.877s

Epoch 165 of 500
  training loss:		7.454942E-03
  validation loss:		4.547893E-03
Epoch took 0.877s

Epoch 166 of 500
  training loss:		7.351710E-03
  validation loss:		6.321582E-03
Epoch took 0.877s

Epoch 167 of 500
  training loss:		7.638230E-03
  validation loss:		4.392941E-03
Epoch took 0.877s

Epoch 168 of 500
  training loss:		7.266279E-03
  validation loss:		5.328831E-03
Epoch took 0.877s

Epoch 169 of 500
  training loss:		7.830345E-03
  validation loss:		5.065395E-03
Epoch took 0.877s

Epoch 170 of 500
  training loss:		7.238782E-03
  validation loss:		4.756321E-03
Epoch took 0.877s

Epoch 171 of 500
  training loss:		7.570814E-03
  validation loss:		7.129019E-03
Epoch took 0.877s

Epoch 172 of 500
  training loss:		7.243814E-03
  validation loss:		7.089171E-03
Epoch took 0.877s

Epoch 173 of 500
  training loss:		7.029269E-03
  validation loss:		4.052024E-03
Epoch took 0.877s

Epoch 174 of 500
  training loss:		7.473603E-03
  validation loss:		7.669256E-03
Epoch took 0.877s

Epoch 175 of 500
  training loss:		7.409174E-03
  validation loss:		5.504724E-03
Epoch took 0.877s

Epoch 176 of 500
  training loss:		6.813811E-03
  validation loss:		6.504495E-03
Epoch took 0.877s

Epoch 177 of 500
  training loss:		7.177884E-03
  validation loss:		5.693004E-03
Epoch took 0.877s

Epoch 178 of 500
  training loss:		6.941654E-03
  validation loss:		8.836385E-03
Epoch took 0.877s

Epoch 179 of 500
  training loss:		7.244594E-03
  validation loss:		7.539100E-03
Epoch took 0.877s

Epoch 180 of 500
  training loss:		6.935195E-03
  validation loss:		4.274083E-03
Epoch took 0.877s

Early stopping, val-loss increased over the last 10 epochs from 0.00540096874106 to 0.0064291261615
Saving model from epoch 170
Training RMSE: 0.00478815
Validation RMSE: 0.00476264
Test RMSE: 0.0047486545518
Test MSE: 2.25497187785e-05
Test MAE: 0.00380431627855
Test R2: -240060210.478 

