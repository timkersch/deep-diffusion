Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		3.555446E-01
  validation loss:		9.967387E-02
Epoch took 2.056s

Epoch 2 of 500
  training loss:		1.362626E-01
  validation loss:		8.227151E-02
Epoch took 2.008s

Epoch 3 of 500
  training loss:		1.063752E-01
  validation loss:		5.920891E-02
Epoch took 2.008s

Epoch 4 of 500
  training loss:		8.833312E-02
  validation loss:		5.457558E-02
Epoch took 2.008s

Epoch 5 of 500
  training loss:		7.533910E-02
  validation loss:		4.508148E-02
Epoch took 2.008s

Epoch 6 of 500
  training loss:		6.424089E-02
  validation loss:		3.927486E-02
Epoch took 2.008s

Epoch 7 of 500
  training loss:		5.670340E-02
  validation loss:		3.744894E-02
Epoch took 2.008s

Epoch 8 of 500
  training loss:		5.082640E-02
  validation loss:		2.648913E-02
Epoch took 2.007s

Epoch 9 of 500
  training loss:		4.480338E-02
  validation loss:		3.331473E-02
Epoch took 2.007s

Epoch 10 of 500
  training loss:		4.014045E-02
  validation loss:		2.865600E-02
Epoch took 2.007s

Epoch 11 of 500
  training loss:		3.574134E-02
  validation loss:		2.064410E-02
Epoch took 2.008s

Epoch 12 of 500
  training loss:		3.285036E-02
  validation loss:		2.151373E-02
Epoch took 2.008s

Epoch 13 of 500
  training loss:		2.924227E-02
  validation loss:		2.019638E-02
Epoch took 2.007s

Epoch 14 of 500
  training loss:		2.681748E-02
  validation loss:		1.979803E-02
Epoch took 2.008s

Epoch 15 of 500
  training loss:		2.439793E-02
  validation loss:		1.586173E-02
Epoch took 2.008s

Epoch 16 of 500
  training loss:		2.280047E-02
  validation loss:		1.729179E-02
Epoch took 2.007s

Epoch 17 of 500
  training loss:		2.110016E-02
  validation loss:		1.436017E-02
Epoch took 2.007s

Epoch 18 of 500
  training loss:		1.937368E-02
  validation loss:		1.487916E-02
Epoch took 2.008s

Epoch 19 of 500
  training loss:		1.794136E-02
  validation loss:		1.449642E-02
Epoch took 2.008s

Epoch 20 of 500
  training loss:		1.709133E-02
  validation loss:		1.213979E-02
Epoch took 2.008s

Epoch 21 of 500
  training loss:		1.589148E-02
  validation loss:		1.193661E-02
Epoch took 2.007s

Epoch 22 of 500
  training loss:		1.551308E-02
  validation loss:		1.007146E-02
Epoch took 2.007s

Epoch 23 of 500
  training loss:		1.449384E-02
  validation loss:		1.279097E-02
Epoch took 2.008s

Epoch 24 of 500
  training loss:		1.377652E-02
  validation loss:		1.068268E-02
Epoch took 2.009s

Epoch 25 of 500
  training loss:		1.326507E-02
  validation loss:		8.616099E-03
Epoch took 2.008s

Epoch 26 of 500
  training loss:		1.283719E-02
  validation loss:		1.004596E-02
Epoch took 2.008s

Epoch 27 of 500
  training loss:		1.221526E-02
  validation loss:		1.457802E-02
Epoch took 2.008s

Epoch 28 of 500
  training loss:		1.160880E-02
  validation loss:		7.210130E-03
Epoch took 2.008s

Epoch 29 of 500
  training loss:		1.144828E-02
  validation loss:		1.311161E-02
Epoch took 2.008s

Epoch 30 of 500
  training loss:		1.100940E-02
  validation loss:		7.570538E-03
Epoch took 2.008s

Epoch 31 of 500
  training loss:		1.054792E-02
  validation loss:		1.048246E-02
Epoch took 2.008s

Epoch 32 of 500
  training loss:		1.058792E-02
  validation loss:		7.459233E-03
Epoch took 2.007s

Epoch 33 of 500
  training loss:		1.003159E-02
  validation loss:		6.399693E-03
Epoch took 2.007s

Epoch 34 of 500
  training loss:		9.700054E-03
  validation loss:		4.890452E-03
Epoch took 2.007s

Epoch 35 of 500
  training loss:		9.542929E-03
  validation loss:		7.744635E-03
Epoch took 2.007s

Epoch 36 of 500
  training loss:		9.215049E-03
  validation loss:		6.890012E-03
Epoch took 2.008s

Epoch 37 of 500
  training loss:		9.264472E-03
  validation loss:		6.199331E-03
Epoch took 2.009s

Epoch 38 of 500
  training loss:		8.722406E-03
  validation loss:		9.437990E-03
Epoch took 2.008s

Epoch 39 of 500
  training loss:		8.680311E-03
  validation loss:		6.042195E-03
Epoch took 2.008s

Epoch 40 of 500
  training loss:		8.758660E-03
  validation loss:		6.214255E-03
Epoch took 2.008s

Epoch 41 of 500
  training loss:		8.365021E-03
  validation loss:		7.430176E-03
Epoch took 2.008s

Epoch 42 of 500
  training loss:		8.190316E-03
  validation loss:		9.706697E-03
Epoch took 2.007s

Epoch 43 of 500
  training loss:		8.161187E-03
  validation loss:		5.608683E-03
Epoch took 2.008s

Epoch 44 of 500
  training loss:		7.963521E-03
  validation loss:		7.611573E-03
Epoch took 2.009s

Epoch 45 of 500
  training loss:		7.736772E-03
  validation loss:		7.033727E-03
Epoch took 2.007s

Epoch 46 of 500
  training loss:		7.793127E-03
  validation loss:		7.230808E-03
Epoch took 2.007s

Epoch 47 of 500
  training loss:		7.853831E-03
  validation loss:		6.980466E-03
Epoch took 2.008s

Epoch 48 of 500
  training loss:		7.834535E-03
  validation loss:		4.325899E-03
Epoch took 2.007s

Epoch 49 of 500
  training loss:		7.417410E-03
  validation loss:		5.224019E-03
Epoch took 2.008s

Epoch 50 of 500
  training loss:		7.393916E-03
  validation loss:		7.424788E-03
Epoch took 2.008s

Epoch 51 of 500
  training loss:		7.191806E-03
  validation loss:		6.966204E-03
Epoch took 2.007s

Epoch 52 of 500
  training loss:		7.100933E-03
  validation loss:		1.139021E-02
Epoch took 2.007s

Epoch 53 of 500
  training loss:		7.020239E-03
  validation loss:		5.136225E-03
Epoch took 2.007s

Epoch 54 of 500
  training loss:		6.879026E-03
  validation loss:		8.810200E-03
Epoch took 2.008s

Epoch 55 of 500
  training loss:		7.174765E-03
  validation loss:		9.015240E-03
Epoch took 2.007s

Epoch 56 of 500
  training loss:		6.745517E-03
  validation loss:		5.902526E-03
Epoch took 2.008s

Epoch 57 of 500
  training loss:		6.639352E-03
  validation loss:		8.177304E-03
Epoch took 2.008s

Epoch 58 of 500
  training loss:		6.755704E-03
  validation loss:		5.423590E-03
Epoch took 2.008s

Epoch 59 of 500
  training loss:		6.577184E-03
  validation loss:		5.525527E-03
Epoch took 2.008s

Epoch 60 of 500
  training loss:		6.450309E-03
  validation loss:		5.918315E-03
Epoch took 2.008s

Epoch 61 of 500
  training loss:		6.362263E-03
  validation loss:		5.452598E-03
Epoch took 2.008s

Epoch 62 of 500
  training loss:		6.281254E-03
  validation loss:		5.538215E-03
Epoch took 2.008s

Epoch 63 of 500
  training loss:		6.398765E-03
  validation loss:		3.599206E-03
Epoch took 2.008s

Epoch 64 of 500
  training loss:		6.298955E-03
  validation loss:		6.211375E-03
Epoch took 2.007s

Epoch 65 of 500
  training loss:		6.200154E-03
  validation loss:		7.218851E-03
Epoch took 2.007s

Epoch 66 of 500
  training loss:		6.195645E-03
  validation loss:		4.655490E-03
Epoch took 2.008s

Epoch 67 of 500
  training loss:		6.059757E-03
  validation loss:		2.762921E-03
Epoch took 2.008s

Epoch 68 of 500
  training loss:		5.921444E-03
  validation loss:		4.277079E-03
Epoch took 2.008s

Epoch 69 of 500
  training loss:		6.000481E-03
  validation loss:		6.102329E-03
Epoch took 2.008s

Epoch 70 of 500
  training loss:		5.953218E-03
  validation loss:		6.575342E-03
Epoch took 2.007s

Epoch 71 of 500
  training loss:		6.125535E-03
  validation loss:		6.251540E-03
Epoch took 2.008s

Epoch 72 of 500
  training loss:		6.037886E-03
  validation loss:		4.739385E-03
Epoch took 2.008s

Epoch 73 of 500
  training loss:		5.759879E-03
  validation loss:		3.744003E-03
Epoch took 2.008s

Epoch 74 of 500
  training loss:		5.853280E-03
  validation loss:		4.723663E-03
Epoch took 2.007s

Epoch 75 of 500
  training loss:		5.702202E-03
  validation loss:		4.848953E-03
Epoch took 2.007s

Epoch 76 of 500
  training loss:		5.829547E-03
  validation loss:		4.802081E-03
Epoch took 2.007s

Epoch 77 of 500
  training loss:		5.628890E-03
  validation loss:		6.316522E-03
Epoch took 2.008s

Epoch 78 of 500
  training loss:		5.333177E-03
  validation loss:		6.249683E-03
Epoch took 2.007s

Epoch 79 of 500
  training loss:		5.591247E-03
  validation loss:		3.409563E-03
Epoch took 2.008s

Epoch 80 of 500
  training loss:		5.706774E-03
  validation loss:		4.818882E-03
Epoch took 2.008s

Epoch 81 of 500
  training loss:		5.498346E-03
  validation loss:		4.055081E-03
Epoch took 2.008s

Epoch 82 of 500
  training loss:		5.722190E-03
  validation loss:		4.578448E-03
Epoch took 2.007s

Epoch 83 of 500
  training loss:		5.303031E-03
  validation loss:		3.999898E-03
Epoch took 2.008s

Epoch 84 of 500
  training loss:		5.463424E-03
  validation loss:		8.717292E-03
Epoch took 2.008s

Epoch 85 of 500
  training loss:		5.158861E-03
  validation loss:		2.620212E-03
Epoch took 2.008s

Epoch 86 of 500
  training loss:		5.385613E-03
  validation loss:		3.911935E-03
Epoch took 2.007s

Epoch 87 of 500
  training loss:		5.184340E-03
  validation loss:		5.673848E-03
Epoch took 2.007s

Epoch 88 of 500
  training loss:		5.343074E-03
  validation loss:		4.716938E-03
Epoch took 2.008s

Epoch 89 of 500
  training loss:		5.415026E-03
  validation loss:		3.118172E-03
Epoch took 2.008s

Epoch 90 of 500
  training loss:		5.231962E-03
  validation loss:		3.018585E-03
Epoch took 2.007s

Epoch 91 of 500
  training loss:		5.148334E-03
  validation loss:		3.852441E-03
Epoch took 2.007s

Epoch 92 of 500
  training loss:		5.231721E-03
  validation loss:		5.038417E-03
Epoch took 2.007s

Epoch 93 of 500
  training loss:		4.998430E-03
  validation loss:		4.263302E-03
Epoch took 2.008s

Epoch 94 of 500
  training loss:		5.083351E-03
  validation loss:		2.686844E-03
Epoch took 2.008s

Epoch 95 of 500
  training loss:		5.152879E-03
  validation loss:		4.980945E-03
Epoch took 2.008s

Epoch 96 of 500
  training loss:		5.060107E-03
  validation loss:		6.787801E-03
Epoch took 2.007s

Epoch 97 of 500
  training loss:		5.027057E-03
  validation loss:		4.589019E-03
Epoch took 2.008s

Epoch 98 of 500
  training loss:		5.062708E-03
  validation loss:		3.786727E-03
Epoch took 2.008s

Epoch 99 of 500
  training loss:		4.972258E-03
  validation loss:		3.232558E-03
Epoch took 2.007s

Epoch 100 of 500
  training loss:		4.927635E-03
  validation loss:		4.368656E-03
Epoch took 2.007s

Epoch 101 of 500
  training loss:		4.827935E-03
  validation loss:		5.597101E-03
Epoch took 2.007s

Epoch 102 of 500
  training loss:		4.907594E-03
  validation loss:		6.230232E-03
Epoch took 2.007s

Epoch 103 of 500
  training loss:		4.906570E-03
  validation loss:		5.761521E-03
Epoch took 2.007s

Epoch 104 of 500
  training loss:		4.776063E-03
  validation loss:		6.467463E-03
Epoch took 2.008s

Epoch 105 of 500
  training loss:		4.762004E-03
  validation loss:		5.187242E-03
Epoch took 2.008s

Epoch 106 of 500
  training loss:		4.751671E-03
  validation loss:		2.551403E-03
Epoch took 2.007s

Epoch 107 of 500
  training loss:		5.004668E-03
  validation loss:		5.673101E-03
Epoch took 2.007s

Epoch 108 of 500
  training loss:		5.024559E-03
  validation loss:		4.710513E-03
Epoch took 2.008s

Epoch 109 of 500
  training loss:		4.900948E-03
  validation loss:		3.655846E-03
Epoch took 2.008s

Epoch 110 of 500
  training loss:		4.918565E-03
  validation loss:		5.397324E-03
Epoch took 2.008s

Epoch 111 of 500
  training loss:		4.587533E-03
  validation loss:		5.653283E-03
Epoch took 2.008s

Epoch 112 of 500
  training loss:		4.814579E-03
  validation loss:		4.329907E-03
Epoch took 2.008s

Epoch 113 of 500
  training loss:		4.848777E-03
  validation loss:		2.874362E-03
Epoch took 2.008s

Epoch 114 of 500
  training loss:		4.678582E-03
  validation loss:		3.616816E-03
Epoch took 2.007s

Epoch 115 of 500
  training loss:		4.665687E-03
  validation loss:		4.587759E-03
Epoch took 2.010s

Epoch 116 of 500
  training loss:		4.548317E-03
  validation loss:		3.611464E-03
Epoch took 2.009s

Epoch 117 of 500
  training loss:		4.682693E-03
  validation loss:		7.025757E-03
Epoch took 2.008s

Epoch 118 of 500
  training loss:		4.797515E-03
  validation loss:		3.327880E-03
Epoch took 2.008s

Epoch 119 of 500
  training loss:		4.370526E-03
  validation loss:		4.159790E-03
Epoch took 2.008s

Epoch 120 of 500
  training loss:		4.649118E-03
  validation loss:		3.902397E-03
Epoch took 2.007s

Early stopping, val-loss increased over the last 20 epochs from 0.00439985587739 to 0.00471605809225
Saving model from epoch 100
Training RMSE: 0.00439337
Validation RMSE: 0.00440907
Test RMSE: 0.00434152083471
Test MSE: 1.8848804757e-05
Test MAE: 0.00287818466313
Test R2: -200660955.44 

