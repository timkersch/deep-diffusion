Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		2.013898E-01
  validation loss:		9.172343E-02
Epoch took 2.049s

Epoch 2 of 500
  training loss:		1.129034E-01
  validation loss:		7.591724E-02
Epoch took 2.013s

Epoch 3 of 500
  training loss:		8.375729E-02
  validation loss:		4.522183E-02
Epoch took 2.013s

Epoch 4 of 500
  training loss:		6.543662E-02
  validation loss:		4.131614E-02
Epoch took 2.013s

Epoch 5 of 500
  training loss:		5.112799E-02
  validation loss:		2.996921E-02
Epoch took 2.013s

Epoch 6 of 500
  training loss:		4.170703E-02
  validation loss:		2.627522E-02
Epoch took 2.013s

Epoch 7 of 500
  training loss:		3.362779E-02
  validation loss:		2.412273E-02
Epoch took 2.013s

Epoch 8 of 500
  training loss:		2.827877E-02
  validation loss:		2.408638E-02
Epoch took 2.013s

Epoch 9 of 500
  training loss:		2.397275E-02
  validation loss:		1.429541E-02
Epoch took 2.013s

Epoch 10 of 500
  training loss:		2.097545E-02
  validation loss:		1.437669E-02
Epoch took 2.013s

Epoch 11 of 500
  training loss:		1.853496E-02
  validation loss:		1.653097E-02
Epoch took 2.013s

Epoch 12 of 500
  training loss:		1.658853E-02
  validation loss:		1.622817E-02
Epoch took 2.013s

Epoch 13 of 500
  training loss:		1.516092E-02
  validation loss:		1.290779E-02
Epoch took 2.013s

Epoch 14 of 500
  training loss:		1.373571E-02
  validation loss:		1.217073E-02
Epoch took 2.013s

Epoch 15 of 500
  training loss:		1.302093E-02
  validation loss:		7.387708E-03
Epoch took 2.013s

Epoch 16 of 500
  training loss:		1.256586E-02
  validation loss:		8.280085E-03
Epoch took 2.013s

Epoch 17 of 500
  training loss:		1.159361E-02
  validation loss:		1.074620E-02
Epoch took 2.013s

Epoch 18 of 500
  training loss:		1.127658E-02
  validation loss:		1.486614E-02
Epoch took 2.013s

Epoch 19 of 500
  training loss:		1.069529E-02
  validation loss:		1.641004E-02
Epoch took 2.016s

Epoch 20 of 500
  training loss:		1.015688E-02
  validation loss:		8.444861E-03
Epoch took 2.014s

Epoch 21 of 500
  training loss:		9.832032E-03
  validation loss:		6.222692E-03
Epoch took 2.014s

Epoch 22 of 500
  training loss:		9.354842E-03
  validation loss:		6.954509E-03
Epoch took 2.012s

Epoch 23 of 500
  training loss:		9.284611E-03
  validation loss:		1.062668E-02
Epoch took 2.013s

Epoch 24 of 500
  training loss:		8.723853E-03
  validation loss:		9.948761E-03
Epoch took 2.013s

Epoch 25 of 500
  training loss:		8.580684E-03
  validation loss:		9.817025E-03
Epoch took 2.013s

Epoch 26 of 500
  training loss:		8.560468E-03
  validation loss:		6.711410E-03
Epoch took 2.013s

Epoch 27 of 500
  training loss:		8.227236E-03
  validation loss:		9.719597E-03
Epoch took 2.013s

Epoch 28 of 500
  training loss:		7.829946E-03
  validation loss:		4.611675E-03
Epoch took 2.013s

Epoch 29 of 500
  training loss:		8.079458E-03
  validation loss:		6.249947E-03
Epoch took 2.013s

Epoch 30 of 500
  training loss:		7.703079E-03
  validation loss:		6.129927E-03
Epoch took 2.013s

Epoch 31 of 500
  training loss:		7.513483E-03
  validation loss:		9.457477E-03
Epoch took 2.013s

Epoch 32 of 500
  training loss:		7.315816E-03
  validation loss:		9.373263E-03
Epoch took 2.013s

Epoch 33 of 500
  training loss:		7.476510E-03
  validation loss:		1.565932E-02
Epoch took 2.013s

Epoch 34 of 500
  training loss:		6.888948E-03
  validation loss:		7.565468E-03
Epoch took 2.013s

Epoch 35 of 500
  training loss:		6.989822E-03
  validation loss:		7.595264E-03
Epoch took 2.013s

Epoch 36 of 500
  training loss:		7.253945E-03
  validation loss:		7.292044E-03
Epoch took 2.013s

Epoch 37 of 500
  training loss:		6.722200E-03
  validation loss:		7.902421E-03
Epoch took 2.013s

Epoch 38 of 500
  training loss:		6.669074E-03
  validation loss:		9.466782E-03
Epoch took 2.013s

Epoch 39 of 500
  training loss:		6.508176E-03
  validation loss:		6.094711E-03
Epoch took 2.013s

Epoch 40 of 500
  training loss:		6.567616E-03
  validation loss:		4.150076E-03
Epoch took 2.013s

Epoch 41 of 500
  training loss:		6.457744E-03
  validation loss:		1.005214E-02
Epoch took 2.013s

Epoch 42 of 500
  training loss:		6.215642E-03
  validation loss:		7.363187E-03
Epoch took 2.013s

Epoch 43 of 500
  training loss:		6.382406E-03
  validation loss:		8.590228E-03
Epoch took 2.013s

Epoch 44 of 500
  training loss:		6.217984E-03
  validation loss:		6.201522E-03
Epoch took 2.013s

Epoch 45 of 500
  training loss:		6.189656E-03
  validation loss:		6.771597E-03
Epoch took 2.013s

Epoch 46 of 500
  training loss:		5.867899E-03
  validation loss:		5.759367E-03
Epoch took 2.013s

Epoch 47 of 500
  training loss:		5.920492E-03
  validation loss:		4.277525E-03
Epoch took 2.013s

Epoch 48 of 500
  training loss:		6.058622E-03
  validation loss:		7.931262E-03
Epoch took 2.013s

Epoch 49 of 500
  training loss:		5.801898E-03
  validation loss:		1.189994E-02
Epoch took 2.013s

Epoch 50 of 500
  training loss:		5.679047E-03
  validation loss:		3.642073E-03
Epoch took 2.013s

Epoch 51 of 500
  training loss:		5.654197E-03
  validation loss:		3.969485E-03
Epoch took 2.013s

Epoch 52 of 500
  training loss:		5.409516E-03
  validation loss:		8.951974E-03
Epoch took 2.013s

Epoch 53 of 500
  training loss:		5.374731E-03
  validation loss:		4.143691E-03
Epoch took 2.013s

Epoch 54 of 500
  training loss:		5.467841E-03
  validation loss:		6.697209E-03
Epoch took 2.013s

Epoch 55 of 500
  training loss:		5.487583E-03
  validation loss:		3.855527E-03
Epoch took 2.013s

Epoch 56 of 500
  training loss:		5.497583E-03
  validation loss:		3.697837E-03
Epoch took 2.013s

Epoch 57 of 500
  training loss:		5.483277E-03
  validation loss:		3.945593E-03
Epoch took 2.012s

Epoch 58 of 500
  training loss:		5.227383E-03
  validation loss:		7.220717E-03
Epoch took 2.013s

Epoch 59 of 500
  training loss:		5.322222E-03
  validation loss:		5.398929E-03
Epoch took 2.014s

Epoch 60 of 500
  training loss:		5.242756E-03
  validation loss:		3.244089E-03
Epoch took 2.013s

Epoch 61 of 500
  training loss:		5.295472E-03
  validation loss:		5.942252E-03
Epoch took 2.013s

Epoch 62 of 500
  training loss:		5.028252E-03
  validation loss:		6.766146E-03
Epoch took 2.013s

Epoch 63 of 500
  training loss:		5.273361E-03
  validation loss:		4.123241E-03
Epoch took 2.013s

Epoch 64 of 500
  training loss:		5.161141E-03
  validation loss:		4.988657E-03
Epoch took 2.013s

Epoch 65 of 500
  training loss:		5.104206E-03
  validation loss:		6.101726E-03
Epoch took 2.012s

Epoch 66 of 500
  training loss:		4.901140E-03
  validation loss:		8.779329E-03
Epoch took 2.012s

Epoch 67 of 500
  training loss:		4.884224E-03
  validation loss:		6.326303E-03
Epoch took 2.013s

Epoch 68 of 500
  training loss:		5.066179E-03
  validation loss:		4.363654E-03
Epoch took 2.013s

Epoch 69 of 500
  training loss:		4.846174E-03
  validation loss:		2.973518E-03
Epoch took 2.013s

Epoch 70 of 500
  training loss:		4.861689E-03
  validation loss:		5.013695E-03
Epoch took 2.012s

Epoch 71 of 500
  training loss:		4.769298E-03
  validation loss:		2.813414E-03
Epoch took 2.013s

Epoch 72 of 500
  training loss:		4.720888E-03
  validation loss:		3.761356E-03
Epoch took 2.013s

Epoch 73 of 500
  training loss:		4.463481E-03
  validation loss:		5.012954E-03
Epoch took 2.013s

Epoch 74 of 500
  training loss:		4.648429E-03
  validation loss:		5.779738E-03
Epoch took 2.013s

Epoch 75 of 500
  training loss:		4.703792E-03
  validation loss:		6.451711E-03
Epoch took 2.013s

Epoch 76 of 500
  training loss:		4.775811E-03
  validation loss:		1.325438E-02
Epoch took 2.013s

Epoch 77 of 500
  training loss:		4.662428E-03
  validation loss:		4.306843E-03
Epoch took 2.013s

Epoch 78 of 500
  training loss:		4.564963E-03
  validation loss:		3.173946E-03
Epoch took 2.013s

Epoch 79 of 500
  training loss:		4.591858E-03
  validation loss:		7.190975E-03
Epoch took 2.013s

Epoch 80 of 500
  training loss:		4.335727E-03
  validation loss:		3.782291E-03
Epoch took 2.013s

Epoch 81 of 500
  training loss:		4.939737E-03
  validation loss:		4.514472E-03
Epoch took 2.013s

Epoch 82 of 500
  training loss:		4.630851E-03
  validation loss:		5.775737E-03
Epoch took 2.013s

Epoch 83 of 500
  training loss:		4.248663E-03
  validation loss:		3.267847E-03
Epoch took 2.013s

Epoch 84 of 500
  training loss:		4.245600E-03
  validation loss:		2.294495E-03
Epoch took 2.013s

Epoch 85 of 500
  training loss:		4.294284E-03
  validation loss:		2.092645E-03
Epoch took 2.013s

Epoch 86 of 500
  training loss:		4.250746E-03
  validation loss:		7.847733E-03
Epoch took 2.013s

Epoch 87 of 500
  training loss:		4.485832E-03
  validation loss:		5.223093E-03
Epoch took 2.013s

Epoch 88 of 500
  training loss:		4.205871E-03
  validation loss:		2.736438E-03
Epoch took 2.013s

Epoch 89 of 500
  training loss:		4.339834E-03
  validation loss:		3.053037E-03
Epoch took 2.013s

Epoch 90 of 500
  training loss:		4.478678E-03
  validation loss:		2.941030E-03
Epoch took 2.013s

Epoch 91 of 500
  training loss:		4.260901E-03
  validation loss:		6.079660E-03
Epoch took 2.013s

Epoch 92 of 500
  training loss:		4.122121E-03
  validation loss:		6.299146E-03
Epoch took 2.015s

Epoch 93 of 500
  training loss:		4.020524E-03
  validation loss:		4.885493E-03
Epoch took 2.014s

Epoch 94 of 500
  training loss:		4.384519E-03
  validation loss:		5.886837E-03
Epoch took 2.014s

Epoch 95 of 500
  training loss:		4.341594E-03
  validation loss:		3.105168E-03
Epoch took 2.013s

Epoch 96 of 500
  training loss:		4.130953E-03
  validation loss:		4.436052E-03
Epoch took 2.014s

Epoch 97 of 500
  training loss:		4.017840E-03
  validation loss:		5.377236E-03
Epoch took 2.014s

Epoch 98 of 500
  training loss:		4.105588E-03
  validation loss:		4.223452E-03
Epoch took 2.014s

Epoch 99 of 500
  training loss:		4.211851E-03
  validation loss:		2.135827E-03
Epoch took 2.013s

Epoch 100 of 500
  training loss:		3.836712E-03
  validation loss:		2.722641E-03
Epoch took 2.013s

Epoch 101 of 500
  training loss:		3.882077E-03
  validation loss:		2.318237E-03
Epoch took 2.013s

Epoch 102 of 500
  training loss:		4.151129E-03
  validation loss:		4.924350E-03
Epoch took 2.014s

Epoch 103 of 500
  training loss:		3.934736E-03
  validation loss:		6.129092E-03
Epoch took 2.013s

Epoch 104 of 500
  training loss:		3.925125E-03
  validation loss:		2.925068E-03
Epoch took 2.013s

Epoch 105 of 500
  training loss:		3.910747E-03
  validation loss:		5.298130E-03
Epoch took 2.013s

Epoch 106 of 500
  training loss:		3.962705E-03
  validation loss:		7.857169E-03
Epoch took 2.013s

Epoch 107 of 500
  training loss:		3.985769E-03
  validation loss:		2.842147E-03
Epoch took 2.013s

Epoch 108 of 500
  training loss:		4.142498E-03
  validation loss:		4.617746E-03
Epoch took 2.013s

Epoch 109 of 500
  training loss:		3.898112E-03
  validation loss:		3.068965E-03
Epoch took 2.013s

Epoch 110 of 500
  training loss:		3.751439E-03
  validation loss:		3.511278E-03
Epoch took 2.013s

Epoch 111 of 500
  training loss:		3.744025E-03
  validation loss:		4.099984E-03
Epoch took 2.013s

Epoch 112 of 500
  training loss:		3.822768E-03
  validation loss:		2.533242E-03
Epoch took 2.013s

Epoch 113 of 500
  training loss:		3.705037E-03
  validation loss:		4.893895E-03
Epoch took 2.013s

Epoch 114 of 500
  training loss:		3.789291E-03
  validation loss:		4.130383E-03
Epoch took 2.013s

Epoch 115 of 500
  training loss:		3.759708E-03
  validation loss:		6.570957E-03
Epoch took 2.013s

Epoch 116 of 500
  training loss:		3.660983E-03
  validation loss:		2.869223E-03
Epoch took 2.013s

Epoch 117 of 500
  training loss:		3.714495E-03
  validation loss:		2.541835E-03
Epoch took 2.013s

Epoch 118 of 500
  training loss:		3.705947E-03
  validation loss:		2.705599E-03
Epoch took 2.013s

Epoch 119 of 500
  training loss:		3.565390E-03
  validation loss:		2.785328E-03
Epoch took 2.013s

Epoch 120 of 500
  training loss:		3.745705E-03
  validation loss:		3.200879E-03
Epoch took 2.013s

Epoch 121 of 500
  training loss:		3.835394E-03
  validation loss:		6.713911E-03
Epoch took 2.013s

Epoch 122 of 500
  training loss:		3.572308E-03
  validation loss:		2.654476E-03
Epoch took 2.013s

Epoch 123 of 500
  training loss:		3.830419E-03
  validation loss:		3.534596E-03
Epoch took 2.013s

Epoch 124 of 500
  training loss:		3.715160E-03
  validation loss:		2.186702E-03
Epoch took 2.012s

Epoch 125 of 500
  training loss:		3.759049E-03
  validation loss:		2.802657E-03
Epoch took 2.013s

Epoch 126 of 500
  training loss:		3.425195E-03
  validation loss:		2.297389E-03
Epoch took 2.013s

Epoch 127 of 500
  training loss:		3.548110E-03
  validation loss:		4.027185E-03
Epoch took 2.013s

Epoch 128 of 500
  training loss:		3.632756E-03
  validation loss:		2.193607E-03
Epoch took 2.013s

Epoch 129 of 500
  training loss:		3.375168E-03
  validation loss:		2.998471E-03
Epoch took 2.013s

Epoch 130 of 500
  training loss:		3.566430E-03
  validation loss:		1.679667E-03
Epoch took 2.013s

Epoch 131 of 500
  training loss:		3.732908E-03
  validation loss:		1.736621E-03
Epoch took 2.013s

Epoch 132 of 500
  training loss:		3.356216E-03
  validation loss:		4.185849E-03
Epoch took 2.013s

Epoch 133 of 500
  training loss:		3.473356E-03
  validation loss:		2.418919E-03
Epoch took 2.013s

Epoch 134 of 500
  training loss:		3.364273E-03
  validation loss:		3.803790E-03
Epoch took 2.013s

Epoch 135 of 500
  training loss:		3.453776E-03
  validation loss:		1.636034E-03
Epoch took 2.013s

Epoch 136 of 500
  training loss:		3.392505E-03
  validation loss:		2.477528E-03
Epoch took 2.013s

Epoch 137 of 500
  training loss:		3.433531E-03
  validation loss:		2.396272E-03
Epoch took 2.013s

Epoch 138 of 500
  training loss:		3.424532E-03
  validation loss:		3.433498E-03
Epoch took 2.013s

Epoch 139 of 500
  training loss:		3.476785E-03
  validation loss:		2.581774E-03
Epoch took 2.013s

Epoch 140 of 500
  training loss:		3.439224E-03
  validation loss:		3.948781E-03
Epoch took 2.013s

Epoch 141 of 500
  training loss:		3.399153E-03
  validation loss:		3.017744E-03
Epoch took 2.013s

Epoch 142 of 500
  training loss:		3.347769E-03
  validation loss:		3.959270E-03
Epoch took 2.013s

Epoch 143 of 500
  training loss:		3.281842E-03
  validation loss:		2.607512E-03
Epoch took 2.013s

Epoch 144 of 500
  training loss:		3.277145E-03
  validation loss:		2.443436E-03
Epoch took 2.013s

Epoch 145 of 500
  training loss:		3.327498E-03
  validation loss:		1.358591E-03
Epoch took 2.013s

Epoch 146 of 500
  training loss:		3.148238E-03
  validation loss:		2.995862E-03
Epoch took 2.013s

Epoch 147 of 500
  training loss:		3.348508E-03
  validation loss:		2.980620E-03
Epoch took 2.013s

Epoch 148 of 500
  training loss:		3.422533E-03
  validation loss:		2.873340E-03
Epoch took 2.013s

Epoch 149 of 500
  training loss:		3.147725E-03
  validation loss:		2.417992E-03
Epoch took 2.014s

Epoch 150 of 500
  training loss:		3.391545E-03
  validation loss:		3.708826E-03
Epoch took 2.013s

Epoch 151 of 500
  training loss:		3.484413E-03
  validation loss:		2.000560E-03
Epoch took 2.013s

Epoch 152 of 500
  training loss:		3.291003E-03
  validation loss:		2.014517E-03
Epoch took 2.014s

Epoch 153 of 500
  training loss:		3.158903E-03
  validation loss:		2.291030E-03
Epoch took 2.013s

Epoch 154 of 500
  training loss:		3.201288E-03
  validation loss:		3.456761E-03
Epoch took 2.013s

Epoch 155 of 500
  training loss:		3.254686E-03
  validation loss:		3.197706E-03
Epoch took 2.013s

Epoch 156 of 500
  training loss:		3.157093E-03
  validation loss:		1.858581E-03
Epoch took 2.013s

Epoch 157 of 500
  training loss:		3.352020E-03
  validation loss:		3.384433E-03
Epoch took 2.013s

Epoch 158 of 500
  training loss:		3.151054E-03
  validation loss:		3.174502E-03
Epoch took 2.014s

Epoch 159 of 500
  training loss:		3.112651E-03
  validation loss:		2.358943E-03
Epoch took 2.014s

Epoch 160 of 500
  training loss:		3.182277E-03
  validation loss:		1.996120E-03
Epoch took 2.014s

Epoch 161 of 500
  training loss:		3.230922E-03
  validation loss:		1.866085E-03
Epoch took 2.013s

Epoch 162 of 500
  training loss:		3.085080E-03
  validation loss:		2.478661E-03
Epoch took 2.013s

Epoch 163 of 500
  training loss:		3.306360E-03
  validation loss:		2.604376E-03
Epoch took 2.014s

Epoch 164 of 500
  training loss:		3.077558E-03
  validation loss:		4.283353E-03
Epoch took 2.013s

Epoch 165 of 500
  training loss:		3.097725E-03
  validation loss:		3.779461E-03
Epoch took 2.013s

Epoch 166 of 500
  training loss:		3.228639E-03
  validation loss:		3.603490E-03
Epoch took 2.013s

Epoch 167 of 500
  training loss:		3.147246E-03
  validation loss:		2.802247E-03
Epoch took 2.013s

Epoch 168 of 500
  training loss:		3.112120E-03
  validation loss:		1.790521E-03
Epoch took 2.014s

Epoch 169 of 500
  training loss:		3.335703E-03
  validation loss:		2.642028E-03
Epoch took 2.013s

Epoch 170 of 500
  training loss:		2.976858E-03
  validation loss:		3.027113E-03
Epoch took 2.013s

Epoch 171 of 500
  training loss:		2.804992E-03
  validation loss:		3.746129E-03
Epoch took 2.013s

Epoch 172 of 500
  training loss:		2.975480E-03
  validation loss:		3.171686E-03
Epoch took 2.013s

Epoch 173 of 500
  training loss:		2.891695E-03
  validation loss:		3.391952E-03
Epoch took 2.013s

Epoch 174 of 500
  training loss:		3.098867E-03
  validation loss:		3.019594E-03
Epoch took 2.013s

Epoch 175 of 500
  training loss:		3.099917E-03
  validation loss:		1.859157E-03
Epoch took 2.013s

Epoch 176 of 500
  training loss:		2.927972E-03
  validation loss:		3.567533E-03
Epoch took 2.013s

Epoch 177 of 500
  training loss:		2.904904E-03
  validation loss:		4.974610E-03
Epoch took 2.013s

Epoch 178 of 500
  training loss:		3.074871E-03
  validation loss:		1.818047E-03
Epoch took 2.013s

Epoch 179 of 500
  training loss:		2.954112E-03
  validation loss:		2.664318E-03
Epoch took 2.013s

Epoch 180 of 500
  training loss:		2.939960E-03
  validation loss:		1.903589E-03
Epoch took 2.013s

Early stopping, val-loss increased over the last 15 epochs from 0.00271633927757 to 0.00293213427684
Saving model from epoch 165
Training RMSE: 0.00378712
Validation RMSE: 0.00378875
Test RMSE: 0.00374183570966
Test MSE: 1.40013344208e-05
Test MAE: 0.00327744008973
Test R2: -149055663.59 

