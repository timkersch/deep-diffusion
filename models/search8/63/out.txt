Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		6.570949E-02
  validation loss:		4.542416E-02
Epoch took 2.046s

Epoch 2 of 500
  training loss:		3.074137E-02
  validation loss:		4.975169E-02
Epoch took 2.010s

Epoch 3 of 500
  training loss:		2.081466E-02
  validation loss:		2.342864E-02
Epoch took 2.012s

Epoch 4 of 500
  training loss:		2.225713E-02
  validation loss:		2.777801E-02
Epoch took 2.012s

Epoch 5 of 500
  training loss:		1.890321E-02
  validation loss:		3.018227E-02
Epoch took 2.012s

Epoch 6 of 500
  training loss:		1.587932E-02
  validation loss:		3.216808E-02
Epoch took 2.016s

Epoch 7 of 500
  training loss:		1.552815E-02
  validation loss:		6.205574E-02
Epoch took 2.016s

Epoch 8 of 500
  training loss:		1.652380E-02
  validation loss:		2.173711E-02
Epoch took 2.020s

Epoch 9 of 500
  training loss:		1.568845E-02
  validation loss:		2.752988E-02
Epoch took 2.021s

Epoch 10 of 500
  training loss:		1.465513E-02
  validation loss:		1.224958E-02
Epoch took 2.020s

Epoch 11 of 500
  training loss:		1.332750E-02
  validation loss:		3.051172E-02
Epoch took 2.023s

Epoch 12 of 500
  training loss:		1.139112E-02
  validation loss:		1.533144E-02
Epoch took 2.023s

Epoch 13 of 500
  training loss:		1.259841E-02
  validation loss:		2.072931E-02
Epoch took 2.022s

Epoch 14 of 500
  training loss:		1.354588E-02
  validation loss:		9.837352E-03
Epoch took 2.024s

Epoch 15 of 500
  training loss:		1.245771E-02
  validation loss:		9.559672E-03
Epoch took 2.025s

Epoch 16 of 500
  training loss:		1.168419E-02
  validation loss:		1.479380E-02
Epoch took 2.028s

Epoch 17 of 500
  training loss:		1.165917E-02
  validation loss:		1.571390E-02
Epoch took 2.026s

Epoch 18 of 500
  training loss:		1.114995E-02
  validation loss:		1.897321E-02
Epoch took 2.032s

Epoch 19 of 500
  training loss:		1.094182E-02
  validation loss:		1.859606E-02
Epoch took 2.029s

Epoch 20 of 500
  training loss:		1.309280E-02
  validation loss:		1.244175E-02
Epoch took 2.025s

Epoch 21 of 500
  training loss:		1.056376E-02
  validation loss:		2.015717E-02
Epoch took 2.035s

Epoch 22 of 500
  training loss:		1.037682E-02
  validation loss:		1.190352E-02
Epoch took 2.029s

Epoch 23 of 500
  training loss:		1.036012E-02
  validation loss:		1.033518E-02
Epoch took 2.031s

Epoch 24 of 500
  training loss:		9.960854E-03
  validation loss:		1.230396E-02
Epoch took 2.031s

Epoch 25 of 500
  training loss:		9.963588E-03
  validation loss:		8.845735E-03
Epoch took 2.030s

Epoch 26 of 500
  training loss:		1.041562E-02
  validation loss:		9.165315E-03
Epoch took 2.031s

Epoch 27 of 500
  training loss:		9.540278E-03
  validation loss:		8.433413E-03
Epoch took 2.032s

Epoch 28 of 500
  training loss:		1.003193E-02
  validation loss:		6.345442E-03
Epoch took 2.030s

Epoch 29 of 500
  training loss:		9.983097E-03
  validation loss:		9.099582E-03
Epoch took 2.030s

Epoch 30 of 500
  training loss:		9.234751E-03
  validation loss:		6.023311E-03
Epoch took 2.035s

Epoch 31 of 500
  training loss:		9.398260E-03
  validation loss:		1.724522E-02
Epoch took 2.031s

Epoch 32 of 500
  training loss:		9.298907E-03
  validation loss:		1.135787E-02
Epoch took 2.031s

Epoch 33 of 500
  training loss:		9.674563E-03
  validation loss:		2.228216E-02
Epoch took 2.033s

Epoch 34 of 500
  training loss:		9.930832E-03
  validation loss:		5.162111E-03
Epoch took 2.036s

Epoch 35 of 500
  training loss:		8.154640E-03
  validation loss:		1.091859E-02
Epoch took 2.036s

Epoch 36 of 500
  training loss:		8.767442E-03
  validation loss:		1.582689E-02
Epoch took 2.038s

Epoch 37 of 500
  training loss:		8.568973E-03
  validation loss:		3.267077E-02
Epoch took 2.037s

Epoch 38 of 500
  training loss:		9.455779E-03
  validation loss:		1.806320E-02
Epoch took 2.036s

Epoch 39 of 500
  training loss:		9.920826E-03
  validation loss:		8.677361E-03
Epoch took 2.038s

Epoch 40 of 500
  training loss:		8.824670E-03
  validation loss:		2.727189E-02
Epoch took 2.037s

Epoch 41 of 500
  training loss:		8.394314E-03
  validation loss:		1.142715E-02
Epoch took 2.038s

Epoch 42 of 500
  training loss:		8.584446E-03
  validation loss:		7.973747E-03
Epoch took 2.043s

Epoch 43 of 500
  training loss:		8.729178E-03
  validation loss:		1.039693E-02
Epoch took 2.039s

Epoch 44 of 500
  training loss:		1.282371E-02
  validation loss:		6.337137E-03
Epoch took 2.039s

Epoch 45 of 500
  training loss:		1.491207E-02
  validation loss:		1.819433E-02
Epoch took 2.046s

Epoch 46 of 500
  training loss:		1.149007E-02
  validation loss:		1.445414E-02
Epoch took 2.043s

Epoch 47 of 500
  training loss:		1.223204E-02
  validation loss:		7.707956E-03
Epoch took 2.044s

Epoch 48 of 500
  training loss:		1.178181E-02
  validation loss:		2.881057E-03
Epoch took 2.045s

Epoch 49 of 500
  training loss:		1.336909E-02
  validation loss:		8.764240E-03
Epoch took 2.044s

Epoch 50 of 500
  training loss:		1.031419E-02
  validation loss:		1.597621E-02
Epoch took 2.047s

Epoch 51 of 500
  training loss:		1.028390E-02
  validation loss:		1.152713E-02
Epoch took 2.046s

Epoch 52 of 500
  training loss:		1.243305E-02
  validation loss:		8.872833E-03
Epoch took 2.046s

Epoch 53 of 500
  training loss:		1.052327E-02
  validation loss:		5.611627E-03
Epoch took 2.044s

Epoch 54 of 500
  training loss:		1.207609E-02
  validation loss:		5.710177E-03
Epoch took 2.047s

Epoch 55 of 500
  training loss:		1.089013E-02
  validation loss:		1.244738E-02
Epoch took 2.048s

Epoch 56 of 500
  training loss:		1.135145E-02
  validation loss:		6.341628E-03
Epoch took 2.046s

Epoch 57 of 500
  training loss:		9.281253E-03
  validation loss:		2.139382E-02
Epoch took 2.045s

Epoch 58 of 500
  training loss:		8.634322E-03
  validation loss:		1.938418E-02
Epoch took 2.048s

Epoch 59 of 500
  training loss:		9.799567E-03
  validation loss:		2.619281E-03
Epoch took 2.050s

Epoch 60 of 500
  training loss:		8.764292E-03
  validation loss:		4.363012E-03
Epoch took 2.044s

Epoch 61 of 500
  training loss:		8.245890E-03
  validation loss:		5.988076E-03
Epoch took 2.053s

Epoch 62 of 500
  training loss:		9.790074E-03
  validation loss:		1.362987E-02
Epoch took 2.046s

Epoch 63 of 500
  training loss:		1.013134E-02
  validation loss:		8.818106E-03
Epoch took 2.049s

Epoch 64 of 500
  training loss:		8.705919E-03
  validation loss:		1.148200E-02
Epoch took 2.050s

Epoch 65 of 500
  training loss:		9.599870E-03
  validation loss:		6.659627E-03
Epoch took 2.049s

Epoch 66 of 500
  training loss:		9.342886E-03
  validation loss:		7.627866E-03
Epoch took 2.054s

Epoch 67 of 500
  training loss:		1.012854E-02
  validation loss:		1.069192E-02
Epoch took 2.050s

Epoch 68 of 500
  training loss:		8.496274E-03
  validation loss:		9.285716E-03
Epoch took 2.054s

Epoch 69 of 500
  training loss:		8.511256E-03
  validation loss:		6.288268E-03
Epoch took 2.052s

Epoch 70 of 500
  training loss:		8.446784E-03
  validation loss:		1.460814E-02
Epoch took 2.049s

Epoch 71 of 500
  training loss:		8.530407E-03
  validation loss:		8.451501E-03
Epoch took 2.056s

Epoch 72 of 500
  training loss:		6.324611E-03
  validation loss:		3.389623E-03
Epoch took 2.057s

Epoch 73 of 500
  training loss:		5.641640E-03
  validation loss:		2.366992E-03
Epoch took 2.057s

Epoch 74 of 500
  training loss:		5.025498E-03
  validation loss:		7.480701E-03
Epoch took 2.053s

Epoch 75 of 500
  training loss:		5.311041E-03
  validation loss:		2.058152E-03
Epoch took 2.054s

Epoch 76 of 500
  training loss:		5.560911E-03
  validation loss:		7.497613E-03
Epoch took 2.054s

Epoch 77 of 500
  training loss:		5.375959E-03
  validation loss:		4.341710E-03
Epoch took 2.055s

Epoch 78 of 500
  training loss:		5.386064E-03
  validation loss:		1.074990E-02
Epoch took 2.053s

Epoch 79 of 500
  training loss:		4.501162E-03
  validation loss:		2.333231E-02
Epoch took 2.053s

Epoch 80 of 500
  training loss:		4.619301E-03
  validation loss:		4.676976E-03
Epoch took 2.053s

Epoch 81 of 500
  training loss:		3.859192E-03
  validation loss:		2.019307E-02
Epoch took 2.058s

Epoch 82 of 500
  training loss:		3.939907E-03
  validation loss:		1.115737E-03
Epoch took 2.056s

Epoch 83 of 500
  training loss:		3.899411E-03
  validation loss:		7.075531E-03
Epoch took 2.061s

Epoch 84 of 500
  training loss:		3.653678E-03
  validation loss:		4.081416E-03
Epoch took 2.061s

Epoch 85 of 500
  training loss:		4.496164E-03
  validation loss:		3.061233E-03
Epoch took 2.056s

Epoch 86 of 500
  training loss:		2.873967E-03
  validation loss:		4.720188E-03
Epoch took 2.060s

Epoch 87 of 500
  training loss:		3.890110E-03
  validation loss:		2.149374E-02
Epoch took 2.054s

Epoch 88 of 500
  training loss:		3.029326E-03
  validation loss:		5.123783E-03
Epoch took 2.058s

Epoch 89 of 500
  training loss:		2.443426E-03
  validation loss:		1.154737E-01
Epoch took 2.056s

Epoch 90 of 500
  training loss:		2.661355E-03
  validation loss:		4.889352E-02
Epoch took 2.054s

Epoch 91 of 500
  training loss:		2.299789E-03
  validation loss:		6.450753E-02
Epoch took 2.054s

Epoch 92 of 500
  training loss:		2.068209E-03
  validation loss:		8.012293E-02
Epoch took 2.055s

Epoch 93 of 500
  training loss:		2.362519E-03
  validation loss:		2.958911E-02
Epoch took 2.056s

Epoch 94 of 500
  training loss:		2.261491E-03
  validation loss:		1.460944E-02
Epoch took 2.054s

Epoch 95 of 500
  training loss:		1.676110E-03
  validation loss:		2.430323E-02
Epoch took 2.057s

Epoch 96 of 500
  training loss:		1.450846E-03
  validation loss:		9.406814E-03
Epoch took 2.052s

Epoch 97 of 500
  training loss:		3.106699E-03
  validation loss:		1.068028E-02
Epoch took 2.052s

Epoch 98 of 500
  training loss:		1.312598E-03
  validation loss:		4.989900E-03
Epoch took 2.064s

Epoch 99 of 500
  training loss:		1.106109E-03
  validation loss:		8.027182E-03
Epoch took 2.052s

Epoch 100 of 500
  training loss:		1.090794E-03
  validation loss:		1.397046E-02
Epoch took 2.053s

Early stopping, val-loss increased over the last 20 epochs from 0.00847125352885 to 0.0245719413527
Saving model from epoch 80
Training RMSE: 0.00469816
Validation RMSE: 0.00470614
Test RMSE: 0.00461794342846
Test MSE: 2.13254006667e-05
Test MAE: 0.00278137251735
Test R2: -227026337.087 

