Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		2.634292E-01
  validation loss:		1.015880E-01
Epoch took 0.911s

Epoch 2 of 500
  training loss:		1.189380E-01
  validation loss:		6.440159E-02
Epoch took 0.877s

Epoch 3 of 500
  training loss:		1.013803E-01
  validation loss:		5.363349E-02
Epoch took 0.879s

Epoch 4 of 500
  training loss:		8.992100E-02
  validation loss:		4.472849E-02
Epoch took 0.879s

Epoch 5 of 500
  training loss:		8.430598E-02
  validation loss:		4.250908E-02
Epoch took 0.879s

Epoch 6 of 500
  training loss:		7.951834E-02
  validation loss:		5.078899E-02
Epoch took 0.879s

Epoch 7 of 500
  training loss:		7.531174E-02
  validation loss:		4.207305E-02
Epoch took 0.879s

Epoch 8 of 500
  training loss:		7.258395E-02
  validation loss:		3.849492E-02
Epoch took 0.879s

Epoch 9 of 500
  training loss:		6.718549E-02
  validation loss:		3.823948E-02
Epoch took 0.879s

Epoch 10 of 500
  training loss:		6.528118E-02
  validation loss:		3.556597E-02
Epoch took 0.879s

Epoch 11 of 500
  training loss:		6.272949E-02
  validation loss:		3.474458E-02
Epoch took 0.879s

Epoch 12 of 500
  training loss:		6.276824E-02
  validation loss:		2.942925E-02
Epoch took 0.879s

Epoch 13 of 500
  training loss:		5.918994E-02
  validation loss:		3.387515E-02
Epoch took 0.879s

Epoch 14 of 500
  training loss:		5.861838E-02
  validation loss:		2.819229E-02
Epoch took 0.879s

Epoch 15 of 500
  training loss:		5.797898E-02
  validation loss:		3.178072E-02
Epoch took 0.879s

Epoch 16 of 500
  training loss:		5.567733E-02
  validation loss:		3.118694E-02
Epoch took 0.879s

Epoch 17 of 500
  training loss:		5.481427E-02
  validation loss:		3.589654E-02
Epoch took 0.879s

Epoch 18 of 500
  training loss:		5.322068E-02
  validation loss:		2.577534E-02
Epoch took 0.879s

Epoch 19 of 500
  training loss:		5.340047E-02
  validation loss:		2.829120E-02
Epoch took 0.879s

Epoch 20 of 500
  training loss:		4.998862E-02
  validation loss:		2.551228E-02
Epoch took 0.879s

Epoch 21 of 500
  training loss:		5.152672E-02
  validation loss:		3.171701E-02
Epoch took 0.879s

Epoch 22 of 500
  training loss:		4.890292E-02
  validation loss:		2.603720E-02
Epoch took 0.879s

Epoch 23 of 500
  training loss:		4.867053E-02
  validation loss:		2.732328E-02
Epoch took 0.879s

Epoch 24 of 500
  training loss:		4.749035E-02
  validation loss:		2.900315E-02
Epoch took 0.879s

Epoch 25 of 500
  training loss:		4.660895E-02
  validation loss:		2.818070E-02
Epoch took 0.879s

Epoch 26 of 500
  training loss:		4.667879E-02
  validation loss:		2.169165E-02
Epoch took 0.879s

Epoch 27 of 500
  training loss:		4.451819E-02
  validation loss:		2.597747E-02
Epoch took 0.879s

Epoch 28 of 500
  training loss:		4.350855E-02
  validation loss:		2.665398E-02
Epoch took 0.879s

Epoch 29 of 500
  training loss:		4.487371E-02
  validation loss:		2.322844E-02
Epoch took 0.879s

Epoch 30 of 500
  training loss:		4.272140E-02
  validation loss:		1.877911E-02
Epoch took 0.879s

Epoch 31 of 500
  training loss:		4.163864E-02
  validation loss:		2.226123E-02
Epoch took 0.879s

Epoch 32 of 500
  training loss:		4.260062E-02
  validation loss:		2.905198E-02
Epoch took 0.879s

Epoch 33 of 500
  training loss:		4.157116E-02
  validation loss:		2.463238E-02
Epoch took 0.879s

Epoch 34 of 500
  training loss:		4.033210E-02
  validation loss:		2.195639E-02
Epoch took 0.879s

Epoch 35 of 500
  training loss:		4.090176E-02
  validation loss:		2.259483E-02
Epoch took 0.879s

Epoch 36 of 500
  training loss:		3.998485E-02
  validation loss:		1.963955E-02
Epoch took 0.879s

Epoch 37 of 500
  training loss:		3.838486E-02
  validation loss:		2.397371E-02
Epoch took 0.879s

Epoch 38 of 500
  training loss:		3.796539E-02
  validation loss:		2.117181E-02
Epoch took 0.879s

Epoch 39 of 500
  training loss:		3.863790E-02
  validation loss:		2.085730E-02
Epoch took 0.879s

Epoch 40 of 500
  training loss:		3.710875E-02
  validation loss:		1.761311E-02
Epoch took 0.879s

Epoch 41 of 500
  training loss:		3.675906E-02
  validation loss:		2.346595E-02
Epoch took 0.879s

Epoch 42 of 500
  training loss:		3.599929E-02
  validation loss:		2.367066E-02
Epoch took 0.879s

Epoch 43 of 500
  training loss:		3.607324E-02
  validation loss:		1.901699E-02
Epoch took 0.879s

Epoch 44 of 500
  training loss:		3.514169E-02
  validation loss:		1.900768E-02
Epoch took 0.879s

Epoch 45 of 500
  training loss:		3.566728E-02
  validation loss:		2.298432E-02
Epoch took 0.879s

Epoch 46 of 500
  training loss:		3.424459E-02
  validation loss:		1.781231E-02
Epoch took 0.879s

Epoch 47 of 500
  training loss:		3.343601E-02
  validation loss:		1.970538E-02
Epoch took 0.879s

Epoch 48 of 500
  training loss:		3.347912E-02
  validation loss:		3.155585E-02
Epoch took 0.879s

Epoch 49 of 500
  training loss:		3.360639E-02
  validation loss:		1.784086E-02
Epoch took 0.879s

Epoch 50 of 500
  training loss:		3.327559E-02
  validation loss:		1.759747E-02
Epoch took 0.879s

Epoch 51 of 500
  training loss:		3.223417E-02
  validation loss:		1.914268E-02
Epoch took 0.879s

Epoch 52 of 500
  training loss:		3.184794E-02
  validation loss:		2.066594E-02
Epoch took 0.879s

Epoch 53 of 500
  training loss:		3.199614E-02
  validation loss:		1.688291E-02
Epoch took 0.879s

Epoch 54 of 500
  training loss:		3.124909E-02
  validation loss:		1.640918E-02
Epoch took 0.879s

Epoch 55 of 500
  training loss:		3.130007E-02
  validation loss:		1.833599E-02
Epoch took 0.879s

Epoch 56 of 500
  training loss:		3.052020E-02
  validation loss:		1.657377E-02
Epoch took 0.879s

Epoch 57 of 500
  training loss:		3.047933E-02
  validation loss:		1.530420E-02
Epoch took 0.879s

Epoch 58 of 500
  training loss:		3.043727E-02
  validation loss:		1.827485E-02
Epoch took 0.879s

Epoch 59 of 500
  training loss:		3.013710E-02
  validation loss:		1.880043E-02
Epoch took 0.879s

Epoch 60 of 500
  training loss:		2.914902E-02
  validation loss:		1.919673E-02
Epoch took 0.879s

Epoch 61 of 500
  training loss:		2.981066E-02
  validation loss:		1.834591E-02
Epoch took 0.879s

Epoch 62 of 500
  training loss:		2.926340E-02
  validation loss:		2.029345E-02
Epoch took 0.879s

Epoch 63 of 500
  training loss:		2.798747E-02
  validation loss:		1.337399E-02
Epoch took 0.879s

Epoch 64 of 500
  training loss:		2.867133E-02
  validation loss:		2.457375E-02
Epoch took 0.879s

Epoch 65 of 500
  training loss:		2.841195E-02
  validation loss:		1.375996E-02
Epoch took 0.879s

Epoch 66 of 500
  training loss:		2.747173E-02
  validation loss:		1.919067E-02
Epoch took 0.879s

Epoch 67 of 500
  training loss:		2.694949E-02
  validation loss:		1.385468E-02
Epoch took 0.879s

Epoch 68 of 500
  training loss:		2.652111E-02
  validation loss:		1.420884E-02
Epoch took 0.879s

Epoch 69 of 500
  training loss:		2.708398E-02
  validation loss:		1.486199E-02
Epoch took 0.879s

Epoch 70 of 500
  training loss:		2.716453E-02
  validation loss:		1.397168E-02
Epoch took 0.879s

Epoch 71 of 500
  training loss:		2.581697E-02
  validation loss:		1.597291E-02
Epoch took 0.879s

Epoch 72 of 500
  training loss:		2.578135E-02
  validation loss:		1.286320E-02
Epoch took 0.879s

Epoch 73 of 500
  training loss:		2.624934E-02
  validation loss:		1.397247E-02
Epoch took 0.879s

Epoch 74 of 500
  training loss:		2.480616E-02
  validation loss:		1.444060E-02
Epoch took 0.878s

Epoch 75 of 500
  training loss:		2.529879E-02
  validation loss:		1.631849E-02
Epoch took 0.878s

Epoch 76 of 500
  training loss:		2.525903E-02
  validation loss:		1.336490E-02
Epoch took 0.879s

Epoch 77 of 500
  training loss:		2.481472E-02
  validation loss:		1.508040E-02
Epoch took 0.879s

Epoch 78 of 500
  training loss:		2.449883E-02
  validation loss:		1.266910E-02
Epoch took 0.879s

Epoch 79 of 500
  training loss:		2.453737E-02
  validation loss:		1.701313E-02
Epoch took 0.879s

Epoch 80 of 500
  training loss:		2.379515E-02
  validation loss:		1.366428E-02
Epoch took 0.879s

Epoch 81 of 500
  training loss:		2.433216E-02
  validation loss:		1.179110E-02
Epoch took 0.879s

Epoch 82 of 500
  training loss:		2.350005E-02
  validation loss:		1.477714E-02
Epoch took 0.879s

Epoch 83 of 500
  training loss:		2.346182E-02
  validation loss:		1.249158E-02
Epoch took 0.879s

Epoch 84 of 500
  training loss:		2.351266E-02
  validation loss:		1.358847E-02
Epoch took 0.879s

Epoch 85 of 500
  training loss:		2.325307E-02
  validation loss:		1.173732E-02
Epoch took 0.879s

Epoch 86 of 500
  training loss:		2.335707E-02
  validation loss:		1.704098E-02
Epoch took 0.879s

Epoch 87 of 500
  training loss:		2.310748E-02
  validation loss:		1.168624E-02
Epoch took 0.879s

Epoch 88 of 500
  training loss:		2.262507E-02
  validation loss:		1.201662E-02
Epoch took 0.879s

Epoch 89 of 500
  training loss:		2.228344E-02
  validation loss:		1.184044E-02
Epoch took 0.879s

Epoch 90 of 500
  training loss:		2.218162E-02
  validation loss:		9.138285E-03
Epoch took 0.879s

Epoch 91 of 500
  training loss:		2.238137E-02
  validation loss:		1.063035E-02
Epoch took 0.879s

Epoch 92 of 500
  training loss:		2.164387E-02
  validation loss:		1.330643E-02
Epoch took 0.879s

Epoch 93 of 500
  training loss:		2.161411E-02
  validation loss:		1.352715E-02
Epoch took 0.878s

Epoch 94 of 500
  training loss:		2.135884E-02
  validation loss:		9.987613E-03
Epoch took 0.879s

Epoch 95 of 500
  training loss:		2.151688E-02
  validation loss:		1.196898E-02
Epoch took 0.879s

Epoch 96 of 500
  training loss:		2.098426E-02
  validation loss:		1.088619E-02
Epoch took 0.879s

Epoch 97 of 500
  training loss:		2.123284E-02
  validation loss:		1.518055E-02
Epoch took 0.878s

Epoch 98 of 500
  training loss:		2.092027E-02
  validation loss:		1.098666E-02
Epoch took 0.879s

Epoch 99 of 500
  training loss:		2.054016E-02
  validation loss:		1.364258E-02
Epoch took 0.879s

Epoch 100 of 500
  training loss:		2.059084E-02
  validation loss:		1.132483E-02
Epoch took 0.879s

Epoch 101 of 500
  training loss:		2.028533E-02
  validation loss:		1.273684E-02
Epoch took 0.879s

Epoch 102 of 500
  training loss:		2.055118E-02
  validation loss:		1.089026E-02
Epoch took 0.879s

Epoch 103 of 500
  training loss:		2.037132E-02
  validation loss:		1.179587E-02
Epoch took 0.879s

Epoch 104 of 500
  training loss:		1.944100E-02
  validation loss:		1.181785E-02
Epoch took 0.879s

Epoch 105 of 500
  training loss:		1.996613E-02
  validation loss:		1.125171E-02
Epoch took 0.879s

Epoch 106 of 500
  training loss:		1.961022E-02
  validation loss:		1.284477E-02
Epoch took 0.879s

Epoch 107 of 500
  training loss:		1.968888E-02
  validation loss:		1.154944E-02
Epoch took 0.879s

Epoch 108 of 500
  training loss:		2.008549E-02
  validation loss:		9.721409E-03
Epoch took 0.879s

Epoch 109 of 500
  training loss:		1.885796E-02
  validation loss:		9.124817E-03
Epoch took 0.879s

Epoch 110 of 500
  training loss:		1.912045E-02
  validation loss:		8.917774E-03
Epoch took 0.879s

Epoch 111 of 500
  training loss:		1.884797E-02
  validation loss:		1.112664E-02
Epoch took 0.879s

Epoch 112 of 500
  training loss:		1.875924E-02
  validation loss:		1.054147E-02
Epoch took 0.879s

Epoch 113 of 500
  training loss:		1.868049E-02
  validation loss:		9.606618E-03
Epoch took 0.879s

Epoch 114 of 500
  training loss:		1.837576E-02
  validation loss:		9.922676E-03
Epoch took 0.879s

Epoch 115 of 500
  training loss:		1.805733E-02
  validation loss:		8.939060E-03
Epoch took 0.879s

Epoch 116 of 500
  training loss:		1.873058E-02
  validation loss:		1.113599E-02
Epoch took 0.879s

Epoch 117 of 500
  training loss:		1.773872E-02
  validation loss:		9.341569E-03
Epoch took 0.879s

Epoch 118 of 500
  training loss:		1.754885E-02
  validation loss:		1.181081E-02
Epoch took 0.879s

Epoch 119 of 500
  training loss:		1.809882E-02
  validation loss:		1.395818E-02
Epoch took 0.879s

Epoch 120 of 500
  training loss:		1.772553E-02
  validation loss:		9.518232E-03
Epoch took 0.879s

Epoch 121 of 500
  training loss:		1.777892E-02
  validation loss:		9.685958E-03
Epoch took 0.879s

Epoch 122 of 500
  training loss:		1.750758E-02
  validation loss:		1.018228E-02
Epoch took 0.879s

Epoch 123 of 500
  training loss:		1.770961E-02
  validation loss:		1.082245E-02
Epoch took 0.879s

Epoch 124 of 500
  training loss:		1.812618E-02
  validation loss:		9.916384E-03
Epoch took 0.881s

Epoch 125 of 500
  training loss:		1.713969E-02
  validation loss:		9.489791E-03
Epoch took 0.878s

Epoch 126 of 500
  training loss:		1.671077E-02
  validation loss:		8.333407E-03
Epoch took 0.879s

Epoch 127 of 500
  training loss:		1.717641E-02
  validation loss:		1.089543E-02
Epoch took 0.878s

Epoch 128 of 500
  training loss:		1.653665E-02
  validation loss:		8.960219E-03
Epoch took 0.879s

Epoch 129 of 500
  training loss:		1.687905E-02
  validation loss:		1.197208E-02
Epoch took 0.879s

Epoch 130 of 500
  training loss:		1.685915E-02
  validation loss:		9.933876E-03
Epoch took 0.879s

Epoch 131 of 500
  training loss:		1.641620E-02
  validation loss:		8.765999E-03
Epoch took 0.879s

Epoch 132 of 500
  training loss:		1.650343E-02
  validation loss:		1.113448E-02
Epoch took 0.879s

Epoch 133 of 500
  training loss:		1.629898E-02
  validation loss:		9.720362E-03
Epoch took 0.879s

Epoch 134 of 500
  training loss:		1.634136E-02
  validation loss:		9.720053E-03
Epoch took 0.879s

Epoch 135 of 500
  training loss:		1.601604E-02
  validation loss:		1.188049E-02
Epoch took 0.879s

Epoch 136 of 500
  training loss:		1.605151E-02
  validation loss:		8.030245E-03
Epoch took 0.879s

Epoch 137 of 500
  training loss:		1.552792E-02
  validation loss:		7.840390E-03
Epoch took 0.879s

Epoch 138 of 500
  training loss:		1.567799E-02
  validation loss:		9.873376E-03
Epoch took 0.879s

Epoch 139 of 500
  training loss:		1.548627E-02
  validation loss:		9.531124E-03
Epoch took 0.879s

Epoch 140 of 500
  training loss:		1.530831E-02
  validation loss:		1.145009E-02
Epoch took 0.879s

Epoch 141 of 500
  training loss:		1.545008E-02
  validation loss:		1.312307E-02
Epoch took 0.879s

Epoch 142 of 500
  training loss:		1.539259E-02
  validation loss:		8.274453E-03
Epoch took 0.879s

Epoch 143 of 500
  training loss:		1.517495E-02
  validation loss:		8.328788E-03
Epoch took 0.879s

Epoch 144 of 500
  training loss:		1.482395E-02
  validation loss:		9.216107E-03
Epoch took 0.879s

Epoch 145 of 500
  training loss:		1.501218E-02
  validation loss:		1.050900E-02
Epoch took 0.879s

Epoch 146 of 500
  training loss:		1.502681E-02
  validation loss:		8.299124E-03
Epoch took 0.879s

Epoch 147 of 500
  training loss:		1.480677E-02
  validation loss:		7.793307E-03
Epoch took 0.879s

Epoch 148 of 500
  training loss:		1.459938E-02
  validation loss:		7.881777E-03
Epoch took 0.879s

Epoch 149 of 500
  training loss:		1.452331E-02
  validation loss:		1.086715E-02
Epoch took 0.879s

Epoch 150 of 500
  training loss:		1.461148E-02
  validation loss:		9.587521E-03
Epoch took 0.879s

Epoch 151 of 500
  training loss:		1.461293E-02
  validation loss:		8.371178E-03
Epoch took 0.879s

Epoch 152 of 500
  training loss:		1.415531E-02
  validation loss:		8.801123E-03
Epoch took 0.879s

Epoch 153 of 500
  training loss:		1.429526E-02
  validation loss:		8.982304E-03
Epoch took 0.879s

Epoch 154 of 500
  training loss:		1.436402E-02
  validation loss:		8.468433E-03
Epoch took 0.879s

Epoch 155 of 500
  training loss:		1.402269E-02
  validation loss:		8.735114E-03
Epoch took 0.879s

Epoch 156 of 500
  training loss:		1.422791E-02
  validation loss:		9.064230E-03
Epoch took 0.879s

Epoch 157 of 500
  training loss:		1.440957E-02
  validation loss:		7.017877E-03
Epoch took 0.879s

Epoch 158 of 500
  training loss:		1.415415E-02
  validation loss:		9.759694E-03
Epoch took 0.879s

Epoch 159 of 500
  training loss:		1.366954E-02
  validation loss:		8.363561E-03
Epoch took 0.879s

Epoch 160 of 500
  training loss:		1.393322E-02
  validation loss:		7.307367E-03
Epoch took 0.879s

Epoch 161 of 500
  training loss:		1.335056E-02
  validation loss:		7.108306E-03
Epoch took 0.879s

Epoch 162 of 500
  training loss:		1.344848E-02
  validation loss:		8.016368E-03
Epoch took 0.879s

Epoch 163 of 500
  training loss:		1.348633E-02
  validation loss:		1.007017E-02
Epoch took 0.879s

Epoch 164 of 500
  training loss:		1.394052E-02
  validation loss:		9.386795E-03
Epoch took 0.879s

Epoch 165 of 500
  training loss:		1.373859E-02
  validation loss:		7.892677E-03
Epoch took 0.879s

Epoch 166 of 500
  training loss:		1.316525E-02
  validation loss:		6.144677E-03
Epoch took 0.879s

Epoch 167 of 500
  training loss:		1.302385E-02
  validation loss:		6.855655E-03
Epoch took 0.880s

Epoch 168 of 500
  training loss:		1.338710E-02
  validation loss:		8.088626E-03
Epoch took 0.878s

Epoch 169 of 500
  training loss:		1.283019E-02
  validation loss:		7.805128E-03
Epoch took 0.879s

Epoch 170 of 500
  training loss:		1.305480E-02
  validation loss:		9.555201E-03
Epoch took 0.879s

Epoch 171 of 500
  training loss:		1.290871E-02
  validation loss:		8.436407E-03
Epoch took 0.879s

Epoch 172 of 500
  training loss:		1.323706E-02
  validation loss:		9.211195E-03
Epoch took 0.879s

Epoch 173 of 500
  training loss:		1.253850E-02
  validation loss:		9.200800E-03
Epoch took 0.879s

Epoch 174 of 500
  training loss:		1.261831E-02
  validation loss:		7.701506E-03
Epoch took 0.879s

Epoch 175 of 500
  training loss:		1.269422E-02
  validation loss:		7.549393E-03
Epoch took 0.879s

Epoch 176 of 500
  training loss:		1.263230E-02
  validation loss:		7.712648E-03
Epoch took 0.879s

Epoch 177 of 500
  training loss:		1.205367E-02
  validation loss:		7.899195E-03
Epoch took 0.879s

Epoch 178 of 500
  training loss:		1.217386E-02
  validation loss:		6.628075E-03
Epoch took 0.879s

Epoch 179 of 500
  training loss:		1.228350E-02
  validation loss:		7.114157E-03
Epoch took 0.879s

Epoch 180 of 500
  training loss:		1.259315E-02
  validation loss:		6.526535E-03
Epoch took 0.879s

Epoch 181 of 500
  training loss:		1.237995E-02
  validation loss:		1.167776E-02
Epoch took 0.879s

Epoch 182 of 500
  training loss:		1.227242E-02
  validation loss:		7.249496E-03
Epoch took 0.879s

Epoch 183 of 500
  training loss:		1.188530E-02
  validation loss:		6.941197E-03
Epoch took 0.879s

Epoch 184 of 500
  training loss:		1.176344E-02
  validation loss:		8.233514E-03
Epoch took 0.879s

Epoch 185 of 500
  training loss:		1.195504E-02
  validation loss:		8.598186E-03
Epoch took 0.879s

Epoch 186 of 500
  training loss:		1.227698E-02
  validation loss:		6.154980E-03
Epoch took 0.879s

Epoch 187 of 500
  training loss:		1.214607E-02
  validation loss:		9.429582E-03
Epoch took 0.879s

Epoch 188 of 500
  training loss:		1.165900E-02
  validation loss:		8.004781E-03
Epoch took 0.879s

Epoch 189 of 500
  training loss:		1.169903E-02
  validation loss:		7.784021E-03
Epoch took 0.878s

Epoch 190 of 500
  training loss:		1.200928E-02
  validation loss:		7.430100E-03
Epoch took 0.879s

Epoch 191 of 500
  training loss:		1.139352E-02
  validation loss:		7.335997E-03
Epoch took 0.879s

Epoch 192 of 500
  training loss:		1.165442E-02
  validation loss:		7.290004E-03
Epoch took 0.879s

Epoch 193 of 500
  training loss:		1.153990E-02
  validation loss:		8.067171E-03
Epoch took 0.879s

Epoch 194 of 500
  training loss:		1.171188E-02
  validation loss:		6.283796E-03
Epoch took 0.879s

Epoch 195 of 500
  training loss:		1.191552E-02
  validation loss:		6.219828E-03
Epoch took 0.878s

Early stopping, val-loss increased over the last 15 epochs from 0.00776194649362 to 0.00778002749074
Saving model from epoch 180
Training RMSE: 0.00654566
Validation RMSE: 0.00653865
Test RMSE: 0.00649178773165
Test MSE: 4.21433069278e-05
Test MAE: 0.00520122749731
Test R2: -448650002.976 

