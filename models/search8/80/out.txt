Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		5.828328E-01
  validation loss:		1.451931E+02
Epoch took 0.749s

Epoch 2 of 500
  training loss:		1.684477E-01
  validation loss:		4.144293E-01
Epoch took 0.701s

Epoch 3 of 500
  training loss:		8.327225E-02
  validation loss:		8.595503E-02
Epoch took 0.701s

Epoch 4 of 500
  training loss:		7.200440E-02
  validation loss:		4.405776E-02
Epoch took 0.701s

Epoch 5 of 500
  training loss:		6.929507E-02
  validation loss:		4.014091E-02
Epoch took 0.701s

Epoch 6 of 500
  training loss:		6.522318E-02
  validation loss:		3.682084E-02
Epoch took 0.700s

Epoch 7 of 500
  training loss:		5.804950E-02
  validation loss:		4.411481E-02
Epoch took 0.701s

Epoch 8 of 500
  training loss:		5.694262E-02
  validation loss:		4.427121E-02
Epoch took 0.700s

Epoch 9 of 500
  training loss:		5.821558E-02
  validation loss:		3.807099E-02
Epoch took 0.701s

Epoch 10 of 500
  training loss:		5.418527E-02
  validation loss:		3.375261E-02
Epoch took 0.700s

Epoch 11 of 500
  training loss:		5.356310E-02
  validation loss:		3.344172E-02
Epoch took 0.700s

Epoch 12 of 500
  training loss:		5.256443E-02
  validation loss:		5.070763E-02
Epoch took 0.700s

Epoch 13 of 500
  training loss:		5.269845E-02
  validation loss:		4.189293E-02
Epoch took 0.700s

Epoch 14 of 500
  training loss:		4.831754E-02
  validation loss:		3.286477E-02
Epoch took 0.700s

Epoch 15 of 500
  training loss:		5.085941E-02
  validation loss:		3.700988E-02
Epoch took 0.700s

Epoch 16 of 500
  training loss:		5.047972E-02
  validation loss:		2.736563E-02
Epoch took 0.701s

Epoch 17 of 500
  training loss:		4.685657E-02
  validation loss:		4.625049E-02
Epoch took 0.700s

Epoch 18 of 500
  training loss:		5.000214E-02
  validation loss:		4.169625E-02
Epoch took 0.700s

Epoch 19 of 500
  training loss:		4.656007E-02
  validation loss:		3.144372E-02
Epoch took 0.700s

Epoch 20 of 500
  training loss:		4.670540E-02
  validation loss:		4.123068E-02
Epoch took 0.700s

Epoch 21 of 500
  training loss:		4.639988E-02
  validation loss:		3.997840E-02
Epoch took 0.700s

Epoch 22 of 500
  training loss:		4.379868E-02
  validation loss:		3.068593E-02
Epoch took 0.700s

Epoch 23 of 500
  training loss:		4.338109E-02
  validation loss:		4.561547E-02
Epoch took 0.700s

Epoch 24 of 500
  training loss:		4.449689E-02
  validation loss:		3.163962E-02
Epoch took 0.700s

Epoch 25 of 500
  training loss:		4.255014E-02
  validation loss:		4.061127E-02
Epoch took 0.699s

Epoch 26 of 500
  training loss:		4.328847E-02
  validation loss:		3.327254E-02
Epoch took 0.700s

Epoch 27 of 500
  training loss:		4.445149E-02
  validation loss:		3.107782E-02
Epoch took 0.701s

Epoch 28 of 500
  training loss:		4.517231E-02
  validation loss:		3.230146E-02
Epoch took 0.700s

Epoch 29 of 500
  training loss:		4.280322E-02
  validation loss:		2.571573E-02
Epoch took 0.700s

Epoch 30 of 500
  training loss:		3.999141E-02
  validation loss:		4.983493E-02
Epoch took 0.701s

Epoch 31 of 500
  training loss:		4.390121E-02
  validation loss:		3.863814E-02
Epoch took 0.700s

Epoch 32 of 500
  training loss:		4.166170E-02
  validation loss:		2.810675E-02
Epoch took 0.700s

Epoch 33 of 500
  training loss:		4.026266E-02
  validation loss:		2.862277E-02
Epoch took 0.700s

Epoch 34 of 500
  training loss:		4.084847E-02
  validation loss:		3.035278E-02
Epoch took 0.700s

Epoch 35 of 500
  training loss:		4.008829E-02
  validation loss:		4.019273E-02
Epoch took 0.700s

Epoch 36 of 500
  training loss:		4.006667E-02
  validation loss:		3.159918E-02
Epoch took 0.701s

Epoch 37 of 500
  training loss:		3.757580E-02
  validation loss:		2.835577E-02
Epoch took 0.700s

Epoch 38 of 500
  training loss:		3.797387E-02
  validation loss:		3.929737E-02
Epoch took 0.700s

Epoch 39 of 500
  training loss:		3.736777E-02
  validation loss:		3.765044E-02
Epoch took 0.701s

Epoch 40 of 500
  training loss:		3.691742E-02
  validation loss:		2.595368E-02
Epoch took 0.700s

Epoch 41 of 500
  training loss:		3.827038E-02
  validation loss:		3.051705E-02
Epoch took 0.701s

Epoch 42 of 500
  training loss:		3.816383E-02
  validation loss:		3.537646E-02
Epoch took 0.700s

Epoch 43 of 500
  training loss:		3.806930E-02
  validation loss:		3.239653E-02
Epoch took 0.700s

Epoch 44 of 500
  training loss:		3.957448E-02
  validation loss:		2.567081E-02
Epoch took 0.700s

Epoch 45 of 500
  training loss:		3.622981E-02
  validation loss:		3.392736E-02
Epoch took 0.700s

Epoch 46 of 500
  training loss:		3.634283E-02
  validation loss:		2.548766E-02
Epoch took 0.700s

Epoch 47 of 500
  training loss:		3.683782E-02
  validation loss:		2.375031E-02
Epoch took 0.700s

Epoch 48 of 500
  training loss:		3.436068E-02
  validation loss:		2.856095E-02
Epoch took 0.700s

Epoch 49 of 500
  training loss:		3.517960E-02
  validation loss:		2.539403E-02
Epoch took 0.700s

Epoch 50 of 500
  training loss:		3.629816E-02
  validation loss:		2.312199E-02
Epoch took 0.700s

Epoch 51 of 500
  training loss:		3.643883E-02
  validation loss:		2.474911E-02
Epoch took 0.700s

Epoch 52 of 500
  training loss:		3.509689E-02
  validation loss:		3.209529E-02
Epoch took 0.701s

Epoch 53 of 500
  training loss:		3.771718E-02
  validation loss:		2.941305E-02
Epoch took 0.700s

Epoch 54 of 500
  training loss:		3.449809E-02
  validation loss:		3.050399E-02
Epoch took 0.701s

Epoch 55 of 500
  training loss:		3.441534E-02
  validation loss:		2.287039E-02
Epoch took 0.700s

Epoch 56 of 500
  training loss:		3.429981E-02
  validation loss:		2.376664E-02
Epoch took 0.700s

Epoch 57 of 500
  training loss:		3.605369E-02
  validation loss:		4.145148E-02
Epoch took 0.700s

Epoch 58 of 500
  training loss:		3.382779E-02
  validation loss:		2.101434E-02
Epoch took 0.700s

Epoch 59 of 500
  training loss:		3.336006E-02
  validation loss:		2.427764E-02
Epoch took 0.700s

Epoch 60 of 500
  training loss:		3.434107E-02
  validation loss:		2.133455E-02
Epoch took 0.703s

Epoch 61 of 500
  training loss:		3.236723E-02
  validation loss:		2.118213E-02
Epoch took 0.703s

Epoch 62 of 500
  training loss:		3.555067E-02
  validation loss:		2.784523E-02
Epoch took 0.703s

Epoch 63 of 500
  training loss:		3.362327E-02
  validation loss:		2.153609E-02
Epoch took 0.703s

Epoch 64 of 500
  training loss:		3.391105E-02
  validation loss:		2.420449E-02
Epoch took 0.703s

Epoch 65 of 500
  training loss:		3.265608E-02
  validation loss:		2.255095E-02
Epoch took 0.703s

Epoch 66 of 500
  training loss:		3.325783E-02
  validation loss:		2.760355E-02
Epoch took 0.702s

Epoch 67 of 500
  training loss:		3.341429E-02
  validation loss:		2.477681E-02
Epoch took 0.702s

Epoch 68 of 500
  training loss:		3.283612E-02
  validation loss:		2.912678E-02
Epoch took 0.703s

Epoch 69 of 500
  training loss:		3.346712E-02
  validation loss:		2.592663E-02
Epoch took 0.703s

Epoch 70 of 500
  training loss:		3.428650E-02
  validation loss:		2.145045E-02
Epoch took 0.703s

Epoch 71 of 500
  training loss:		3.238132E-02
  validation loss:		2.775216E-02
Epoch took 0.703s

Epoch 72 of 500
  training loss:		3.421284E-02
  validation loss:		3.947715E-02
Epoch took 0.703s

Epoch 73 of 500
  training loss:		3.062964E-02
  validation loss:		2.760763E-02
Epoch took 0.703s

Epoch 74 of 500
  training loss:		3.153133E-02
  validation loss:		4.126477E-02
Epoch took 0.703s

Epoch 75 of 500
  training loss:		3.167018E-02
  validation loss:		2.755133E-02
Epoch took 0.703s

Epoch 76 of 500
  training loss:		3.203901E-02
  validation loss:		2.528840E-02
Epoch took 0.704s

Epoch 77 of 500
  training loss:		3.086164E-02
  validation loss:		2.016140E-02
Epoch took 0.703s

Epoch 78 of 500
  training loss:		3.077816E-02
  validation loss:		2.426367E-02
Epoch took 0.703s

Epoch 79 of 500
  training loss:		3.206854E-02
  validation loss:		2.066611E-02
Epoch took 0.703s

Epoch 80 of 500
  training loss:		3.026929E-02
  validation loss:		2.288010E-02
Epoch took 0.703s

Epoch 81 of 500
  training loss:		3.085235E-02
  validation loss:		2.534894E-02
Epoch took 0.708s

Epoch 82 of 500
  training loss:		3.033563E-02
  validation loss:		2.765414E-02
Epoch took 0.705s

Epoch 83 of 500
  training loss:		2.934764E-02
  validation loss:		2.800663E-02
Epoch took 0.711s

Epoch 84 of 500
  training loss:		3.191285E-02
  validation loss:		2.158431E-02
Epoch took 0.705s

Epoch 85 of 500
  training loss:		3.079504E-02
  validation loss:		1.948902E-02
Epoch took 0.708s

Epoch 86 of 500
  training loss:		2.944381E-02
  validation loss:		2.373678E-02
Epoch took 0.707s

Epoch 87 of 500
  training loss:		3.031542E-02
  validation loss:		1.761132E-02
Epoch took 0.707s

Epoch 88 of 500
  training loss:		3.056997E-02
  validation loss:		2.094956E-02
Epoch took 0.707s

Epoch 89 of 500
  training loss:		2.982516E-02
  validation loss:		1.934311E-02
Epoch took 0.710s

Epoch 90 of 500
  training loss:		3.022266E-02
  validation loss:		2.355197E-02
Epoch took 0.707s

Epoch 91 of 500
  training loss:		3.128199E-02
  validation loss:		2.416674E-02
Epoch took 0.703s

Epoch 92 of 500
  training loss:		2.957170E-02
  validation loss:		2.638246E-02
Epoch took 0.703s

Epoch 93 of 500
  training loss:		2.894157E-02
  validation loss:		4.002538E-02
Epoch took 0.703s

Epoch 94 of 500
  training loss:		2.984499E-02
  validation loss:		3.803893E-02
Epoch took 0.703s

Epoch 95 of 500
  training loss:		2.912144E-02
  validation loss:		2.297646E-02
Epoch took 0.703s

Epoch 96 of 500
  training loss:		2.949610E-02
  validation loss:		2.073573E-02
Epoch took 0.703s

Epoch 97 of 500
  training loss:		2.793917E-02
  validation loss:		1.998554E-02
Epoch took 0.703s

Epoch 98 of 500
  training loss:		2.848989E-02
  validation loss:		2.574683E-02
Epoch took 0.704s

Epoch 99 of 500
  training loss:		2.819237E-02
  validation loss:		1.956060E-02
Epoch took 0.703s

Epoch 100 of 500
  training loss:		2.903066E-02
  validation loss:		1.911377E-02
Epoch took 0.703s

Epoch 101 of 500
  training loss:		2.912494E-02
  validation loss:		2.779478E-02
Epoch took 0.703s

Epoch 102 of 500
  training loss:		2.790402E-02
  validation loss:		2.906890E-02
Epoch took 0.703s

Epoch 103 of 500
  training loss:		2.805035E-02
  validation loss:		1.973431E-02
Epoch took 0.703s

Epoch 104 of 500
  training loss:		2.874811E-02
  validation loss:		2.691811E-02
Epoch took 0.703s

Epoch 105 of 500
  training loss:		2.791624E-02
  validation loss:		3.360988E-02
Epoch took 0.703s

Epoch 106 of 500
  training loss:		2.764794E-02
  validation loss:		1.883848E-02
Epoch took 0.704s

Epoch 107 of 500
  training loss:		2.717564E-02
  validation loss:		1.754234E-02
Epoch took 0.704s

Epoch 108 of 500
  training loss:		2.752649E-02
  validation loss:		2.707162E-02
Epoch took 0.702s

Epoch 109 of 500
  training loss:		2.811739E-02
  validation loss:		2.167088E-02
Epoch took 0.703s

Epoch 110 of 500
  training loss:		2.780895E-02
  validation loss:		2.156942E-02
Epoch took 0.703s

Epoch 111 of 500
  training loss:		2.721628E-02
  validation loss:		1.957363E-02
Epoch took 0.703s

Epoch 112 of 500
  training loss:		2.738276E-02
  validation loss:		2.480768E-02
Epoch took 0.703s

Epoch 113 of 500
  training loss:		2.762159E-02
  validation loss:		1.646666E-02
Epoch took 0.703s

Epoch 114 of 500
  training loss:		2.685981E-02
  validation loss:		1.717999E-02
Epoch took 0.703s

Epoch 115 of 500
  training loss:		2.730311E-02
  validation loss:		2.016271E-02
Epoch took 0.703s

Epoch 116 of 500
  training loss:		2.773009E-02
  validation loss:		1.785713E-02
Epoch took 0.703s

Epoch 117 of 500
  training loss:		2.564252E-02
  validation loss:		2.319407E-02
Epoch took 0.703s

Epoch 118 of 500
  training loss:		2.845380E-02
  validation loss:		2.138813E-02
Epoch took 0.703s

Epoch 119 of 500
  training loss:		2.620833E-02
  validation loss:		1.756890E-02
Epoch took 0.703s

Epoch 120 of 500
  training loss:		2.620358E-02
  validation loss:		2.621640E-02
Epoch took 0.703s

Epoch 121 of 500
  training loss:		2.581100E-02
  validation loss:		2.161286E-02
Epoch took 0.703s

Epoch 122 of 500
  training loss:		2.592097E-02
  validation loss:		2.642428E-02
Epoch took 0.703s

Epoch 123 of 500
  training loss:		2.660142E-02
  validation loss:		1.938991E-02
Epoch took 0.703s

Epoch 124 of 500
  training loss:		2.625946E-02
  validation loss:		2.352782E-02
Epoch took 0.703s

Epoch 125 of 500
  training loss:		2.707436E-02
  validation loss:		2.546656E-02
Epoch took 0.703s

Epoch 126 of 500
  training loss:		2.602268E-02
  validation loss:		2.018356E-02
Epoch took 0.704s

Epoch 127 of 500
  training loss:		2.580293E-02
  validation loss:		1.981230E-02
Epoch took 0.703s

Epoch 128 of 500
  training loss:		2.630368E-02
  validation loss:		2.519437E-02
Epoch took 0.703s

Epoch 129 of 500
  training loss:		2.623404E-02
  validation loss:		1.596407E-02
Epoch took 0.703s

Epoch 130 of 500
  training loss:		2.621623E-02
  validation loss:		2.336695E-02
Epoch took 0.703s

Epoch 131 of 500
  training loss:		2.605240E-02
  validation loss:		2.109603E-02
Epoch took 0.703s

Epoch 132 of 500
  training loss:		2.459913E-02
  validation loss:		1.941807E-02
Epoch took 0.703s

Epoch 133 of 500
  training loss:		2.657110E-02
  validation loss:		1.488751E-02
Epoch took 0.703s

Epoch 134 of 500
  training loss:		2.599332E-02
  validation loss:		2.990010E-02
Epoch took 0.703s

Epoch 135 of 500
  training loss:		2.727597E-02
  validation loss:		2.471562E-02
Epoch took 0.703s

Epoch 136 of 500
  training loss:		2.566237E-02
  validation loss:		2.086057E-02
Epoch took 0.704s

Epoch 137 of 500
  training loss:		2.727668E-02
  validation loss:		3.165348E-02
Epoch took 0.703s

Epoch 138 of 500
  training loss:		2.624670E-02
  validation loss:		1.658814E-02
Epoch took 0.703s

Epoch 139 of 500
  training loss:		2.550896E-02
  validation loss:		1.731782E-02
Epoch took 0.703s

Epoch 140 of 500
  training loss:		2.518967E-02
  validation loss:		2.611959E-02
Epoch took 0.704s

Epoch 141 of 500
  training loss:		2.495638E-02
  validation loss:		2.036109E-02
Epoch took 0.704s

Epoch 142 of 500
  training loss:		2.599925E-02
  validation loss:		2.661635E-02
Epoch took 0.703s

Epoch 143 of 500
  training loss:		2.466389E-02
  validation loss:		1.768897E-02
Epoch took 0.703s

Epoch 144 of 500
  training loss:		2.559556E-02
  validation loss:		2.033279E-02
Epoch took 0.703s

Epoch 145 of 500
  training loss:		2.352774E-02
  validation loss:		2.061265E-02
Epoch took 0.702s

Epoch 146 of 500
  training loss:		2.390440E-02
  validation loss:		2.209766E-02
Epoch took 0.704s

Epoch 147 of 500
  training loss:		2.415563E-02
  validation loss:		1.846156E-02
Epoch took 0.704s

Epoch 148 of 500
  training loss:		2.425468E-02
  validation loss:		2.394695E-02
Epoch took 0.703s

Epoch 149 of 500
  training loss:		2.427367E-02
  validation loss:		2.512155E-02
Epoch took 0.703s

Epoch 150 of 500
  training loss:		2.502078E-02
  validation loss:		1.959942E-02
Epoch took 0.703s

Epoch 151 of 500
  training loss:		2.454723E-02
  validation loss:		2.604265E-02
Epoch took 0.703s

Epoch 152 of 500
  training loss:		2.377996E-02
  validation loss:		1.908814E-02
Epoch took 0.703s

Epoch 153 of 500
  training loss:		2.399183E-02
  validation loss:		2.631245E-02
Epoch took 0.703s

Epoch 154 of 500
  training loss:		2.577846E-02
  validation loss:		1.778700E-02
Epoch took 0.703s

Epoch 155 of 500
  training loss:		2.358911E-02
  validation loss:		1.990262E-02
Epoch took 0.704s

Epoch 156 of 500
  training loss:		2.341451E-02
  validation loss:		1.676526E-02
Epoch took 0.704s

Epoch 157 of 500
  training loss:		2.364934E-02
  validation loss:		1.567055E-02
Epoch took 0.704s

Epoch 158 of 500
  training loss:		2.600790E-02
  validation loss:		1.817330E-02
Epoch took 0.703s

Epoch 159 of 500
  training loss:		2.352400E-02
  validation loss:		1.920726E-02
Epoch took 0.703s

Epoch 160 of 500
  training loss:		2.273835E-02
  validation loss:		1.859012E-02
Epoch took 0.703s

Epoch 161 of 500
  training loss:		2.326726E-02
  validation loss:		1.780993E-02
Epoch took 0.704s

Epoch 162 of 500
  training loss:		2.338472E-02
  validation loss:		1.705056E-02
Epoch took 0.704s

Epoch 163 of 500
  training loss:		2.242970E-02
  validation loss:		1.866556E-02
Epoch took 0.703s

Epoch 164 of 500
  training loss:		2.409615E-02
  validation loss:		1.448350E-02
Epoch took 0.704s

Epoch 165 of 500
  training loss:		2.450890E-02
  validation loss:		1.835300E-02
Epoch took 0.704s

Epoch 166 of 500
  training loss:		2.290448E-02
  validation loss:		2.001378E-02
Epoch took 0.703s

Epoch 167 of 500
  training loss:		2.312172E-02
  validation loss:		1.802622E-02
Epoch took 0.703s

Epoch 168 of 500
  training loss:		2.312713E-02
  validation loss:		1.935171E-02
Epoch took 0.703s

Epoch 169 of 500
  training loss:		2.307394E-02
  validation loss:		1.538857E-02
Epoch took 0.703s

Epoch 170 of 500
  training loss:		2.308926E-02
  validation loss:		2.200281E-02
Epoch took 0.703s

Epoch 171 of 500
  training loss:		2.233342E-02
  validation loss:		2.170001E-02
Epoch took 0.704s

Epoch 172 of 500
  training loss:		2.355321E-02
  validation loss:		2.405292E-02
Epoch took 0.703s

Epoch 173 of 500
  training loss:		2.238876E-02
  validation loss:		1.381523E-02
Epoch took 0.706s

Epoch 174 of 500
  training loss:		2.286271E-02
  validation loss:		1.776728E-02
Epoch took 0.703s

Epoch 175 of 500
  training loss:		2.173410E-02
  validation loss:		2.208013E-02
Epoch took 0.705s

Epoch 176 of 500
  training loss:		2.374245E-02
  validation loss:		1.724045E-02
Epoch took 0.703s

Epoch 177 of 500
  training loss:		2.444801E-02
  validation loss:		1.539959E-02
Epoch took 0.703s

Epoch 178 of 500
  training loss:		2.180434E-02
  validation loss:		1.355282E-02
Epoch took 0.702s

Epoch 179 of 500
  training loss:		2.272252E-02
  validation loss:		1.597687E-02
Epoch took 0.703s

Epoch 180 of 500
  training loss:		2.200922E-02
  validation loss:		1.417628E-02
Epoch took 0.703s

Epoch 181 of 500
  training loss:		2.218937E-02
  validation loss:		2.014836E-02
Epoch took 0.703s

Epoch 182 of 500
  training loss:		2.254463E-02
  validation loss:		2.244585E-02
Epoch took 0.703s

Epoch 183 of 500
  training loss:		2.246443E-02
  validation loss:		2.056386E-02
Epoch took 0.703s

Epoch 184 of 500
  training loss:		2.194909E-02
  validation loss:		2.179963E-02
Epoch took 0.703s

Epoch 185 of 500
  training loss:		2.177713E-02
  validation loss:		1.682906E-02
Epoch took 0.703s

Epoch 186 of 500
  training loss:		2.300536E-02
  validation loss:		1.907638E-02
Epoch took 0.703s

Epoch 187 of 500
  training loss:		2.173935E-02
  validation loss:		1.749405E-02
Epoch took 0.702s

Epoch 188 of 500
  training loss:		2.260437E-02
  validation loss:		2.667500E-02
Epoch took 0.703s

Epoch 189 of 500
  training loss:		2.207137E-02
  validation loss:		1.974149E-02
Epoch took 0.702s

Epoch 190 of 500
  training loss:		2.229519E-02
  validation loss:		1.778815E-02
Epoch took 0.703s

Epoch 191 of 500
  training loss:		2.240369E-02
  validation loss:		1.933880E-02
Epoch took 0.703s

Epoch 192 of 500
  training loss:		2.140132E-02
  validation loss:		2.036740E-02
Epoch took 0.703s

Epoch 193 of 500
  training loss:		2.217670E-02
  validation loss:		1.794384E-02
Epoch took 0.703s

Epoch 194 of 500
  training loss:		2.207712E-02
  validation loss:		1.646525E-02
Epoch took 0.703s

Epoch 195 of 500
  training loss:		2.251358E-02
  validation loss:		1.523691E-02
Epoch took 0.703s

Epoch 196 of 500
  training loss:		2.079171E-02
  validation loss:		1.562911E-02
Epoch took 0.703s

Epoch 197 of 500
  training loss:		2.180259E-02
  validation loss:		1.865085E-02
Epoch took 0.703s

Epoch 198 of 500
  training loss:		2.250766E-02
  validation loss:		2.215892E-02
Epoch took 0.703s

Epoch 199 of 500
  training loss:		2.196504E-02
  validation loss:		1.622004E-02
Epoch took 0.703s

Epoch 200 of 500
  training loss:		2.070919E-02
  validation loss:		2.271213E-02
Epoch took 0.703s

Early stopping, val-loss increased over the last 20 epochs from 0.017845360451 to 0.0193642543111
Saving model from epoch 180
Training RMSE: 0.0140944
Validation RMSE: 0.014171
Test RMSE: 0.0139963692054
Test MSE: 0.000195898348466
Test MAE: 0.0112193105742
Test R2: -2085498216.1 

