Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		4.711191E-01
  validation loss:		2.041173E+02
Epoch took 0.760s

Epoch 2 of 500
  training loss:		1.310909E-01
  validation loss:		4.256887E-01
Epoch took 0.700s

Epoch 3 of 500
  training loss:		7.802103E-02
  validation loss:		6.802417E-02
Epoch took 0.703s

Epoch 4 of 500
  training loss:		7.063678E-02
  validation loss:		5.654284E-02
Epoch took 0.700s

Epoch 5 of 500
  training loss:		6.235296E-02
  validation loss:		5.609221E-02
Epoch took 0.701s

Epoch 6 of 500
  training loss:		5.770261E-02
  validation loss:		3.470447E-02
Epoch took 0.700s

Epoch 7 of 500
  training loss:		5.629237E-02
  validation loss:		5.779982E-02
Epoch took 0.700s

Epoch 8 of 500
  training loss:		5.262329E-02
  validation loss:		4.277011E-02
Epoch took 0.700s

Epoch 9 of 500
  training loss:		5.021681E-02
  validation loss:		3.872460E-02
Epoch took 0.701s

Epoch 10 of 500
  training loss:		5.119185E-02
  validation loss:		3.339124E-02
Epoch took 0.700s

Epoch 11 of 500
  training loss:		4.856236E-02
  validation loss:		4.242435E-02
Epoch took 0.700s

Epoch 12 of 500
  training loss:		4.962919E-02
  validation loss:		3.803670E-02
Epoch took 0.700s

Epoch 13 of 500
  training loss:		4.808944E-02
  validation loss:		3.636159E-02
Epoch took 0.701s

Epoch 14 of 500
  training loss:		4.988632E-02
  validation loss:		3.754350E-02
Epoch took 0.701s

Epoch 15 of 500
  training loss:		4.401354E-02
  validation loss:		3.614242E-02
Epoch took 0.700s

Epoch 16 of 500
  training loss:		4.594055E-02
  validation loss:		4.044776E-02
Epoch took 0.700s

Epoch 17 of 500
  training loss:		4.491891E-02
  validation loss:		5.139629E-02
Epoch took 0.701s

Epoch 18 of 500
  training loss:		4.617061E-02
  validation loss:		2.879142E-02
Epoch took 0.701s

Epoch 19 of 500
  training loss:		4.386089E-02
  validation loss:		5.077662E-02
Epoch took 0.700s

Epoch 20 of 500
  training loss:		4.575844E-02
  validation loss:		5.617732E-02
Epoch took 0.700s

Epoch 21 of 500
  training loss:		4.479783E-02
  validation loss:		3.050451E-02
Epoch took 0.701s

Epoch 22 of 500
  training loss:		4.081783E-02
  validation loss:		4.077262E-02
Epoch took 0.700s

Epoch 23 of 500
  training loss:		4.099959E-02
  validation loss:		3.553319E-02
Epoch took 0.701s

Epoch 24 of 500
  training loss:		4.218906E-02
  validation loss:		3.410928E-02
Epoch took 0.700s

Epoch 25 of 500
  training loss:		4.006054E-02
  validation loss:		2.512550E-02
Epoch took 0.703s

Epoch 26 of 500
  training loss:		3.980732E-02
  validation loss:		2.626837E-02
Epoch took 0.703s

Epoch 27 of 500
  training loss:		3.962990E-02
  validation loss:		2.588229E-02
Epoch took 0.702s

Epoch 28 of 500
  training loss:		3.759407E-02
  validation loss:		3.535401E-02
Epoch took 0.703s

Epoch 29 of 500
  training loss:		3.973107E-02
  validation loss:		3.071745E-02
Epoch took 0.702s

Epoch 30 of 500
  training loss:		4.128093E-02
  validation loss:		2.951986E-02
Epoch took 0.703s

Epoch 31 of 500
  training loss:		3.923541E-02
  validation loss:		3.124686E-02
Epoch took 0.703s

Epoch 32 of 500
  training loss:		3.831663E-02
  validation loss:		3.730971E-02
Epoch took 0.702s

Epoch 33 of 500
  training loss:		3.916161E-02
  validation loss:		3.199149E-02
Epoch took 0.703s

Epoch 34 of 500
  training loss:		3.492995E-02
  validation loss:		2.664412E-02
Epoch took 0.703s

Epoch 35 of 500
  training loss:		3.687815E-02
  validation loss:		4.324122E-02
Epoch took 0.703s

Epoch 36 of 500
  training loss:		3.734791E-02
  validation loss:		2.856699E-02
Epoch took 0.703s

Epoch 37 of 500
  training loss:		3.847543E-02
  validation loss:		3.037302E-02
Epoch took 0.702s

Epoch 38 of 500
  training loss:		3.687198E-02
  validation loss:		2.744023E-02
Epoch took 0.702s

Epoch 39 of 500
  training loss:		3.651269E-02
  validation loss:		3.562968E-02
Epoch took 0.703s

Epoch 40 of 500
  training loss:		3.647575E-02
  validation loss:		2.810101E-02
Epoch took 0.703s

Early stopping, val-loss increased over the last 10 epochs from 0.0313787074967 to 0.0320544343442
Saving model from epoch 30
Training RMSE: 0.0298786
Validation RMSE: 0.0295306
Test RMSE: 0.0297293886542
Test MSE: 0.000883836590219
Test MAE: 0.023458102718
Test R2: -9409164280.38 

