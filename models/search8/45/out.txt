Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		2.512938E-01
  validation loss:		4.242723E-01
Epoch took 0.826s

Epoch 2 of 500
  training loss:		9.453282E-02
  validation loss:		6.255586E-02
Epoch took 0.774s

Epoch 3 of 500
  training loss:		8.267395E-02
  validation loss:		6.729064E-02
Epoch took 0.776s

Epoch 4 of 500
  training loss:		7.642441E-02
  validation loss:		4.262913E-02
Epoch took 0.774s

Epoch 5 of 500
  training loss:		7.082820E-02
  validation loss:		4.708895E-02
Epoch took 0.776s

Epoch 6 of 500
  training loss:		6.648809E-02
  validation loss:		3.751763E-02
Epoch took 0.774s

Epoch 7 of 500
  training loss:		6.285782E-02
  validation loss:		6.485380E-02
Epoch took 0.774s

Epoch 8 of 500
  training loss:		6.317750E-02
  validation loss:		5.033709E-02
Epoch took 0.774s

Epoch 9 of 500
  training loss:		6.132605E-02
  validation loss:		3.975732E-02
Epoch took 0.774s

Epoch 10 of 500
  training loss:		5.895973E-02
  validation loss:		4.275763E-02
Epoch took 0.774s

Epoch 11 of 500
  training loss:		5.702363E-02
  validation loss:		3.063432E-02
Epoch took 0.774s

Epoch 12 of 500
  training loss:		5.603302E-02
  validation loss:		4.191570E-02
Epoch took 0.774s

Epoch 13 of 500
  training loss:		5.402195E-02
  validation loss:		3.527667E-02
Epoch took 0.774s

Epoch 14 of 500
  training loss:		5.264318E-02
  validation loss:		3.416132E-02
Epoch took 0.774s

Epoch 15 of 500
  training loss:		5.316335E-02
  validation loss:		2.696714E-02
Epoch took 0.774s

Epoch 16 of 500
  training loss:		5.019219E-02
  validation loss:		3.557613E-02
Epoch took 0.774s

Epoch 17 of 500
  training loss:		4.829250E-02
  validation loss:		3.455229E-02
Epoch took 0.774s

Epoch 18 of 500
  training loss:		4.874255E-02
  validation loss:		4.222365E-02
Epoch took 0.774s

Epoch 19 of 500
  training loss:		4.968641E-02
  validation loss:		5.328438E-02
Epoch took 0.774s

Epoch 20 of 500
  training loss:		4.662827E-02
  validation loss:		2.892925E-02
Epoch took 0.774s

Epoch 21 of 500
  training loss:		4.756313E-02
  validation loss:		4.260802E-02
Epoch took 0.774s

Epoch 22 of 500
  training loss:		4.570431E-02
  validation loss:		3.451250E-02
Epoch took 0.774s

Epoch 23 of 500
  training loss:		4.405307E-02
  validation loss:		2.957855E-02
Epoch took 0.774s

Epoch 24 of 500
  training loss:		4.569921E-02
  validation loss:		3.411943E-02
Epoch took 0.774s

Epoch 25 of 500
  training loss:		4.383674E-02
  validation loss:		2.498638E-02
Epoch took 0.774s

Epoch 26 of 500
  training loss:		4.292800E-02
  validation loss:		3.359812E-02
Epoch took 0.774s

Epoch 27 of 500
  training loss:		4.242333E-02
  validation loss:		3.540422E-02
Epoch took 0.774s

Epoch 28 of 500
  training loss:		4.188324E-02
  validation loss:		3.603743E-02
Epoch took 0.774s

Epoch 29 of 500
  training loss:		4.159525E-02
  validation loss:		4.125365E-02
Epoch took 0.774s

Epoch 30 of 500
  training loss:		4.093273E-02
  validation loss:		3.896322E-02
Epoch took 0.774s

Epoch 31 of 500
  training loss:		4.117093E-02
  validation loss:		2.195652E-02
Epoch took 0.774s

Epoch 32 of 500
  training loss:		3.774592E-02
  validation loss:		2.617592E-02
Epoch took 0.774s

Epoch 33 of 500
  training loss:		4.014497E-02
  validation loss:		3.342720E-02
Epoch took 0.774s

Epoch 34 of 500
  training loss:		3.898548E-02
  validation loss:		3.321249E-02
Epoch took 0.774s

Epoch 35 of 500
  training loss:		3.903940E-02
  validation loss:		2.982978E-02
Epoch took 0.774s

Epoch 36 of 500
  training loss:		3.885898E-02
  validation loss:		2.267168E-02
Epoch took 0.774s

Epoch 37 of 500
  training loss:		3.756398E-02
  validation loss:		2.160142E-02
Epoch took 0.774s

Epoch 38 of 500
  training loss:		3.674212E-02
  validation loss:		2.957438E-02
Epoch took 0.774s

Epoch 39 of 500
  training loss:		3.745628E-02
  validation loss:		2.547667E-02
Epoch took 0.774s

Epoch 40 of 500
  training loss:		3.673217E-02
  validation loss:		2.577749E-02
Epoch took 0.774s

Epoch 41 of 500
  training loss:		3.642999E-02
  validation loss:		2.088874E-02
Epoch took 0.774s

Epoch 42 of 500
  training loss:		3.580670E-02
  validation loss:		3.014571E-02
Epoch took 0.774s

Epoch 43 of 500
  training loss:		3.449622E-02
  validation loss:		2.417113E-02
Epoch took 0.774s

Epoch 44 of 500
  training loss:		3.589007E-02
  validation loss:		3.627291E-02
Epoch took 0.775s

Epoch 45 of 500
  training loss:		3.670361E-02
  validation loss:		2.370422E-02
Epoch took 0.774s

Epoch 46 of 500
  training loss:		3.495435E-02
  validation loss:		2.121456E-02
Epoch took 0.774s

Epoch 47 of 500
  training loss:		3.367210E-02
  validation loss:		2.043397E-02
Epoch took 0.774s

Epoch 48 of 500
  training loss:		3.308276E-02
  validation loss:		2.622443E-02
Epoch took 0.774s

Epoch 49 of 500
  training loss:		3.393118E-02
  validation loss:		2.559979E-02
Epoch took 0.774s

Epoch 50 of 500
  training loss:		3.369556E-02
  validation loss:		2.194461E-02
Epoch took 0.774s

Epoch 51 of 500
  training loss:		3.377136E-02
  validation loss:		2.695097E-02
Epoch took 0.774s

Epoch 52 of 500
  training loss:		3.219758E-02
  validation loss:		2.397613E-02
Epoch took 0.776s

Epoch 53 of 500
  training loss:		3.258389E-02
  validation loss:		2.063304E-02
Epoch took 0.777s

Epoch 54 of 500
  training loss:		3.223530E-02
  validation loss:		1.969117E-02
Epoch took 0.777s

Epoch 55 of 500
  training loss:		3.140773E-02
  validation loss:		2.908769E-02
Epoch took 0.776s

Epoch 56 of 500
  training loss:		3.262318E-02
  validation loss:		2.264940E-02
Epoch took 0.776s

Epoch 57 of 500
  training loss:		3.138694E-02
  validation loss:		2.770789E-02
Epoch took 0.777s

Epoch 58 of 500
  training loss:		3.210797E-02
  validation loss:		2.228389E-02
Epoch took 0.776s

Epoch 59 of 500
  training loss:		3.176966E-02
  validation loss:		2.181747E-02
Epoch took 0.776s

Epoch 60 of 500
  training loss:		3.152178E-02
  validation loss:		2.343126E-02
Epoch took 0.777s

Epoch 61 of 500
  training loss:		3.111632E-02
  validation loss:		2.046217E-02
Epoch took 0.776s

Epoch 62 of 500
  training loss:		2.987979E-02
  validation loss:		1.818042E-02
Epoch took 0.776s

Epoch 63 of 500
  training loss:		2.963754E-02
  validation loss:		2.743473E-02
Epoch took 0.777s

Epoch 64 of 500
  training loss:		3.038445E-02
  validation loss:		2.195296E-02
Epoch took 0.776s

Epoch 65 of 500
  training loss:		3.002725E-02
  validation loss:		3.174913E-02
Epoch took 0.776s

Epoch 66 of 500
  training loss:		2.943843E-02
  validation loss:		1.760543E-02
Epoch took 0.776s

Epoch 67 of 500
  training loss:		2.956369E-02
  validation loss:		2.312051E-02
Epoch took 0.776s

Epoch 68 of 500
  training loss:		2.853794E-02
  validation loss:		2.120069E-02
Epoch took 0.776s

Epoch 69 of 500
  training loss:		2.807759E-02
  validation loss:		1.704755E-02
Epoch took 0.776s

Epoch 70 of 500
  training loss:		2.993301E-02
  validation loss:		2.516067E-02
Epoch took 0.776s

Epoch 71 of 500
  training loss:		2.909088E-02
  validation loss:		1.584345E-02
Epoch took 0.776s

Epoch 72 of 500
  training loss:		2.745060E-02
  validation loss:		1.738073E-02
Epoch took 0.776s

Epoch 73 of 500
  training loss:		2.772300E-02
  validation loss:		1.999488E-02
Epoch took 0.776s

Epoch 74 of 500
  training loss:		2.776172E-02
  validation loss:		1.582344E-02
Epoch took 0.776s

Epoch 75 of 500
  training loss:		2.729302E-02
  validation loss:		1.401200E-02
Epoch took 0.776s

Epoch 76 of 500
  training loss:		2.772858E-02
  validation loss:		2.301728E-02
Epoch took 0.776s

Epoch 77 of 500
  training loss:		2.734608E-02
  validation loss:		1.969767E-02
Epoch took 0.776s

Epoch 78 of 500
  training loss:		2.718509E-02
  validation loss:		2.131353E-02
Epoch took 0.776s

Epoch 79 of 500
  training loss:		2.753134E-02
  validation loss:		2.365226E-02
Epoch took 0.776s

Epoch 80 of 500
  training loss:		2.653257E-02
  validation loss:		1.750882E-02
Epoch took 0.776s

Epoch 81 of 500
  training loss:		2.646534E-02
  validation loss:		1.689421E-02
Epoch took 0.776s

Epoch 82 of 500
  training loss:		2.659855E-02
  validation loss:		1.462186E-02
Epoch took 0.776s

Epoch 83 of 500
  training loss:		2.512216E-02
  validation loss:		1.708741E-02
Epoch took 0.776s

Epoch 84 of 500
  training loss:		2.583565E-02
  validation loss:		2.237350E-02
Epoch took 0.776s

Epoch 85 of 500
  training loss:		2.482484E-02
  validation loss:		1.847406E-02
Epoch took 0.776s

Epoch 86 of 500
  training loss:		2.613111E-02
  validation loss:		2.054780E-02
Epoch took 0.776s

Epoch 87 of 500
  training loss:		2.567640E-02
  validation loss:		1.769375E-02
Epoch took 0.776s

Epoch 88 of 500
  training loss:		2.498612E-02
  validation loss:		1.828896E-02
Epoch took 0.777s

Epoch 89 of 500
  training loss:		2.548710E-02
  validation loss:		1.735640E-02
Epoch took 0.777s

Epoch 90 of 500
  training loss:		2.487997E-02
  validation loss:		1.586444E-02
Epoch took 0.777s

Epoch 91 of 500
  training loss:		2.511557E-02
  validation loss:		1.918021E-02
Epoch took 0.777s

Epoch 92 of 500
  training loss:		2.495955E-02
  validation loss:		1.700783E-02
Epoch took 0.776s

Epoch 93 of 500
  training loss:		2.404137E-02
  validation loss:		1.617180E-02
Epoch took 0.777s

Epoch 94 of 500
  training loss:		2.456968E-02
  validation loss:		1.564374E-02
Epoch took 0.776s

Epoch 95 of 500
  training loss:		2.374980E-02
  validation loss:		1.422490E-02
Epoch took 0.776s

Epoch 96 of 500
  training loss:		2.328230E-02
  validation loss:		2.098106E-02
Epoch took 0.776s

Epoch 97 of 500
  training loss:		2.501033E-02
  validation loss:		2.195130E-02
Epoch took 0.776s

Epoch 98 of 500
  training loss:		2.424788E-02
  validation loss:		1.215735E-02
Epoch took 0.776s

Epoch 99 of 500
  training loss:		2.377009E-02
  validation loss:		1.491569E-02
Epoch took 0.776s

Epoch 100 of 500
  training loss:		2.375592E-02
  validation loss:		1.415031E-02
Epoch took 0.776s

Epoch 101 of 500
  training loss:		2.307037E-02
  validation loss:		2.084418E-02
Epoch took 0.777s

Epoch 102 of 500
  training loss:		2.305466E-02
  validation loss:		1.806984E-02
Epoch took 0.776s

Epoch 103 of 500
  training loss:		2.322210E-02
  validation loss:		1.683415E-02
Epoch took 0.776s

Epoch 104 of 500
  training loss:		2.294393E-02
  validation loss:		2.004867E-02
Epoch took 0.776s

Epoch 105 of 500
  training loss:		2.243730E-02
  validation loss:		1.593544E-02
Epoch took 0.776s

Epoch 106 of 500
  training loss:		2.375211E-02
  validation loss:		2.134307E-02
Epoch took 0.776s

Epoch 107 of 500
  training loss:		2.325347E-02
  validation loss:		1.474878E-02
Epoch took 0.776s

Epoch 108 of 500
  training loss:		2.304569E-02
  validation loss:		1.925801E-02
Epoch took 0.777s

Epoch 109 of 500
  training loss:		2.254926E-02
  validation loss:		1.780047E-02
Epoch took 0.776s

Epoch 110 of 500
  training loss:		2.292297E-02
  validation loss:		1.443062E-02
Epoch took 0.777s

Epoch 111 of 500
  training loss:		2.190562E-02
  validation loss:		1.576475E-02
Epoch took 0.776s

Epoch 112 of 500
  training loss:		2.189125E-02
  validation loss:		1.519626E-02
Epoch took 0.776s

Epoch 113 of 500
  training loss:		2.226614E-02
  validation loss:		1.650306E-02
Epoch took 0.776s

Epoch 114 of 500
  training loss:		2.207169E-02
  validation loss:		1.797463E-02
Epoch took 0.776s

Epoch 115 of 500
  training loss:		2.139481E-02
  validation loss:		1.502624E-02
Epoch took 0.776s

Epoch 116 of 500
  training loss:		2.228159E-02
  validation loss:		1.920167E-02
Epoch took 0.776s

Epoch 117 of 500
  training loss:		2.122200E-02
  validation loss:		1.302796E-02
Epoch took 0.777s

Epoch 118 of 500
  training loss:		2.132715E-02
  validation loss:		2.030834E-02
Epoch took 0.777s

Epoch 119 of 500
  training loss:		2.152136E-02
  validation loss:		1.528346E-02
Epoch took 0.777s

Epoch 120 of 500
  training loss:		2.164025E-02
  validation loss:		1.619011E-02
Epoch took 0.776s

Epoch 121 of 500
  training loss:		2.171411E-02
  validation loss:		1.720179E-02
Epoch took 0.777s

Epoch 122 of 500
  training loss:		2.105206E-02
  validation loss:		1.563039E-02
Epoch took 0.776s

Epoch 123 of 500
  training loss:		2.021910E-02
  validation loss:		1.461297E-02
Epoch took 0.776s

Epoch 124 of 500
  training loss:		2.137049E-02
  validation loss:		1.403702E-02
Epoch took 0.777s

Epoch 125 of 500
  training loss:		2.053147E-02
  validation loss:		1.557840E-02
Epoch took 0.776s

Epoch 126 of 500
  training loss:		2.023743E-02
  validation loss:		1.413880E-02
Epoch took 0.776s

Epoch 127 of 500
  training loss:		2.019296E-02
  validation loss:		1.490388E-02
Epoch took 0.777s

Epoch 128 of 500
  training loss:		2.029725E-02
  validation loss:		1.225939E-02
Epoch took 0.776s

Epoch 129 of 500
  training loss:		2.005075E-02
  validation loss:		1.861551E-02
Epoch took 0.776s

Epoch 130 of 500
  training loss:		1.986677E-02
  validation loss:		1.551036E-02
Epoch took 0.776s

Epoch 131 of 500
  training loss:		1.947997E-02
  validation loss:		1.488497E-02
Epoch took 0.776s

Epoch 132 of 500
  training loss:		1.983403E-02
  validation loss:		1.159927E-02
Epoch took 0.776s

Epoch 133 of 500
  training loss:		1.908708E-02
  validation loss:		1.353666E-02
Epoch took 0.776s

Epoch 134 of 500
  training loss:		1.993217E-02
  validation loss:		1.613024E-02
Epoch took 0.777s

Epoch 135 of 500
  training loss:		2.001954E-02
  validation loss:		1.729124E-02
Epoch took 0.777s

Epoch 136 of 500
  training loss:		1.922154E-02
  validation loss:		1.293404E-02
Epoch took 0.776s

Epoch 137 of 500
  training loss:		2.009060E-02
  validation loss:		1.172817E-02
Epoch took 0.776s

Epoch 138 of 500
  training loss:		1.948442E-02
  validation loss:		1.316823E-02
Epoch took 0.777s

Epoch 139 of 500
  training loss:		1.886687E-02
  validation loss:		1.068641E-02
Epoch took 0.776s

Epoch 140 of 500
  training loss:		1.929775E-02
  validation loss:		2.161378E-02
Epoch took 0.776s

Epoch 141 of 500
  training loss:		1.950715E-02
  validation loss:		1.450648E-02
Epoch took 0.776s

Epoch 142 of 500
  training loss:		1.881095E-02
  validation loss:		1.366427E-02
Epoch took 0.776s

Epoch 143 of 500
  training loss:		1.939888E-02
  validation loss:		1.395107E-02
Epoch took 0.776s

Epoch 144 of 500
  training loss:		1.909324E-02
  validation loss:		1.469613E-02
Epoch took 0.776s

Epoch 145 of 500
  training loss:		1.926621E-02
  validation loss:		1.228095E-02
Epoch took 0.777s

Epoch 146 of 500
  training loss:		1.914955E-02
  validation loss:		2.292391E-02
Epoch took 0.776s

Epoch 147 of 500
  training loss:		1.889022E-02
  validation loss:		1.319311E-02
Epoch took 0.777s

Epoch 148 of 500
  training loss:		1.800759E-02
  validation loss:		1.242710E-02
Epoch took 0.776s

Epoch 149 of 500
  training loss:		1.812373E-02
  validation loss:		1.296917E-02
Epoch took 0.776s

Epoch 150 of 500
  training loss:		1.876610E-02
  validation loss:		1.221253E-02
Epoch took 0.777s

Epoch 151 of 500
  training loss:		1.871308E-02
  validation loss:		1.250474E-02
Epoch took 0.777s

Epoch 152 of 500
  training loss:		1.860684E-02
  validation loss:		1.284811E-02
Epoch took 0.776s

Epoch 153 of 500
  training loss:		1.783753E-02
  validation loss:		1.252358E-02
Epoch took 0.776s

Epoch 154 of 500
  training loss:		1.754874E-02
  validation loss:		1.127520E-02
Epoch took 0.777s

Epoch 155 of 500
  training loss:		1.733037E-02
  validation loss:		1.221769E-02
Epoch took 0.777s

Epoch 156 of 500
  training loss:		1.899089E-02
  validation loss:		1.392344E-02
Epoch took 0.776s

Epoch 157 of 500
  training loss:		1.803107E-02
  validation loss:		1.967127E-02
Epoch took 0.777s

Epoch 158 of 500
  training loss:		1.832889E-02
  validation loss:		1.258496E-02
Epoch took 0.776s

Epoch 159 of 500
  training loss:		1.798158E-02
  validation loss:		1.334899E-02
Epoch took 0.776s

Epoch 160 of 500
  training loss:		1.785749E-02
  validation loss:		1.392174E-02
Epoch took 0.777s

Epoch 161 of 500
  training loss:		1.805701E-02
  validation loss:		1.162592E-02
Epoch took 0.776s

Epoch 162 of 500
  training loss:		1.744037E-02
  validation loss:		1.110896E-02
Epoch took 0.776s

Epoch 163 of 500
  training loss:		1.759737E-02
  validation loss:		1.302923E-02
Epoch took 0.776s

Epoch 164 of 500
  training loss:		1.756216E-02
  validation loss:		1.119668E-02
Epoch took 0.777s

Epoch 165 of 500
  training loss:		1.655967E-02
  validation loss:		1.209225E-02
Epoch took 0.777s

Epoch 166 of 500
  training loss:		1.731251E-02
  validation loss:		1.171546E-02
Epoch took 0.777s

Epoch 167 of 500
  training loss:		1.766618E-02
  validation loss:		1.070681E-02
Epoch took 0.777s

Epoch 168 of 500
  training loss:		1.760048E-02
  validation loss:		1.068170E-02
Epoch took 0.777s

Epoch 169 of 500
  training loss:		1.698350E-02
  validation loss:		1.292559E-02
Epoch took 0.776s

Epoch 170 of 500
  training loss:		1.624079E-02
  validation loss:		1.073642E-02
Epoch took 0.776s

Epoch 171 of 500
  training loss:		1.676078E-02
  validation loss:		1.231727E-02
Epoch took 0.777s

Epoch 172 of 500
  training loss:		1.696306E-02
  validation loss:		1.064679E-02
Epoch took 0.777s

Epoch 173 of 500
  training loss:		1.719983E-02
  validation loss:		1.150751E-02
Epoch took 0.776s

Epoch 174 of 500
  training loss:		1.711334E-02
  validation loss:		9.874778E-03
Epoch took 0.777s

Epoch 175 of 500
  training loss:		1.661046E-02
  validation loss:		1.492399E-02
Epoch took 0.776s

Epoch 176 of 500
  training loss:		1.593073E-02
  validation loss:		1.016930E-02
Epoch took 0.776s

Epoch 177 of 500
  training loss:		1.721140E-02
  validation loss:		1.327697E-02
Epoch took 0.776s

Epoch 178 of 500
  training loss:		1.647357E-02
  validation loss:		1.276784E-02
Epoch took 0.776s

Epoch 179 of 500
  training loss:		1.619341E-02
  validation loss:		1.158966E-02
Epoch took 0.777s

Epoch 180 of 500
  training loss:		1.587871E-02
  validation loss:		1.120115E-02
Epoch took 0.777s

Epoch 181 of 500
  training loss:		1.688298E-02
  validation loss:		1.158835E-02
Epoch took 0.777s

Epoch 182 of 500
  training loss:		1.632260E-02
  validation loss:		1.169620E-02
Epoch took 0.776s

Epoch 183 of 500
  training loss:		1.601694E-02
  validation loss:		9.176698E-03
Epoch took 0.776s

Epoch 184 of 500
  training loss:		1.627137E-02
  validation loss:		1.000081E-02
Epoch took 0.776s

Epoch 185 of 500
  training loss:		1.643809E-02
  validation loss:		1.028585E-02
Epoch took 0.776s

Epoch 186 of 500
  training loss:		1.619480E-02
  validation loss:		1.209732E-02
Epoch took 0.776s

Epoch 187 of 500
  training loss:		1.592562E-02
  validation loss:		1.092417E-02
Epoch took 0.776s

Epoch 188 of 500
  training loss:		1.545179E-02
  validation loss:		1.198153E-02
Epoch took 0.776s

Epoch 189 of 500
  training loss:		1.581901E-02
  validation loss:		1.062434E-02
Epoch took 0.776s

Epoch 190 of 500
  training loss:		1.604724E-02
  validation loss:		9.789591E-03
Epoch took 0.776s

Epoch 191 of 500
  training loss:		1.606950E-02
  validation loss:		1.256945E-02
Epoch took 0.776s

Epoch 192 of 500
  training loss:		1.569758E-02
  validation loss:		1.061550E-02
Epoch took 0.776s

Epoch 193 of 500
  training loss:		1.583828E-02
  validation loss:		1.074348E-02
Epoch took 0.777s

Epoch 194 of 500
  training loss:		1.600294E-02
  validation loss:		1.182155E-02
Epoch took 0.777s

Epoch 195 of 500
  training loss:		1.539876E-02
  validation loss:		1.487131E-02
Epoch took 0.776s

Epoch 196 of 500
  training loss:		1.519850E-02
  validation loss:		1.266502E-02
Epoch took 0.776s

Epoch 197 of 500
  training loss:		1.538112E-02
  validation loss:		1.121365E-02
Epoch took 0.776s

Epoch 198 of 500
  training loss:		1.520422E-02
  validation loss:		1.150677E-02
Epoch took 0.776s

Epoch 199 of 500
  training loss:		1.535463E-02
  validation loss:		1.069948E-02
Epoch took 0.777s

Epoch 200 of 500
  training loss:		1.509150E-02
  validation loss:		1.647947E-02
Epoch took 0.776s

Epoch 201 of 500
  training loss:		1.462149E-02
  validation loss:		9.355022E-03
Epoch took 0.776s

Epoch 202 of 500
  training loss:		1.564902E-02
  validation loss:		1.221563E-02
Epoch took 0.777s

Epoch 203 of 500
  training loss:		1.470594E-02
  validation loss:		1.270571E-02
Epoch took 0.778s

Epoch 204 of 500
  training loss:		1.519408E-02
  validation loss:		1.215566E-02
Epoch took 0.777s

Epoch 205 of 500
  training loss:		1.530501E-02
  validation loss:		1.025944E-02
Epoch took 0.776s

Epoch 206 of 500
  training loss:		1.477784E-02
  validation loss:		1.104935E-02
Epoch took 0.776s

Epoch 207 of 500
  training loss:		1.472851E-02
  validation loss:		1.163644E-02
Epoch took 0.776s

Epoch 208 of 500
  training loss:		1.471692E-02
  validation loss:		9.649467E-03
Epoch took 0.777s

Epoch 209 of 500
  training loss:		1.501075E-02
  validation loss:		9.390123E-03
Epoch took 0.777s

Epoch 210 of 500
  training loss:		1.577587E-02
  validation loss:		1.058821E-02
Epoch took 0.776s

Early stopping, val-loss increased over the last 15 epochs from 0.01125240893 to 0.0114379630079
Saving model from epoch 195
Training RMSE: 0.0148352
Validation RMSE: 0.0148785
Test RMSE: 0.0145279457793
Test MSE: 0.000211061211303
Test MAE: 0.00944908894598
Test R2: -2246919416.32 

