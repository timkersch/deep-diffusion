Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		4.830253E-01
  validation loss:		2.413661E-01
Epoch took 2.009s

Epoch 2 of 500
  training loss:		2.564138E-01
  validation loss:		1.577841E-01
Epoch took 2.003s

Epoch 3 of 500
  training loss:		2.110015E-01
  validation loss:		1.209108E-01
Epoch took 2.003s

Epoch 4 of 500
  training loss:		1.871873E-01
  validation loss:		1.123961E-01
Epoch took 2.003s

Epoch 5 of 500
  training loss:		1.705273E-01
  validation loss:		9.166361E-02
Epoch took 2.003s

Epoch 6 of 500
  training loss:		1.599982E-01
  validation loss:		8.306953E-02
Epoch took 2.003s

Epoch 7 of 500
  training loss:		1.479633E-01
  validation loss:		7.999140E-02
Epoch took 2.003s

Epoch 8 of 500
  training loss:		1.405047E-01
  validation loss:		7.689585E-02
Epoch took 2.002s

Epoch 9 of 500
  training loss:		1.328882E-01
  validation loss:		6.638602E-02
Epoch took 2.003s

Epoch 10 of 500
  training loss:		1.274973E-01
  validation loss:		6.904212E-02
Epoch took 2.004s

Epoch 11 of 500
  training loss:		1.215635E-01
  validation loss:		6.027553E-02
Epoch took 2.003s

Epoch 12 of 500
  training loss:		1.159816E-01
  validation loss:		5.794547E-02
Epoch took 2.003s

Epoch 13 of 500
  training loss:		1.132154E-01
  validation loss:		5.806609E-02
Epoch took 2.003s

Epoch 14 of 500
  training loss:		1.079458E-01
  validation loss:		5.546524E-02
Epoch took 2.003s

Epoch 15 of 500
  training loss:		1.036316E-01
  validation loss:		5.365219E-02
Epoch took 2.003s

Epoch 16 of 500
  training loss:		1.022420E-01
  validation loss:		5.607515E-02
Epoch took 2.003s

Epoch 17 of 500
  training loss:		9.711270E-02
  validation loss:		5.005384E-02
Epoch took 2.003s

Epoch 18 of 500
  training loss:		9.487143E-02
  validation loss:		4.930462E-02
Epoch took 2.004s

Epoch 19 of 500
  training loss:		9.205883E-02
  validation loss:		5.073450E-02
Epoch took 2.003s

Epoch 20 of 500
  training loss:		8.913402E-02
  validation loss:		4.798520E-02
Epoch took 2.003s

Epoch 21 of 500
  training loss:		8.805823E-02
  validation loss:		4.483772E-02
Epoch took 2.003s

Epoch 22 of 500
  training loss:		8.525520E-02
  validation loss:		4.676985E-02
Epoch took 2.003s

Epoch 23 of 500
  training loss:		8.246721E-02
  validation loss:		4.377428E-02
Epoch took 2.003s

Epoch 24 of 500
  training loss:		7.983733E-02
  validation loss:		4.169962E-02
Epoch took 2.003s

Epoch 25 of 500
  training loss:		7.872958E-02
  validation loss:		4.655457E-02
Epoch took 2.003s

Epoch 26 of 500
  training loss:		7.607673E-02
  validation loss:		3.957379E-02
Epoch took 2.003s

Epoch 27 of 500
  training loss:		7.484076E-02
  validation loss:		4.786186E-02
Epoch took 2.003s

Epoch 28 of 500
  training loss:		7.224375E-02
  validation loss:		3.681919E-02
Epoch took 2.003s

Epoch 29 of 500
  training loss:		7.093389E-02
  validation loss:		3.417362E-02
Epoch took 2.003s

Epoch 30 of 500
  training loss:		6.789689E-02
  validation loss:		3.929404E-02
Epoch took 2.003s

Epoch 31 of 500
  training loss:		6.722728E-02
  validation loss:		3.561090E-02
Epoch took 2.004s

Epoch 32 of 500
  training loss:		6.613057E-02
  validation loss:		3.471533E-02
Epoch took 2.003s

Epoch 33 of 500
  training loss:		6.401994E-02
  validation loss:		3.742474E-02
Epoch took 2.003s

Epoch 34 of 500
  training loss:		6.184242E-02
  validation loss:		3.415230E-02
Epoch took 2.003s

Epoch 35 of 500
  training loss:		6.014018E-02
  validation loss:		3.621369E-02
Epoch took 2.003s

Epoch 36 of 500
  training loss:		5.980318E-02
  validation loss:		3.107919E-02
Epoch took 2.003s

Epoch 37 of 500
  training loss:		5.788866E-02
  validation loss:		3.435623E-02
Epoch took 2.003s

Epoch 38 of 500
  training loss:		5.581468E-02
  validation loss:		3.095075E-02
Epoch took 2.003s

Epoch 39 of 500
  training loss:		5.575320E-02
  validation loss:		2.710126E-02
Epoch took 2.003s

Epoch 40 of 500
  training loss:		5.392062E-02
  validation loss:		2.904181E-02
Epoch took 2.006s

Epoch 41 of 500
  training loss:		5.184370E-02
  validation loss:		2.774941E-02
Epoch took 2.003s

Epoch 42 of 500
  training loss:		5.114393E-02
  validation loss:		2.919404E-02
Epoch took 2.003s

Epoch 43 of 500
  training loss:		4.987399E-02
  validation loss:		2.404308E-02
Epoch took 2.003s

Epoch 44 of 500
  training loss:		4.904060E-02
  validation loss:		2.562718E-02
Epoch took 2.003s

Epoch 45 of 500
  training loss:		4.813262E-02
  validation loss:		2.449397E-02
Epoch took 2.003s

Epoch 46 of 500
  training loss:		4.742532E-02
  validation loss:		2.306472E-02
Epoch took 2.003s

Epoch 47 of 500
  training loss:		4.522693E-02
  validation loss:		2.214772E-02
Epoch took 2.003s

Epoch 48 of 500
  training loss:		4.514355E-02
  validation loss:		2.611597E-02
Epoch took 2.003s

Epoch 49 of 500
  training loss:		4.355976E-02
  validation loss:		2.590538E-02
Epoch took 2.003s

Epoch 50 of 500
  training loss:		4.242776E-02
  validation loss:		2.388350E-02
Epoch took 2.003s

Epoch 51 of 500
  training loss:		4.199475E-02
  validation loss:		2.734117E-02
Epoch took 2.003s

Epoch 52 of 500
  training loss:		4.111409E-02
  validation loss:		2.354567E-02
Epoch took 2.003s

Epoch 53 of 500
  training loss:		3.964019E-02
  validation loss:		2.430869E-02
Epoch took 2.003s

Epoch 54 of 500
  training loss:		3.831411E-02
  validation loss:		2.413781E-02
Epoch took 2.003s

Epoch 55 of 500
  training loss:		3.831950E-02
  validation loss:		2.236468E-02
Epoch took 2.003s

Epoch 56 of 500
  training loss:		3.779311E-02
  validation loss:		2.253675E-02
Epoch took 2.003s

Epoch 57 of 500
  training loss:		3.636416E-02
  validation loss:		2.069755E-02
Epoch took 2.003s

Epoch 58 of 500
  training loss:		3.589045E-02
  validation loss:		2.012165E-02
Epoch took 2.003s

Epoch 59 of 500
  training loss:		3.478685E-02
  validation loss:		1.913939E-02
Epoch took 2.003s

Epoch 60 of 500
  training loss:		3.392275E-02
  validation loss:		2.014162E-02
Epoch took 2.003s

Epoch 61 of 500
  training loss:		3.369766E-02
  validation loss:		1.763806E-02
Epoch took 2.003s

Epoch 62 of 500
  training loss:		3.317826E-02
  validation loss:		1.960666E-02
Epoch took 2.003s

Epoch 63 of 500
  training loss:		3.198337E-02
  validation loss:		1.915798E-02
Epoch took 2.003s

Epoch 64 of 500
  training loss:		3.138317E-02
  validation loss:		1.753375E-02
Epoch took 2.002s

Epoch 65 of 500
  training loss:		3.016457E-02
  validation loss:		1.880443E-02
Epoch took 2.003s

Epoch 66 of 500
  training loss:		3.000230E-02
  validation loss:		1.884069E-02
Epoch took 2.003s

Epoch 67 of 500
  training loss:		2.927441E-02
  validation loss:		1.874824E-02
Epoch took 2.003s

Epoch 68 of 500
  training loss:		2.867778E-02
  validation loss:		1.673405E-02
Epoch took 2.003s

Epoch 69 of 500
  training loss:		2.795502E-02
  validation loss:		1.875355E-02
Epoch took 2.004s

Epoch 70 of 500
  training loss:		2.727180E-02
  validation loss:		1.683826E-02
Epoch took 2.003s

Epoch 71 of 500
  training loss:		2.698571E-02
  validation loss:		1.746594E-02
Epoch took 2.003s

Epoch 72 of 500
  training loss:		2.588818E-02
  validation loss:		1.537233E-02
Epoch took 2.003s

Epoch 73 of 500
  training loss:		2.556150E-02
  validation loss:		1.578975E-02
Epoch took 2.003s

Epoch 74 of 500
  training loss:		2.472825E-02
  validation loss:		1.574969E-02
Epoch took 2.003s

Epoch 75 of 500
  training loss:		2.418937E-02
  validation loss:		1.581849E-02
Epoch took 2.003s

Epoch 76 of 500
  training loss:		2.371489E-02
  validation loss:		1.749352E-02
Epoch took 2.002s

Epoch 77 of 500
  training loss:		2.311444E-02
  validation loss:		1.404521E-02
Epoch took 2.003s

Epoch 78 of 500
  training loss:		2.259458E-02
  validation loss:		1.489785E-02
Epoch took 2.003s

Epoch 79 of 500
  training loss:		2.227399E-02
  validation loss:		1.384656E-02
Epoch took 2.003s

Epoch 80 of 500
  training loss:		2.196084E-02
  validation loss:		1.572860E-02
Epoch took 2.003s

Epoch 81 of 500
  training loss:		2.125813E-02
  validation loss:		1.825441E-02
Epoch took 2.002s

Epoch 82 of 500
  training loss:		2.112731E-02
  validation loss:		1.238100E-02
Epoch took 2.003s

Epoch 83 of 500
  training loss:		2.076605E-02
  validation loss:		1.504903E-02
Epoch took 2.003s

Epoch 84 of 500
  training loss:		1.999176E-02
  validation loss:		1.248635E-02
Epoch took 2.003s

Epoch 85 of 500
  training loss:		1.966072E-02
  validation loss:		1.465874E-02
Epoch took 2.003s

Epoch 86 of 500
  training loss:		1.964167E-02
  validation loss:		1.528718E-02
Epoch took 2.002s

Epoch 87 of 500
  training loss:		1.892147E-02
  validation loss:		1.502744E-02
Epoch took 2.003s

Epoch 88 of 500
  training loss:		1.846419E-02
  validation loss:		1.323895E-02
Epoch took 2.002s

Epoch 89 of 500
  training loss:		1.828916E-02
  validation loss:		1.383984E-02
Epoch took 2.003s

Epoch 90 of 500
  training loss:		1.809863E-02
  validation loss:		1.547202E-02
Epoch took 2.003s

Epoch 91 of 500
  training loss:		1.738638E-02
  validation loss:		1.051858E-02
Epoch took 2.003s

Epoch 92 of 500
  training loss:		1.756309E-02
  validation loss:		1.229732E-02
Epoch took 2.003s

Epoch 93 of 500
  training loss:		1.713566E-02
  validation loss:		1.228000E-02
Epoch took 2.003s

Epoch 94 of 500
  training loss:		1.677725E-02
  validation loss:		1.347601E-02
Epoch took 2.002s

Epoch 95 of 500
  training loss:		1.650950E-02
  validation loss:		1.182561E-02
Epoch took 2.003s

Epoch 96 of 500
  training loss:		1.608760E-02
  validation loss:		1.208524E-02
Epoch took 2.002s

Epoch 97 of 500
  training loss:		1.589327E-02
  validation loss:		1.077408E-02
Epoch took 2.003s

Epoch 98 of 500
  training loss:		1.575972E-02
  validation loss:		1.116032E-02
Epoch took 2.002s

Epoch 99 of 500
  training loss:		1.553778E-02
  validation loss:		9.751652E-03
Epoch took 2.002s

Epoch 100 of 500
  training loss:		1.513244E-02
  validation loss:		9.912794E-03
Epoch took 2.002s

Epoch 101 of 500
  training loss:		1.519868E-02
  validation loss:		1.351510E-02
Epoch took 2.003s

Epoch 102 of 500
  training loss:		1.480948E-02
  validation loss:		1.142014E-02
Epoch took 2.003s

Epoch 103 of 500
  training loss:		1.472198E-02
  validation loss:		1.117308E-02
Epoch took 2.003s

Epoch 104 of 500
  training loss:		1.463292E-02
  validation loss:		8.551100E-03
Epoch took 2.003s

Epoch 105 of 500
  training loss:		1.409696E-02
  validation loss:		8.120394E-03
Epoch took 2.003s

Epoch 106 of 500
  training loss:		1.421230E-02
  validation loss:		9.488925E-03
Epoch took 2.003s

Epoch 107 of 500
  training loss:		1.391929E-02
  validation loss:		1.030241E-02
Epoch took 2.003s

Epoch 108 of 500
  training loss:		1.355492E-02
  validation loss:		1.132539E-02
Epoch took 2.003s

Epoch 109 of 500
  training loss:		1.346874E-02
  validation loss:		8.821371E-03
Epoch took 2.003s

Epoch 110 of 500
  training loss:		1.309825E-02
  validation loss:		9.028034E-03
Epoch took 2.003s

Epoch 111 of 500
  training loss:		1.321614E-02
  validation loss:		1.051861E-02
Epoch took 2.003s

Epoch 112 of 500
  training loss:		1.299645E-02
  validation loss:		1.101661E-02
Epoch took 2.003s

Epoch 113 of 500
  training loss:		1.269106E-02
  validation loss:		8.046103E-03
Epoch took 2.003s

Epoch 114 of 500
  training loss:		1.261111E-02
  validation loss:		9.325642E-03
Epoch took 2.003s

Epoch 115 of 500
  training loss:		1.220596E-02
  validation loss:		7.961496E-03
Epoch took 2.003s

Epoch 116 of 500
  training loss:		1.239340E-02
  validation loss:		9.554204E-03
Epoch took 2.003s

Epoch 117 of 500
  training loss:		1.216762E-02
  validation loss:		8.360725E-03
Epoch took 2.003s

Epoch 118 of 500
  training loss:		1.184493E-02
  validation loss:		8.076049E-03
Epoch took 2.005s

Epoch 119 of 500
  training loss:		1.186642E-02
  validation loss:		8.682730E-03
Epoch took 2.003s

Epoch 120 of 500
  training loss:		1.150072E-02
  validation loss:		8.148635E-03
Epoch took 2.003s

Epoch 121 of 500
  training loss:		1.163284E-02
  validation loss:		1.081581E-02
Epoch took 2.003s

Epoch 122 of 500
  training loss:		1.133396E-02
  validation loss:		7.579398E-03
Epoch took 2.003s

Epoch 123 of 500
  training loss:		1.123907E-02
  validation loss:		7.888857E-03
Epoch took 2.003s

Epoch 124 of 500
  training loss:		1.121916E-02
  validation loss:		1.129997E-02
Epoch took 2.003s

Epoch 125 of 500
  training loss:		1.117516E-02
  validation loss:		9.818165E-03
Epoch took 2.003s

Epoch 126 of 500
  training loss:		1.096892E-02
  validation loss:		8.090064E-03
Epoch took 2.003s

Epoch 127 of 500
  training loss:		1.084732E-02
  validation loss:		1.215762E-02
Epoch took 2.002s

Epoch 128 of 500
  training loss:		1.072638E-02
  validation loss:		9.836587E-03
Epoch took 2.002s

Epoch 129 of 500
  training loss:		1.042528E-02
  validation loss:		7.852850E-03
Epoch took 2.003s

Epoch 130 of 500
  training loss:		1.060129E-02
  validation loss:		6.861328E-03
Epoch took 2.003s

Epoch 131 of 500
  training loss:		1.042690E-02
  validation loss:		8.718232E-03
Epoch took 2.003s

Epoch 132 of 500
  training loss:		1.017429E-02
  validation loss:		6.870132E-03
Epoch took 2.003s

Epoch 133 of 500
  training loss:		1.016295E-02
  validation loss:		8.435178E-03
Epoch took 2.003s

Epoch 134 of 500
  training loss:		1.000187E-02
  validation loss:		7.335017E-03
Epoch took 2.003s

Epoch 135 of 500
  training loss:		1.004195E-02
  validation loss:		8.523009E-03
Epoch took 2.003s

Epoch 136 of 500
  training loss:		9.717383E-03
  validation loss:		7.200841E-03
Epoch took 2.003s

Epoch 137 of 500
  training loss:		9.823249E-03
  validation loss:		9.383535E-03
Epoch took 2.003s

Epoch 138 of 500
  training loss:		9.519863E-03
  validation loss:		5.821507E-03
Epoch took 2.003s

Epoch 139 of 500
  training loss:		9.614977E-03
  validation loss:		1.017816E-02
Epoch took 2.003s

Epoch 140 of 500
  training loss:		9.602278E-03
  validation loss:		6.561640E-03
Epoch took 2.003s

Epoch 141 of 500
  training loss:		9.471784E-03
  validation loss:		7.596536E-03
Epoch took 2.003s

Epoch 142 of 500
  training loss:		9.269233E-03
  validation loss:		1.011361E-02
Epoch took 2.003s

Epoch 143 of 500
  training loss:		9.197747E-03
  validation loss:		8.604234E-03
Epoch took 2.003s

Epoch 144 of 500
  training loss:		9.136444E-03
  validation loss:		7.514518E-03
Epoch took 2.003s

Epoch 145 of 500
  training loss:		8.946444E-03
  validation loss:		7.683668E-03
Epoch took 2.003s

Epoch 146 of 500
  training loss:		9.138786E-03
  validation loss:		7.821836E-03
Epoch took 2.003s

Epoch 147 of 500
  training loss:		8.917280E-03
  validation loss:		7.855729E-03
Epoch took 2.003s

Epoch 148 of 500
  training loss:		8.784202E-03
  validation loss:		5.418617E-03
Epoch took 2.003s

Epoch 149 of 500
  training loss:		8.899345E-03
  validation loss:		5.858959E-03
Epoch took 2.003s

Epoch 150 of 500
  training loss:		8.729645E-03
  validation loss:		8.271798E-03
Epoch took 2.003s

Epoch 151 of 500
  training loss:		8.672780E-03
  validation loss:		9.534815E-03
Epoch took 2.003s

Epoch 152 of 500
  training loss:		8.452537E-03
  validation loss:		8.720466E-03
Epoch took 2.003s

Epoch 153 of 500
  training loss:		8.451695E-03
  validation loss:		6.842601E-03
Epoch took 2.003s

Epoch 154 of 500
  training loss:		8.466089E-03
  validation loss:		6.916325E-03
Epoch took 2.003s

Epoch 155 of 500
  training loss:		8.296377E-03
  validation loss:		8.442915E-03
Epoch took 2.003s

Epoch 156 of 500
  training loss:		8.443926E-03
  validation loss:		7.508249E-03
Epoch took 2.003s

Epoch 157 of 500
  training loss:		8.144104E-03
  validation loss:		7.450703E-03
Epoch took 2.003s

Epoch 158 of 500
  training loss:		8.198891E-03
  validation loss:		5.249030E-03
Epoch took 2.002s

Epoch 159 of 500
  training loss:		8.089692E-03
  validation loss:		5.638970E-03
Epoch took 2.003s

Epoch 160 of 500
  training loss:		8.067434E-03
  validation loss:		6.760159E-03
Epoch took 2.003s

Epoch 161 of 500
  training loss:		7.904515E-03
  validation loss:		5.023833E-03
Epoch took 2.003s

Epoch 162 of 500
  training loss:		7.845025E-03
  validation loss:		7.135380E-03
Epoch took 2.003s

Epoch 163 of 500
  training loss:		7.880580E-03
  validation loss:		8.550198E-03
Epoch took 2.002s

Epoch 164 of 500
  training loss:		7.829619E-03
  validation loss:		7.328366E-03
Epoch took 2.003s

Epoch 165 of 500
  training loss:		7.726780E-03
  validation loss:		7.432021E-03
Epoch took 2.003s

Epoch 166 of 500
  training loss:		7.761188E-03
  validation loss:		5.698849E-03
Epoch took 2.003s

Epoch 167 of 500
  training loss:		7.624617E-03
  validation loss:		8.973235E-03
Epoch took 2.003s

Epoch 168 of 500
  training loss:		7.586053E-03
  validation loss:		7.595145E-03
Epoch took 2.003s

Epoch 169 of 500
  training loss:		7.598014E-03
  validation loss:		1.025595E-02
Epoch took 2.003s

Epoch 170 of 500
  training loss:		7.701629E-03
  validation loss:		7.148087E-03
Epoch took 2.003s

Epoch 171 of 500
  training loss:		7.462313E-03
  validation loss:		6.128680E-03
Epoch took 2.003s

Epoch 172 of 500
  training loss:		7.441499E-03
  validation loss:		8.401048E-03
Epoch took 2.003s

Epoch 173 of 500
  training loss:		7.391625E-03
  validation loss:		5.056463E-03
Epoch took 2.003s

Epoch 174 of 500
  training loss:		7.404255E-03
  validation loss:		6.630491E-03
Epoch took 2.002s

Epoch 175 of 500
  training loss:		7.269115E-03
  validation loss:		6.045980E-03
Epoch took 2.003s

Epoch 176 of 500
  training loss:		7.281877E-03
  validation loss:		7.964632E-03
Epoch took 2.002s

Epoch 177 of 500
  training loss:		7.278942E-03
  validation loss:		1.154531E-02
Epoch took 2.002s

Epoch 178 of 500
  training loss:		7.277353E-03
  validation loss:		6.304395E-03
Epoch took 2.003s

Epoch 179 of 500
  training loss:		7.016892E-03
  validation loss:		7.843673E-03
Epoch took 2.003s

Epoch 180 of 500
  training loss:		7.139454E-03
  validation loss:		4.246086E-03
Epoch took 2.003s

Epoch 181 of 500
  training loss:		7.078225E-03
  validation loss:		7.686906E-03
Epoch took 2.003s

Epoch 182 of 500
  training loss:		7.050641E-03
  validation loss:		9.097445E-03
Epoch took 2.003s

Epoch 183 of 500
  training loss:		6.954141E-03
  validation loss:		5.999249E-03
Epoch took 2.003s

Epoch 184 of 500
  training loss:		6.821735E-03
  validation loss:		5.556582E-03
Epoch took 2.003s

Epoch 185 of 500
  training loss:		7.011721E-03
  validation loss:		5.894983E-03
Epoch took 2.003s

Epoch 186 of 500
  training loss:		6.899502E-03
  validation loss:		6.743774E-03
Epoch took 2.003s

Epoch 187 of 500
  training loss:		6.745258E-03
  validation loss:		6.132086E-03
Epoch took 2.003s

Epoch 188 of 500
  training loss:		6.756000E-03
  validation loss:		5.097317E-03
Epoch took 2.003s

Epoch 189 of 500
  training loss:		6.856886E-03
  validation loss:		7.815741E-03
Epoch took 2.003s

Epoch 190 of 500
  training loss:		6.720787E-03
  validation loss:		5.823807E-03
Epoch took 2.006s

Epoch 191 of 500
  training loss:		6.679727E-03
  validation loss:		6.309590E-03
Epoch took 2.003s

Epoch 192 of 500
  training loss:		6.641502E-03
  validation loss:		8.033297E-03
Epoch took 2.003s

Epoch 193 of 500
  training loss:		6.553902E-03
  validation loss:		6.510779E-03
Epoch took 2.003s

Epoch 194 of 500
  training loss:		6.750485E-03
  validation loss:		8.548989E-03
Epoch took 2.003s

Epoch 195 of 500
  training loss:		6.526355E-03
  validation loss:		6.080918E-03
Epoch took 2.003s

Epoch 196 of 500
  training loss:		6.506038E-03
  validation loss:		6.522602E-03
Epoch took 2.003s

Epoch 197 of 500
  training loss:		6.534201E-03
  validation loss:		6.219122E-03
Epoch took 2.003s

Epoch 198 of 500
  training loss:		6.491712E-03
  validation loss:		5.046293E-03
Epoch took 2.003s

Epoch 199 of 500
  training loss:		6.500371E-03
  validation loss:		6.254540E-03
Epoch took 2.003s

Epoch 200 of 500
  training loss:		6.486923E-03
  validation loss:		5.495113E-03
Epoch took 2.003s

Epoch 201 of 500
  training loss:		6.361271E-03
  validation loss:		7.523735E-03
Epoch took 2.003s

Epoch 202 of 500
  training loss:		6.358312E-03
  validation loss:		9.173792E-03
Epoch took 2.003s

Epoch 203 of 500
  training loss:		6.461793E-03
  validation loss:		5.218917E-03
Epoch took 2.003s

Epoch 204 of 500
  training loss:		6.220691E-03
  validation loss:		6.869156E-03
Epoch took 2.003s

Epoch 205 of 500
  training loss:		6.218474E-03
  validation loss:		4.664515E-03
Epoch took 2.003s

Epoch 206 of 500
  training loss:		6.271653E-03
  validation loss:		4.536979E-03
Epoch took 2.003s

Epoch 207 of 500
  training loss:		6.128429E-03
  validation loss:		6.445312E-03
Epoch took 2.003s

Epoch 208 of 500
  training loss:		6.173235E-03
  validation loss:		6.478197E-03
Epoch took 2.003s

Epoch 209 of 500
  training loss:		6.167680E-03
  validation loss:		6.243623E-03
Epoch took 2.003s

Epoch 210 of 500
  training loss:		6.127305E-03
  validation loss:		5.065394E-03
Epoch took 2.003s

Epoch 211 of 500
  training loss:		6.021253E-03
  validation loss:		4.730576E-03
Epoch took 2.003s

Epoch 212 of 500
  training loss:		6.039428E-03
  validation loss:		9.737750E-03
Epoch took 2.003s

Epoch 213 of 500
  training loss:		6.224239E-03
  validation loss:		5.810654E-03
Epoch took 2.003s

Epoch 214 of 500
  training loss:		5.878086E-03
  validation loss:		7.257360E-03
Epoch took 2.003s

Epoch 215 of 500
  training loss:		6.070294E-03
  validation loss:		7.887293E-03
Epoch took 2.002s

Epoch 216 of 500
  training loss:		5.971586E-03
  validation loss:		8.621068E-03
Epoch took 2.003s

Epoch 217 of 500
  training loss:		5.951117E-03
  validation loss:		9.073742E-03
Epoch took 2.003s

Epoch 218 of 500
  training loss:		5.900893E-03
  validation loss:		7.139120E-03
Epoch took 2.003s

Epoch 219 of 500
  training loss:		5.881438E-03
  validation loss:		4.925983E-03
Epoch took 2.003s

Epoch 220 of 500
  training loss:		5.840144E-03
  validation loss:		5.359895E-03
Epoch took 2.003s

Early stopping, val-loss increased over the last 20 epochs from 0.00654345667621 to 0.00663815295386
Saving model from epoch 200
Training RMSE: 0.00549418
Validation RMSE: 0.00551147
Test RMSE: 0.00547000858933
Test MSE: 2.99209950754e-05
Test MAE: 0.00459473347291
Test R2: -318533500.336 

