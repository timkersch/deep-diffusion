Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.482664E-01
  validation loss:		3.662765E-01
Epoch took 0.836s

Epoch 2 of 500
  training loss:		8.060119E-02
  validation loss:		1.484246E-01
Epoch took 0.776s

Epoch 3 of 500
  training loss:		7.223068E-02
  validation loss:		7.746438E-02
Epoch took 0.776s

Epoch 4 of 500
  training loss:		6.217745E-02
  validation loss:		7.221391E-02
Epoch took 0.776s

Epoch 5 of 500
  training loss:		5.354144E-02
  validation loss:		5.431649E-02
Epoch took 0.776s

Epoch 6 of 500
  training loss:		5.130921E-02
  validation loss:		4.773157E-02
Epoch took 0.776s

Epoch 7 of 500
  training loss:		4.858217E-02
  validation loss:		5.324779E-02
Epoch took 0.776s

Epoch 8 of 500
  training loss:		4.838224E-02
  validation loss:		4.878988E-02
Epoch took 0.776s

Epoch 9 of 500
  training loss:		4.402928E-02
  validation loss:		5.091421E-02
Epoch took 0.777s

Epoch 10 of 500
  training loss:		3.879670E-02
  validation loss:		4.028171E-02
Epoch took 0.776s

Epoch 11 of 500
  training loss:		3.547738E-02
  validation loss:		3.622074E-02
Epoch took 0.776s

Epoch 12 of 500
  training loss:		3.728695E-02
  validation loss:		3.528210E-02
Epoch took 0.775s

Epoch 13 of 500
  training loss:		3.486315E-02
  validation loss:		3.243911E-02
Epoch took 0.776s

Epoch 14 of 500
  training loss:		3.174264E-02
  validation loss:		2.643071E-02
Epoch took 0.776s

Epoch 15 of 500
  training loss:		3.203238E-02
  validation loss:		2.478331E-02
Epoch took 0.776s

Epoch 16 of 500
  training loss:		2.969804E-02
  validation loss:		2.476506E-02
Epoch took 0.776s

Epoch 17 of 500
  training loss:		2.794871E-02
  validation loss:		3.841638E-02
Epoch took 0.776s

Epoch 18 of 500
  training loss:		2.822877E-02
  validation loss:		2.577198E-02
Epoch took 0.776s

Epoch 19 of 500
  training loss:		2.592294E-02
  validation loss:		2.843802E-02
Epoch took 0.776s

Epoch 20 of 500
  training loss:		2.604587E-02
  validation loss:		2.749779E-02
Epoch took 0.777s

Epoch 21 of 500
  training loss:		2.464520E-02
  validation loss:		2.052680E-02
Epoch took 0.777s

Epoch 22 of 500
  training loss:		2.541815E-02
  validation loss:		2.276908E-02
Epoch took 0.775s

Epoch 23 of 500
  training loss:		2.499008E-02
  validation loss:		2.266718E-02
Epoch took 0.776s

Epoch 24 of 500
  training loss:		2.171987E-02
  validation loss:		1.907173E-02
Epoch took 0.776s

Epoch 25 of 500
  training loss:		2.406795E-02
  validation loss:		2.024053E-02
Epoch took 0.776s

Epoch 26 of 500
  training loss:		2.199802E-02
  validation loss:		2.396690E-02
Epoch took 0.776s

Epoch 27 of 500
  training loss:		2.261963E-02
  validation loss:		2.319599E-02
Epoch took 0.776s

Epoch 28 of 500
  training loss:		2.030997E-02
  validation loss:		2.008852E-02
Epoch took 0.776s

Epoch 29 of 500
  training loss:		2.037370E-02
  validation loss:		1.768289E-02
Epoch took 0.775s

Epoch 30 of 500
  training loss:		2.262342E-02
  validation loss:		2.234283E-02
Epoch took 0.776s

Epoch 31 of 500
  training loss:		1.972030E-02
  validation loss:		1.624871E-02
Epoch took 0.776s

Epoch 32 of 500
  training loss:		1.855513E-02
  validation loss:		1.490153E-02
Epoch took 0.776s

Epoch 33 of 500
  training loss:		1.844538E-02
  validation loss:		1.974102E-02
Epoch took 0.776s

Epoch 34 of 500
  training loss:		1.781721E-02
  validation loss:		1.658791E-02
Epoch took 0.776s

Epoch 35 of 500
  training loss:		1.633297E-02
  validation loss:		1.460428E-02
Epoch took 0.776s

Epoch 36 of 500
  training loss:		1.692228E-02
  validation loss:		1.633537E-02
Epoch took 0.775s

Epoch 37 of 500
  training loss:		1.725067E-02
  validation loss:		1.588517E-02
Epoch took 0.776s

Epoch 38 of 500
  training loss:		1.682020E-02
  validation loss:		1.373690E-02
Epoch took 0.776s

Epoch 39 of 500
  training loss:		1.970016E-02
  validation loss:		1.937502E-02
Epoch took 0.775s

Epoch 40 of 500
  training loss:		1.794949E-02
  validation loss:		1.571023E-02
Epoch took 0.775s

Epoch 41 of 500
  training loss:		1.609010E-02
  validation loss:		1.413432E-02
Epoch took 0.776s

Epoch 42 of 500
  training loss:		1.655660E-02
  validation loss:		1.601059E-02
Epoch took 0.776s

Epoch 43 of 500
  training loss:		1.826198E-02
  validation loss:		1.268405E-02
Epoch took 0.776s

Epoch 44 of 500
  training loss:		1.502437E-02
  validation loss:		1.707938E-02
Epoch took 0.776s

Epoch 45 of 500
  training loss:		1.450152E-02
  validation loss:		1.243700E-02
Epoch took 0.776s

Epoch 46 of 500
  training loss:		1.618910E-02
  validation loss:		1.303375E-02
Epoch took 0.775s

Epoch 47 of 500
  training loss:		1.513030E-02
  validation loss:		1.952507E-02
Epoch took 0.775s

Epoch 48 of 500
  training loss:		1.392670E-02
  validation loss:		1.185950E-02
Epoch took 0.775s

Epoch 49 of 500
  training loss:		1.605586E-02
  validation loss:		1.680629E-02
Epoch took 0.776s

Epoch 50 of 500
  training loss:		1.329017E-02
  validation loss:		8.660091E-03
Epoch took 0.776s

Epoch 51 of 500
  training loss:		1.303537E-02
  validation loss:		1.012348E-02
Epoch took 0.776s

Epoch 52 of 500
  training loss:		1.296940E-02
  validation loss:		1.044795E-02
Epoch took 0.776s

Epoch 53 of 500
  training loss:		1.359671E-02
  validation loss:		2.061206E-02
Epoch took 0.776s

Epoch 54 of 500
  training loss:		1.486855E-02
  validation loss:		1.419287E-02
Epoch took 0.776s

Epoch 55 of 500
  training loss:		1.257252E-02
  validation loss:		1.150358E-02
Epoch took 0.776s

Epoch 56 of 500
  training loss:		1.253913E-02
  validation loss:		1.214021E-02
Epoch took 0.775s

Epoch 57 of 500
  training loss:		1.166910E-02
  validation loss:		1.973949E-02
Epoch took 0.775s

Epoch 58 of 500
  training loss:		1.202510E-02
  validation loss:		1.486661E-02
Epoch took 0.776s

Epoch 59 of 500
  training loss:		1.289044E-02
  validation loss:		1.135157E-02
Epoch took 0.775s

Epoch 60 of 500
  training loss:		1.307104E-02
  validation loss:		1.226580E-02
Epoch took 0.776s

Epoch 61 of 500
  training loss:		1.212167E-02
  validation loss:		9.432665E-03
Epoch took 0.775s

Epoch 62 of 500
  training loss:		1.213765E-02
  validation loss:		1.185775E-02
Epoch took 0.776s

Epoch 63 of 500
  training loss:		1.177826E-02
  validation loss:		8.658139E-03
Epoch took 0.776s

Epoch 64 of 500
  training loss:		1.205460E-02
  validation loss:		1.865804E-02
Epoch took 0.778s

Epoch 65 of 500
  training loss:		1.146305E-02
  validation loss:		1.040177E-02
Epoch took 0.778s

Epoch 66 of 500
  training loss:		1.227781E-02
  validation loss:		2.074138E-02
Epoch took 0.778s

Epoch 67 of 500
  training loss:		1.254696E-02
  validation loss:		5.850213E-03
Epoch took 0.778s

Epoch 68 of 500
  training loss:		1.109093E-02
  validation loss:		9.366569E-03
Epoch took 0.778s

Epoch 69 of 500
  training loss:		9.585962E-03
  validation loss:		1.079187E-02
Epoch took 0.778s

Epoch 70 of 500
  training loss:		1.041380E-02
  validation loss:		9.702831E-03
Epoch took 0.778s

Epoch 71 of 500
  training loss:		1.022151E-02
  validation loss:		1.268368E-02
Epoch took 0.778s

Epoch 72 of 500
  training loss:		1.145224E-02
  validation loss:		1.306733E-02
Epoch took 0.778s

Epoch 73 of 500
  training loss:		1.022819E-02
  validation loss:		6.669737E-03
Epoch took 0.778s

Epoch 74 of 500
  training loss:		1.053624E-02
  validation loss:		9.992751E-03
Epoch took 0.778s

Epoch 75 of 500
  training loss:		1.063591E-02
  validation loss:		8.947223E-03
Epoch took 0.778s

Epoch 76 of 500
  training loss:		1.050251E-02
  validation loss:		8.130911E-03
Epoch took 0.778s

Epoch 77 of 500
  training loss:		9.689851E-03
  validation loss:		7.061780E-03
Epoch took 0.778s

Epoch 78 of 500
  training loss:		9.470123E-03
  validation loss:		5.593200E-03
Epoch took 0.778s

Epoch 79 of 500
  training loss:		1.003800E-02
  validation loss:		6.395996E-03
Epoch took 0.778s

Epoch 80 of 500
  training loss:		1.010374E-02
  validation loss:		1.009437E-02
Epoch took 0.778s

Epoch 81 of 500
  training loss:		8.978326E-03
  validation loss:		7.314432E-03
Epoch took 0.779s

Epoch 82 of 500
  training loss:		8.763485E-03
  validation loss:		6.882348E-03
Epoch took 0.778s

Epoch 83 of 500
  training loss:		1.082187E-02
  validation loss:		9.467901E-03
Epoch took 0.778s

Epoch 84 of 500
  training loss:		9.655436E-03
  validation loss:		6.380718E-03
Epoch took 0.778s

Epoch 85 of 500
  training loss:		9.071797E-03
  validation loss:		1.171952E-02
Epoch took 0.778s

Epoch 86 of 500
  training loss:		8.441504E-03
  validation loss:		6.447675E-03
Epoch took 0.778s

Epoch 87 of 500
  training loss:		8.567058E-03
  validation loss:		6.484523E-03
Epoch took 0.778s

Epoch 88 of 500
  training loss:		8.083187E-03
  validation loss:		6.802503E-03
Epoch took 0.778s

Epoch 89 of 500
  training loss:		8.564600E-03
  validation loss:		6.684173E-03
Epoch took 0.778s

Epoch 90 of 500
  training loss:		8.886718E-03
  validation loss:		1.423394E-02
Epoch took 0.778s

Epoch 91 of 500
  training loss:		1.100008E-02
  validation loss:		5.896667E-03
Epoch took 0.778s

Epoch 92 of 500
  training loss:		8.992764E-03
  validation loss:		7.663732E-03
Epoch took 0.778s

Epoch 93 of 500
  training loss:		9.251730E-03
  validation loss:		6.583991E-03
Epoch took 0.778s

Epoch 94 of 500
  training loss:		9.020564E-03
  validation loss:		8.341338E-03
Epoch took 0.777s

Epoch 95 of 500
  training loss:		7.995210E-03
  validation loss:		6.598950E-03
Epoch took 0.778s

Epoch 96 of 500
  training loss:		8.073617E-03
  validation loss:		8.133681E-03
Epoch took 0.778s

Epoch 97 of 500
  training loss:		7.422614E-03
  validation loss:		3.737285E-03
Epoch took 0.778s

Epoch 98 of 500
  training loss:		7.602558E-03
  validation loss:		4.426276E-03
Epoch took 0.778s

Epoch 99 of 500
  training loss:		9.002286E-03
  validation loss:		9.173692E-03
Epoch took 0.778s

Epoch 100 of 500
  training loss:		8.465834E-03
  validation loss:		4.972218E-03
Epoch took 0.778s

Epoch 101 of 500
  training loss:		8.521531E-03
  validation loss:		4.976941E-03
Epoch took 0.778s

Epoch 102 of 500
  training loss:		7.294369E-03
  validation loss:		4.326323E-03
Epoch took 0.778s

Epoch 103 of 500
  training loss:		6.999690E-03
  validation loss:		8.240145E-03
Epoch took 0.778s

Epoch 104 of 500
  training loss:		8.723861E-03
  validation loss:		4.570101E-03
Epoch took 0.778s

Epoch 105 of 500
  training loss:		6.972587E-03
  validation loss:		3.801554E-03
Epoch took 0.778s

Epoch 106 of 500
  training loss:		8.394569E-03
  validation loss:		4.440182E-03
Epoch took 0.778s

Epoch 107 of 500
  training loss:		7.384228E-03
  validation loss:		5.036586E-03
Epoch took 0.778s

Epoch 108 of 500
  training loss:		6.890458E-03
  validation loss:		4.728934E-03
Epoch took 0.778s

Epoch 109 of 500
  training loss:		8.478294E-03
  validation loss:		8.539701E-03
Epoch took 0.778s

Epoch 110 of 500
  training loss:		7.546185E-03
  validation loss:		1.203257E-02
Epoch took 0.778s

Epoch 111 of 500
  training loss:		9.087614E-03
  validation loss:		9.709370E-03
Epoch took 0.778s

Epoch 112 of 500
  training loss:		7.564684E-03
  validation loss:		1.146496E-02
Epoch took 0.778s

Epoch 113 of 500
  training loss:		7.247965E-03
  validation loss:		2.793663E-03
Epoch took 0.778s

Epoch 114 of 500
  training loss:		6.875838E-03
  validation loss:		3.061920E-03
Epoch took 0.778s

Epoch 115 of 500
  training loss:		7.029358E-03
  validation loss:		1.621661E-02
Epoch took 0.778s

Epoch 116 of 500
  training loss:		7.192952E-03
  validation loss:		4.262006E-03
Epoch took 0.778s

Epoch 117 of 500
  training loss:		7.354549E-03
  validation loss:		9.658728E-03
Epoch took 0.778s

Epoch 118 of 500
  training loss:		8.203218E-03
  validation loss:		1.060958E-02
Epoch took 0.778s

Epoch 119 of 500
  training loss:		6.859558E-03
  validation loss:		9.544210E-03
Epoch took 0.778s

Epoch 120 of 500
  training loss:		6.326651E-03
  validation loss:		4.520963E-03
Epoch took 0.778s

Epoch 121 of 500
  training loss:		6.386478E-03
  validation loss:		8.175560E-03
Epoch took 0.778s

Epoch 122 of 500
  training loss:		7.355284E-03
  validation loss:		7.788451E-03
Epoch took 0.780s

Epoch 123 of 500
  training loss:		6.370381E-03
  validation loss:		5.669777E-03
Epoch took 0.778s

Epoch 124 of 500
  training loss:		6.547844E-03
  validation loss:		1.069543E-02
Epoch took 0.778s

Epoch 125 of 500
  training loss:		8.238373E-03
  validation loss:		8.130298E-03
Epoch took 0.778s

Epoch 126 of 500
  training loss:		7.467346E-03
  validation loss:		6.613522E-03
Epoch took 0.778s

Epoch 127 of 500
  training loss:		7.929003E-03
  validation loss:		5.037410E-03
Epoch took 0.778s

Epoch 128 of 500
  training loss:		6.320343E-03
  validation loss:		1.292976E-02
Epoch took 0.778s

Epoch 129 of 500
  training loss:		6.577982E-03
  validation loss:		5.184666E-03
Epoch took 0.778s

Epoch 130 of 500
  training loss:		6.634666E-03
  validation loss:		6.940276E-03
Epoch took 0.778s

Epoch 131 of 500
  training loss:		6.456982E-03
  validation loss:		4.368500E-03
Epoch took 0.778s

Epoch 132 of 500
  training loss:		7.019024E-03
  validation loss:		3.733491E-03
Epoch took 0.778s

Epoch 133 of 500
  training loss:		7.213905E-03
  validation loss:		5.462262E-03
Epoch took 0.778s

Epoch 134 of 500
  training loss:		6.607209E-03
  validation loss:		3.982179E-03
Epoch took 0.778s

Epoch 135 of 500
  training loss:		6.330627E-03
  validation loss:		7.715899E-03
Epoch took 0.778s

Epoch 136 of 500
  training loss:		6.258419E-03
  validation loss:		5.036245E-03
Epoch took 0.778s

Epoch 137 of 500
  training loss:		6.376013E-03
  validation loss:		4.831575E-03
Epoch took 0.778s

Epoch 138 of 500
  training loss:		7.284133E-03
  validation loss:		1.218928E-02
Epoch took 0.778s

Epoch 139 of 500
  training loss:		7.242187E-03
  validation loss:		5.160292E-03
Epoch took 0.778s

Epoch 140 of 500
  training loss:		5.830137E-03
  validation loss:		5.706022E-03
Epoch took 0.778s

Epoch 141 of 500
  training loss:		5.919075E-03
  validation loss:		3.634608E-03
Epoch took 0.778s

Epoch 142 of 500
  training loss:		6.521722E-03
  validation loss:		7.978803E-03
Epoch took 0.778s

Epoch 143 of 500
  training loss:		5.986345E-03
  validation loss:		5.733244E-03
Epoch took 0.778s

Epoch 144 of 500
  training loss:		6.070849E-03
  validation loss:		5.309046E-03
Epoch took 0.778s

Epoch 145 of 500
  training loss:		6.214963E-03
  validation loss:		6.294245E-03
Epoch took 0.778s

Epoch 146 of 500
  training loss:		6.497926E-03
  validation loss:		4.212572E-03
Epoch took 0.778s

Epoch 147 of 500
  training loss:		5.733605E-03
  validation loss:		6.595111E-03
Epoch took 0.778s

Epoch 148 of 500
  training loss:		6.929218E-03
  validation loss:		2.820437E-03
Epoch took 0.778s

Epoch 149 of 500
  training loss:		5.828361E-03
  validation loss:		6.391579E-03
Epoch took 0.778s

Epoch 150 of 500
  training loss:		5.847795E-03
  validation loss:		5.713896E-03
Epoch took 0.778s

Epoch 151 of 500
  training loss:		6.862427E-03
  validation loss:		8.013548E-03
Epoch took 0.778s

Epoch 152 of 500
  training loss:		5.685586E-03
  validation loss:		5.678258E-03
Epoch took 0.778s

Epoch 153 of 500
  training loss:		6.183345E-03
  validation loss:		4.428137E-03
Epoch took 0.778s

Epoch 154 of 500
  training loss:		5.960722E-03
  validation loss:		6.744393E-03
Epoch took 0.778s

Epoch 155 of 500
  training loss:		6.004979E-03
  validation loss:		6.989393E-03
Epoch took 0.778s

Epoch 156 of 500
  training loss:		5.738853E-03
  validation loss:		9.600332E-03
Epoch took 0.778s

Epoch 157 of 500
  training loss:		5.825256E-03
  validation loss:		5.435877E-03
Epoch took 0.778s

Epoch 158 of 500
  training loss:		7.519688E-03
  validation loss:		7.714781E-03
Epoch took 0.778s

Epoch 159 of 500
  training loss:		7.035334E-03
  validation loss:		1.478207E-02
Epoch took 0.778s

Epoch 160 of 500
  training loss:		6.957098E-03
  validation loss:		5.350236E-03
Epoch took 0.778s

Epoch 161 of 500
  training loss:		6.882484E-03
  validation loss:		5.845258E-03
Epoch took 0.778s

Epoch 162 of 500
  training loss:		6.830361E-03
  validation loss:		4.721371E-03
Epoch took 0.778s

Epoch 163 of 500
  training loss:		5.993332E-03
  validation loss:		9.188413E-03
Epoch took 0.778s

Epoch 164 of 500
  training loss:		6.116360E-03
  validation loss:		8.526807E-03
Epoch took 0.778s

Epoch 165 of 500
  training loss:		6.058867E-03
  validation loss:		1.025538E-02
Epoch took 0.778s

Epoch 166 of 500
  training loss:		6.968138E-03
  validation loss:		3.450801E-03
Epoch took 0.778s

Epoch 167 of 500
  training loss:		6.340926E-03
  validation loss:		4.662761E-03
Epoch took 0.778s

Epoch 168 of 500
  training loss:		5.761270E-03
  validation loss:		4.901270E-03
Epoch took 0.778s

Epoch 169 of 500
  training loss:		5.934933E-03
  validation loss:		6.028826E-03
Epoch took 0.778s

Epoch 170 of 500
  training loss:		5.592662E-03
  validation loss:		5.793248E-03
Epoch took 0.778s

Epoch 171 of 500
  training loss:		5.759301E-03
  validation loss:		5.179233E-03
Epoch took 0.778s

Epoch 172 of 500
  training loss:		5.733579E-03
  validation loss:		1.126199E-02
Epoch took 0.778s

Epoch 173 of 500
  training loss:		5.915561E-03
  validation loss:		1.392045E-02
Epoch took 0.778s

Epoch 174 of 500
  training loss:		5.294438E-03
  validation loss:		6.842305E-03
Epoch took 0.778s

Epoch 175 of 500
  training loss:		5.608714E-03
  validation loss:		4.338911E-03
Epoch took 0.778s

Epoch 176 of 500
  training loss:		5.557509E-03
  validation loss:		5.213962E-03
Epoch took 0.778s

Epoch 177 of 500
  training loss:		6.296744E-03
  validation loss:		3.889835E-03
Epoch took 0.778s

Epoch 178 of 500
  training loss:		5.491436E-03
  validation loss:		4.391274E-03
Epoch took 0.778s

Epoch 179 of 500
  training loss:		5.126845E-03
  validation loss:		4.888601E-03
Epoch took 0.778s

Epoch 180 of 500
  training loss:		5.800604E-03
  validation loss:		3.731262E-03
Epoch took 0.778s

Epoch 181 of 500
  training loss:		5.079617E-03
  validation loss:		6.221095E-03
Epoch took 0.778s

Epoch 182 of 500
  training loss:		6.037084E-03
  validation loss:		5.394203E-03
Epoch took 0.778s

Epoch 183 of 500
  training loss:		4.818228E-03
  validation loss:		3.681944E-03
Epoch took 0.778s

Epoch 184 of 500
  training loss:		4.991740E-03
  validation loss:		3.600082E-03
Epoch took 0.778s

Epoch 185 of 500
  training loss:		5.382674E-03
  validation loss:		7.205182E-03
Epoch took 0.778s

Epoch 186 of 500
  training loss:		5.234796E-03
  validation loss:		3.307512E-03
Epoch took 0.778s

Epoch 187 of 500
  training loss:		5.375206E-03
  validation loss:		3.440201E-03
Epoch took 0.778s

Epoch 188 of 500
  training loss:		5.127935E-03
  validation loss:		5.330519E-03
Epoch took 0.778s

Epoch 189 of 500
  training loss:		5.336656E-03
  validation loss:		6.454414E-03
Epoch took 0.778s

Epoch 190 of 500
  training loss:		5.695804E-03
  validation loss:		7.093953E-03
Epoch took 0.778s

Epoch 191 of 500
  training loss:		4.938512E-03
  validation loss:		5.523581E-03
Epoch took 0.778s

Epoch 192 of 500
  training loss:		6.474159E-03
  validation loss:		7.170031E-03
Epoch took 0.778s

Epoch 193 of 500
  training loss:		4.965208E-03
  validation loss:		3.248352E-03
Epoch took 0.778s

Epoch 194 of 500
  training loss:		5.807201E-03
  validation loss:		4.341990E-03
Epoch took 0.778s

Epoch 195 of 500
  training loss:		4.887616E-03
  validation loss:		3.328912E-03
Epoch took 0.778s

Epoch 196 of 500
  training loss:		6.505587E-03
  validation loss:		5.702773E-03
Epoch took 0.778s

Epoch 197 of 500
  training loss:		5.162514E-03
  validation loss:		9.362915E-03
Epoch took 0.778s

Epoch 198 of 500
  training loss:		4.728587E-03
  validation loss:		6.933183E-03
Epoch took 0.778s

Epoch 199 of 500
  training loss:		5.778867E-03
  validation loss:		3.765254E-03
Epoch took 0.778s

Epoch 200 of 500
  training loss:		6.312525E-03
  validation loss:		3.651159E-03
Epoch took 0.780s

Epoch 201 of 500
  training loss:		4.874324E-03
  validation loss:		3.273565E-03
Epoch took 0.780s

Epoch 202 of 500
  training loss:		4.950654E-03
  validation loss:		2.894097E-03
Epoch took 0.778s

Epoch 203 of 500
  training loss:		5.142533E-03
  validation loss:		4.291157E-03
Epoch took 0.778s

Epoch 204 of 500
  training loss:		5.223794E-03
  validation loss:		5.372814E-03
Epoch took 0.778s

Epoch 205 of 500
  training loss:		4.989961E-03
  validation loss:		3.222581E-03
Epoch took 0.778s

Epoch 206 of 500
  training loss:		5.535541E-03
  validation loss:		3.358747E-03
Epoch took 0.778s

Epoch 207 of 500
  training loss:		5.230768E-03
  validation loss:		7.181666E-03
Epoch took 0.778s

Epoch 208 of 500
  training loss:		5.462582E-03
  validation loss:		3.004567E-03
Epoch took 0.778s

Epoch 209 of 500
  training loss:		4.729681E-03
  validation loss:		3.506022E-03
Epoch took 0.778s

Epoch 210 of 500
  training loss:		5.107986E-03
  validation loss:		6.385845E-03
Epoch took 0.778s

Epoch 211 of 500
  training loss:		5.040192E-03
  validation loss:		9.552532E-03
Epoch took 0.778s

Epoch 212 of 500
  training loss:		5.949283E-03
  validation loss:		5.746957E-03
Epoch took 0.778s

Epoch 213 of 500
  training loss:		4.319199E-03
  validation loss:		3.598464E-03
Epoch took 0.778s

Epoch 214 of 500
  training loss:		4.741074E-03
  validation loss:		2.964022E-03
Epoch took 0.778s

Epoch 215 of 500
  training loss:		5.520256E-03
  validation loss:		5.652861E-03
Epoch took 0.778s

Epoch 216 of 500
  training loss:		5.825524E-03
  validation loss:		3.329279E-03
Epoch took 0.778s

Epoch 217 of 500
  training loss:		6.023054E-03
  validation loss:		1.415687E-02
Epoch took 0.778s

Epoch 218 of 500
  training loss:		5.588976E-03
  validation loss:		9.029423E-03
Epoch took 0.778s

Epoch 219 of 500
  training loss:		6.908386E-03
  validation loss:		3.922605E-03
Epoch took 0.778s

Epoch 220 of 500
  training loss:		4.785714E-03
  validation loss:		4.145787E-03
Epoch took 0.778s

Epoch 221 of 500
  training loss:		4.947023E-03
  validation loss:		4.870354E-03
Epoch took 0.778s

Epoch 222 of 500
  training loss:		5.412080E-03
  validation loss:		3.058849E-03
Epoch took 0.777s

Epoch 223 of 500
  training loss:		5.298421E-03
  validation loss:		3.741295E-03
Epoch took 0.778s

Epoch 224 of 500
  training loss:		4.392193E-03
  validation loss:		3.244719E-03
Epoch took 0.778s

Epoch 225 of 500
  training loss:		5.285216E-03
  validation loss:		6.811128E-03
Epoch took 0.778s

Epoch 226 of 500
  training loss:		4.862560E-03
  validation loss:		2.890802E-03
Epoch took 0.778s

Epoch 227 of 500
  training loss:		5.358799E-03
  validation loss:		3.673177E-03
Epoch took 0.778s

Epoch 228 of 500
  training loss:		5.810001E-03
  validation loss:		6.676571E-03
Epoch took 0.778s

Epoch 229 of 500
  training loss:		4.799920E-03
  validation loss:		5.116460E-03
Epoch took 0.778s

Epoch 230 of 500
  training loss:		4.946348E-03
  validation loss:		3.598684E-03
Epoch took 0.778s

Epoch 231 of 500
  training loss:		4.442507E-03
  validation loss:		3.684061E-03
Epoch took 0.778s

Epoch 232 of 500
  training loss:		4.693937E-03
  validation loss:		3.877420E-03
Epoch took 0.778s

Epoch 233 of 500
  training loss:		4.592908E-03
  validation loss:		4.905916E-03
Epoch took 0.778s

Epoch 234 of 500
  training loss:		4.668400E-03
  validation loss:		6.280114E-03
Epoch took 0.778s

Epoch 235 of 500
  training loss:		4.999130E-03
  validation loss:		2.583520E-03
Epoch took 0.778s

Epoch 236 of 500
  training loss:		4.643807E-03
  validation loss:		5.804837E-03
Epoch took 0.778s

Epoch 237 of 500
  training loss:		4.576694E-03
  validation loss:		2.724991E-03
Epoch took 0.778s

Epoch 238 of 500
  training loss:		4.459034E-03
  validation loss:		2.083583E-03
Epoch took 0.778s

Epoch 239 of 500
  training loss:		5.710308E-03
  validation loss:		6.680069E-03
Epoch took 0.778s

Epoch 240 of 500
  training loss:		4.754942E-03
  validation loss:		5.474266E-03
Epoch took 0.778s

Epoch 241 of 500
  training loss:		4.669790E-03
  validation loss:		2.167587E-03
Epoch took 0.778s

Epoch 242 of 500
  training loss:		4.738875E-03
  validation loss:		3.487095E-03
Epoch took 0.778s

Epoch 243 of 500
  training loss:		4.995005E-03
  validation loss:		6.454369E-03
Epoch took 0.778s

Epoch 244 of 500
  training loss:		5.064275E-03
  validation loss:		6.528482E-03
Epoch took 0.778s

Epoch 245 of 500
  training loss:		4.747637E-03
  validation loss:		3.547727E-03
Epoch took 0.778s

Epoch 246 of 500
  training loss:		4.769434E-03
  validation loss:		6.295637E-03
Epoch took 0.778s

Epoch 247 of 500
  training loss:		4.867716E-03
  validation loss:		2.302591E-03
Epoch took 0.778s

Epoch 248 of 500
  training loss:		4.799797E-03
  validation loss:		2.690858E-03
Epoch took 0.778s

Epoch 249 of 500
  training loss:		4.375649E-03
  validation loss:		6.542206E-03
Epoch took 0.778s

Epoch 250 of 500
  training loss:		4.596494E-03
  validation loss:		3.936182E-03
Epoch took 0.778s

Epoch 251 of 500
  training loss:		4.387766E-03
  validation loss:		2.405699E-03
Epoch took 0.778s

Epoch 252 of 500
  training loss:		4.658712E-03
  validation loss:		4.051738E-03
Epoch took 0.778s

Epoch 253 of 500
  training loss:		5.211803E-03
  validation loss:		1.717549E-03
Epoch took 0.778s

Epoch 254 of 500
  training loss:		4.510838E-03
  validation loss:		3.513825E-03
Epoch took 0.778s

Epoch 255 of 500
  training loss:		4.646060E-03
  validation loss:		3.862175E-03
Epoch took 0.778s

Epoch 256 of 500
  training loss:		4.260380E-03
  validation loss:		4.968094E-03
Epoch took 0.778s

Epoch 257 of 500
  training loss:		4.180384E-03
  validation loss:		3.780743E-03
Epoch took 0.778s

Epoch 258 of 500
  training loss:		5.415546E-03
  validation loss:		5.400178E-03
Epoch took 0.778s

Epoch 259 of 500
  training loss:		4.466347E-03
  validation loss:		3.765519E-03
Epoch took 0.778s

Epoch 260 of 500
  training loss:		4.633442E-03
  validation loss:		4.100723E-03
Epoch took 0.778s

Epoch 261 of 500
  training loss:		4.260232E-03
  validation loss:		3.251396E-03
Epoch took 0.778s

Epoch 262 of 500
  training loss:		4.145931E-03
  validation loss:		5.348084E-03
Epoch took 0.778s

Epoch 263 of 500
  training loss:		4.960867E-03
  validation loss:		4.342954E-03
Epoch took 0.778s

Epoch 264 of 500
  training loss:		4.561112E-03
  validation loss:		3.597626E-03
Epoch took 0.778s

Epoch 265 of 500
  training loss:		3.992047E-03
  validation loss:		3.870399E-03
Epoch took 0.778s

Epoch 266 of 500
  training loss:		4.120720E-03
  validation loss:		4.220936E-03
Epoch took 0.778s

Epoch 267 of 500
  training loss:		4.204249E-03
  validation loss:		1.110907E-02
Epoch took 0.778s

Epoch 268 of 500
  training loss:		4.776872E-03
  validation loss:		5.269984E-03
Epoch took 0.778s

Epoch 269 of 500
  training loss:		4.634045E-03
  validation loss:		6.485275E-03
Epoch took 0.778s

Epoch 270 of 500
  training loss:		5.117102E-03
  validation loss:		3.766237E-03
Epoch took 0.778s

Epoch 271 of 500
  training loss:		4.621177E-03
  validation loss:		4.555986E-03
Epoch took 0.778s

Epoch 272 of 500
  training loss:		5.045021E-03
  validation loss:		4.018744E-03
Epoch took 0.778s

Epoch 273 of 500
  training loss:		4.774802E-03
  validation loss:		8.019974E-03
Epoch took 0.778s

Epoch 274 of 500
  training loss:		4.567215E-03
  validation loss:		3.182449E-03
Epoch took 0.778s

Epoch 275 of 500
  training loss:		4.093719E-03
  validation loss:		4.863983E-03
Epoch took 0.778s

Epoch 276 of 500
  training loss:		5.242061E-03
  validation loss:		4.559005E-03
Epoch took 0.778s

Epoch 277 of 500
  training loss:		5.509651E-03
  validation loss:		3.477189E-03
Epoch took 0.778s

Epoch 278 of 500
  training loss:		4.536922E-03
  validation loss:		5.098114E-03
Epoch took 0.778s

Epoch 279 of 500
  training loss:		4.262483E-03
  validation loss:		3.993428E-03
Epoch took 0.778s

Epoch 280 of 500
  training loss:		4.279910E-03
  validation loss:		5.313176E-03
Epoch took 0.778s

Early stopping, val-loss increased over the last 20 epochs from 0.00407594882288 to 0.0049172006942
Saving model from epoch 260
Training RMSE: 0.00409652
Validation RMSE: 0.00410291
Test RMSE: 0.00410538073629
Test MSE: 1.68541519088e-05
Test MAE: 0.00346231227741
Test R2: -179426266.553 

