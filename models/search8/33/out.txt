Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		1.068325E-01
  validation loss:		3.165587E-02
Epoch took 2.066s

Epoch 2 of 500
  training loss:		3.773571E-02
  validation loss:		4.834122E-02
Epoch took 2.016s

Epoch 3 of 500
  training loss:		2.822387E-02
  validation loss:		1.357575E-02
Epoch took 2.016s

Epoch 4 of 500
  training loss:		2.215083E-02
  validation loss:		2.742896E-02
Epoch took 2.017s

Epoch 5 of 500
  training loss:		1.953435E-02
  validation loss:		2.312115E-02
Epoch took 2.016s

Epoch 6 of 500
  training loss:		1.727869E-02
  validation loss:		1.509922E-02
Epoch took 2.016s

Epoch 7 of 500
  training loss:		1.538390E-02
  validation loss:		1.732160E-02
Epoch took 2.016s

Epoch 8 of 500
  training loss:		1.369210E-02
  validation loss:		1.207651E-02
Epoch took 2.016s

Epoch 9 of 500
  training loss:		1.303532E-02
  validation loss:		1.479089E-02
Epoch took 2.016s

Epoch 10 of 500
  training loss:		1.225901E-02
  validation loss:		6.177233E-03
Epoch took 2.016s

Epoch 11 of 500
  training loss:		1.041572E-02
  validation loss:		2.927845E-03
Epoch took 2.016s

Epoch 12 of 500
  training loss:		1.145795E-02
  validation loss:		1.320756E-02
Epoch took 2.015s

Epoch 13 of 500
  training loss:		9.373794E-03
  validation loss:		7.277417E-03
Epoch took 2.016s

Epoch 14 of 500
  training loss:		9.704550E-03
  validation loss:		1.712479E-02
Epoch took 2.016s

Epoch 15 of 500
  training loss:		9.012520E-03
  validation loss:		9.664308E-03
Epoch took 2.016s

Epoch 16 of 500
  training loss:		9.337936E-03
  validation loss:		1.693602E-02
Epoch took 2.016s

Epoch 17 of 500
  training loss:		7.665250E-03
  validation loss:		1.428318E-02
Epoch took 2.016s

Epoch 18 of 500
  training loss:		8.383893E-03
  validation loss:		1.260870E-02
Epoch took 2.016s

Epoch 19 of 500
  training loss:		8.058314E-03
  validation loss:		1.318498E-02
Epoch took 2.016s

Epoch 20 of 500
  training loss:		7.729201E-03
  validation loss:		1.100837E-02
Epoch took 2.016s

Epoch 21 of 500
  training loss:		6.937864E-03
  validation loss:		6.963057E-03
Epoch took 2.016s

Epoch 22 of 500
  training loss:		7.096295E-03
  validation loss:		1.564929E-02
Epoch took 2.016s

Epoch 23 of 500
  training loss:		6.765678E-03
  validation loss:		1.058683E-02
Epoch took 2.016s

Epoch 24 of 500
  training loss:		6.573372E-03
  validation loss:		9.697290E-03
Epoch took 2.017s

Epoch 25 of 500
  training loss:		6.519621E-03
  validation loss:		3.680867E-03
Epoch took 2.016s

Epoch 26 of 500
  training loss:		6.374660E-03
  validation loss:		1.954566E-02
Epoch took 2.016s

Epoch 27 of 500
  training loss:		5.900035E-03
  validation loss:		5.449693E-03
Epoch took 2.016s

Epoch 28 of 500
  training loss:		6.096767E-03
  validation loss:		2.234106E-02
Epoch took 2.016s

Epoch 29 of 500
  training loss:		6.479259E-03
  validation loss:		8.292715E-03
Epoch took 2.016s

Epoch 30 of 500
  training loss:		5.935763E-03
  validation loss:		6.569737E-03
Epoch took 2.016s

Epoch 31 of 500
  training loss:		5.825106E-03
  validation loss:		1.642140E-02
Epoch took 2.016s

Epoch 32 of 500
  training loss:		5.666983E-03
  validation loss:		5.985904E-03
Epoch took 2.016s

Epoch 33 of 500
  training loss:		5.246067E-03
  validation loss:		7.188006E-03
Epoch took 2.016s

Epoch 34 of 500
  training loss:		5.188974E-03
  validation loss:		6.507857E-03
Epoch took 2.016s

Epoch 35 of 500
  training loss:		5.046507E-03
  validation loss:		4.811407E-03
Epoch took 2.016s

Epoch 36 of 500
  training loss:		5.455799E-03
  validation loss:		4.360546E-03
Epoch took 2.016s

Epoch 37 of 500
  training loss:		5.427705E-03
  validation loss:		9.787820E-03
Epoch took 2.017s

Epoch 38 of 500
  training loss:		5.276433E-03
  validation loss:		2.398457E-03
Epoch took 2.017s

Epoch 39 of 500
  training loss:		5.097669E-03
  validation loss:		1.230681E-02
Epoch took 2.017s

Epoch 40 of 500
  training loss:		5.280669E-03
  validation loss:		6.719328E-03
Epoch took 2.017s

Epoch 41 of 500
  training loss:		4.714425E-03
  validation loss:		1.052431E-02
Epoch took 2.017s

Epoch 42 of 500
  training loss:		4.555048E-03
  validation loss:		4.352795E-03
Epoch took 2.017s

Epoch 43 of 500
  training loss:		4.796311E-03
  validation loss:		1.411439E-02
Epoch took 2.017s

Epoch 44 of 500
  training loss:		4.766849E-03
  validation loss:		8.788218E-03
Epoch took 2.017s

Epoch 45 of 500
  training loss:		4.866835E-03
  validation loss:		9.277965E-03
Epoch took 2.017s

Epoch 46 of 500
  training loss:		4.870524E-03
  validation loss:		1.328848E-02
Epoch took 2.017s

Epoch 47 of 500
  training loss:		4.337273E-03
  validation loss:		4.071059E-03
Epoch took 2.017s

Epoch 48 of 500
  training loss:		4.460220E-03
  validation loss:		4.634818E-03
Epoch took 2.017s

Epoch 49 of 500
  training loss:		4.102554E-03
  validation loss:		6.459426E-03
Epoch took 2.017s

Epoch 50 of 500
  training loss:		4.680648E-03
  validation loss:		1.999783E-02
Epoch took 2.017s

Epoch 51 of 500
  training loss:		4.370918E-03
  validation loss:		1.126586E-02
Epoch took 2.018s

Epoch 52 of 500
  training loss:		4.185325E-03
  validation loss:		4.044443E-03
Epoch took 2.017s

Epoch 53 of 500
  training loss:		4.623693E-03
  validation loss:		3.601484E-03
Epoch took 2.017s

Epoch 54 of 500
  training loss:		4.666752E-03
  validation loss:		5.317027E-03
Epoch took 2.017s

Epoch 55 of 500
  training loss:		4.249829E-03
  validation loss:		1.966169E-02
Epoch took 2.017s

Epoch 56 of 500
  training loss:		3.985769E-03
  validation loss:		3.506810E-03
Epoch took 2.017s

Epoch 57 of 500
  training loss:		3.945933E-03
  validation loss:		9.463215E-03
Epoch took 2.017s

Epoch 58 of 500
  training loss:		3.954103E-03
  validation loss:		4.917786E-03
Epoch took 2.017s

Epoch 59 of 500
  training loss:		3.908173E-03
  validation loss:		1.084133E-02
Epoch took 2.017s

Epoch 60 of 500
  training loss:		3.856724E-03
  validation loss:		2.827154E-03
Epoch took 2.017s

Early stopping, val-loss increased over the last 15 epochs from 0.00823634771312 to 0.00825989376356
Saving model from epoch 45
Training RMSE: 0.00930148
Validation RMSE: 0.00930798
Test RMSE: 0.00921219587326
Test MSE: 8.48645504448e-05
Test MAE: 0.0083341030404
Test R2: -903452595.31 

