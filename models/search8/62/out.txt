Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		7.270092E-02
  validation loss:		4.997943E-02
Epoch took 2.053s

Epoch 2 of 500
  training loss:		2.534558E-02
  validation loss:		1.888596E-02
Epoch took 2.015s

Epoch 3 of 500
  training loss:		1.927944E-02
  validation loss:		1.334698E-02
Epoch took 2.014s

Epoch 4 of 500
  training loss:		1.589216E-02
  validation loss:		2.619806E-02
Epoch took 2.015s

Epoch 5 of 500
  training loss:		1.439551E-02
  validation loss:		1.752910E-02
Epoch took 2.015s

Epoch 6 of 500
  training loss:		1.358724E-02
  validation loss:		1.131849E-02
Epoch took 2.016s

Epoch 7 of 500
  training loss:		1.234753E-02
  validation loss:		1.890825E-02
Epoch took 2.017s

Epoch 8 of 500
  training loss:		1.204474E-02
  validation loss:		1.732204E-02
Epoch took 2.017s

Epoch 9 of 500
  training loss:		1.032943E-02
  validation loss:		1.586363E-02
Epoch took 2.017s

Epoch 10 of 500
  training loss:		1.025989E-02
  validation loss:		1.720299E-02
Epoch took 2.017s

Epoch 11 of 500
  training loss:		1.056228E-02
  validation loss:		9.716010E-03
Epoch took 2.020s

Epoch 12 of 500
  training loss:		8.759372E-03
  validation loss:		1.906427E-02
Epoch took 2.019s

Epoch 13 of 500
  training loss:		9.913805E-03
  validation loss:		7.352651E-02
Epoch took 2.023s

Epoch 14 of 500
  training loss:		9.412259E-03
  validation loss:		1.678656E-02
Epoch took 2.023s

Epoch 15 of 500
  training loss:		9.297326E-03
  validation loss:		1.082682E-02
Epoch took 2.023s

Epoch 16 of 500
  training loss:		8.662673E-03
  validation loss:		8.865296E-03
Epoch took 2.024s

Epoch 17 of 500
  training loss:		7.917076E-03
  validation loss:		1.298234E-02
Epoch took 2.025s

Epoch 18 of 500
  training loss:		8.436890E-03
  validation loss:		1.942028E-02
Epoch took 2.024s

Epoch 19 of 500
  training loss:		8.462674E-03
  validation loss:		1.369316E-02
Epoch took 2.025s

Epoch 20 of 500
  training loss:		8.327149E-03
  validation loss:		1.441754E-02
Epoch took 2.025s

Epoch 21 of 500
  training loss:		8.468112E-03
  validation loss:		7.834691E-03
Epoch took 2.026s

Epoch 22 of 500
  training loss:		8.286534E-03
  validation loss:		3.638731E-03
Epoch took 2.026s

Epoch 23 of 500
  training loss:		1.001681E-02
  validation loss:		1.681036E-02
Epoch took 2.027s

Epoch 24 of 500
  training loss:		7.786305E-03
  validation loss:		1.517765E-02
Epoch took 2.027s

Epoch 25 of 500
  training loss:		9.740426E-03
  validation loss:		8.356109E-03
Epoch took 2.029s

Epoch 26 of 500
  training loss:		8.333964E-03
  validation loss:		9.563276E-03
Epoch took 2.029s

Epoch 27 of 500
  training loss:		8.141144E-03
  validation loss:		5.850782E-03
Epoch took 2.027s

Epoch 28 of 500
  training loss:		9.136110E-03
  validation loss:		1.164132E-02
Epoch took 2.033s

Epoch 29 of 500
  training loss:		7.976376E-03
  validation loss:		1.329282E-02
Epoch took 2.030s

Epoch 30 of 500
  training loss:		9.002728E-03
  validation loss:		2.308372E-02
Epoch took 2.031s

Epoch 31 of 500
  training loss:		8.281995E-03
  validation loss:		2.009086E-02
Epoch took 2.027s

Epoch 32 of 500
  training loss:		7.824472E-03
  validation loss:		1.492884E-02
Epoch took 2.032s

Epoch 33 of 500
  training loss:		6.959029E-03
  validation loss:		1.400681E-02
Epoch took 2.032s

Epoch 34 of 500
  training loss:		8.107832E-03
  validation loss:		1.901298E-02
Epoch took 2.028s

Epoch 35 of 500
  training loss:		8.340459E-03
  validation loss:		1.742006E-02
Epoch took 2.030s

Epoch 36 of 500
  training loss:		8.241377E-03
  validation loss:		1.179597E-02
Epoch took 2.031s

Epoch 37 of 500
  training loss:		7.177930E-03
  validation loss:		1.621353E-02
Epoch took 2.033s

Epoch 38 of 500
  training loss:		7.855673E-03
  validation loss:		3.576168E-03
Epoch took 2.031s

Epoch 39 of 500
  training loss:		6.937550E-03
  validation loss:		4.057328E-03
Epoch took 2.034s

Epoch 40 of 500
  training loss:		9.199740E-03
  validation loss:		1.185955E-02
Epoch took 2.034s

Epoch 41 of 500
  training loss:		6.971428E-03
  validation loss:		8.894092E-03
Epoch took 2.034s

Epoch 42 of 500
  training loss:		9.396848E-03
  validation loss:		4.744421E-03
Epoch took 2.033s

Epoch 43 of 500
  training loss:		7.837078E-03
  validation loss:		9.211961E-03
Epoch took 2.034s

Epoch 44 of 500
  training loss:		9.476309E-03
  validation loss:		1.658005E-02
Epoch took 2.033s

Epoch 45 of 500
  training loss:		9.156074E-03
  validation loss:		1.983575E-02
Epoch took 2.030s

Epoch 46 of 500
  training loss:		6.557336E-03
  validation loss:		7.692845E-03
Epoch took 2.040s

Epoch 47 of 500
  training loss:		8.228349E-03
  validation loss:		5.854220E-03
Epoch took 2.037s

Epoch 48 of 500
  training loss:		6.369282E-03
  validation loss:		1.177927E-02
Epoch took 2.038s

Epoch 49 of 500
  training loss:		8.677408E-03
  validation loss:		7.409860E-03
Epoch took 2.039s

Epoch 50 of 500
  training loss:		9.050608E-03
  validation loss:		6.389409E-03
Epoch took 2.035s

Epoch 51 of 500
  training loss:		7.264266E-03
  validation loss:		8.812342E-03
Epoch took 2.035s

Epoch 52 of 500
  training loss:		7.946678E-03
  validation loss:		7.772263E-03
Epoch took 2.035s

Epoch 53 of 500
  training loss:		6.100251E-03
  validation loss:		9.421978E-03
Epoch took 2.041s

Epoch 54 of 500
  training loss:		8.665762E-03
  validation loss:		6.374349E-03
Epoch took 2.036s

Epoch 55 of 500
  training loss:		7.913760E-03
  validation loss:		6.070604E-03
Epoch took 2.038s

Epoch 56 of 500
  training loss:		7.757190E-03
  validation loss:		1.036810E-02
Epoch took 2.038s

Epoch 57 of 500
  training loss:		7.346799E-03
  validation loss:		1.326057E-02
Epoch took 2.041s

Epoch 58 of 500
  training loss:		6.079395E-03
  validation loss:		4.738817E-03
Epoch took 2.041s

Epoch 59 of 500
  training loss:		6.400090E-03
  validation loss:		1.952048E-03
Epoch took 2.040s

Epoch 60 of 500
  training loss:		6.293725E-03
  validation loss:		2.150360E-02
Epoch took 2.041s

Epoch 61 of 500
  training loss:		5.951280E-03
  validation loss:		6.598635E-03
Epoch took 2.037s

Epoch 62 of 500
  training loss:		7.263263E-03
  validation loss:		6.625948E-03
Epoch took 2.045s

Epoch 63 of 500
  training loss:		8.252978E-03
  validation loss:		4.000779E-03
Epoch took 2.042s

Epoch 64 of 500
  training loss:		5.946540E-03
  validation loss:		4.637248E-03
Epoch took 2.041s

Epoch 65 of 500
  training loss:		6.199279E-03
  validation loss:		2.984415E-02
Epoch took 2.039s

Epoch 66 of 500
  training loss:		8.448965E-03
  validation loss:		1.129975E-02
Epoch took 2.042s

Epoch 67 of 500
  training loss:		6.627623E-03
  validation loss:		8.091981E-03
Epoch took 2.042s

Epoch 68 of 500
  training loss:		7.960124E-03
  validation loss:		6.723999E-03
Epoch took 2.041s

Epoch 69 of 500
  training loss:		8.397998E-03
  validation loss:		2.602275E-02
Epoch took 2.040s

Epoch 70 of 500
  training loss:		6.359729E-03
  validation loss:		8.359379E-03
Epoch took 2.040s

Epoch 71 of 500
  training loss:		6.250709E-03
  validation loss:		5.938490E-03
Epoch took 2.041s

Epoch 72 of 500
  training loss:		7.198614E-03
  validation loss:		7.074688E-03
Epoch took 2.042s

Epoch 73 of 500
  training loss:		6.399133E-03
  validation loss:		5.505549E-03
Epoch took 2.044s

Epoch 74 of 500
  training loss:		7.875119E-03
  validation loss:		9.471017E-03
Epoch took 2.044s

Epoch 75 of 500
  training loss:		7.395100E-03
  validation loss:		9.724220E-03
Epoch took 2.043s

Epoch 76 of 500
  training loss:		8.105745E-03
  validation loss:		5.622420E-03
Epoch took 2.043s

Epoch 77 of 500
  training loss:		7.203909E-03
  validation loss:		9.911332E-03
Epoch took 2.043s

Epoch 78 of 500
  training loss:		7.432618E-03
  validation loss:		1.472351E-02
Epoch took 2.044s

Epoch 79 of 500
  training loss:		7.100727E-03
  validation loss:		4.840093E-03
Epoch took 2.043s

Epoch 80 of 500
  training loss:		5.618844E-03
  validation loss:		5.014996E-03
Epoch took 2.045s

Early stopping, val-loss increased over the last 20 epochs from 0.00943332764953 to 0.0095015470468
Saving model from epoch 60
Training RMSE: 0.0225179
Validation RMSE: 0.0227143
Test RMSE: 0.0219895783812
Test MSE: 0.000483541516587
Test MAE: 0.00724818417802
Test R2: -5147695531.22 

