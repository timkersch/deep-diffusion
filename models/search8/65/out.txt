Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		2.664525E-01
  validation loss:		1.441018E-01
Epoch took 0.916s

Epoch 2 of 500
  training loss:		1.297005E-01
  validation loss:		6.328215E-02
Epoch took 0.871s

Epoch 3 of 500
  training loss:		1.106226E-01
  validation loss:		5.276586E-02
Epoch took 0.875s

Epoch 4 of 500
  training loss:		9.893425E-02
  validation loss:		4.322650E-02
Epoch took 0.878s

Epoch 5 of 500
  training loss:		9.146036E-02
  validation loss:		6.744815E-02
Epoch took 0.878s

Epoch 6 of 500
  training loss:		8.644728E-02
  validation loss:		3.961672E-02
Epoch took 0.878s

Epoch 7 of 500
  training loss:		8.377948E-02
  validation loss:		4.549342E-02
Epoch took 0.878s

Epoch 8 of 500
  training loss:		7.865725E-02
  validation loss:		4.387571E-02
Epoch took 0.878s

Epoch 9 of 500
  training loss:		7.757047E-02
  validation loss:		3.995454E-02
Epoch took 0.877s

Epoch 10 of 500
  training loss:		7.516079E-02
  validation loss:		4.216425E-02
Epoch took 0.878s

Epoch 11 of 500
  training loss:		7.145481E-02
  validation loss:		5.513229E-02
Epoch took 0.878s

Epoch 12 of 500
  training loss:		6.967874E-02
  validation loss:		3.416487E-02
Epoch took 0.878s

Epoch 13 of 500
  training loss:		6.838366E-02
  validation loss:		3.778205E-02
Epoch took 0.878s

Epoch 14 of 500
  training loss:		6.593174E-02
  validation loss:		3.720126E-02
Epoch took 0.878s

Epoch 15 of 500
  training loss:		6.533524E-02
  validation loss:		3.042228E-02
Epoch took 0.878s

Epoch 16 of 500
  training loss:		6.381403E-02
  validation loss:		3.807014E-02
Epoch took 0.878s

Epoch 17 of 500
  training loss:		6.244682E-02
  validation loss:		3.714999E-02
Epoch took 0.878s

Epoch 18 of 500
  training loss:		6.088327E-02
  validation loss:		5.279967E-02
Epoch took 0.878s

Epoch 19 of 500
  training loss:		5.911342E-02
  validation loss:		3.125204E-02
Epoch took 0.878s

Epoch 20 of 500
  training loss:		5.891430E-02
  validation loss:		3.184328E-02
Epoch took 0.878s

Epoch 21 of 500
  training loss:		5.640396E-02
  validation loss:		4.492005E-02
Epoch took 0.878s

Epoch 22 of 500
  training loss:		5.749292E-02
  validation loss:		3.938062E-02
Epoch took 0.878s

Epoch 23 of 500
  training loss:		5.599174E-02
  validation loss:		4.042090E-02
Epoch took 0.878s

Epoch 24 of 500
  training loss:		5.478533E-02
  validation loss:		3.180403E-02
Epoch took 0.878s

Epoch 25 of 500
  training loss:		5.342677E-02
  validation loss:		2.928699E-02
Epoch took 0.878s

Epoch 26 of 500
  training loss:		5.297382E-02
  validation loss:		3.758772E-02
Epoch took 0.878s

Epoch 27 of 500
  training loss:		5.211820E-02
  validation loss:		2.847564E-02
Epoch took 0.878s

Epoch 28 of 500
  training loss:		5.024952E-02
  validation loss:		2.758734E-02
Epoch took 0.881s

Epoch 29 of 500
  training loss:		5.090893E-02
  validation loss:		3.312168E-02
Epoch took 0.878s

Epoch 30 of 500
  training loss:		4.875610E-02
  validation loss:		2.449834E-02
Epoch took 0.879s

Epoch 31 of 500
  training loss:		4.847843E-02
  validation loss:		2.667694E-02
Epoch took 0.878s

Epoch 32 of 500
  training loss:		4.799450E-02
  validation loss:		2.491803E-02
Epoch took 0.878s

Epoch 33 of 500
  training loss:		4.740627E-02
  validation loss:		3.018715E-02
Epoch took 0.878s

Epoch 34 of 500
  training loss:		4.668642E-02
  validation loss:		2.967012E-02
Epoch took 0.878s

Epoch 35 of 500
  training loss:		4.548479E-02
  validation loss:		2.247562E-02
Epoch took 0.878s

Epoch 36 of 500
  training loss:		4.623661E-02
  validation loss:		3.064005E-02
Epoch took 0.878s

Epoch 37 of 500
  training loss:		4.490144E-02
  validation loss:		2.366408E-02
Epoch took 0.878s

Epoch 38 of 500
  training loss:		4.544122E-02
  validation loss:		2.538066E-02
Epoch took 0.878s

Epoch 39 of 500
  training loss:		4.367119E-02
  validation loss:		2.140173E-02
Epoch took 0.878s

Epoch 40 of 500
  training loss:		4.223332E-02
  validation loss:		2.386662E-02
Epoch took 0.878s

Epoch 41 of 500
  training loss:		4.228440E-02
  validation loss:		2.058112E-02
Epoch took 0.878s

Epoch 42 of 500
  training loss:		4.104861E-02
  validation loss:		2.195979E-02
Epoch took 0.878s

Epoch 43 of 500
  training loss:		4.208271E-02
  validation loss:		2.342681E-02
Epoch took 0.877s

Epoch 44 of 500
  training loss:		4.173423E-02
  validation loss:		2.991525E-02
Epoch took 0.878s

Epoch 45 of 500
  training loss:		4.003931E-02
  validation loss:		2.188398E-02
Epoch took 0.878s

Epoch 46 of 500
  training loss:		3.962055E-02
  validation loss:		2.058438E-02
Epoch took 0.877s

Epoch 47 of 500
  training loss:		3.956665E-02
  validation loss:		2.250305E-02
Epoch took 0.878s

Epoch 48 of 500
  training loss:		3.882295E-02
  validation loss:		3.043949E-02
Epoch took 0.878s

Epoch 49 of 500
  training loss:		3.897684E-02
  validation loss:		2.196564E-02
Epoch took 0.878s

Epoch 50 of 500
  training loss:		3.870585E-02
  validation loss:		1.882197E-02
Epoch took 0.878s

Epoch 51 of 500
  training loss:		3.821302E-02
  validation loss:		1.873076E-02
Epoch took 0.878s

Epoch 52 of 500
  training loss:		3.752045E-02
  validation loss:		2.569749E-02
Epoch took 0.878s

Epoch 53 of 500
  training loss:		3.665212E-02
  validation loss:		2.110298E-02
Epoch took 0.878s

Epoch 54 of 500
  training loss:		3.630268E-02
  validation loss:		1.787214E-02
Epoch took 0.878s

Epoch 55 of 500
  training loss:		3.624358E-02
  validation loss:		3.377190E-02
Epoch took 0.877s

Epoch 56 of 500
  training loss:		3.564981E-02
  validation loss:		2.369193E-02
Epoch took 0.877s

Epoch 57 of 500
  training loss:		3.568286E-02
  validation loss:		1.969737E-02
Epoch took 0.878s

Epoch 58 of 500
  training loss:		3.479623E-02
  validation loss:		1.808307E-02
Epoch took 0.877s

Epoch 59 of 500
  training loss:		3.484716E-02
  validation loss:		2.179731E-02
Epoch took 0.878s

Epoch 60 of 500
  training loss:		3.422300E-02
  validation loss:		2.085692E-02
Epoch took 0.877s

Epoch 61 of 500
  training loss:		3.402794E-02
  validation loss:		2.089541E-02
Epoch took 0.878s

Epoch 62 of 500
  training loss:		3.319892E-02
  validation loss:		2.031334E-02
Epoch took 0.878s

Epoch 63 of 500
  training loss:		3.316256E-02
  validation loss:		1.597672E-02
Epoch took 0.878s

Epoch 64 of 500
  training loss:		3.285596E-02
  validation loss:		1.946726E-02
Epoch took 0.878s

Epoch 65 of 500
  training loss:		3.361030E-02
  validation loss:		1.855054E-02
Epoch took 0.878s

Epoch 66 of 500
  training loss:		3.245200E-02
  validation loss:		1.723560E-02
Epoch took 0.878s

Epoch 67 of 500
  training loss:		3.232604E-02
  validation loss:		1.660253E-02
Epoch took 0.878s

Epoch 68 of 500
  training loss:		3.157910E-02
  validation loss:		1.604994E-02
Epoch took 0.878s

Epoch 69 of 500
  training loss:		3.142710E-02
  validation loss:		1.758345E-02
Epoch took 0.878s

Epoch 70 of 500
  training loss:		3.139841E-02
  validation loss:		1.529307E-02
Epoch took 0.878s

Epoch 71 of 500
  training loss:		3.165388E-02
  validation loss:		1.731779E-02
Epoch took 0.878s

Epoch 72 of 500
  training loss:		3.164389E-02
  validation loss:		1.442002E-02
Epoch took 0.878s

Epoch 73 of 500
  training loss:		3.042761E-02
  validation loss:		1.577845E-02
Epoch took 0.878s

Epoch 74 of 500
  training loss:		2.993760E-02
  validation loss:		1.458641E-02
Epoch took 0.878s

Epoch 75 of 500
  training loss:		2.924897E-02
  validation loss:		1.705044E-02
Epoch took 0.878s

Epoch 76 of 500
  training loss:		2.917920E-02
  validation loss:		1.629376E-02
Epoch took 0.878s

Epoch 77 of 500
  training loss:		2.950050E-02
  validation loss:		1.785363E-02
Epoch took 0.878s

Epoch 78 of 500
  training loss:		2.907399E-02
  validation loss:		1.312388E-02
Epoch took 0.878s

Epoch 79 of 500
  training loss:		2.872189E-02
  validation loss:		1.717923E-02
Epoch took 0.878s

Epoch 80 of 500
  training loss:		2.876026E-02
  validation loss:		1.569255E-02
Epoch took 0.878s

Epoch 81 of 500
  training loss:		2.882081E-02
  validation loss:		1.515751E-02
Epoch took 0.878s

Epoch 82 of 500
  training loss:		2.859663E-02
  validation loss:		1.819839E-02
Epoch took 0.877s

Epoch 83 of 500
  training loss:		2.754377E-02
  validation loss:		1.902235E-02
Epoch took 0.877s

Epoch 84 of 500
  training loss:		2.791898E-02
  validation loss:		1.805821E-02
Epoch took 0.878s

Epoch 85 of 500
  training loss:		2.804524E-02
  validation loss:		2.293655E-02
Epoch took 0.878s

Epoch 86 of 500
  training loss:		2.721798E-02
  validation loss:		1.592144E-02
Epoch took 0.878s

Epoch 87 of 500
  training loss:		2.741142E-02
  validation loss:		1.800775E-02
Epoch took 0.877s

Epoch 88 of 500
  training loss:		2.663445E-02
  validation loss:		2.236811E-02
Epoch took 0.878s

Epoch 89 of 500
  training loss:		2.695498E-02
  validation loss:		1.386126E-02
Epoch took 0.877s

Epoch 90 of 500
  training loss:		2.682691E-02
  validation loss:		1.470577E-02
Epoch took 0.878s

Epoch 91 of 500
  training loss:		2.676822E-02
  validation loss:		1.669116E-02
Epoch took 0.877s

Epoch 92 of 500
  training loss:		2.590367E-02
  validation loss:		1.434506E-02
Epoch took 0.878s

Epoch 93 of 500
  training loss:		2.581632E-02
  validation loss:		1.667881E-02
Epoch took 0.878s

Epoch 94 of 500
  training loss:		2.624374E-02
  validation loss:		2.448815E-02
Epoch took 0.877s

Epoch 95 of 500
  training loss:		2.516936E-02
  validation loss:		1.885817E-02
Epoch took 0.878s

Epoch 96 of 500
  training loss:		2.497784E-02
  validation loss:		1.283740E-02
Epoch took 0.877s

Epoch 97 of 500
  training loss:		2.489461E-02
  validation loss:		1.357101E-02
Epoch took 0.877s

Epoch 98 of 500
  training loss:		2.455961E-02
  validation loss:		1.443246E-02
Epoch took 0.878s

Epoch 99 of 500
  training loss:		2.487622E-02
  validation loss:		1.400785E-02
Epoch took 0.878s

Epoch 100 of 500
  training loss:		2.433376E-02
  validation loss:		1.381852E-02
Epoch took 0.878s

Early stopping, val-loss increased over the last 20 epochs from 0.0168632011873 to 0.0168982957088
Saving model from epoch 80
Training RMSE: 0.015907
Validation RMSE: 0.0157219
Test RMSE: 0.0156453177333
Test MSE: 0.000244775961619
Test MAE: 0.0119575187564
Test R2: -2605840252.81 

