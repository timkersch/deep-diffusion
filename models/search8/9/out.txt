Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		4.167644E-01
  validation loss:		1.321747E-01
Epoch took 0.925s

Epoch 2 of 500
  training loss:		1.266223E-01
  validation loss:		7.667149E-02
Epoch took 0.870s

Epoch 3 of 500
  training loss:		9.900901E-02
  validation loss:		5.902887E-02
Epoch took 0.870s

Epoch 4 of 500
  training loss:		9.034412E-02
  validation loss:		6.468807E-02
Epoch took 0.870s

Epoch 5 of 500
  training loss:		8.339971E-02
  validation loss:		4.149910E-02
Epoch took 0.872s

Epoch 6 of 500
  training loss:		7.777363E-02
  validation loss:		3.958959E-02
Epoch took 0.876s

Epoch 7 of 500
  training loss:		7.494907E-02
  validation loss:		3.900512E-02
Epoch took 0.876s

Epoch 8 of 500
  training loss:		7.006192E-02
  validation loss:		4.028651E-02
Epoch took 0.876s

Epoch 9 of 500
  training loss:		6.880243E-02
  validation loss:		3.181679E-02
Epoch took 0.876s

Epoch 10 of 500
  training loss:		6.463409E-02
  validation loss:		4.722378E-02
Epoch took 0.876s

Epoch 11 of 500
  training loss:		6.220148E-02
  validation loss:		2.775533E-02
Epoch took 0.876s

Epoch 12 of 500
  training loss:		6.085959E-02
  validation loss:		3.299292E-02
Epoch took 0.876s

Epoch 13 of 500
  training loss:		5.848439E-02
  validation loss:		2.966219E-02
Epoch took 0.876s

Epoch 14 of 500
  training loss:		5.677031E-02
  validation loss:		3.074109E-02
Epoch took 0.876s

Epoch 15 of 500
  training loss:		5.579637E-02
  validation loss:		3.021852E-02
Epoch took 0.876s

Epoch 16 of 500
  training loss:		5.280725E-02
  validation loss:		2.705240E-02
Epoch took 0.876s

Epoch 17 of 500
  training loss:		5.351725E-02
  validation loss:		2.509077E-02
Epoch took 0.876s

Epoch 18 of 500
  training loss:		5.147898E-02
  validation loss:		2.937265E-02
Epoch took 0.876s

Epoch 19 of 500
  training loss:		5.133211E-02
  validation loss:		2.622592E-02
Epoch took 0.876s

Epoch 20 of 500
  training loss:		5.053118E-02
  validation loss:		2.531390E-02
Epoch took 0.876s

Epoch 21 of 500
  training loss:		4.778523E-02
  validation loss:		2.382481E-02
Epoch took 0.876s

Epoch 22 of 500
  training loss:		4.731407E-02
  validation loss:		2.094123E-02
Epoch took 0.875s

Epoch 23 of 500
  training loss:		4.655113E-02
  validation loss:		2.117701E-02
Epoch took 0.876s

Epoch 24 of 500
  training loss:		4.494854E-02
  validation loss:		2.347057E-02
Epoch took 0.876s

Epoch 25 of 500
  training loss:		4.374497E-02
  validation loss:		2.172655E-02
Epoch took 0.876s

Epoch 26 of 500
  training loss:		4.514312E-02
  validation loss:		2.432121E-02
Epoch took 0.876s

Epoch 27 of 500
  training loss:		4.274163E-02
  validation loss:		2.535077E-02
Epoch took 0.876s

Epoch 28 of 500
  training loss:		4.264380E-02
  validation loss:		2.206664E-02
Epoch took 0.876s

Epoch 29 of 500
  training loss:		4.289795E-02
  validation loss:		2.620888E-02
Epoch took 0.876s

Epoch 30 of 500
  training loss:		4.131540E-02
  validation loss:		2.604040E-02
Epoch took 0.876s

Epoch 31 of 500
  training loss:		4.010123E-02
  validation loss:		2.402061E-02
Epoch took 0.876s

Epoch 32 of 500
  training loss:		3.952779E-02
  validation loss:		2.101870E-02
Epoch took 0.876s

Epoch 33 of 500
  training loss:		3.981489E-02
  validation loss:		2.750667E-02
Epoch took 0.876s

Epoch 34 of 500
  training loss:		3.895198E-02
  validation loss:		1.718358E-02
Epoch took 0.876s

Epoch 35 of 500
  training loss:		3.892010E-02
  validation loss:		2.642443E-02
Epoch took 0.876s

Epoch 36 of 500
  training loss:		3.704656E-02
  validation loss:		2.624156E-02
Epoch took 0.876s

Epoch 37 of 500
  training loss:		3.670411E-02
  validation loss:		1.760177E-02
Epoch took 0.876s

Epoch 38 of 500
  training loss:		3.582322E-02
  validation loss:		1.970173E-02
Epoch took 0.876s

Epoch 39 of 500
  training loss:		3.557036E-02
  validation loss:		2.105838E-02
Epoch took 0.876s

Epoch 40 of 500
  training loss:		3.553164E-02
  validation loss:		1.822508E-02
Epoch took 0.876s

Epoch 41 of 500
  training loss:		3.426163E-02
  validation loss:		2.055410E-02
Epoch took 0.876s

Epoch 42 of 500
  training loss:		3.439647E-02
  validation loss:		1.764359E-02
Epoch took 0.876s

Epoch 43 of 500
  training loss:		3.437311E-02
  validation loss:		1.773694E-02
Epoch took 0.876s

Epoch 44 of 500
  training loss:		3.296723E-02
  validation loss:		1.911605E-02
Epoch took 0.876s

Epoch 45 of 500
  training loss:		3.388217E-02
  validation loss:		1.735325E-02
Epoch took 0.876s

Epoch 46 of 500
  training loss:		3.325350E-02
  validation loss:		1.872526E-02
Epoch took 0.876s

Epoch 47 of 500
  training loss:		3.271005E-02
  validation loss:		1.802879E-02
Epoch took 0.875s

Epoch 48 of 500
  training loss:		3.250902E-02
  validation loss:		1.671439E-02
Epoch took 0.876s

Epoch 49 of 500
  training loss:		3.222305E-02
  validation loss:		2.162176E-02
Epoch took 0.876s

Epoch 50 of 500
  training loss:		3.124413E-02
  validation loss:		2.003051E-02
Epoch took 0.876s

Epoch 51 of 500
  training loss:		3.097548E-02
  validation loss:		1.839394E-02
Epoch took 0.876s

Epoch 52 of 500
  training loss:		3.038049E-02
  validation loss:		1.736820E-02
Epoch took 0.876s

Epoch 53 of 500
  training loss:		3.023962E-02
  validation loss:		1.725800E-02
Epoch took 0.876s

Epoch 54 of 500
  training loss:		3.005484E-02
  validation loss:		1.482167E-02
Epoch took 0.876s

Epoch 55 of 500
  training loss:		2.942449E-02
  validation loss:		2.037555E-02
Epoch took 0.876s

Epoch 56 of 500
  training loss:		2.923053E-02
  validation loss:		1.525414E-02
Epoch took 0.876s

Epoch 57 of 500
  training loss:		2.869200E-02
  validation loss:		1.765605E-02
Epoch took 0.876s

Epoch 58 of 500
  training loss:		2.838010E-02
  validation loss:		1.569127E-02
Epoch took 0.876s

Epoch 59 of 500
  training loss:		2.834474E-02
  validation loss:		2.155610E-02
Epoch took 0.876s

Epoch 60 of 500
  training loss:		2.793381E-02
  validation loss:		2.228222E-02
Epoch took 0.876s

Epoch 61 of 500
  training loss:		2.786175E-02
  validation loss:		2.017206E-02
Epoch took 0.876s

Epoch 62 of 500
  training loss:		2.673153E-02
  validation loss:		1.450603E-02
Epoch took 0.876s

Epoch 63 of 500
  training loss:		2.723651E-02
  validation loss:		2.036506E-02
Epoch took 0.876s

Epoch 64 of 500
  training loss:		2.669085E-02
  validation loss:		1.465808E-02
Epoch took 0.876s

Epoch 65 of 500
  training loss:		2.595372E-02
  validation loss:		1.500444E-02
Epoch took 0.876s

Epoch 66 of 500
  training loss:		2.540541E-02
  validation loss:		1.694286E-02
Epoch took 0.876s

Epoch 67 of 500
  training loss:		2.614011E-02
  validation loss:		1.382169E-02
Epoch took 0.876s

Epoch 68 of 500
  training loss:		2.608636E-02
  validation loss:		1.268570E-02
Epoch took 0.875s

Epoch 69 of 500
  training loss:		2.505156E-02
  validation loss:		1.420974E-02
Epoch took 0.876s

Epoch 70 of 500
  training loss:		2.551494E-02
  validation loss:		1.421906E-02
Epoch took 0.876s

Epoch 71 of 500
  training loss:		2.530995E-02
  validation loss:		1.931444E-02
Epoch took 0.876s

Epoch 72 of 500
  training loss:		2.445129E-02
  validation loss:		1.577064E-02
Epoch took 0.876s

Epoch 73 of 500
  training loss:		2.479594E-02
  validation loss:		1.364469E-02
Epoch took 0.876s

Epoch 74 of 500
  training loss:		2.456573E-02
  validation loss:		1.451753E-02
Epoch took 0.876s

Epoch 75 of 500
  training loss:		2.439304E-02
  validation loss:		1.238190E-02
Epoch took 0.876s

Epoch 76 of 500
  training loss:		2.411590E-02
  validation loss:		1.868499E-02
Epoch took 0.876s

Epoch 77 of 500
  training loss:		2.362889E-02
  validation loss:		1.283383E-02
Epoch took 0.876s

Epoch 78 of 500
  training loss:		2.349706E-02
  validation loss:		1.302862E-02
Epoch took 0.876s

Epoch 79 of 500
  training loss:		2.330284E-02
  validation loss:		1.174711E-02
Epoch took 0.876s

Epoch 80 of 500
  training loss:		2.278050E-02
  validation loss:		1.301276E-02
Epoch took 0.876s

Epoch 81 of 500
  training loss:		2.313656E-02
  validation loss:		1.245043E-02
Epoch took 0.876s

Epoch 82 of 500
  training loss:		2.296715E-02
  validation loss:		1.201836E-02
Epoch took 0.876s

Epoch 83 of 500
  training loss:		2.260430E-02
  validation loss:		1.217676E-02
Epoch took 0.876s

Epoch 84 of 500
  training loss:		2.238893E-02
  validation loss:		1.090626E-02
Epoch took 0.876s

Epoch 85 of 500
  training loss:		2.221779E-02
  validation loss:		1.388860E-02
Epoch took 0.876s

Epoch 86 of 500
  training loss:		2.216407E-02
  validation loss:		2.074533E-02
Epoch took 0.876s

Epoch 87 of 500
  training loss:		2.131879E-02
  validation loss:		9.989348E-03
Epoch took 0.876s

Epoch 88 of 500
  training loss:		2.142661E-02
  validation loss:		1.232009E-02
Epoch took 0.876s

Epoch 89 of 500
  training loss:		2.200237E-02
  validation loss:		1.220298E-02
Epoch took 0.876s

Epoch 90 of 500
  training loss:		2.154945E-02
  validation loss:		1.206943E-02
Epoch took 0.876s

Epoch 91 of 500
  training loss:		2.144557E-02
  validation loss:		1.209757E-02
Epoch took 0.876s

Epoch 92 of 500
  training loss:		2.102277E-02
  validation loss:		1.079354E-02
Epoch took 0.876s

Epoch 93 of 500
  training loss:		2.059774E-02
  validation loss:		1.176791E-02
Epoch took 0.876s

Epoch 94 of 500
  training loss:		2.077985E-02
  validation loss:		1.733304E-02
Epoch took 0.876s

Epoch 95 of 500
  training loss:		2.003450E-02
  validation loss:		1.254345E-02
Epoch took 0.876s

Epoch 96 of 500
  training loss:		2.026744E-02
  validation loss:		1.158496E-02
Epoch took 0.876s

Epoch 97 of 500
  training loss:		2.022841E-02
  validation loss:		1.105437E-02
Epoch took 0.876s

Epoch 98 of 500
  training loss:		1.988283E-02
  validation loss:		1.020631E-02
Epoch took 0.876s

Epoch 99 of 500
  training loss:		2.007787E-02
  validation loss:		1.154822E-02
Epoch took 0.876s

Epoch 100 of 500
  training loss:		2.007910E-02
  validation loss:		1.444965E-02
Epoch took 0.876s

Epoch 101 of 500
  training loss:		1.988767E-02
  validation loss:		1.135503E-02
Epoch took 0.876s

Epoch 102 of 500
  training loss:		1.941527E-02
  validation loss:		1.501224E-02
Epoch took 0.877s

Epoch 103 of 500
  training loss:		1.931477E-02
  validation loss:		1.041049E-02
Epoch took 0.876s

Epoch 104 of 500
  training loss:		1.894095E-02
  validation loss:		1.077804E-02
Epoch took 0.876s

Epoch 105 of 500
  training loss:		1.931562E-02
  validation loss:		1.117648E-02
Epoch took 0.876s

Epoch 106 of 500
  training loss:		1.900367E-02
  validation loss:		9.347246E-03
Epoch took 0.875s

Epoch 107 of 500
  training loss:		1.897084E-02
  validation loss:		1.053019E-02
Epoch took 0.876s

Epoch 108 of 500
  training loss:		1.883948E-02
  validation loss:		1.130062E-02
Epoch took 0.876s

Epoch 109 of 500
  training loss:		1.837887E-02
  validation loss:		1.065781E-02
Epoch took 0.876s

Epoch 110 of 500
  training loss:		1.862285E-02
  validation loss:		8.732107E-03
Epoch took 0.876s

Epoch 111 of 500
  training loss:		1.834608E-02
  validation loss:		9.451118E-03
Epoch took 0.876s

Epoch 112 of 500
  training loss:		1.851424E-02
  validation loss:		1.008485E-02
Epoch took 0.876s

Epoch 113 of 500
  training loss:		1.799402E-02
  validation loss:		1.071122E-02
Epoch took 0.876s

Epoch 114 of 500
  training loss:		1.802460E-02
  validation loss:		1.483586E-02
Epoch took 0.876s

Epoch 115 of 500
  training loss:		1.769194E-02
  validation loss:		9.873298E-03
Epoch took 0.876s

Epoch 116 of 500
  training loss:		1.762166E-02
  validation loss:		1.033909E-02
Epoch took 0.876s

Epoch 117 of 500
  training loss:		1.755636E-02
  validation loss:		9.742298E-03
Epoch took 0.876s

Epoch 118 of 500
  training loss:		1.772262E-02
  validation loss:		1.055629E-02
Epoch took 0.876s

Epoch 119 of 500
  training loss:		1.732281E-02
  validation loss:		9.874338E-03
Epoch took 0.876s

Epoch 120 of 500
  training loss:		1.709570E-02
  validation loss:		1.158339E-02
Epoch took 0.876s

Epoch 121 of 500
  training loss:		1.678863E-02
  validation loss:		1.163533E-02
Epoch took 0.876s

Epoch 122 of 500
  training loss:		1.732831E-02
  validation loss:		1.233048E-02
Epoch took 0.876s

Epoch 123 of 500
  training loss:		1.710562E-02
  validation loss:		9.487035E-03
Epoch took 0.876s

Epoch 124 of 500
  training loss:		1.661171E-02
  validation loss:		8.260796E-03
Epoch took 0.876s

Epoch 125 of 500
  training loss:		1.681138E-02
  validation loss:		1.144958E-02
Epoch took 0.876s

Epoch 126 of 500
  training loss:		1.680714E-02
  validation loss:		1.082733E-02
Epoch took 0.876s

Epoch 127 of 500
  training loss:		1.627139E-02
  validation loss:		1.063688E-02
Epoch took 0.876s

Epoch 128 of 500
  training loss:		1.671094E-02
  validation loss:		8.578224E-03
Epoch took 0.876s

Epoch 129 of 500
  training loss:		1.627059E-02
  validation loss:		9.095803E-03
Epoch took 0.876s

Epoch 130 of 500
  training loss:		1.570113E-02
  validation loss:		9.323871E-03
Epoch took 0.876s

Epoch 131 of 500
  training loss:		1.596878E-02
  validation loss:		1.088851E-02
Epoch took 0.876s

Epoch 132 of 500
  training loss:		1.606211E-02
  validation loss:		8.179587E-03
Epoch took 0.876s

Epoch 133 of 500
  training loss:		1.561673E-02
  validation loss:		9.948729E-03
Epoch took 0.876s

Epoch 134 of 500
  training loss:		1.571709E-02
  validation loss:		8.906183E-03
Epoch took 0.876s

Epoch 135 of 500
  training loss:		1.551280E-02
  validation loss:		9.855946E-03
Epoch took 0.876s

Epoch 136 of 500
  training loss:		1.581326E-02
  validation loss:		1.011065E-02
Epoch took 0.876s

Epoch 137 of 500
  training loss:		1.548013E-02
  validation loss:		9.328578E-03
Epoch took 0.876s

Epoch 138 of 500
  training loss:		1.525107E-02
  validation loss:		8.912020E-03
Epoch took 0.876s

Epoch 139 of 500
  training loss:		1.494574E-02
  validation loss:		1.003206E-02
Epoch took 0.876s

Epoch 140 of 500
  training loss:		1.541521E-02
  validation loss:		8.989518E-03
Epoch took 0.876s

Epoch 141 of 500
  training loss:		1.542250E-02
  validation loss:		7.503330E-03
Epoch took 0.876s

Epoch 142 of 500
  training loss:		1.491151E-02
  validation loss:		8.415410E-03
Epoch took 0.876s

Epoch 143 of 500
  training loss:		1.441647E-02
  validation loss:		1.143053E-02
Epoch took 0.876s

Epoch 144 of 500
  training loss:		1.494221E-02
  validation loss:		7.811892E-03
Epoch took 0.876s

Epoch 145 of 500
  training loss:		1.437441E-02
  validation loss:		1.208317E-02
Epoch took 0.876s

Epoch 146 of 500
  training loss:		1.495867E-02
  validation loss:		8.606684E-03
Epoch took 0.876s

Epoch 147 of 500
  training loss:		1.466755E-02
  validation loss:		7.601285E-03
Epoch took 0.876s

Epoch 148 of 500
  training loss:		1.485289E-02
  validation loss:		9.367869E-03
Epoch took 0.876s

Epoch 149 of 500
  training loss:		1.466385E-02
  validation loss:		1.365233E-02
Epoch took 0.876s

Epoch 150 of 500
  training loss:		1.436127E-02
  validation loss:		1.006509E-02
Epoch took 0.876s

Early stopping, val-loss increased over the last 10 epochs from 0.00951517869348 to 0.0096537587807
Saving model from epoch 140
Training RMSE: 0.00895072
Validation RMSE: 0.00899672
Test RMSE: 0.00894360709935
Test MSE: 7.99881017883e-05
Test MAE: 0.0070453598164
Test R2: -851538764.226 

