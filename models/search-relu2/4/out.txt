Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		2.046883E-02
  validation loss:		4.391209E-03

Epoch 2 of 100
  training loss:		2.938570E-03
  validation loss:		4.809253E-03

Epoch 3 of 100
  training loss:		2.002358E-03
  validation loss:		9.429508E-04

Epoch 4 of 100
  training loss:		1.264811E-03
  validation loss:		9.267699E-04

Epoch 5 of 100
  training loss:		1.009054E-03
  validation loss:		1.920079E-03

Epoch 6 of 100
  training loss:		7.935569E-04
  validation loss:		5.529406E-04

Epoch 7 of 100
  training loss:		6.269333E-04
  validation loss:		3.547154E-04

Epoch 8 of 100
  training loss:		5.774091E-04
  validation loss:		2.378770E-04

Epoch 9 of 100
  training loss:		4.411421E-04
  validation loss:		1.934202E-04

Epoch 10 of 100
  training loss:		3.977860E-04
  validation loss:		2.661970E-04

Epoch 11 of 100
  training loss:		3.364473E-04
  validation loss:		2.735253E-04

Epoch 12 of 100
  training loss:		3.193516E-04
  validation loss:		3.581893E-04

Epoch 13 of 100
  training loss:		3.329107E-04
  validation loss:		5.148188E-04

Epoch 14 of 100
  training loss:		2.748523E-04
  validation loss:		1.570025E-04

Epoch 15 of 100
  training loss:		2.144958E-04
  validation loss:		1.896075E-04

Epoch 16 of 100
  training loss:		1.924772E-04
  validation loss:		7.825095E-05

Epoch 17 of 100
  training loss:		2.059188E-04
  validation loss:		6.062464E-05

Epoch 18 of 100
  training loss:		1.750306E-04
  validation loss:		1.799631E-04

Epoch 19 of 100
  training loss:		1.796655E-04
  validation loss:		1.086325E-04

Epoch 20 of 100
  training loss:		1.365912E-04
  validation loss:		4.735302E-04

Epoch 21 of 100
  training loss:		1.526991E-04
  validation loss:		3.461379E-05

Epoch 22 of 100
  training loss:		1.204541E-04
  validation loss:		4.324321E-05

Epoch 23 of 100
  training loss:		1.205446E-04
  validation loss:		3.039992E-05

Epoch 24 of 100
  training loss:		1.268901E-04
  validation loss:		1.167478E-04

Epoch 25 of 100
  training loss:		1.240615E-04
  validation loss:		1.701721E-04

Epoch 26 of 100
  training loss:		1.217932E-04
  validation loss:		3.281059E-05

Epoch 27 of 100
  training loss:		9.243787E-05
  validation loss:		1.113630E-04

Epoch 28 of 100
  training loss:		8.862967E-05
  validation loss:		6.916774E-05

Epoch 29 of 100
  training loss:		7.713356E-05
  validation loss:		1.738088E-04

Epoch 30 of 100
  training loss:		8.972965E-05
  validation loss:		4.269002E-05

Epoch 31 of 100
  training loss:		4.860586E-05
  validation loss:		8.857674E-05

Epoch 32 of 100
  training loss:		8.120532E-05
  validation loss:		4.796862E-05

Epoch 33 of 100
  training loss:		8.217777E-05
  validation loss:		1.150705E-04

Epoch 34 of 100
  training loss:		7.133258E-05
  validation loss:		2.858106E-05

Epoch 35 of 100
  training loss:		4.672805E-05
  validation loss:		2.280415E-05

Epoch 36 of 100
  training loss:		4.405259E-05
  validation loss:		3.149953E-05

Epoch 37 of 100
  training loss:		5.293101E-05
  validation loss:		3.956955E-05

Epoch 38 of 100
  training loss:		3.900616E-05
  validation loss:		4.135043E-05

Epoch 39 of 100
  training loss:		5.915236E-05
  validation loss:		6.824734E-05

Epoch 40 of 100
  training loss:		5.067592E-05
  validation loss:		1.099442E-04

Epoch 41 of 100
  training loss:		3.043199E-05
  validation loss:		3.312867E-05

Epoch 42 of 100
  training loss:		3.671063E-05
  validation loss:		3.604837E-05

Epoch 43 of 100
  training loss:		4.168890E-05
  validation loss:		2.935789E-05

Epoch 44 of 100
  training loss:		5.485398E-05
  validation loss:		1.024716E-04

Epoch 45 of 100
  training loss:		4.333912E-05
  validation loss:		1.708679E-05

Epoch 46 of 100
  training loss:		2.354212E-05
  validation loss:		1.347441E-05

Epoch 47 of 100
  training loss:		4.492015E-05
  validation loss:		6.026583E-05

Epoch 48 of 100
  training loss:		2.831171E-05
  validation loss:		1.029871E-05

Epoch 49 of 100
  training loss:		2.404519E-05
  validation loss:		6.802844E-05

Epoch 50 of 100
  training loss:		3.681735E-05
  validation loss:		1.312763E-04

Epoch 51 of 100
  training loss:		2.246047E-05
  validation loss:		1.088588E-05

Epoch 52 of 100
  training loss:		2.561803E-05
  validation loss:		4.057660E-05

Epoch 53 of 100
  training loss:		1.459203E-05
  validation loss:		7.844564E-06

Epoch 54 of 100
  training loss:		2.916897E-05
  validation loss:		1.377680E-05

Epoch 55 of 100
  training loss:		3.397963E-05
  validation loss:		2.211492E-05

Epoch 56 of 100
  training loss:		2.108442E-05
  validation loss:		7.980293E-06

Epoch 57 of 100
  training loss:		3.666228E-05
  validation loss:		3.848033E-05

Epoch 58 of 100
  training loss:		2.038751E-05
  validation loss:		1.873575E-05

Epoch 59 of 100
  training loss:		1.055198E-05
  validation loss:		1.454069E-05

Epoch 60 of 100
  training loss:		2.352817E-05
  validation loss:		9.086980E-06

Epoch 61 of 100
  training loss:		1.733418E-05
  validation loss:		1.241724E-05

Epoch 62 of 100
  training loss:		2.051741E-05
  validation loss:		1.336220E-05

Epoch 63 of 100
  training loss:		2.945248E-05
  validation loss:		2.085031E-05

Epoch 64 of 100
  training loss:		1.369133E-05
  validation loss:		1.692690E-05

Epoch 65 of 100
  training loss:		2.094595E-05
  validation loss:		2.008146E-05

Epoch 66 of 100
  training loss:		2.717643E-05
  validation loss:		1.162290E-04

Epoch 67 of 100
  training loss:		1.337608E-05
  validation loss:		6.426851E-06

Epoch 68 of 100
  training loss:		1.487573E-05
  validation loss:		3.001959E-06

Epoch 69 of 100
  training loss:		1.255021E-05
  validation loss:		1.440283E-05

Epoch 70 of 100
  training loss:		1.857696E-05
  validation loss:		9.789398E-06

Epoch 71 of 100
  training loss:		1.350617E-05
  validation loss:		1.129814E-05

Epoch 72 of 100
  training loss:		7.938238E-06
  validation loss:		6.273904E-06

Epoch 73 of 100
  training loss:		1.433683E-05
  validation loss:		2.942347E-06

Epoch 74 of 100
  training loss:		1.258135E-05
  validation loss:		1.987814E-05

Epoch 75 of 100
  training loss:		1.446773E-05
  validation loss:		9.914501E-06

Epoch 76 of 100
  training loss:		1.262585E-05
  validation loss:		4.852556E-06

Epoch 77 of 100
  training loss:		3.179291E-05
  validation loss:		3.315197E-05

Epoch 78 of 100
  training loss:		1.054166E-05
  validation loss:		4.989301E-06

Epoch 79 of 100
  training loss:		6.960761E-06
  validation loss:		2.468555E-06

Epoch 80 of 100
  training loss:		1.031530E-05
  validation loss:		7.354902E-06

Epoch 81 of 100
  training loss:		1.150670E-05
  validation loss:		4.666694E-06

Epoch 82 of 100
  training loss:		1.139778E-05
  validation loss:		9.188168E-06

Epoch 83 of 100
  training loss:		1.051214E-05
  validation loss:		1.548861E-05

Epoch 84 of 100
  training loss:		8.652561E-06
  validation loss:		8.375026E-06

Epoch 85 of 100
  training loss:		2.060775E-05
  validation loss:		4.778061E-06

Epoch 86 of 100
  training loss:		5.937324E-06
  validation loss:		1.093441E-05

Epoch 87 of 100
  training loss:		1.302092E-05
  validation loss:		2.939509E-05

Epoch 88 of 100
  training loss:		1.503403E-05
  validation loss:		2.526002E-05

Epoch 89 of 100
  training loss:		1.237931E-05
  validation loss:		5.255473E-06

Epoch 90 of 100
  training loss:		5.124305E-06
  validation loss:		1.401766E-05

Epoch 91 of 100
  training loss:		7.160141E-06
  validation loss:		9.171259E-07

Epoch 92 of 100
  training loss:		1.345579E-05
  validation loss:		5.269800E-05

Epoch 93 of 100
  training loss:		8.426997E-06
  validation loss:		8.246275E-06

Epoch 94 of 100
  training loss:		9.146860E-06
  validation loss:		1.524574E-05

Epoch 95 of 100
  training loss:		1.619491E-05
  validation loss:		9.484673E-05

Epoch 96 of 100
  training loss:		1.560721E-05
  validation loss:		5.728941E-06

Epoch 97 of 100
  training loss:		5.156240E-06
  validation loss:		3.695974E-06

Epoch 98 of 100
  training loss:		3.738990E-06
  validation loss:		3.353296E-06

Epoch 99 of 100
  training loss:		5.528218E-06
  validation loss:		2.667619E-06

Epoch 100 of 100
  training loss:		7.485182E-06
  validation loss:		1.124191E-06

Training RMSE: 0.00105488613135
Validation RMSE: 0.00106191656018
