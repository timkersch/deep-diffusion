Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		7.255621E-01
  validation loss:		2.704033E-01

Epoch 2 of 100
  training loss:		1.632554E-01
  validation loss:		4.807060E-02

Epoch 3 of 100
  training loss:		5.429593E-02
  validation loss:		9.935772E-03

Epoch 4 of 100
  training loss:		2.683829E-02
  validation loss:		5.927235E-03

Epoch 5 of 100
  training loss:		2.004577E-02
  validation loss:		4.059744E-03

Epoch 6 of 100
  training loss:		1.659936E-02
  validation loss:		4.225927E-03

Epoch 7 of 100
  training loss:		1.392690E-02
  validation loss:		2.903011E-03

Epoch 8 of 100
  training loss:		1.228530E-02
  validation loss:		3.184621E-03

Epoch 9 of 100
  training loss:		1.071455E-02
  validation loss:		1.973317E-03

Epoch 10 of 100
  training loss:		9.248371E-03
  validation loss:		1.524732E-03

Epoch 11 of 100
  training loss:		8.273183E-03
  validation loss:		1.791196E-03

Epoch 12 of 100
  training loss:		7.418058E-03
  validation loss:		1.470242E-03

Epoch 13 of 100
  training loss:		7.230003E-03
  validation loss:		1.042844E-03

Epoch 14 of 100
  training loss:		7.099803E-03
  validation loss:		3.140032E-03

Epoch 15 of 100
  training loss:		5.862437E-03
  validation loss:		1.164656E-03

Epoch 16 of 100
  training loss:		5.607461E-03
  validation loss:		8.289747E-04

Epoch 17 of 100
  training loss:		5.332298E-03
  validation loss:		1.277296E-03

Epoch 18 of 100
  training loss:		4.577957E-03
  validation loss:		8.146358E-04

Epoch 19 of 100
  training loss:		4.420715E-03
  validation loss:		9.693185E-04

Epoch 20 of 100
  training loss:		3.973198E-03
  validation loss:		8.319230E-04

Epoch 21 of 100
  training loss:		4.135586E-03
  validation loss:		8.201115E-04

Epoch 22 of 100
  training loss:		4.254647E-03
  validation loss:		8.892788E-04

Epoch 23 of 100
  training loss:		3.837566E-03
  validation loss:		5.474037E-04

Epoch 24 of 100
  training loss:		3.357892E-03
  validation loss:		7.900878E-04

Epoch 25 of 100
  training loss:		3.018038E-03
  validation loss:		4.849982E-04

Epoch 26 of 100
  training loss:		2.863255E-03
  validation loss:		8.037853E-04

Epoch 27 of 100
  training loss:		2.948378E-03
  validation loss:		7.895202E-04

Epoch 28 of 100
  training loss:		2.672469E-03
  validation loss:		4.757214E-04

Epoch 29 of 100
  training loss:		2.649426E-03
  validation loss:		3.642484E-04

Epoch 30 of 100
  training loss:		2.641425E-03
  validation loss:		1.239052E-03

Early stopping, val-loss increased over the last 5 epochs from 0.000706375994737 to 0.000734465527511
Training RMSE: 0.0193355317034
Validation RMSE: 0.0190831163236
