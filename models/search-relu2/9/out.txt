Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.463945E+00
  validation loss:		6.847578E-01

Epoch 2 of 100
  training loss:		5.482256E-01
  validation loss:		2.448796E-01

Epoch 3 of 100
  training loss:		2.379048E-01
  validation loss:		9.474241E-02

Epoch 4 of 100
  training loss:		1.175847E-01
  validation loss:		2.512253E-02

Epoch 5 of 100
  training loss:		6.582474E-02
  validation loss:		7.236748E-03

Epoch 6 of 100
  training loss:		3.910916E-02
  validation loss:		5.298085E-03

Epoch 7 of 100
  training loss:		2.945129E-02
  validation loss:		6.697499E-03

Epoch 8 of 100
  training loss:		2.116370E-02
  validation loss:		3.904916E-03

Epoch 9 of 100
  training loss:		1.831949E-02
  validation loss:		3.762422E-03

Epoch 10 of 100
  training loss:		1.485525E-02
  validation loss:		3.336049E-03

Epoch 11 of 100
  training loss:		1.351709E-02
  validation loss:		4.324827E-03

Epoch 12 of 100
  training loss:		1.228287E-02
  validation loss:		4.250646E-03

Epoch 13 of 100
  training loss:		1.138465E-02
  validation loss:		5.576423E-03

Epoch 14 of 100
  training loss:		9.960079E-03
  validation loss:		3.493445E-03

Epoch 15 of 100
  training loss:		9.747928E-03
  validation loss:		2.745733E-03

Epoch 16 of 100
  training loss:		9.329316E-03
  validation loss:		3.704766E-03

Epoch 17 of 100
  training loss:		7.945774E-03
  validation loss:		1.403330E-03

Epoch 18 of 100
  training loss:		7.108272E-03
  validation loss:		2.604581E-03

Epoch 19 of 100
  training loss:		7.048904E-03
  validation loss:		1.588691E-03

Epoch 20 of 100
  training loss:		6.502052E-03
  validation loss:		1.932158E-03

Epoch 21 of 100
  training loss:		5.758216E-03
  validation loss:		2.127055E-03

Epoch 22 of 100
  training loss:		5.661519E-03
  validation loss:		1.344719E-03

Epoch 23 of 100
  training loss:		5.387660E-03
  validation loss:		1.364982E-03

Epoch 24 of 100
  training loss:		5.000369E-03
  validation loss:		1.789509E-03

Epoch 25 of 100
  training loss:		5.001318E-03
  validation loss:		2.523989E-03

Epoch 26 of 100
  training loss:		4.337539E-03
  validation loss:		1.003197E-03

Epoch 27 of 100
  training loss:		4.181631E-03
  validation loss:		9.008765E-04

Epoch 28 of 100
  training loss:		3.935212E-03
  validation loss:		9.811365E-04

Epoch 29 of 100
  training loss:		3.976067E-03
  validation loss:		1.730271E-03

Epoch 30 of 100
  training loss:		3.665969E-03
  validation loss:		1.382458E-03

Epoch 31 of 100
  training loss:		3.630982E-03
  validation loss:		8.434379E-04

Epoch 32 of 100
  training loss:		3.487293E-03
  validation loss:		1.088714E-03

Epoch 33 of 100
  training loss:		3.092971E-03
  validation loss:		1.210947E-03

Epoch 34 of 100
  training loss:		3.114202E-03
  validation loss:		8.550150E-04

Epoch 35 of 100
  training loss:		3.104594E-03
  validation loss:		8.044513E-04

Epoch 36 of 100
  training loss:		3.034544E-03
  validation loss:		8.059114E-04

Epoch 37 of 100
  training loss:		2.757892E-03
  validation loss:		1.301589E-03

Epoch 38 of 100
  training loss:		2.640133E-03
  validation loss:		7.836360E-04

Epoch 39 of 100
  training loss:		2.636173E-03
  validation loss:		7.915771E-04

Epoch 40 of 100
  training loss:		2.373114E-03
  validation loss:		5.275737E-04

Epoch 41 of 100
  training loss:		2.706577E-03
  validation loss:		5.739646E-04

Epoch 42 of 100
  training loss:		2.257855E-03
  validation loss:		8.131943E-04

Epoch 43 of 100
  training loss:		2.336884E-03
  validation loss:		4.160709E-04

Epoch 44 of 100
  training loss:		2.347010E-03
  validation loss:		1.603116E-03

Epoch 45 of 100
  training loss:		2.176475E-03
  validation loss:		8.639193E-04

Epoch 46 of 100
  training loss:		2.056007E-03
  validation loss:		4.093681E-04

Epoch 47 of 100
  training loss:		2.105272E-03
  validation loss:		8.688135E-04

Epoch 48 of 100
  training loss:		1.913636E-03
  validation loss:		8.336327E-04

Epoch 49 of 100
  training loss:		1.769035E-03
  validation loss:		4.450485E-04

Epoch 50 of 100
  training loss:		1.859664E-03
  validation loss:		4.947675E-04

Epoch 51 of 100
  training loss:		1.935775E-03
  validation loss:		6.305834E-04

Epoch 52 of 100
  training loss:		1.769879E-03
  validation loss:		3.646846E-04

Epoch 53 of 100
  training loss:		1.751794E-03
  validation loss:		5.415436E-04

Epoch 54 of 100
  training loss:		1.741583E-03
  validation loss:		4.188415E-04

Epoch 55 of 100
  training loss:		1.593108E-03
  validation loss:		4.501661E-04

Epoch 56 of 100
  training loss:		1.505712E-03
  validation loss:		5.406605E-04

Epoch 57 of 100
  training loss:		1.497229E-03
  validation loss:		3.457226E-04

Epoch 58 of 100
  training loss:		1.542858E-03
  validation loss:		4.152159E-04

Epoch 59 of 100
  training loss:		1.387388E-03
  validation loss:		4.947169E-04

Epoch 60 of 100
  training loss:		1.581972E-03
  validation loss:		6.212372E-04

Epoch 61 of 100
  training loss:		1.439941E-03
  validation loss:		2.438358E-04

Epoch 62 of 100
  training loss:		1.367459E-03
  validation loss:		3.521949E-04

Epoch 63 of 100
  training loss:		1.219385E-03
  validation loss:		4.369741E-04

Epoch 64 of 100
  training loss:		1.239094E-03
  validation loss:		2.602422E-04

Epoch 65 of 100
  training loss:		1.236801E-03
  validation loss:		5.940457E-04

Epoch 66 of 100
  training loss:		1.289634E-03
  validation loss:		5.124026E-04

Epoch 67 of 100
  training loss:		1.152008E-03
  validation loss:		3.769809E-04

Epoch 68 of 100
  training loss:		1.371511E-03
  validation loss:		4.231306E-04

Epoch 69 of 100
  training loss:		1.122396E-03
  validation loss:		3.761733E-04

Epoch 70 of 100
  training loss:		1.132157E-03
  validation loss:		5.753057E-04

Epoch 71 of 100
  training loss:		1.103301E-03
  validation loss:		5.668064E-04

Epoch 72 of 100
  training loss:		1.035534E-03
  validation loss:		3.482505E-04

Epoch 73 of 100
  training loss:		1.028811E-03
  validation loss:		2.396009E-04

Epoch 74 of 100
  training loss:		9.923065E-04
  validation loss:		2.691835E-04

Epoch 75 of 100
  training loss:		9.904718E-04
  validation loss:		1.638083E-04

Epoch 76 of 100
  training loss:		9.843916E-04
  validation loss:		2.254945E-04

Epoch 77 of 100
  training loss:		1.008621E-03
  validation loss:		2.457197E-04

Epoch 78 of 100
  training loss:		9.489226E-04
  validation loss:		1.721698E-04

Epoch 79 of 100
  training loss:		9.279700E-04
  validation loss:		2.108966E-04

Epoch 80 of 100
  training loss:		8.901446E-04
  validation loss:		2.547891E-04

Epoch 81 of 100
  training loss:		9.269420E-04
  validation loss:		3.868591E-04

Epoch 82 of 100
  training loss:		8.620414E-04
  validation loss:		1.608847E-04

Epoch 83 of 100
  training loss:		8.741116E-04
  validation loss:		1.979410E-04

Epoch 84 of 100
  training loss:		8.701739E-04
  validation loss:		2.192958E-04

Epoch 85 of 100
  training loss:		8.449036E-04
  validation loss:		4.373826E-04

Epoch 86 of 100
  training loss:		7.949146E-04
  validation loss:		1.576079E-04

Epoch 87 of 100
  training loss:		8.174974E-04
  validation loss:		2.095709E-04

Epoch 88 of 100
  training loss:		7.773536E-04
  validation loss:		1.714873E-04

Epoch 89 of 100
  training loss:		7.860207E-04
  validation loss:		3.023496E-04

Epoch 90 of 100
  training loss:		7.851709E-04
  validation loss:		3.499862E-04

Epoch 91 of 100
  training loss:		7.867045E-04
  validation loss:		1.856150E-04

Epoch 92 of 100
  training loss:		7.325468E-04
  validation loss:		1.364698E-04

Epoch 93 of 100
  training loss:		7.438906E-04
  validation loss:		1.383147E-04

Epoch 94 of 100
  training loss:		7.225385E-04
  validation loss:		2.323630E-04

Epoch 95 of 100
  training loss:		6.834851E-04
  validation loss:		1.331297E-04

Epoch 96 of 100
  training loss:		7.537521E-04
  validation loss:		1.830651E-04

Epoch 97 of 100
  training loss:		6.937616E-04
  validation loss:		2.146247E-04

Epoch 98 of 100
  training loss:		6.686275E-04
  validation loss:		2.381420E-04

Epoch 99 of 100
  training loss:		6.950380E-04
  validation loss:		1.025255E-04

Epoch 100 of 100
  training loss:		6.752443E-04
  validation loss:		2.419913E-04

Training RMSE: 0.01546095089
Validation RMSE: 0.0155488804003
