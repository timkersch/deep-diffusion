Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		1.391691E-01
  validation loss:		6.513409E-02
Epoch took 0.840s

Epoch 2 of 300
  training loss:		5.725937E-02
  validation loss:		4.830540E-02
Epoch took 0.721s

Epoch 3 of 300
  training loss:		4.589182E-02
  validation loss:		4.223832E-02
Epoch took 0.722s

Epoch 4 of 300
  training loss:		4.094882E-02
  validation loss:		3.647026E-02
Epoch took 0.723s

Epoch 5 of 300
  training loss:		3.819235E-02
  validation loss:		3.306463E-02
Epoch took 0.722s

Epoch 6 of 300
  training loss:		3.495047E-02
  validation loss:		3.324766E-02
Epoch took 0.722s

Epoch 7 of 300
  training loss:		3.375204E-02
  validation loss:		3.037273E-02
Epoch took 0.722s

Epoch 8 of 300
  training loss:		3.241428E-02
  validation loss:		3.105166E-02
Epoch took 0.722s

Epoch 9 of 300
  training loss:		3.210174E-02
  validation loss:		2.864987E-02
Epoch took 0.722s

Epoch 10 of 300
  training loss:		2.993491E-02
  validation loss:		2.758196E-02
Epoch took 0.724s

Epoch 11 of 300
  training loss:		3.091225E-02
  validation loss:		2.794207E-02
Epoch took 0.724s

Epoch 12 of 300
  training loss:		3.109744E-02
  validation loss:		2.865512E-02
Epoch took 0.724s

Epoch 13 of 300
  training loss:		2.940488E-02
  validation loss:		3.105878E-02
Epoch took 0.724s

Epoch 14 of 300
  training loss:		2.892351E-02
  validation loss:		2.707575E-02
Epoch took 0.724s

Epoch 15 of 300
  training loss:		2.848877E-02
  validation loss:		2.761961E-02
Epoch took 0.724s

Epoch 16 of 300
  training loss:		2.880995E-02
  validation loss:		2.721788E-02
Epoch took 0.723s

Epoch 17 of 300
  training loss:		2.791465E-02
  validation loss:		2.832836E-02
Epoch took 0.723s

Epoch 18 of 300
  training loss:		2.878440E-02
  validation loss:		2.880099E-02
Epoch took 0.724s

Epoch 19 of 300
  training loss:		2.856376E-02
  validation loss:		2.768121E-02
Epoch took 0.723s

Epoch 20 of 300
  training loss:		2.821149E-02
  validation loss:		2.745216E-02
Epoch took 0.724s

Epoch 21 of 300
  training loss:		2.774475E-02
  validation loss:		2.821694E-02
Epoch took 0.723s

Epoch 22 of 300
  training loss:		2.783900E-02
  validation loss:		2.690680E-02
Epoch took 0.722s

Epoch 23 of 300
  training loss:		2.824056E-02
  validation loss:		2.626633E-02
Epoch took 0.722s

Epoch 24 of 300
  training loss:		2.855671E-02
  validation loss:		2.701954E-02
Epoch took 0.723s

Epoch 25 of 300
  training loss:		2.761728E-02
  validation loss:		2.588557E-02
Epoch took 0.723s

Epoch 26 of 300
  training loss:		2.793601E-02
  validation loss:		2.671648E-02
Epoch took 0.723s

Epoch 27 of 300
  training loss:		2.756676E-02
  validation loss:		2.681942E-02
Epoch took 0.723s

Epoch 28 of 300
  training loss:		2.754898E-02
  validation loss:		2.663807E-02
Epoch took 0.723s

Epoch 29 of 300
  training loss:		2.735390E-02
  validation loss:		2.592617E-02
Epoch took 0.723s

Epoch 30 of 300
  training loss:		2.755573E-02
  validation loss:		2.653277E-02
Epoch took 0.723s

Epoch 31 of 300
  training loss:		2.790523E-02
  validation loss:		2.646253E-02
Epoch took 0.723s

Epoch 32 of 300
  training loss:		2.763056E-02
  validation loss:		2.604000E-02
Epoch took 0.723s

Epoch 33 of 300
  training loss:		2.792303E-02
  validation loss:		2.827107E-02
Epoch took 0.723s

Epoch 34 of 300
  training loss:		2.747222E-02
  validation loss:		2.692249E-02
Epoch took 0.723s

Epoch 35 of 300
  training loss:		2.775462E-02
  validation loss:		2.676393E-02
Epoch took 0.724s

Epoch 36 of 300
  training loss:		2.795004E-02
  validation loss:		2.638428E-02
Epoch took 0.723s

Epoch 37 of 300
  training loss:		2.728949E-02
  validation loss:		2.618947E-02
Epoch took 0.723s

Epoch 38 of 300
  training loss:		2.770224E-02
  validation loss:		2.670333E-02
Epoch took 0.723s

Epoch 39 of 300
  training loss:		2.739822E-02
  validation loss:		2.616240E-02
Epoch took 0.724s

Epoch 40 of 300
  training loss:		2.750948E-02
  validation loss:		2.693413E-02
Epoch took 0.723s

Epoch 41 of 300
  training loss:		2.748335E-02
  validation loss:		2.705854E-02
Epoch took 0.722s

Epoch 42 of 300
  training loss:		2.731182E-02
  validation loss:		2.717995E-02
Epoch took 0.724s

Epoch 43 of 300
  training loss:		2.763460E-02
  validation loss:		2.730199E-02
Epoch took 0.723s

Epoch 44 of 300
  training loss:		2.740790E-02
  validation loss:		2.599158E-02
Epoch took 0.725s

Epoch 45 of 300
  training loss:		2.726577E-02
  validation loss:		2.826099E-02
Epoch took 0.724s

Epoch 46 of 300
  training loss:		2.753125E-02
  validation loss:		2.656057E-02
Epoch took 0.723s

Epoch 47 of 300
  training loss:		2.720397E-02
  validation loss:		2.593678E-02
Epoch took 0.722s

Epoch 48 of 300
  training loss:		2.727086E-02
  validation loss:		2.616664E-02
Epoch took 0.723s

Epoch 49 of 300
  training loss:		2.753494E-02
  validation loss:		2.636399E-02
Epoch took 0.723s

Epoch 50 of 300
  training loss:		2.733604E-02
  validation loss:		2.656949E-02
Epoch took 0.722s

Epoch 51 of 300
  training loss:		2.737583E-02
  validation loss:		2.639502E-02
Epoch took 0.723s

Epoch 52 of 300
  training loss:		2.725197E-02
  validation loss:		2.629347E-02
Epoch took 0.723s

Epoch 53 of 300
  training loss:		2.713277E-02
  validation loss:		2.662551E-02
Epoch took 0.723s

Epoch 54 of 300
  training loss:		2.734310E-02
  validation loss:		2.615341E-02
Epoch took 0.724s

Epoch 55 of 300
  training loss:		2.740302E-02
  validation loss:		2.610000E-02
Epoch took 0.723s

Epoch 56 of 300
  training loss:		2.707348E-02
  validation loss:		2.637396E-02
Epoch took 0.724s

Epoch 57 of 300
  training loss:		2.724009E-02
  validation loss:		2.604851E-02
Epoch took 0.723s

Epoch 58 of 300
  training loss:		2.702111E-02
  validation loss:		2.604042E-02
Epoch took 0.723s

Epoch 59 of 300
  training loss:		2.711930E-02
  validation loss:		2.631215E-02
Epoch took 0.723s

Epoch 60 of 300
  training loss:		2.712075E-02
  validation loss:		2.634708E-02
Epoch took 0.723s

Epoch 61 of 300
  training loss:		2.707255E-02
  validation loss:		2.634248E-02
Epoch took 0.722s

Epoch 62 of 300
  training loss:		2.698527E-02
  validation loss:		2.588578E-02
Epoch took 0.723s

Epoch 63 of 300
  training loss:		2.692474E-02
  validation loss:		2.578331E-02
Epoch took 0.723s

Epoch 64 of 300
  training loss:		2.684928E-02
  validation loss:		2.613475E-02
Epoch took 0.722s

Epoch 65 of 300
  training loss:		2.697792E-02
  validation loss:		2.598628E-02
Epoch took 0.723s

Epoch 66 of 300
  training loss:		2.688675E-02
  validation loss:		2.584417E-02
Epoch took 0.723s

Epoch 67 of 300
  training loss:		2.689212E-02
  validation loss:		2.580476E-02
Epoch took 0.722s

Epoch 68 of 300
  training loss:		2.696065E-02
  validation loss:		2.631963E-02
Epoch took 0.723s

Epoch 69 of 300
  training loss:		2.691498E-02
  validation loss:		2.609662E-02
Epoch took 0.723s

Epoch 70 of 300
  training loss:		2.710876E-02
  validation loss:		2.679943E-02
Epoch took 0.723s

Epoch 71 of 300
  training loss:		2.694165E-02
  validation loss:		2.588608E-02
Epoch took 0.723s

Epoch 72 of 300
  training loss:		2.693136E-02
  validation loss:		2.626702E-02
Epoch took 0.723s

Epoch 73 of 300
  training loss:		2.697462E-02
  validation loss:		2.588973E-02
Epoch took 0.722s

Epoch 74 of 300
  training loss:		2.701449E-02
  validation loss:		2.630817E-02
Epoch took 0.722s

Epoch 75 of 300
  training loss:		2.729295E-02
  validation loss:		2.594844E-02
Epoch took 0.723s

Epoch 76 of 300
  training loss:		2.691186E-02
  validation loss:		2.569938E-02
Epoch took 0.723s

Epoch 77 of 300
  training loss:		2.697721E-02
  validation loss:		2.635273E-02
Epoch took 0.723s

Epoch 78 of 300
  training loss:		2.708665E-02
  validation loss:		2.588380E-02
Epoch took 0.722s

Epoch 79 of 300
  training loss:		2.684445E-02
  validation loss:		2.575689E-02
Epoch took 0.723s

Epoch 80 of 300
  training loss:		2.691853E-02
  validation loss:		2.564187E-02
Epoch took 0.723s

Epoch 81 of 300
  training loss:		2.694502E-02
  validation loss:		2.566258E-02
Epoch took 0.722s

Epoch 82 of 300
  training loss:		2.714451E-02
  validation loss:		2.807101E-02
Epoch took 0.722s

Epoch 83 of 300
  training loss:		2.730433E-02
  validation loss:		2.657957E-02
Epoch took 0.723s

Epoch 84 of 300
  training loss:		2.704040E-02
  validation loss:		2.567909E-02
Epoch took 0.723s

Epoch 85 of 300
  training loss:		2.683506E-02
  validation loss:		2.593150E-02
Epoch took 0.722s

Epoch 86 of 300
  training loss:		2.689474E-02
  validation loss:		2.590404E-02
Epoch took 0.723s

Epoch 87 of 300
  training loss:		2.683006E-02
  validation loss:		2.601221E-02
Epoch took 0.724s

Epoch 88 of 300
  training loss:		2.677136E-02
  validation loss:		2.575934E-02
Epoch took 0.722s

Epoch 89 of 300
  training loss:		2.687569E-02
  validation loss:		2.612385E-02
Epoch took 0.724s

Epoch 90 of 300
  training loss:		2.680581E-02
  validation loss:		2.568036E-02
Epoch took 0.723s

Epoch 91 of 300
  training loss:		2.687649E-02
  validation loss:		2.575338E-02
Epoch took 0.723s

Epoch 92 of 300
  training loss:		2.668554E-02
  validation loss:		2.586237E-02
Epoch took 0.722s

Epoch 93 of 300
  training loss:		2.679427E-02
  validation loss:		2.586155E-02
Epoch took 0.724s

Epoch 94 of 300
  training loss:		2.685597E-02
  validation loss:		2.603299E-02
Epoch took 0.723s

Epoch 95 of 300
  training loss:		2.687882E-02
  validation loss:		2.585327E-02
Epoch took 0.722s

Epoch 96 of 300
  training loss:		2.699090E-02
  validation loss:		2.572599E-02
Epoch took 0.722s

Epoch 97 of 300
  training loss:		2.690802E-02
  validation loss:		2.580611E-02
Epoch took 0.723s

Epoch 98 of 300
  training loss:		2.671659E-02
  validation loss:		2.588784E-02
Epoch took 0.723s

Epoch 99 of 300
  training loss:		2.681681E-02
  validation loss:		2.594620E-02
Epoch took 0.722s

Epoch 100 of 300
  training loss:		2.678173E-02
  validation loss:		2.559325E-02
Epoch took 0.723s

Epoch 101 of 300
  training loss:		2.677337E-02
  validation loss:		2.581149E-02
Epoch took 0.723s

Epoch 102 of 300
  training loss:		2.680164E-02
  validation loss:		2.558281E-02
Epoch took 0.723s

Epoch 103 of 300
  training loss:		2.703253E-02
  validation loss:		2.641374E-02
Epoch took 0.723s

Epoch 104 of 300
  training loss:		2.696140E-02
  validation loss:		2.607029E-02
Epoch took 0.723s

Epoch 105 of 300
  training loss:		2.691370E-02
  validation loss:		2.716782E-02
Epoch took 0.722s

Epoch 106 of 300
  training loss:		2.695774E-02
  validation loss:		2.663648E-02
Epoch took 0.723s

Epoch 107 of 300
  training loss:		2.681749E-02
  validation loss:		2.560505E-02
Epoch took 0.723s

Epoch 108 of 300
  training loss:		2.671635E-02
  validation loss:		2.564004E-02
Epoch took 0.722s

Epoch 109 of 300
  training loss:		2.682253E-02
  validation loss:		2.612347E-02
Epoch took 0.724s

Epoch 110 of 300
  training loss:		2.708610E-02
  validation loss:		2.569820E-02
Epoch took 0.722s

Epoch 111 of 300
  training loss:		2.681343E-02
  validation loss:		2.578178E-02
Epoch took 0.723s

Epoch 112 of 300
  training loss:		2.677388E-02
  validation loss:		2.597083E-02
Epoch took 0.723s

Epoch 113 of 300
  training loss:		2.661712E-02
  validation loss:		2.636577E-02
Epoch took 0.723s

Epoch 114 of 300
  training loss:		2.707336E-02
  validation loss:		2.582084E-02
Epoch took 0.722s

Epoch 115 of 300
  training loss:		2.673868E-02
  validation loss:		2.554706E-02
Epoch took 0.723s

Epoch 116 of 300
  training loss:		2.661957E-02
  validation loss:		2.572355E-02
Epoch took 0.723s

Epoch 117 of 300
  training loss:		2.688338E-02
  validation loss:		2.602555E-02
Epoch took 0.722s

Epoch 118 of 300
  training loss:		2.705546E-02
  validation loss:		2.572948E-02
Epoch took 0.725s

Epoch 119 of 300
  training loss:		2.674586E-02
  validation loss:		2.575901E-02
Epoch took 0.723s

Epoch 120 of 300
  training loss:		2.669214E-02
  validation loss:		2.568710E-02
Epoch took 0.724s

Epoch 121 of 300
  training loss:		2.684903E-02
  validation loss:		2.581987E-02
Epoch took 0.723s

Epoch 122 of 300
  training loss:		2.672924E-02
  validation loss:		2.607328E-02
Epoch took 0.723s

Epoch 123 of 300
  training loss:		2.674165E-02
  validation loss:		2.582645E-02
Epoch took 0.723s

Epoch 124 of 300
  training loss:		2.678334E-02
  validation loss:		2.556555E-02
Epoch took 0.722s

Epoch 125 of 300
  training loss:		2.665906E-02
  validation loss:		2.551661E-02
Epoch took 0.723s

Epoch 126 of 300
  training loss:		2.663242E-02
  validation loss:		2.570054E-02
Epoch took 0.723s

Epoch 127 of 300
  training loss:		2.670152E-02
  validation loss:		2.563784E-02
Epoch took 0.725s

Epoch 128 of 300
  training loss:		2.657359E-02
  validation loss:		2.558678E-02
Epoch took 0.724s

Epoch 129 of 300
  training loss:		2.658655E-02
  validation loss:		2.557300E-02
Epoch took 0.724s

Epoch 130 of 300
  training loss:		2.686435E-02
  validation loss:		2.557509E-02
Epoch took 0.723s

Epoch 131 of 300
  training loss:		2.672046E-02
  validation loss:		2.587466E-02
Epoch took 0.723s

Epoch 132 of 300
  training loss:		2.671379E-02
  validation loss:		2.552277E-02
Epoch took 0.723s

Epoch 133 of 300
  training loss:		2.690659E-02
  validation loss:		2.572962E-02
Epoch took 0.723s

Epoch 134 of 300
  training loss:		2.655757E-02
  validation loss:		2.578075E-02
Epoch took 0.723s

Epoch 135 of 300
  training loss:		2.657286E-02
  validation loss:		2.570222E-02
Epoch took 0.724s

Epoch 136 of 300
  training loss:		2.654136E-02
  validation loss:		2.532817E-02
Epoch took 0.723s

Epoch 137 of 300
  training loss:		2.665489E-02
  validation loss:		2.553995E-02
Epoch took 0.723s

Epoch 138 of 300
  training loss:		2.664771E-02
  validation loss:		2.595489E-02
Epoch took 0.723s

Epoch 139 of 300
  training loss:		2.662596E-02
  validation loss:		2.593230E-02
Epoch took 0.722s

Epoch 140 of 300
  training loss:		2.680113E-02
  validation loss:		2.590595E-02
Epoch took 0.722s

Epoch 141 of 300
  training loss:		2.661204E-02
  validation loss:		2.546368E-02
Epoch took 0.722s

Epoch 142 of 300
  training loss:		2.654182E-02
  validation loss:		2.579123E-02
Epoch took 0.723s

Epoch 143 of 300
  training loss:		2.661594E-02
  validation loss:		2.615542E-02
Epoch took 0.723s

Epoch 144 of 300
  training loss:		2.651659E-02
  validation loss:		2.565124E-02
Epoch took 0.723s

Epoch 145 of 300
  training loss:		2.655565E-02
  validation loss:		2.578370E-02
Epoch took 0.722s

Epoch 146 of 300
  training loss:		2.665405E-02
  validation loss:		2.616496E-02
Epoch took 0.723s

Epoch 147 of 300
  training loss:		2.659428E-02
  validation loss:		2.573274E-02
Epoch took 0.722s

Epoch 148 of 300
  training loss:		2.667727E-02
  validation loss:		2.605122E-02
Epoch took 0.722s

Epoch 149 of 300
  training loss:		2.657831E-02
  validation loss:		2.600519E-02
Epoch took 0.723s

Epoch 150 of 300
  training loss:		2.663464E-02
  validation loss:		2.551682E-02
Epoch took 0.723s

Epoch 151 of 300
  training loss:		2.661020E-02
  validation loss:		2.585328E-02
Epoch took 0.723s

Epoch 152 of 300
  training loss:		2.658773E-02
  validation loss:		2.594463E-02
Epoch took 0.723s

Epoch 153 of 300
  training loss:		2.654663E-02
  validation loss:		2.573241E-02
Epoch took 0.723s

Epoch 154 of 300
  training loss:		2.658938E-02
  validation loss:		2.572751E-02
Epoch took 0.723s

Epoch 155 of 300
  training loss:		2.650388E-02
  validation loss:		2.546483E-02
Epoch took 0.723s

Epoch 156 of 300
  training loss:		2.656856E-02
  validation loss:		2.556904E-02
Epoch took 0.722s

Epoch 157 of 300
  training loss:		2.670553E-02
  validation loss:		2.566174E-02
Epoch took 0.722s

Epoch 158 of 300
  training loss:		2.649247E-02
  validation loss:		2.548649E-02
Epoch took 0.723s

Epoch 159 of 300
  training loss:		2.701478E-02
  validation loss:		2.727158E-02
Epoch took 0.723s

Epoch 160 of 300
  training loss:		2.687579E-02
  validation loss:		2.582909E-02
Epoch took 0.723s

Early stopping, val-loss increased over the last 20 epochs from 0.0257073144273 to 0.0258428408557
Saving model from epoch 140
Training MSE: 2.56157e-14
Validation MSE: 2.49346e-14
Training R2: 0.728570476358
Validation R2: 0.734715083182
