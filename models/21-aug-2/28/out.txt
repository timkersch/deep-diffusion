Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		3.485549E-01
  validation loss:		7.090088E-02
Epoch took 0.769s

Epoch 2 of 300
  training loss:		6.075555E-02
  validation loss:		5.143397E-02
Epoch took 0.724s

Epoch 3 of 300
  training loss:		5.133948E-02
  validation loss:		4.687169E-02
Epoch took 0.723s

Epoch 4 of 300
  training loss:		4.666507E-02
  validation loss:		3.871211E-02
Epoch took 0.723s

Epoch 5 of 300
  training loss:		3.994521E-02
  validation loss:		4.138463E-02
Epoch took 0.724s

Epoch 6 of 300
  training loss:		4.224942E-02
  validation loss:		4.174174E-02
Epoch took 0.723s

Epoch 7 of 300
  training loss:		3.618089E-02
  validation loss:		3.219299E-02
Epoch took 0.723s

Epoch 8 of 300
  training loss:		3.439646E-02
  validation loss:		3.036925E-02
Epoch took 0.724s

Epoch 9 of 300
  training loss:		3.459529E-02
  validation loss:		2.953441E-02
Epoch took 0.724s

Epoch 10 of 300
  training loss:		3.070001E-02
  validation loss:		2.955433E-02
Epoch took 0.724s

Epoch 11 of 300
  training loss:		3.035694E-02
  validation loss:		3.093922E-02
Epoch took 0.724s

Epoch 12 of 300
  training loss:		3.068870E-02
  validation loss:		3.068058E-02
Epoch took 0.725s

Epoch 13 of 300
  training loss:		3.007283E-02
  validation loss:		3.089962E-02
Epoch took 0.725s

Epoch 14 of 300
  training loss:		2.881372E-02
  validation loss:		2.802634E-02
Epoch took 0.725s

Epoch 15 of 300
  training loss:		2.938757E-02
  validation loss:		2.780087E-02
Epoch took 0.726s

Epoch 16 of 300
  training loss:		2.875083E-02
  validation loss:		2.750472E-02
Epoch took 0.724s

Epoch 17 of 300
  training loss:		2.805441E-02
  validation loss:		2.626466E-02
Epoch took 0.723s

Epoch 18 of 300
  training loss:		2.828295E-02
  validation loss:		2.701364E-02
Epoch took 0.724s

Epoch 19 of 300
  training loss:		2.781883E-02
  validation loss:		2.606080E-02
Epoch took 0.724s

Epoch 20 of 300
  training loss:		2.797162E-02
  validation loss:		2.670854E-02
Epoch took 0.725s

Epoch 21 of 300
  training loss:		2.770795E-02
  validation loss:		2.688074E-02
Epoch took 0.724s

Epoch 22 of 300
  training loss:		2.806612E-02
  validation loss:		2.776930E-02
Epoch took 0.724s

Epoch 23 of 300
  training loss:		2.799873E-02
  validation loss:		2.629087E-02
Epoch took 0.723s

Epoch 24 of 300
  training loss:		2.799556E-02
  validation loss:		2.724590E-02
Epoch took 0.723s

Epoch 25 of 300
  training loss:		2.775763E-02
  validation loss:		2.640753E-02
Epoch took 0.724s

Epoch 26 of 300
  training loss:		2.748308E-02
  validation loss:		2.605444E-02
Epoch took 0.724s

Epoch 27 of 300
  training loss:		2.781151E-02
  validation loss:		2.646248E-02
Epoch took 0.724s

Epoch 28 of 300
  training loss:		2.741463E-02
  validation loss:		2.625942E-02
Epoch took 0.723s

Epoch 29 of 300
  training loss:		2.740290E-02
  validation loss:		2.783021E-02
Epoch took 0.724s

Epoch 30 of 300
  training loss:		2.736170E-02
  validation loss:		2.635290E-02
Epoch took 0.723s

Epoch 31 of 300
  training loss:		2.714350E-02
  validation loss:		2.602524E-02
Epoch took 0.724s

Epoch 32 of 300
  training loss:		2.749438E-02
  validation loss:		2.584986E-02
Epoch took 0.724s

Epoch 33 of 300
  training loss:		2.726856E-02
  validation loss:		2.639509E-02
Epoch took 0.724s

Epoch 34 of 300
  training loss:		2.770505E-02
  validation loss:		2.682956E-02
Epoch took 0.723s

Epoch 35 of 300
  training loss:		2.741196E-02
  validation loss:		2.651338E-02
Epoch took 0.724s

Epoch 36 of 300
  training loss:		2.708693E-02
  validation loss:		2.614611E-02
Epoch took 0.724s

Epoch 37 of 300
  training loss:		2.718857E-02
  validation loss:		2.589872E-02
Epoch took 0.724s

Epoch 38 of 300
  training loss:		2.717523E-02
  validation loss:		2.639753E-02
Epoch took 0.723s

Epoch 39 of 300
  training loss:		2.701570E-02
  validation loss:		2.759237E-02
Epoch took 0.724s

Epoch 40 of 300
  training loss:		2.761231E-02
  validation loss:		2.698661E-02
Epoch took 0.724s

Epoch 41 of 300
  training loss:		2.728700E-02
  validation loss:		2.570093E-02
Epoch took 0.723s

Epoch 42 of 300
  training loss:		2.692872E-02
  validation loss:		2.579565E-02
Epoch took 0.724s

Epoch 43 of 300
  training loss:		2.697532E-02
  validation loss:		2.613211E-02
Epoch took 0.724s

Epoch 44 of 300
  training loss:		2.727208E-02
  validation loss:		2.580631E-02
Epoch took 0.726s

Epoch 45 of 300
  training loss:		2.695923E-02
  validation loss:		2.611308E-02
Epoch took 0.726s

Epoch 46 of 300
  training loss:		2.753196E-02
  validation loss:		2.633009E-02
Epoch took 0.724s

Epoch 47 of 300
  training loss:		2.715149E-02
  validation loss:		2.611695E-02
Epoch took 0.725s

Epoch 48 of 300
  training loss:		2.702725E-02
  validation loss:		2.580652E-02
Epoch took 0.724s

Epoch 49 of 300
  training loss:		2.681491E-02
  validation loss:		2.583498E-02
Epoch took 0.724s

Epoch 50 of 300
  training loss:		2.701708E-02
  validation loss:		2.575159E-02
Epoch took 0.724s

Epoch 51 of 300
  training loss:		2.720284E-02
  validation loss:		2.642483E-02
Epoch took 0.724s

Epoch 52 of 300
  training loss:		2.715029E-02
  validation loss:		2.628119E-02
Epoch took 0.724s

Epoch 53 of 300
  training loss:		2.701848E-02
  validation loss:		2.601484E-02
Epoch took 0.724s

Epoch 54 of 300
  training loss:		2.697855E-02
  validation loss:		2.646073E-02
Epoch took 0.724s

Epoch 55 of 300
  training loss:		2.689084E-02
  validation loss:		2.550891E-02
Epoch took 0.724s

Epoch 56 of 300
  training loss:		2.682854E-02
  validation loss:		2.592873E-02
Epoch took 0.724s

Epoch 57 of 300
  training loss:		2.691626E-02
  validation loss:		2.593771E-02
Epoch took 0.724s

Epoch 58 of 300
  training loss:		2.700288E-02
  validation loss:		2.585563E-02
Epoch took 0.724s

Epoch 59 of 300
  training loss:		2.684901E-02
  validation loss:		2.594564E-02
Epoch took 0.724s

Epoch 60 of 300
  training loss:		2.689716E-02
  validation loss:		2.625704E-02
Epoch took 0.723s

Epoch 61 of 300
  training loss:		2.689908E-02
  validation loss:		2.585504E-02
Epoch took 0.724s

Epoch 62 of 300
  training loss:		2.683248E-02
  validation loss:		2.626985E-02
Epoch took 0.725s

Epoch 63 of 300
  training loss:		2.713511E-02
  validation loss:		2.578339E-02
Epoch took 0.724s

Epoch 64 of 300
  training loss:		2.678410E-02
  validation loss:		2.581349E-02
Epoch took 0.724s

Epoch 65 of 300
  training loss:		2.684732E-02
  validation loss:		2.592380E-02
Epoch took 0.724s

Epoch 66 of 300
  training loss:		2.677476E-02
  validation loss:		2.557488E-02
Epoch took 0.724s

Epoch 67 of 300
  training loss:		2.693526E-02
  validation loss:		2.580848E-02
Epoch took 0.723s

Epoch 68 of 300
  training loss:		2.695353E-02
  validation loss:		2.587522E-02
Epoch took 0.724s

Epoch 69 of 300
  training loss:		2.704291E-02
  validation loss:		2.613316E-02
Epoch took 0.724s

Epoch 70 of 300
  training loss:		2.754223E-02
  validation loss:		3.186154E-02
Epoch took 0.723s

Epoch 71 of 300
  training loss:		2.954040E-02
  validation loss:		2.703853E-02
Epoch took 0.724s

Epoch 72 of 300
  training loss:		2.747785E-02
  validation loss:		2.754100E-02
Epoch took 0.725s

Epoch 73 of 300
  training loss:		2.738525E-02
  validation loss:		2.607142E-02
Epoch took 0.724s

Epoch 74 of 300
  training loss:		2.706035E-02
  validation loss:		2.586950E-02
Epoch took 0.723s

Epoch 75 of 300
  training loss:		2.699388E-02
  validation loss:		2.600743E-02
Epoch took 0.725s

Epoch 76 of 300
  training loss:		2.699769E-02
  validation loss:		2.621515E-02
Epoch took 0.724s

Epoch 77 of 300
  training loss:		2.693274E-02
  validation loss:		2.600868E-02
Epoch took 0.724s

Epoch 78 of 300
  training loss:		2.679806E-02
  validation loss:		2.606266E-02
Epoch took 0.724s

Epoch 79 of 300
  training loss:		2.673982E-02
  validation loss:		2.590609E-02
Epoch took 0.724s

Epoch 80 of 300
  training loss:		2.672083E-02
  validation loss:		2.594064E-02
Epoch took 0.724s

Early stopping, val-loss increased over the last 20 epochs from 0.0260001729553 to 0.0263779981476
Saving model from epoch 60
Training MSE: 2.60293e-14
Validation MSE: 2.52212e-14
Training R2: 0.724187311745
Validation R2: 0.731666759737
