Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		1.020453E-01
  validation loss:		6.013794E-02
Epoch took 1.439s

Epoch 2 of 300
  training loss:		5.565680E-02
  validation loss:		4.976754E-02
Epoch took 1.395s

Epoch 3 of 300
  training loss:		4.711026E-02
  validation loss:		4.172834E-02
Epoch took 1.394s

Epoch 4 of 300
  training loss:		4.129738E-02
  validation loss:		3.951856E-02
Epoch took 1.393s

Epoch 5 of 300
  training loss:		3.779810E-02
  validation loss:		3.471994E-02
Epoch took 1.393s

Epoch 6 of 300
  training loss:		3.485687E-02
  validation loss:		3.552444E-02
Epoch took 1.393s

Epoch 7 of 300
  training loss:		3.368431E-02
  validation loss:		3.194281E-02
Epoch took 1.391s

Epoch 8 of 300
  training loss:		3.211290E-02
  validation loss:		2.942620E-02
Epoch took 1.395s

Epoch 9 of 300
  training loss:		3.161469E-02
  validation loss:		2.896338E-02
Epoch took 1.405s

Epoch 10 of 300
  training loss:		3.078767E-02
  validation loss:		3.034368E-02
Epoch took 1.404s

Epoch 11 of 300
  training loss:		3.057827E-02
  validation loss:		3.000112E-02
Epoch took 1.403s

Epoch 12 of 300
  training loss:		2.991591E-02
  validation loss:		2.688002E-02
Epoch took 1.404s

Epoch 13 of 300
  training loss:		2.975627E-02
  validation loss:		2.827076E-02
Epoch took 1.404s

Epoch 14 of 300
  training loss:		2.933496E-02
  validation loss:		2.809463E-02
Epoch took 1.404s

Epoch 15 of 300
  training loss:		2.950188E-02
  validation loss:		2.805166E-02
Epoch took 1.404s

Epoch 16 of 300
  training loss:		2.951935E-02
  validation loss:		2.713756E-02
Epoch took 1.404s

Epoch 17 of 300
  training loss:		2.910367E-02
  validation loss:		2.627356E-02
Epoch took 1.405s

Epoch 18 of 300
  training loss:		2.864678E-02
  validation loss:		2.651591E-02
Epoch took 1.405s

Epoch 19 of 300
  training loss:		2.925502E-02
  validation loss:		2.776468E-02
Epoch took 1.404s

Epoch 20 of 300
  training loss:		2.866650E-02
  validation loss:		2.666870E-02
Epoch took 1.404s

Epoch 21 of 300
  training loss:		2.872524E-02
  validation loss:		2.787287E-02
Epoch took 1.404s

Epoch 22 of 300
  training loss:		2.855886E-02
  validation loss:		2.958223E-02
Epoch took 1.405s

Epoch 23 of 300
  training loss:		2.859308E-02
  validation loss:		2.760237E-02
Epoch took 1.405s

Epoch 24 of 300
  training loss:		2.862763E-02
  validation loss:		2.845184E-02
Epoch took 1.404s

Epoch 25 of 300
  training loss:		2.862081E-02
  validation loss:		2.850459E-02
Epoch took 1.404s

Epoch 26 of 300
  training loss:		2.857480E-02
  validation loss:		2.724288E-02
Epoch took 1.405s

Epoch 27 of 300
  training loss:		2.822209E-02
  validation loss:		2.585336E-02
Epoch took 1.405s

Epoch 28 of 300
  training loss:		2.810290E-02
  validation loss:		2.711064E-02
Epoch took 1.404s

Epoch 29 of 300
  training loss:		2.827507E-02
  validation loss:		2.796589E-02
Epoch took 1.404s

Epoch 30 of 300
  training loss:		2.867849E-02
  validation loss:		2.687953E-02
Epoch took 1.406s

Epoch 31 of 300
  training loss:		2.809580E-02
  validation loss:		2.625350E-02
Epoch took 1.405s

Epoch 32 of 300
  training loss:		2.820707E-02
  validation loss:		2.652948E-02
Epoch took 1.405s

Epoch 33 of 300
  training loss:		2.844189E-02
  validation loss:		2.963159E-02
Epoch took 1.404s

Epoch 34 of 300
  training loss:		2.796457E-02
  validation loss:		2.575757E-02
Epoch took 1.404s

Epoch 35 of 300
  training loss:		2.797320E-02
  validation loss:		2.733852E-02
Epoch took 1.404s

Epoch 36 of 300
  training loss:		2.794019E-02
  validation loss:		2.585725E-02
Epoch took 1.404s

Epoch 37 of 300
  training loss:		2.777382E-02
  validation loss:		2.770235E-02
Epoch took 1.404s

Epoch 38 of 300
  training loss:		2.820496E-02
  validation loss:		2.637482E-02
Epoch took 1.404s

Epoch 39 of 300
  training loss:		2.792898E-02
  validation loss:		2.692865E-02
Epoch took 1.404s

Epoch 40 of 300
  training loss:		2.794517E-02
  validation loss:		2.672237E-02
Epoch took 1.405s

Epoch 41 of 300
  training loss:		2.783362E-02
  validation loss:		2.671362E-02
Epoch took 1.404s

Epoch 42 of 300
  training loss:		2.788121E-02
  validation loss:		2.956021E-02
Epoch took 1.405s

Epoch 43 of 300
  training loss:		2.764478E-02
  validation loss:		2.645986E-02
Epoch took 1.404s

Epoch 44 of 300
  training loss:		2.793512E-02
  validation loss:		2.750883E-02
Epoch took 1.404s

Epoch 45 of 300
  training loss:		2.780724E-02
  validation loss:		2.745717E-02
Epoch took 1.404s

Epoch 46 of 300
  training loss:		2.756239E-02
  validation loss:		2.586292E-02
Epoch took 1.404s

Epoch 47 of 300
  training loss:		2.774109E-02
  validation loss:		2.587183E-02
Epoch took 1.404s

Epoch 48 of 300
  training loss:		2.772183E-02
  validation loss:		2.589392E-02
Epoch took 1.405s

Epoch 49 of 300
  training loss:		2.757697E-02
  validation loss:		2.603815E-02
Epoch took 1.404s

Epoch 50 of 300
  training loss:		2.767091E-02
  validation loss:		2.653547E-02
Epoch took 1.404s

Epoch 51 of 300
  training loss:		2.775197E-02
  validation loss:		2.891198E-02
Epoch took 1.404s

Epoch 52 of 300
  training loss:		2.752140E-02
  validation loss:		2.645392E-02
Epoch took 1.404s

Epoch 53 of 300
  training loss:		2.740482E-02
  validation loss:		2.658170E-02
Epoch took 1.404s

Epoch 54 of 300
  training loss:		2.745028E-02
  validation loss:		2.705896E-02
Epoch took 1.404s

Epoch 55 of 300
  training loss:		2.743926E-02
  validation loss:		2.676768E-02
Epoch took 1.403s

Epoch 56 of 300
  training loss:		2.750291E-02
  validation loss:		2.679648E-02
Epoch took 1.404s

Epoch 57 of 300
  training loss:		2.727371E-02
  validation loss:		2.606557E-02
Epoch took 1.404s

Epoch 58 of 300
  training loss:		2.728967E-02
  validation loss:		2.698531E-02
Epoch took 1.404s

Epoch 59 of 300
  training loss:		2.749020E-02
  validation loss:		2.621818E-02
Epoch took 1.406s

Epoch 60 of 300
  training loss:		2.730324E-02
  validation loss:		2.707435E-02
Epoch took 1.404s

Epoch 61 of 300
  training loss:		2.720675E-02
  validation loss:		2.636290E-02
Epoch took 1.404s

Epoch 62 of 300
  training loss:		2.732981E-02
  validation loss:		2.593921E-02
Epoch took 1.405s

Epoch 63 of 300
  training loss:		2.748369E-02
  validation loss:		2.659475E-02
Epoch took 1.404s

Epoch 64 of 300
  training loss:		2.725778E-02
  validation loss:		2.566401E-02
Epoch took 1.404s

Epoch 65 of 300
  training loss:		2.717324E-02
  validation loss:		2.695995E-02
Epoch took 1.404s

Epoch 66 of 300
  training loss:		2.723272E-02
  validation loss:		2.750872E-02
Epoch took 1.404s

Epoch 67 of 300
  training loss:		2.731146E-02
  validation loss:		2.711574E-02
Epoch took 1.403s

Epoch 68 of 300
  training loss:		2.729212E-02
  validation loss:		2.636377E-02
Epoch took 1.404s

Epoch 69 of 300
  training loss:		2.710103E-02
  validation loss:		2.587815E-02
Epoch took 1.404s

Epoch 70 of 300
  training loss:		2.715677E-02
  validation loss:		2.702099E-02
Epoch took 1.404s

Epoch 71 of 300
  training loss:		2.718867E-02
  validation loss:		2.576249E-02
Epoch took 1.404s

Epoch 72 of 300
  training loss:		2.717257E-02
  validation loss:		2.677811E-02
Epoch took 1.404s

Epoch 73 of 300
  training loss:		2.706020E-02
  validation loss:		2.616232E-02
Epoch took 1.406s

Epoch 74 of 300
  training loss:		2.711823E-02
  validation loss:		2.590438E-02
Epoch took 1.405s

Epoch 75 of 300
  training loss:		2.700429E-02
  validation loss:		2.643862E-02
Epoch took 1.404s

Epoch 76 of 300
  training loss:		2.704546E-02
  validation loss:		2.615295E-02
Epoch took 1.403s

Epoch 77 of 300
  training loss:		2.710449E-02
  validation loss:		2.748868E-02
Epoch took 1.404s

Epoch 78 of 300
  training loss:		2.698514E-02
  validation loss:		2.577216E-02
Epoch took 1.404s

Epoch 79 of 300
  training loss:		2.701840E-02
  validation loss:		2.567074E-02
Epoch took 1.404s

Epoch 80 of 300
  training loss:		2.694305E-02
  validation loss:		2.578125E-02
Epoch took 1.404s

Epoch 81 of 300
  training loss:		2.693694E-02
  validation loss:		2.629938E-02
Epoch took 1.403s

Epoch 82 of 300
  training loss:		2.702886E-02
  validation loss:		2.714515E-02
Epoch took 1.404s

Epoch 83 of 300
  training loss:		2.707850E-02
  validation loss:		2.679287E-02
Epoch took 1.403s

Epoch 84 of 300
  training loss:		2.705765E-02
  validation loss:		2.595957E-02
Epoch took 1.404s

Epoch 85 of 300
  training loss:		2.688752E-02
  validation loss:		2.600354E-02
Epoch took 1.403s

Epoch 86 of 300
  training loss:		2.705010E-02
  validation loss:		2.567614E-02
Epoch took 1.405s

Epoch 87 of 300
  training loss:		2.693905E-02
  validation loss:		2.588131E-02
Epoch took 1.404s

Epoch 88 of 300
  training loss:		2.685346E-02
  validation loss:		2.559782E-02
Epoch took 1.404s

Epoch 89 of 300
  training loss:		2.695041E-02
  validation loss:		2.579143E-02
Epoch took 1.404s

Epoch 90 of 300
  training loss:		2.691848E-02
  validation loss:		2.573640E-02
Epoch took 1.403s

Epoch 91 of 300
  training loss:		2.690609E-02
  validation loss:		2.577960E-02
Epoch took 1.403s

Epoch 92 of 300
  training loss:		2.688293E-02
  validation loss:		2.579064E-02
Epoch took 1.404s

Epoch 93 of 300
  training loss:		2.690177E-02
  validation loss:		2.583773E-02
Epoch took 1.404s

Epoch 94 of 300
  training loss:		2.683359E-02
  validation loss:		2.566707E-02
Epoch took 1.404s

Epoch 95 of 300
  training loss:		2.688364E-02
  validation loss:		2.671532E-02
Epoch took 1.404s

Epoch 96 of 300
  training loss:		2.689047E-02
  validation loss:		2.610551E-02
Epoch took 1.403s

Epoch 97 of 300
  training loss:		2.684003E-02
  validation loss:		2.571378E-02
Epoch took 1.404s

Epoch 98 of 300
  training loss:		2.690154E-02
  validation loss:		2.592658E-02
Epoch took 1.404s

Epoch 99 of 300
  training loss:		2.684294E-02
  validation loss:		2.566754E-02
Epoch took 1.403s

Epoch 100 of 300
  training loss:		2.686821E-02
  validation loss:		2.583403E-02
Epoch took 1.403s

Epoch 101 of 300
  training loss:		2.686496E-02
  validation loss:		2.589747E-02
Epoch took 1.404s

Epoch 102 of 300
  training loss:		2.677091E-02
  validation loss:		2.605054E-02
Epoch took 1.404s

Epoch 103 of 300
  training loss:		2.685220E-02
  validation loss:		2.583820E-02
Epoch took 1.403s

Epoch 104 of 300
  training loss:		2.683867E-02
  validation loss:		2.587339E-02
Epoch took 1.403s

Epoch 105 of 300
  training loss:		2.674186E-02
  validation loss:		2.578660E-02
Epoch took 1.404s

Epoch 106 of 300
  training loss:		2.674397E-02
  validation loss:		2.594663E-02
Epoch took 1.404s

Epoch 107 of 300
  training loss:		2.670549E-02
  validation loss:		2.598392E-02
Epoch took 1.403s

Epoch 108 of 300
  training loss:		2.670797E-02
  validation loss:		2.558372E-02
Epoch took 1.404s

Epoch 109 of 300
  training loss:		2.682904E-02
  validation loss:		2.576533E-02
Epoch took 1.404s

Epoch 110 of 300
  training loss:		2.679998E-02
  validation loss:		2.675265E-02
Epoch took 1.404s

Epoch 111 of 300
  training loss:		2.666177E-02
  validation loss:		2.555571E-02
Epoch took 1.403s

Epoch 112 of 300
  training loss:		2.673851E-02
  validation loss:		2.560246E-02
Epoch took 1.404s

Epoch 113 of 300
  training loss:		2.677340E-02
  validation loss:		2.648282E-02
Epoch took 1.403s

Epoch 114 of 300
  training loss:		2.667481E-02
  validation loss:		2.565093E-02
Epoch took 1.404s

Epoch 115 of 300
  training loss:		2.674948E-02
  validation loss:		2.574032E-02
Epoch took 1.405s

Epoch 116 of 300
  training loss:		2.675511E-02
  validation loss:		2.576363E-02
Epoch took 1.406s

Epoch 117 of 300
  training loss:		2.663524E-02
  validation loss:		2.568051E-02
Epoch took 1.404s

Epoch 118 of 300
  training loss:		2.677158E-02
  validation loss:		2.596177E-02
Epoch took 1.404s

Epoch 119 of 300
  training loss:		2.664963E-02
  validation loss:		2.561878E-02
Epoch took 1.405s

Epoch 120 of 300
  training loss:		2.671067E-02
  validation loss:		2.560344E-02
Epoch took 1.404s

Epoch 121 of 300
  training loss:		2.672518E-02
  validation loss:		2.599247E-02
Epoch took 1.404s

Epoch 122 of 300
  training loss:		2.659331E-02
  validation loss:		2.566778E-02
Epoch took 1.403s

Epoch 123 of 300
  training loss:		2.662356E-02
  validation loss:		2.555042E-02
Epoch took 1.405s

Epoch 124 of 300
  training loss:		2.669739E-02
  validation loss:		2.547245E-02
Epoch took 1.404s

Epoch 125 of 300
  training loss:		2.664528E-02
  validation loss:		2.542623E-02
Epoch took 1.404s

Epoch 126 of 300
  training loss:		2.668482E-02
  validation loss:		2.596112E-02
Epoch took 1.404s

Epoch 127 of 300
  training loss:		2.665854E-02
  validation loss:		2.547526E-02
Epoch took 1.403s

Epoch 128 of 300
  training loss:		2.663243E-02
  validation loss:		2.544362E-02
Epoch took 1.404s

Epoch 129 of 300
  training loss:		2.663941E-02
  validation loss:		2.556019E-02
Epoch took 1.404s

Epoch 130 of 300
  training loss:		2.662206E-02
  validation loss:		2.550909E-02
Epoch took 1.404s

Epoch 131 of 300
  training loss:		2.665659E-02
  validation loss:		2.566038E-02
Epoch took 1.404s

Epoch 132 of 300
  training loss:		2.658777E-02
  validation loss:		2.565309E-02
Epoch took 1.404s

Epoch 133 of 300
  training loss:		2.665391E-02
  validation loss:		2.554506E-02
Epoch took 1.403s

Epoch 134 of 300
  training loss:		2.663064E-02
  validation loss:		2.664575E-02
Epoch took 1.403s

Epoch 135 of 300
  training loss:		2.660629E-02
  validation loss:		2.555939E-02
Epoch took 1.404s

Epoch 136 of 300
  training loss:		2.659266E-02
  validation loss:		2.562258E-02
Epoch took 1.404s

Epoch 137 of 300
  training loss:		2.658981E-02
  validation loss:		2.561002E-02
Epoch took 1.404s

Epoch 138 of 300
  training loss:		2.661201E-02
  validation loss:		2.550878E-02
Epoch took 1.403s

Epoch 139 of 300
  training loss:		2.656887E-02
  validation loss:		2.573469E-02
Epoch took 1.404s

Epoch 140 of 300
  training loss:		2.663630E-02
  validation loss:		2.538148E-02
Epoch took 1.403s

Epoch 141 of 300
  training loss:		2.657988E-02
  validation loss:		2.580186E-02
Epoch took 1.403s

Epoch 142 of 300
  training loss:		2.654600E-02
  validation loss:		2.542813E-02
Epoch took 1.405s

Epoch 143 of 300
  training loss:		2.654465E-02
  validation loss:		2.558225E-02
Epoch took 1.404s

Epoch 144 of 300
  training loss:		2.653617E-02
  validation loss:		2.549422E-02
Epoch took 1.404s

Epoch 145 of 300
  training loss:		2.658384E-02
  validation loss:		2.558585E-02
Epoch took 1.404s

Epoch 146 of 300
  training loss:		2.656711E-02
  validation loss:		2.547148E-02
Epoch took 1.404s

Epoch 147 of 300
  training loss:		2.655342E-02
  validation loss:		2.548843E-02
Epoch took 1.405s

Epoch 148 of 300
  training loss:		2.651275E-02
  validation loss:		2.553772E-02
Epoch took 1.404s

Epoch 149 of 300
  training loss:		2.652006E-02
  validation loss:		2.550853E-02
Epoch took 1.404s

Epoch 150 of 300
  training loss:		2.651190E-02
  validation loss:		2.550450E-02
Epoch took 1.404s

Epoch 151 of 300
  training loss:		2.648539E-02
  validation loss:		2.554389E-02
Epoch took 1.403s

Epoch 152 of 300
  training loss:		2.656778E-02
  validation loss:		2.561354E-02
Epoch took 1.404s

Epoch 153 of 300
  training loss:		2.646508E-02
  validation loss:		2.541265E-02
Epoch took 1.404s

Epoch 154 of 300
  training loss:		2.655262E-02
  validation loss:		2.565030E-02
Epoch took 1.403s

Epoch 155 of 300
  training loss:		2.650653E-02
  validation loss:		2.540832E-02
Epoch took 1.403s

Epoch 156 of 300
  training loss:		2.649817E-02
  validation loss:		2.581602E-02
Epoch took 1.403s

Epoch 157 of 300
  training loss:		2.656109E-02
  validation loss:		2.553874E-02
Epoch took 1.403s

Epoch 158 of 300
  training loss:		2.647397E-02
  validation loss:		2.565733E-02
Epoch took 1.403s

Epoch 159 of 300
  training loss:		2.648185E-02
  validation loss:		2.556640E-02
Epoch took 1.406s

Epoch 160 of 300
  training loss:		2.654917E-02
  validation loss:		2.543015E-02
Epoch took 1.404s

Epoch 161 of 300
  training loss:		2.656145E-02
  validation loss:		2.554556E-02
Epoch took 1.405s

Epoch 162 of 300
  training loss:		2.648220E-02
  validation loss:		2.565499E-02
Epoch took 1.403s

Epoch 163 of 300
  training loss:		2.651620E-02
  validation loss:		2.552887E-02
Epoch took 1.404s

Epoch 164 of 300
  training loss:		2.648254E-02
  validation loss:		2.564252E-02
Epoch took 1.403s

Epoch 165 of 300
  training loss:		2.645705E-02
  validation loss:		2.561970E-02
Epoch took 1.404s

Epoch 166 of 300
  training loss:		2.647419E-02
  validation loss:		2.567278E-02
Epoch took 1.404s

Epoch 167 of 300
  training loss:		2.642871E-02
  validation loss:		2.611521E-02
Epoch took 1.404s

Epoch 168 of 300
  training loss:		2.646178E-02
  validation loss:		2.584674E-02
Epoch took 1.404s

Epoch 169 of 300
  training loss:		2.653410E-02
  validation loss:		2.565545E-02
Epoch took 1.403s

Epoch 170 of 300
  training loss:		2.643876E-02
  validation loss:		2.540146E-02
Epoch took 1.404s

Epoch 171 of 300
  training loss:		2.647463E-02
  validation loss:		2.565833E-02
Epoch took 1.404s

Epoch 172 of 300
  training loss:		2.644326E-02
  validation loss:		2.538246E-02
Epoch took 1.403s

Epoch 173 of 300
  training loss:		2.650462E-02
  validation loss:		2.558760E-02
Epoch took 1.404s

Epoch 174 of 300
  training loss:		2.647315E-02
  validation loss:		2.538522E-02
Epoch took 1.404s

Epoch 175 of 300
  training loss:		2.645365E-02
  validation loss:		2.545542E-02
Epoch took 1.404s

Epoch 176 of 300
  training loss:		2.645404E-02
  validation loss:		2.552202E-02
Epoch took 1.404s

Epoch 177 of 300
  training loss:		2.654089E-02
  validation loss:		2.559645E-02
Epoch took 1.403s

Epoch 178 of 300
  training loss:		2.644608E-02
  validation loss:		2.575936E-02
Epoch took 1.403s

Epoch 179 of 300
  training loss:		2.640907E-02
  validation loss:		2.536472E-02
Epoch took 1.403s

Epoch 180 of 300
  training loss:		2.646908E-02
  validation loss:		2.545292E-02
Epoch took 1.404s

Early stopping, val-loss increased over the last 20 epochs from 0.0255520159972 to 0.0255923903072
Saving model from epoch 160
Training MSE: 2.53521e-14
Validation MSE: 2.43924e-14
Training R2: 0.731362940525
Validation R2: 0.740483706041
