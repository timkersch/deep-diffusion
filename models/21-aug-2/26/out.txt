Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		2.044049E-01
  validation loss:		8.428957E-02
Epoch took 0.776s

Epoch 2 of 300
  training loss:		7.594329E-02
  validation loss:		6.800799E-02
Epoch took 0.723s

Epoch 3 of 300
  training loss:		6.449230E-02
  validation loss:		5.877386E-02
Epoch took 0.724s

Epoch 4 of 300
  training loss:		5.627259E-02
  validation loss:		5.212858E-02
Epoch took 0.723s

Epoch 5 of 300
  training loss:		5.183862E-02
  validation loss:		5.165968E-02
Epoch took 0.723s

Epoch 6 of 300
  training loss:		4.776545E-02
  validation loss:		4.540909E-02
Epoch took 0.724s

Epoch 7 of 300
  training loss:		4.421670E-02
  validation loss:		4.341617E-02
Epoch took 0.724s

Epoch 8 of 300
  training loss:		4.222243E-02
  validation loss:		4.003221E-02
Epoch took 0.724s

Epoch 9 of 300
  training loss:		3.927154E-02
  validation loss:		3.745802E-02
Epoch took 0.724s

Epoch 10 of 300
  training loss:		3.744319E-02
  validation loss:		3.847986E-02
Epoch took 0.724s

Epoch 11 of 300
  training loss:		3.540948E-02
  validation loss:		3.367118E-02
Epoch took 0.724s

Epoch 12 of 300
  training loss:		3.472637E-02
  validation loss:		3.205651E-02
Epoch took 0.724s

Epoch 13 of 300
  training loss:		3.471484E-02
  validation loss:		3.353486E-02
Epoch took 0.725s

Epoch 14 of 300
  training loss:		3.325447E-02
  validation loss:		3.260098E-02
Epoch took 0.725s

Epoch 15 of 300
  training loss:		3.222218E-02
  validation loss:		3.049274E-02
Epoch took 0.725s

Epoch 16 of 300
  training loss:		3.105612E-02
  validation loss:		2.914994E-02
Epoch took 0.725s

Epoch 17 of 300
  training loss:		3.069227E-02
  validation loss:		2.803947E-02
Epoch took 0.724s

Epoch 18 of 300
  training loss:		2.967125E-02
  validation loss:		2.979245E-02
Epoch took 0.723s

Epoch 19 of 300
  training loss:		2.990934E-02
  validation loss:		2.976146E-02
Epoch took 0.724s

Epoch 20 of 300
  training loss:		3.131633E-02
  validation loss:		3.131251E-02
Epoch took 0.724s

Epoch 21 of 300
  training loss:		2.915308E-02
  validation loss:		2.728687E-02
Epoch took 0.725s

Epoch 22 of 300
  training loss:		2.901930E-02
  validation loss:		2.809163E-02
Epoch took 0.724s

Epoch 23 of 300
  training loss:		2.931751E-02
  validation loss:		2.726018E-02
Epoch took 0.724s

Epoch 24 of 300
  training loss:		2.886222E-02
  validation loss:		2.799301E-02
Epoch took 0.724s

Epoch 25 of 300
  training loss:		2.843128E-02
  validation loss:		2.776706E-02
Epoch took 0.724s

Epoch 26 of 300
  training loss:		2.868277E-02
  validation loss:		2.784605E-02
Epoch took 0.724s

Epoch 27 of 300
  training loss:		2.863675E-02
  validation loss:		2.716220E-02
Epoch took 0.723s

Epoch 28 of 300
  training loss:		2.933843E-02
  validation loss:		2.709294E-02
Epoch took 0.724s

Epoch 29 of 300
  training loss:		2.857637E-02
  validation loss:		2.632342E-02
Epoch took 0.724s

Epoch 30 of 300
  training loss:		2.878487E-02
  validation loss:		2.667548E-02
Epoch took 0.724s

Epoch 31 of 300
  training loss:		2.788892E-02
  validation loss:		2.790118E-02
Epoch took 0.723s

Epoch 32 of 300
  training loss:		2.812258E-02
  validation loss:		2.611782E-02
Epoch took 0.724s

Epoch 33 of 300
  training loss:		2.764853E-02
  validation loss:		2.692822E-02
Epoch took 0.723s

Epoch 34 of 300
  training loss:		2.818239E-02
  validation loss:		2.614256E-02
Epoch took 0.724s

Epoch 35 of 300
  training loss:		2.803601E-02
  validation loss:		2.957374E-02
Epoch took 0.724s

Epoch 36 of 300
  training loss:		2.825998E-02
  validation loss:		3.002902E-02
Epoch took 0.723s

Epoch 37 of 300
  training loss:		2.831751E-02
  validation loss:		2.697812E-02
Epoch took 0.724s

Epoch 38 of 300
  training loss:		2.889447E-02
  validation loss:		2.686702E-02
Epoch took 0.724s

Epoch 39 of 300
  training loss:		2.762559E-02
  validation loss:		2.634646E-02
Epoch took 0.723s

Epoch 40 of 300
  training loss:		2.830841E-02
  validation loss:		2.625380E-02
Epoch took 0.724s

Epoch 41 of 300
  training loss:		2.782760E-02
  validation loss:		2.719816E-02
Epoch took 0.723s

Epoch 42 of 300
  training loss:		2.733536E-02
  validation loss:		2.633520E-02
Epoch took 0.723s

Epoch 43 of 300
  training loss:		2.772763E-02
  validation loss:		3.059389E-02
Epoch took 0.724s

Epoch 44 of 300
  training loss:		2.816382E-02
  validation loss:		2.605566E-02
Epoch took 0.724s

Epoch 45 of 300
  training loss:		2.809444E-02
  validation loss:		2.614892E-02
Epoch took 0.724s

Epoch 46 of 300
  training loss:		2.742908E-02
  validation loss:		2.643354E-02
Epoch took 0.723s

Epoch 47 of 300
  training loss:		2.733604E-02
  validation loss:		2.595904E-02
Epoch took 0.724s

Epoch 48 of 300
  training loss:		2.741464E-02
  validation loss:		2.574201E-02
Epoch took 0.724s

Epoch 49 of 300
  training loss:		2.810235E-02
  validation loss:		2.595857E-02
Epoch took 0.724s

Epoch 50 of 300
  training loss:		2.776771E-02
  validation loss:		2.629895E-02
Epoch took 0.724s

Epoch 51 of 300
  training loss:		2.788937E-02
  validation loss:		2.622836E-02
Epoch took 0.724s

Epoch 52 of 300
  training loss:		2.747662E-02
  validation loss:		2.685178E-02
Epoch took 0.723s

Epoch 53 of 300
  training loss:		2.761248E-02
  validation loss:		2.610442E-02
Epoch took 0.723s

Epoch 54 of 300
  training loss:		2.808872E-02
  validation loss:		2.639630E-02
Epoch took 0.724s

Epoch 55 of 300
  training loss:		2.753272E-02
  validation loss:		2.688895E-02
Epoch took 0.723s

Epoch 56 of 300
  training loss:		2.740177E-02
  validation loss:		2.699949E-02
Epoch took 0.723s

Epoch 57 of 300
  training loss:		2.724519E-02
  validation loss:		2.602075E-02
Epoch took 0.723s

Epoch 58 of 300
  training loss:		2.756615E-02
  validation loss:		2.696320E-02
Epoch took 0.723s

Epoch 59 of 300
  training loss:		2.766726E-02
  validation loss:		2.756739E-02
Epoch took 0.724s

Epoch 60 of 300
  training loss:		2.792253E-02
  validation loss:		2.651897E-02
Epoch took 0.723s

Epoch 61 of 300
  training loss:		2.752323E-02
  validation loss:		2.775594E-02
Epoch took 0.724s

Epoch 62 of 300
  training loss:		2.793506E-02
  validation loss:		2.592769E-02
Epoch took 0.723s

Epoch 63 of 300
  training loss:		2.743158E-02
  validation loss:		2.663051E-02
Epoch took 0.723s

Epoch 64 of 300
  training loss:		2.725565E-02
  validation loss:		2.578248E-02
Epoch took 0.724s

Epoch 65 of 300
  training loss:		2.735772E-02
  validation loss:		2.683326E-02
Epoch took 0.724s

Epoch 66 of 300
  training loss:		2.723069E-02
  validation loss:		2.672207E-02
Epoch took 0.723s

Epoch 67 of 300
  training loss:		2.793708E-02
  validation loss:		2.824485E-02
Epoch took 0.723s

Epoch 68 of 300
  training loss:		2.807632E-02
  validation loss:		2.612707E-02
Epoch took 0.724s

Epoch 69 of 300
  training loss:		2.725574E-02
  validation loss:		2.595212E-02
Epoch took 0.726s

Epoch 70 of 300
  training loss:		2.698464E-02
  validation loss:		2.592712E-02
Epoch took 0.724s

Epoch 71 of 300
  training loss:		2.751333E-02
  validation loss:		2.738622E-02
Epoch took 0.724s

Epoch 72 of 300
  training loss:		2.771211E-02
  validation loss:		2.612338E-02
Epoch took 0.725s

Epoch 73 of 300
  training loss:		2.743635E-02
  validation loss:		2.671876E-02
Epoch took 0.724s

Epoch 74 of 300
  training loss:		2.719705E-02
  validation loss:		2.639591E-02
Epoch took 0.724s

Epoch 75 of 300
  training loss:		2.758111E-02
  validation loss:		2.593521E-02
Epoch took 0.724s

Epoch 76 of 300
  training loss:		2.712876E-02
  validation loss:		2.614620E-02
Epoch took 0.724s

Epoch 77 of 300
  training loss:		2.755095E-02
  validation loss:		2.579702E-02
Epoch took 0.723s

Epoch 78 of 300
  training loss:		2.766101E-02
  validation loss:		2.622507E-02
Epoch took 0.724s

Epoch 79 of 300
  training loss:		2.796216E-02
  validation loss:		2.705665E-02
Epoch took 0.724s

Epoch 80 of 300
  training loss:		2.738196E-02
  validation loss:		2.592800E-02
Epoch took 0.723s

Epoch 81 of 300
  training loss:		2.701103E-02
  validation loss:		2.602205E-02
Epoch took 0.723s

Epoch 82 of 300
  training loss:		2.694070E-02
  validation loss:		2.710255E-02
Epoch took 0.724s

Epoch 83 of 300
  training loss:		2.787444E-02
  validation loss:		2.749010E-02
Epoch took 0.725s

Epoch 84 of 300
  training loss:		2.726511E-02
  validation loss:		2.723854E-02
Epoch took 0.724s

Epoch 85 of 300
  training loss:		2.770600E-02
  validation loss:		2.595238E-02
Epoch took 0.724s

Epoch 86 of 300
  training loss:		2.725747E-02
  validation loss:		2.625031E-02
Epoch took 0.724s

Epoch 87 of 300
  training loss:		2.723368E-02
  validation loss:		2.589523E-02
Epoch took 0.724s

Epoch 88 of 300
  training loss:		2.754152E-02
  validation loss:		2.583003E-02
Epoch took 0.724s

Epoch 89 of 300
  training loss:		2.743805E-02
  validation loss:		2.609465E-02
Epoch took 0.723s

Epoch 90 of 300
  training loss:		2.711801E-02
  validation loss:		2.625912E-02
Epoch took 0.724s

Epoch 91 of 300
  training loss:		2.712194E-02
  validation loss:		2.591359E-02
Epoch took 0.723s

Epoch 92 of 300
  training loss:		2.719636E-02
  validation loss:		2.636190E-02
Epoch took 0.724s

Epoch 93 of 300
  training loss:		2.718874E-02
  validation loss:		2.533959E-02
Epoch took 0.724s

Epoch 94 of 300
  training loss:		2.691427E-02
  validation loss:		2.556896E-02
Epoch took 0.723s

Epoch 95 of 300
  training loss:		2.746099E-02
  validation loss:		2.695224E-02
Epoch took 0.725s

Epoch 96 of 300
  training loss:		2.730171E-02
  validation loss:		2.708183E-02
Epoch took 0.724s

Epoch 97 of 300
  training loss:		2.718647E-02
  validation loss:		2.575654E-02
Epoch took 0.724s

Epoch 98 of 300
  training loss:		2.721091E-02
  validation loss:		2.643629E-02
Epoch took 0.724s

Epoch 99 of 300
  training loss:		2.688822E-02
  validation loss:		2.624051E-02
Epoch took 0.724s

Epoch 100 of 300
  training loss:		2.715100E-02
  validation loss:		2.778628E-02
Epoch took 0.723s

Epoch 101 of 300
  training loss:		2.768067E-02
  validation loss:		2.583520E-02
Epoch took 0.724s

Epoch 102 of 300
  training loss:		2.717174E-02
  validation loss:		2.633093E-02
Epoch took 0.723s

Epoch 103 of 300
  training loss:		2.724970E-02
  validation loss:		2.594536E-02
Epoch took 0.723s

Epoch 104 of 300
  training loss:		2.714043E-02
  validation loss:		2.585562E-02
Epoch took 0.724s

Epoch 105 of 300
  training loss:		2.691171E-02
  validation loss:		2.588886E-02
Epoch took 0.724s

Epoch 106 of 300
  training loss:		2.714386E-02
  validation loss:		2.606592E-02
Epoch took 0.723s

Epoch 107 of 300
  training loss:		2.702670E-02
  validation loss:		2.604932E-02
Epoch took 0.724s

Epoch 108 of 300
  training loss:		2.748038E-02
  validation loss:		2.570713E-02
Epoch took 0.724s

Epoch 109 of 300
  training loss:		2.721144E-02
  validation loss:		2.660818E-02
Epoch took 0.724s

Epoch 110 of 300
  training loss:		2.735182E-02
  validation loss:		2.740476E-02
Epoch took 0.723s

Epoch 111 of 300
  training loss:		2.710671E-02
  validation loss:		2.604236E-02
Epoch took 0.723s

Epoch 112 of 300
  training loss:		2.708087E-02
  validation loss:		2.591496E-02
Epoch took 0.724s

Epoch 113 of 300
  training loss:		2.722665E-02
  validation loss:		2.695235E-02
Epoch took 0.724s

Epoch 114 of 300
  training loss:		2.718910E-02
  validation loss:		2.562374E-02
Epoch took 0.724s

Epoch 115 of 300
  training loss:		2.707202E-02
  validation loss:		2.620210E-02
Epoch took 0.723s

Epoch 116 of 300
  training loss:		2.722798E-02
  validation loss:		2.571658E-02
Epoch took 0.723s

Epoch 117 of 300
  training loss:		2.713321E-02
  validation loss:		2.569775E-02
Epoch took 0.724s

Epoch 118 of 300
  training loss:		2.701757E-02
  validation loss:		2.613856E-02
Epoch took 0.724s

Epoch 119 of 300
  training loss:		2.694054E-02
  validation loss:		2.583605E-02
Epoch took 0.725s

Epoch 120 of 300
  training loss:		2.689633E-02
  validation loss:		2.630029E-02
Epoch took 0.724s

Epoch 121 of 300
  training loss:		2.692511E-02
  validation loss:		2.614533E-02
Epoch took 0.724s

Epoch 122 of 300
  training loss:		2.702567E-02
  validation loss:		2.593303E-02
Epoch took 0.724s

Epoch 123 of 300
  training loss:		2.710009E-02
  validation loss:		2.605990E-02
Epoch took 0.724s

Epoch 124 of 300
  training loss:		2.704806E-02
  validation loss:		2.623690E-02
Epoch took 0.724s

Epoch 125 of 300
  training loss:		2.728214E-02
  validation loss:		2.686690E-02
Epoch took 0.724s

Epoch 126 of 300
  training loss:		2.712087E-02
  validation loss:		2.554155E-02
Epoch took 0.724s

Epoch 127 of 300
  training loss:		2.704385E-02
  validation loss:		2.579753E-02
Epoch took 0.724s

Epoch 128 of 300
  training loss:		2.691875E-02
  validation loss:		2.578423E-02
Epoch took 0.724s

Epoch 129 of 300
  training loss:		2.718326E-02
  validation loss:		2.651038E-02
Epoch took 0.724s

Epoch 130 of 300
  training loss:		2.704892E-02
  validation loss:		2.610688E-02
Epoch took 0.724s

Epoch 131 of 300
  training loss:		2.686434E-02
  validation loss:		2.571072E-02
Epoch took 0.724s

Epoch 132 of 300
  training loss:		2.691410E-02
  validation loss:		2.590051E-02
Epoch took 0.724s

Epoch 133 of 300
  training loss:		2.682512E-02
  validation loss:		2.587815E-02
Epoch took 0.725s

Epoch 134 of 300
  training loss:		2.679853E-02
  validation loss:		2.674102E-02
Epoch took 0.723s

Epoch 135 of 300
  training loss:		2.699420E-02
  validation loss:		2.575509E-02
Epoch took 0.723s

Epoch 136 of 300
  training loss:		2.702049E-02
  validation loss:		2.546825E-02
Epoch took 0.724s

Epoch 137 of 300
  training loss:		2.744009E-02
  validation loss:		2.634734E-02
Epoch took 0.724s

Epoch 138 of 300
  training loss:		2.710733E-02
  validation loss:		2.564954E-02
Epoch took 0.724s

Epoch 139 of 300
  training loss:		2.692888E-02
  validation loss:		2.568763E-02
Epoch took 0.723s

Epoch 140 of 300
  training loss:		2.676147E-02
  validation loss:		2.594293E-02
Epoch took 0.725s

Epoch 141 of 300
  training loss:		2.677811E-02
  validation loss:		2.576661E-02
Epoch took 0.724s

Epoch 142 of 300
  training loss:		2.676225E-02
  validation loss:		2.572041E-02
Epoch took 0.724s

Epoch 143 of 300
  training loss:		2.706886E-02
  validation loss:		2.668750E-02
Epoch took 0.723s

Epoch 144 of 300
  training loss:		2.684083E-02
  validation loss:		2.581850E-02
Epoch took 0.725s

Epoch 145 of 300
  training loss:		2.690437E-02
  validation loss:		2.589770E-02
Epoch took 0.724s

Epoch 146 of 300
  training loss:		2.682666E-02
  validation loss:		2.554167E-02
Epoch took 0.724s

Epoch 147 of 300
  training loss:		2.684314E-02
  validation loss:		2.625519E-02
Epoch took 0.725s

Epoch 148 of 300
  training loss:		2.680386E-02
  validation loss:		2.550565E-02
Epoch took 0.724s

Epoch 149 of 300
  training loss:		2.685814E-02
  validation loss:		2.612271E-02
Epoch took 0.724s

Epoch 150 of 300
  training loss:		2.694981E-02
  validation loss:		2.546025E-02
Epoch took 0.724s

Epoch 151 of 300
  training loss:		2.696524E-02
  validation loss:		2.639044E-02
Epoch took 0.724s

Epoch 152 of 300
  training loss:		2.692333E-02
  validation loss:		2.568039E-02
Epoch took 0.726s

Epoch 153 of 300
  training loss:		2.695983E-02
  validation loss:		2.557747E-02
Epoch took 0.724s

Epoch 154 of 300
  training loss:		2.694277E-02
  validation loss:		2.675837E-02
Epoch took 0.724s

Epoch 155 of 300
  training loss:		2.711227E-02
  validation loss:		2.570754E-02
Epoch took 0.725s

Epoch 156 of 300
  training loss:		2.694975E-02
  validation loss:		2.636740E-02
Epoch took 0.723s

Epoch 157 of 300
  training loss:		2.686379E-02
  validation loss:		2.575588E-02
Epoch took 0.724s

Epoch 158 of 300
  training loss:		2.700986E-02
  validation loss:		2.620778E-02
Epoch took 0.724s

Epoch 159 of 300
  training loss:		2.686738E-02
  validation loss:		2.580264E-02
Epoch took 0.723s

Epoch 160 of 300
  training loss:		2.679942E-02
  validation loss:		2.572741E-02
Epoch took 0.724s

Epoch 161 of 300
  training loss:		2.682169E-02
  validation loss:		2.681319E-02
Epoch took 0.724s

Epoch 162 of 300
  training loss:		2.670868E-02
  validation loss:		2.636136E-02
Epoch took 0.724s

Epoch 163 of 300
  training loss:		2.702383E-02
  validation loss:		2.613384E-02
Epoch took 0.723s

Epoch 164 of 300
  training loss:		2.685095E-02
  validation loss:		2.596906E-02
Epoch took 0.723s

Epoch 165 of 300
  training loss:		2.690454E-02
  validation loss:		2.607563E-02
Epoch took 0.725s

Epoch 166 of 300
  training loss:		2.689956E-02
  validation loss:		2.566547E-02
Epoch took 0.723s

Epoch 167 of 300
  training loss:		2.679576E-02
  validation loss:		2.601130E-02
Epoch took 0.724s

Epoch 168 of 300
  training loss:		2.700321E-02
  validation loss:		2.579367E-02
Epoch took 0.724s

Epoch 169 of 300
  training loss:		2.663070E-02
  validation loss:		2.557065E-02
Epoch took 0.723s

Epoch 170 of 300
  training loss:		2.670285E-02
  validation loss:		2.633819E-02
Epoch took 0.723s

Epoch 171 of 300
  training loss:		2.693157E-02
  validation loss:		2.577049E-02
Epoch took 0.724s

Epoch 172 of 300
  training loss:		2.672330E-02
  validation loss:		2.594585E-02
Epoch took 0.724s

Epoch 173 of 300
  training loss:		2.682050E-02
  validation loss:		2.626221E-02
Epoch took 0.723s

Epoch 174 of 300
  training loss:		2.686152E-02
  validation loss:		2.641288E-02
Epoch took 0.724s

Epoch 175 of 300
  training loss:		2.680291E-02
  validation loss:		2.563360E-02
Epoch took 0.723s

Epoch 176 of 300
  training loss:		2.685750E-02
  validation loss:		2.555946E-02
Epoch took 0.723s

Epoch 177 of 300
  training loss:		2.686619E-02
  validation loss:		2.575253E-02
Epoch took 0.724s

Epoch 178 of 300
  training loss:		2.668576E-02
  validation loss:		2.601164E-02
Epoch took 0.724s

Epoch 179 of 300
  training loss:		2.688398E-02
  validation loss:		2.583247E-02
Epoch took 0.724s

Epoch 180 of 300
  training loss:		2.690795E-02
  validation loss:		2.631046E-02
Epoch took 0.724s

Early stopping, val-loss increased over the last 20 epochs from 0.0259375747138 to 0.0260111989143
Saving model from epoch 160
Training MSE: 2.55066e-14
Validation MSE: 2.46823e-14
Training R2: 0.729726466707
Validation R2: 0.737399580152
