Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		8.761502E-02
  validation loss:		4.957651E-02
Epoch took 1.445s

Epoch 2 of 300
  training loss:		4.765887E-02
  validation loss:		3.960076E-02
Epoch took 1.398s

Epoch 3 of 300
  training loss:		3.880628E-02
  validation loss:		3.584369E-02
Epoch took 1.399s

Epoch 4 of 300
  training loss:		3.449373E-02
  validation loss:		3.092787E-02
Epoch took 1.397s

Epoch 5 of 300
  training loss:		3.119202E-02
  validation loss:		2.834641E-02
Epoch took 1.399s

Epoch 6 of 300
  training loss:		3.028320E-02
  validation loss:		2.812948E-02
Epoch took 1.397s

Epoch 7 of 300
  training loss:		3.011357E-02
  validation loss:		2.901551E-02
Epoch took 1.395s

Epoch 8 of 300
  training loss:		2.929690E-02
  validation loss:		2.754904E-02
Epoch took 1.396s

Epoch 9 of 300
  training loss:		2.930650E-02
  validation loss:		2.738693E-02
Epoch took 1.407s

Epoch 10 of 300
  training loss:		2.949719E-02
  validation loss:		2.947325E-02
Epoch took 1.406s

Epoch 11 of 300
  training loss:		2.998323E-02
  validation loss:		2.750755E-02
Epoch took 1.407s

Epoch 12 of 300
  training loss:		2.839407E-02
  validation loss:		2.729007E-02
Epoch took 1.407s

Epoch 13 of 300
  training loss:		2.829031E-02
  validation loss:		2.666480E-02
Epoch took 1.408s

Epoch 14 of 300
  training loss:		2.888254E-02
  validation loss:		3.183873E-02
Epoch took 1.406s

Epoch 15 of 300
  training loss:		2.819315E-02
  validation loss:		2.658983E-02
Epoch took 1.404s

Epoch 16 of 300
  training loss:		2.735013E-02
  validation loss:		2.698915E-02
Epoch took 1.408s

Epoch 17 of 300
  training loss:		2.781031E-02
  validation loss:		2.702286E-02
Epoch took 1.405s

Epoch 18 of 300
  training loss:		2.842790E-02
  validation loss:		2.629881E-02
Epoch took 1.405s

Epoch 19 of 300
  training loss:		2.859524E-02
  validation loss:		2.891512E-02
Epoch took 1.406s

Epoch 20 of 300
  training loss:		2.751651E-02
  validation loss:		2.594852E-02
Epoch took 1.406s

Epoch 21 of 300
  training loss:		2.856838E-02
  validation loss:		3.119427E-02
Epoch took 1.408s

Epoch 22 of 300
  training loss:		2.750696E-02
  validation loss:		2.634071E-02
Epoch took 1.404s

Epoch 23 of 300
  training loss:		2.690928E-02
  validation loss:		2.579715E-02
Epoch took 1.406s

Epoch 24 of 300
  training loss:		2.725500E-02
  validation loss:		2.841831E-02
Epoch took 1.406s

Epoch 25 of 300
  training loss:		2.866464E-02
  validation loss:		2.574194E-02
Epoch took 1.402s

Epoch 26 of 300
  training loss:		2.684106E-02
  validation loss:		2.551624E-02
Epoch took 1.407s

Epoch 27 of 300
  training loss:		2.719968E-02
  validation loss:		2.591815E-02
Epoch took 1.404s

Epoch 28 of 300
  training loss:		2.657925E-02
  validation loss:		2.557697E-02
Epoch took 1.404s

Epoch 29 of 300
  training loss:		2.818172E-02
  validation loss:		2.773459E-02
Epoch took 1.404s

Epoch 30 of 300
  training loss:		2.919829E-02
  validation loss:		2.550322E-02
Epoch took 1.403s

Epoch 31 of 300
  training loss:		2.647175E-02
  validation loss:		2.532975E-02
Epoch took 1.410s

Epoch 32 of 300
  training loss:		2.748317E-02
  validation loss:		2.560364E-02
Epoch took 1.403s

Epoch 33 of 300
  training loss:		2.660750E-02
  validation loss:		2.551971E-02
Epoch took 1.403s

Epoch 34 of 300
  training loss:		2.647926E-02
  validation loss:		2.582712E-02
Epoch took 1.405s

Epoch 35 of 300
  training loss:		3.082002E-02
  validation loss:		2.569034E-02
Epoch took 1.401s

Epoch 36 of 300
  training loss:		2.638389E-02
  validation loss:		2.542243E-02
Epoch took 1.406s

Epoch 37 of 300
  training loss:		2.629430E-02
  validation loss:		2.542665E-02
Epoch took 1.408s

Epoch 38 of 300
  training loss:		2.625830E-02
  validation loss:		2.538821E-02
Epoch took 1.402s

Epoch 39 of 300
  training loss:		2.629401E-02
  validation loss:		2.533003E-02
Epoch took 1.403s

Epoch 40 of 300
  training loss:		2.633653E-02
  validation loss:		2.535922E-02
Epoch took 1.402s

Epoch 41 of 300
  training loss:		2.913515E-02
  validation loss:		2.572160E-02
Epoch took 1.401s

Epoch 42 of 300
  training loss:		2.639952E-02
  validation loss:		2.542980E-02
Epoch took 1.406s

Epoch 43 of 300
  training loss:		2.779053E-02
  validation loss:		2.550962E-02
Epoch took 1.406s

Epoch 44 of 300
  training loss:		2.791651E-02
  validation loss:		2.624354E-02
Epoch took 1.401s

Epoch 45 of 300
  training loss:		2.635310E-02
  validation loss:		2.544489E-02
Epoch took 1.407s

Epoch 46 of 300
  training loss:		2.626829E-02
  validation loss:		2.533520E-02
Epoch took 1.408s

Epoch 47 of 300
  training loss:		2.631968E-02
  validation loss:		2.586806E-02
Epoch took 1.402s

Epoch 48 of 300
  training loss:		3.074278E-02
  validation loss:		2.578673E-02
Epoch took 1.400s

Epoch 49 of 300
  training loss:		2.628922E-02
  validation loss:		2.533183E-02
Epoch took 1.410s

Epoch 50 of 300
  training loss:		2.623717E-02
  validation loss:		2.551699E-02
Epoch took 1.406s

Epoch 51 of 300
  training loss:		2.718834E-02
  validation loss:		3.058352E-02
Epoch took 1.402s

Epoch 52 of 300
  training loss:		2.995601E-02
  validation loss:		2.604277E-02
Epoch took 1.400s

Epoch 53 of 300
  training loss:		2.639515E-02
  validation loss:		2.538878E-02
Epoch took 1.405s

Epoch 54 of 300
  training loss:		2.622403E-02
  validation loss:		2.534203E-02
Epoch took 1.409s

Epoch 55 of 300
  training loss:		2.668526E-02
  validation loss:		2.603552E-02
Epoch took 1.404s

Epoch 56 of 300
  training loss:		2.623047E-02
  validation loss:		2.532879E-02
Epoch took 1.402s

Epoch 57 of 300
  training loss:		2.766320E-02
  validation loss:		2.545416E-02
Epoch took 1.404s

Epoch 58 of 300
  training loss:		2.622141E-02
  validation loss:		2.534497E-02
Epoch took 1.403s

Epoch 59 of 300
  training loss:		2.624284E-02
  validation loss:		2.515073E-02
Epoch took 1.408s

Epoch 60 of 300
  training loss:		2.618021E-02
  validation loss:		2.531262E-02
Epoch took 1.403s

Epoch 61 of 300
  training loss:		2.958914E-02
  validation loss:		2.528828E-02
Epoch took 1.400s

Epoch 62 of 300
  training loss:		2.621227E-02
  validation loss:		2.527293E-02
Epoch took 1.409s

Epoch 63 of 300
  training loss:		2.618538E-02
  validation loss:		2.519382E-02
Epoch took 1.405s

Epoch 64 of 300
  training loss:		2.617992E-02
  validation loss:		2.547547E-02
Epoch took 1.405s

Epoch 65 of 300
  training loss:		2.842566E-02
  validation loss:		3.321549E-02
Epoch took 1.401s

Epoch 66 of 300
  training loss:		2.647331E-02
  validation loss:		2.530476E-02
Epoch took 1.401s

Epoch 67 of 300
  training loss:		2.620643E-02
  validation loss:		2.524042E-02
Epoch took 1.412s

Epoch 68 of 300
  training loss:		2.617343E-02
  validation loss:		2.530725E-02
Epoch took 1.403s

Epoch 69 of 300
  training loss:		2.616020E-02
  validation loss:		2.529834E-02
Epoch took 1.403s

Epoch 70 of 300
  training loss:		2.838007E-02
  validation loss:		3.853155E-02
Epoch took 1.402s

Epoch 71 of 300
  training loss:		2.710742E-02
  validation loss:		2.521586E-02
Epoch took 1.400s

Epoch 72 of 300
  training loss:		2.617921E-02
  validation loss:		2.517100E-02
Epoch took 1.413s

Epoch 73 of 300
  training loss:		2.614517E-02
  validation loss:		2.522175E-02
Epoch took 1.402s

Epoch 74 of 300
  training loss:		2.628059E-02
  validation loss:		2.657404E-02
Epoch took 1.403s

Epoch 75 of 300
  training loss:		2.850827E-02
  validation loss:		2.551633E-02
Epoch took 1.402s

Epoch 76 of 300
  training loss:		2.627869E-02
  validation loss:		2.560267E-02
Epoch took 1.410s

Epoch 77 of 300
  training loss:		2.832481E-02
  validation loss:		2.544535E-02
Epoch took 1.402s

Epoch 78 of 300
  training loss:		2.620710E-02
  validation loss:		2.528384E-02
Epoch took 1.410s

Epoch 79 of 300
  training loss:		2.619591E-02
  validation loss:		2.515314E-02
Epoch took 1.409s

Epoch 80 of 300
  training loss:		2.626359E-02
  validation loss:		2.690017E-02
Epoch took 1.405s

Early stopping, val-loss increased over the last 20 epochs from 0.025808608966 to 0.0265106235041
Saving model from epoch 60
Training MSE: 2.51306e-14
Validation MSE: 2.43058e-14
Training R2: 0.733710875551
Validation R2: 0.741405734911
