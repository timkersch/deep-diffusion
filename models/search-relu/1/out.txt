Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.005314E-01
  validation loss:		7.997700E-03

Epoch 2 of 100
  training loss:		4.871384E-03
  validation loss:		3.099587E-03

Epoch 3 of 100
  training loss:		2.280021E-03
  validation loss:		1.765099E-03

Epoch 4 of 100
  training loss:		1.447758E-03
  validation loss:		1.198969E-03

Epoch 5 of 100
  training loss:		1.011931E-03
  validation loss:		8.362452E-04

Epoch 6 of 100
  training loss:		7.273741E-04
  validation loss:		6.140771E-04

Epoch 7 of 100
  training loss:		5.535721E-04
  validation loss:		4.716788E-04

Epoch 8 of 100
  training loss:		4.364601E-04
  validation loss:		3.684115E-04

Epoch 9 of 100
  training loss:		3.422384E-04
  validation loss:		2.871931E-04

Epoch 10 of 100
  training loss:		2.739823E-04
  validation loss:		2.274546E-04

Epoch 11 of 100
  training loss:		2.204643E-04
  validation loss:		1.814577E-04

Epoch 12 of 100
  training loss:		1.764340E-04
  validation loss:		1.473170E-04

Epoch 13 of 100
  training loss:		1.407151E-04
  validation loss:		1.160291E-04

Epoch 14 of 100
  training loss:		1.129144E-04
  validation loss:		9.035687E-05

Epoch 15 of 100
  training loss:		9.118500E-05
  validation loss:		7.598123E-05

Epoch 16 of 100
  training loss:		7.355948E-05
  validation loss:		5.980955E-05

Epoch 17 of 100
  training loss:		5.980888E-05
  validation loss:		4.814878E-05

Epoch 18 of 100
  training loss:		4.820035E-05
  validation loss:		3.754371E-05

Epoch 19 of 100
  training loss:		3.794578E-05
  validation loss:		3.004701E-05

Epoch 20 of 100
  training loss:		2.994027E-05
  validation loss:		2.628834E-05

Epoch 21 of 100
  training loss:		2.350995E-05
  validation loss:		1.788139E-05

Epoch 22 of 100
  training loss:		1.869364E-05
  validation loss:		1.520313E-05

Epoch 23 of 100
  training loss:		1.477427E-05
  validation loss:		1.157378E-05

Epoch 24 of 100
  training loss:		1.199690E-05
  validation loss:		9.754894E-06

Epoch 25 of 100
  training loss:		9.773845E-06
  validation loss:		1.144760E-05

Epoch 26 of 100
  training loss:		8.105359E-06
  validation loss:		6.810907E-06

Epoch 27 of 100
  training loss:		6.386066E-06
  validation loss:		5.105390E-06

Epoch 28 of 100
  training loss:		5.100275E-06
  validation loss:		3.862232E-06

Epoch 29 of 100
  training loss:		4.098354E-06
  validation loss:		3.256222E-06

Epoch 30 of 100
  training loss:		3.415644E-06
  validation loss:		2.579415E-06

Epoch 31 of 100
  training loss:		2.939266E-06
  validation loss:		3.259329E-06

Epoch 32 of 100
  training loss:		2.421583E-06
  validation loss:		2.336418E-06

Epoch 33 of 100
  training loss:		2.108417E-06
  validation loss:		1.674378E-06

Epoch 34 of 100
  training loss:		1.867755E-06
  validation loss:		1.420428E-06

Epoch 35 of 100
  training loss:		1.502969E-06
  validation loss:		1.128359E-06

Epoch 36 of 100
  training loss:		1.279157E-06
  validation loss:		9.633711E-07

Epoch 37 of 100
  training loss:		1.037354E-06
  validation loss:		7.204270E-07

Epoch 38 of 100
  training loss:		8.924348E-07
  validation loss:		1.277031E-06

Epoch 39 of 100
  training loss:		7.214744E-07
  validation loss:		6.319414E-07

Epoch 40 of 100
  training loss:		6.065914E-07
  validation loss:		4.393403E-07

Epoch 41 of 100
  training loss:		4.762580E-07
  validation loss:		4.320996E-07

Epoch 42 of 100
  training loss:		4.125718E-07
  validation loss:		2.817908E-07

Epoch 43 of 100
  training loss:		3.555604E-07
  validation loss:		3.567803E-07

Epoch 44 of 100
  training loss:		3.231039E-07
  validation loss:		3.018160E-07

Epoch 45 of 100
  training loss:		2.479699E-07
  validation loss:		1.387509E-07

Epoch 46 of 100
  training loss:		2.072373E-07
  validation loss:		1.938452E-07

Epoch 47 of 100
  training loss:		1.638987E-07
  validation loss:		9.198457E-08

Epoch 48 of 100
  training loss:		1.399776E-07
  validation loss:		7.882961E-08

Epoch 49 of 100
  training loss:		1.252850E-07
  validation loss:		7.201493E-08

Epoch 50 of 100
  training loss:		1.013823E-07
  validation loss:		6.691247E-08

Epoch 51 of 100
  training loss:		7.925907E-08
  validation loss:		3.910161E-08

Epoch 52 of 100
  training loss:		6.744918E-08
  validation loss:		3.233465E-08

Epoch 53 of 100
  training loss:		5.056512E-08
  validation loss:		1.858376E-08

Epoch 54 of 100
  training loss:		6.156276E-08
  validation loss:		2.482706E-08

Epoch 55 of 100
  training loss:		3.012159E-08
  validation loss:		1.199417E-07

Epoch 56 of 100
  training loss:		2.780111E-08
  validation loss:		2.503910E-08

Epoch 57 of 100
  training loss:		1.670415E-08
  validation loss:		2.187023E-08

Epoch 58 of 100
  training loss:		2.018113E-08
  validation loss:		1.102329E-08

Epoch 59 of 100
  training loss:		2.709828E-08
  validation loss:		3.034637E-09

Epoch 60 of 100
  training loss:		1.797982E-08
  validation loss:		2.323029E-07

Epoch 61 of 100
  training loss:		2.783271E-08
  validation loss:		2.970593E-09

Epoch 62 of 100
  training loss:		9.724841E-09
  validation loss:		1.044712E-08

Epoch 63 of 100
  training loss:		2.355101E-08
  validation loss:		4.712980E-08

Epoch 64 of 100
  training loss:		1.094428E-08
  validation loss:		1.205156E-08

Epoch 65 of 100
  training loss:		1.884402E-08
  validation loss:		1.920807E-08

Epoch 66 of 100
  training loss:		1.647804E-08
  validation loss:		9.422875E-08

Epoch 67 of 100
  training loss:		1.626371E-08
  validation loss:		3.168093E-11

Epoch 68 of 100
  training loss:		1.398668E-09
  validation loss:		8.817696E-11

Epoch 69 of 100
  training loss:		2.249687E-08
  validation loss:		3.853373E-11

Epoch 70 of 100
  training loss:		3.327960E-08
  validation loss:		4.307216E-10

Epoch 71 of 100
  training loss:		4.009864E-10
  validation loss:		2.566927E-10

Epoch 72 of 100
  training loss:		4.704490E-08
  validation loss:		1.343424E-11

Epoch 73 of 100
  training loss:		5.690733E-10
  validation loss:		6.384918E-10

Epoch 74 of 100
  training loss:		2.179463E-08
  validation loss:		5.628099E-11

Epoch 75 of 100
  training loss:		1.920663E-08
  validation loss:		5.291962E-08

Epoch 76 of 100
  training loss:		8.419054E-09
  validation loss:		1.774070E-09

Epoch 77 of 100
  training loss:		2.038413E-08
  validation loss:		4.534886E-11

Epoch 78 of 100
  training loss:		1.572233E-12
  validation loss:		9.157371E-14

Epoch 79 of 100
  training loss:		4.462961E-14
  validation loss:		1.319496E-14

Epoch 80 of 100
  training loss:		6.988127E-15
  validation loss:		2.764317E-15

Epoch 81 of 100
  training loss:		1.602301E-15
  validation loss:		7.325827E-16

Epoch 82 of 100
  training loss:		4.089116E-16
  validation loss:		2.307779E-16

Epoch 83 of 100
  training loss:		1.275344E-16
  validation loss:		6.055672E-17

Epoch 84 of 100
  training loss:		3.848407E-17
  validation loss:		2.233721E-17

Epoch 85 of 100
  training loss:		1.473881E-17
  validation loss:		6.966017E-18

Epoch 86 of 100
  training loss:		5.065879E-18
  validation loss:		3.402518E-18

Epoch 87 of 100
  training loss:		3.079826E-07
  validation loss:		1.664506E-08

Epoch 88 of 100
  training loss:		2.942388E-09
  validation loss:		8.668067E-10

Epoch 89 of 100
  training loss:		1.881379E-10
  validation loss:		5.383666E-11

Epoch 90 of 100
  training loss:		2.639196E-11
  validation loss:		1.223414E-11

Epoch 91 of 100
  training loss:		6.131098E-12
  validation loss:		2.177132E-12

Epoch 92 of 100
  training loss:		6.168054E-13
  validation loss:		2.150195E-12

Epoch 93 of 100
  training loss:		2.032658E-08
  validation loss:		4.106568E-11

Epoch 94 of 100
  training loss:		1.956835E-08
  validation loss:		1.992368E-09

Epoch 95 of 100
  training loss:		1.617886E-08
  validation loss:		2.642287E-08

Epoch 96 of 100
  training loss:		1.146503E-08
  validation loss:		4.242729E-13

Epoch 97 of 100
  training loss:		1.908545E-13
  validation loss:		5.913810E-14

Epoch 98 of 100
  training loss:		3.545766E-14
  validation loss:		1.088840E-14

Epoch 99 of 100
  training loss:		6.692188E-15
  validation loss:		2.982020E-15

Epoch 100 of 100
  training loss:		1.647293E-15
  validation loss:		6.292538E-16

Training RMSE: 2.88945746379e-14
Validation RMSE: 2.78977419182e-14
