Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		4.572519E-01
  validation loss:		6.267250E-03

Epoch 2 of 100
  training loss:		4.506493E-03
  validation loss:		3.007754E-03

Epoch 3 of 100
  training loss:		2.126121E-03
  validation loss:		1.374324E-03

Epoch 4 of 100
  training loss:		1.079424E-03
  validation loss:		8.110141E-04

Epoch 5 of 100
  training loss:		6.647285E-04
  validation loss:		5.181289E-04

Epoch 6 of 100
  training loss:		4.619121E-04
  validation loss:		3.959497E-04

Epoch 7 of 100
  training loss:		3.637496E-04
  validation loss:		3.148110E-04

Epoch 8 of 100
  training loss:		2.927441E-04
  validation loss:		2.604169E-04

Epoch 9 of 100
  training loss:		2.434737E-04
  validation loss:		2.225293E-04

Epoch 10 of 100
  training loss:		2.094422E-04
  validation loss:		1.971923E-04

Epoch 11 of 100
  training loss:		1.793231E-04
  validation loss:		1.689672E-04

Epoch 12 of 100
  training loss:		1.549389E-04
  validation loss:		1.436122E-04

Epoch 13 of 100
  training loss:		1.343788E-04
  validation loss:		1.229960E-04

Epoch 14 of 100
  training loss:		1.149517E-04
  validation loss:		1.048501E-04

Epoch 15 of 100
  training loss:		9.805904E-05
  validation loss:		9.104803E-05

Epoch 16 of 100
  training loss:		8.500504E-05
  validation loss:		8.325636E-05

Epoch 17 of 100
  training loss:		7.345187E-05
  validation loss:		6.947785E-05

Epoch 18 of 100
  training loss:		6.474231E-05
  validation loss:		6.417819E-05

Epoch 19 of 100
  training loss:		5.671664E-05
  validation loss:		5.381348E-05

Epoch 20 of 100
  training loss:		4.970719E-05
  validation loss:		4.719905E-05

Epoch 21 of 100
  training loss:		4.342866E-05
  validation loss:		4.102008E-05

Epoch 22 of 100
  training loss:		3.866842E-05
  validation loss:		3.692120E-05

Epoch 23 of 100
  training loss:		3.397167E-05
  validation loss:		3.288501E-05

Epoch 24 of 100
  training loss:		2.995881E-05
  validation loss:		2.962266E-05

Epoch 25 of 100
  training loss:		2.684598E-05
  validation loss:		2.558786E-05

Epoch 26 of 100
  training loss:		2.337044E-05
  validation loss:		2.197192E-05

Epoch 27 of 100
  training loss:		2.073544E-05
  validation loss:		2.132014E-05

Epoch 28 of 100
  training loss:		1.845132E-05
  validation loss:		2.053144E-05

Epoch 29 of 100
  training loss:		1.582029E-05
  validation loss:		1.451945E-05

Epoch 30 of 100
  training loss:		1.381901E-05
  validation loss:		1.403209E-05

Epoch 31 of 100
  training loss:		1.186463E-05
  validation loss:		1.197223E-05

Epoch 32 of 100
  training loss:		1.019830E-05
  validation loss:		9.228341E-06

Epoch 33 of 100
  training loss:		9.271377E-06
  validation loss:		8.529589E-06

Epoch 34 of 100
  training loss:		7.924335E-06
  validation loss:		6.897855E-06

Epoch 35 of 100
  training loss:		6.511066E-06
  validation loss:		6.349469E-06

Epoch 36 of 100
  training loss:		5.517864E-06
  validation loss:		5.205228E-06

Epoch 37 of 100
  training loss:		4.855435E-06
  validation loss:		4.427865E-06

Epoch 38 of 100
  training loss:		4.222385E-06
  validation loss:		3.322398E-06

Epoch 39 of 100
  training loss:		3.269526E-06
  validation loss:		3.649095E-06

Epoch 40 of 100
  training loss:		2.674680E-06
  validation loss:		2.397522E-06

Epoch 41 of 100
  training loss:		2.316848E-06
  validation loss:		2.085534E-06

Epoch 42 of 100
  training loss:		2.045977E-06
  validation loss:		1.800481E-06

Epoch 43 of 100
  training loss:		1.884425E-06
  validation loss:		1.921323E-06

Epoch 44 of 100
  training loss:		1.626204E-06
  validation loss:		1.319247E-06

Epoch 45 of 100
  training loss:		1.311511E-06
  validation loss:		1.451724E-06

Epoch 46 of 100
  training loss:		1.172473E-06
  validation loss:		1.438040E-06

Epoch 47 of 100
  training loss:		1.044269E-06
  validation loss:		1.735750E-06

Epoch 48 of 100
  training loss:		9.738608E-07
  validation loss:		1.236918E-06

Epoch 49 of 100
  training loss:		7.389984E-07
  validation loss:		7.605054E-07

Epoch 50 of 100
  training loss:		6.220443E-07
  validation loss:		5.133858E-07

Epoch 51 of 100
  training loss:		5.735459E-07
  validation loss:		6.720475E-07

Epoch 52 of 100
  training loss:		4.607617E-07
  validation loss:		5.536326E-07

Epoch 53 of 100
  training loss:		3.372666E-07
  validation loss:		3.021555E-07

Epoch 54 of 100
  training loss:		3.077937E-07
  validation loss:		2.000932E-07

Epoch 55 of 100
  training loss:		4.372183E-07
  validation loss:		2.062280E-07

Epoch 56 of 100
  training loss:		2.787747E-07
  validation loss:		2.367823E-07

Epoch 57 of 100
  training loss:		2.221427E-07
  validation loss:		2.805270E-07

Epoch 58 of 100
  training loss:		2.000418E-07
  validation loss:		7.250074E-07

Epoch 59 of 100
  training loss:		5.400430E-07
  validation loss:		1.815930E-07

Epoch 60 of 100
  training loss:		1.769859E-07
  validation loss:		6.634832E-08

Epoch 61 of 100
  training loss:		2.567659E-07
  validation loss:		8.576283E-08

Epoch 62 of 100
  training loss:		1.082956E-06
  validation loss:		5.176897E-07

Epoch 63 of 100
  training loss:		4.070324E-07
  validation loss:		1.074368E-07

Epoch 64 of 100
  training loss:		1.338251E-07
  validation loss:		2.264432E-07

Epoch 65 of 100
  training loss:		6.167584E-07
  validation loss:		7.017888E-08

Epoch 66 of 100
  training loss:		5.906503E-07
  validation loss:		2.176102E-07

Epoch 67 of 100
  training loss:		1.678357E-06
  validation loss:		4.568759E-07

Epoch 68 of 100
  training loss:		3.339060E-07
  validation loss:		1.844539E-06

Epoch 69 of 100
  training loss:		5.156674E-07
  validation loss:		6.941801E-08

Epoch 70 of 100
  training loss:		1.988631E-06
  validation loss:		5.033904E-07

Epoch 71 of 100
  training loss:		2.213832E-07
  validation loss:		4.470560E-07

Epoch 72 of 100
  training loss:		6.354785E-07
  validation loss:		1.405426E-07

Epoch 73 of 100
  training loss:		9.849100E-07
  validation loss:		3.616843E-06

Epoch 74 of 100
  training loss:		1.314610E-06
  validation loss:		2.201794E-07

Epoch 75 of 100
  training loss:		8.877401E-08
  validation loss:		1.189088E-07

Epoch 76 of 100
  training loss:		6.129585E-06
  validation loss:		1.543329E-05

Epoch 77 of 100
  training loss:		1.789648E-06
  validation loss:		1.048937E-08

Epoch 78 of 100
  training loss:		1.839423E-08
  validation loss:		2.566735E-08

Epoch 79 of 100
  training loss:		3.038567E-08
  validation loss:		7.192709E-09

Epoch 80 of 100
  training loss:		2.449240E-08
  validation loss:		4.526614E-08

Epoch 81 of 100
  training loss:		2.289831E-07
  validation loss:		3.008263E-07

Epoch 82 of 100
  training loss:		1.199224E-06
  validation loss:		7.750228E-08

Epoch 83 of 100
  training loss:		1.354709E-06
  validation loss:		7.840415E-07

Epoch 84 of 100
  training loss:		5.311306E-07
  validation loss:		6.698386E-08

Epoch 85 of 100
  training loss:		1.695641E-07
  validation loss:		5.794373E-08

Epoch 86 of 100
  training loss:		1.020332E-06
  validation loss:		2.894742E-07

Epoch 87 of 100
  training loss:		1.379645E-06
  validation loss:		1.591287E-05

Epoch 88 of 100
  training loss:		4.693100E-06
  validation loss:		1.320763E-06

Epoch 89 of 100
  training loss:		7.644983E-08
  validation loss:		1.647871E-09

Epoch 90 of 100
  training loss:		5.363882E-09
  validation loss:		2.994407E-09

Epoch 91 of 100
  training loss:		1.446611E-08
  validation loss:		6.664288E-08

Epoch 92 of 100
  training loss:		4.110982E-06
  validation loss:		8.283372E-06

Epoch 93 of 100
  training loss:		9.977925E-07
  validation loss:		4.621987E-08

Epoch 94 of 100
  training loss:		5.959630E-08
  validation loss:		3.619563E-08

Epoch 95 of 100
  training loss:		1.727288E-07
  validation loss:		3.653303E-08

Epoch 96 of 100
  training loss:		1.985803E-07
  validation loss:		1.776075E-07

Epoch 97 of 100
  training loss:		1.951820E-06
  validation loss:		2.878916E-07

Epoch 98 of 100
  training loss:		2.296010E-07
  validation loss:		6.867716E-07

Epoch 99 of 100
  training loss:		7.377919E-07
  validation loss:		6.794401E-08

Epoch 100 of 100
  training loss:		4.988132E-07
  validation loss:		2.094864E-06

Training RMSE: 1.44474862042e-09
Validation RMSE: 1.41763563235e-09
