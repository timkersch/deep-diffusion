Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		3.022125E-01
  validation loss:		6.031418E-02

Epoch 2 of 100
  training loss:		2.356202E-02
  validation loss:		1.024148E-02

Epoch 3 of 100
  training loss:		7.961619E-03
  validation loss:		6.424352E-03

Epoch 4 of 100
  training loss:		5.386973E-03
  validation loss:		4.580960E-03

Epoch 5 of 100
  training loss:		3.942664E-03
  validation loss:		3.438600E-03

Epoch 6 of 100
  training loss:		3.009871E-03
  validation loss:		2.643984E-03

Epoch 7 of 100
  training loss:		2.322919E-03
  validation loss:		2.043534E-03

Epoch 8 of 100
  training loss:		1.826519E-03
  validation loss:		1.625031E-03

Epoch 9 of 100
  training loss:		1.441970E-03
  validation loss:		1.257087E-03

Epoch 10 of 100
  training loss:		1.132592E-03
  validation loss:		1.001451E-03

Epoch 11 of 100
  training loss:		9.132709E-04
  validation loss:		8.127258E-04

Epoch 12 of 100
  training loss:		7.457502E-04
  validation loss:		6.650909E-04

Epoch 13 of 100
  training loss:		6.105108E-04
  validation loss:		5.481829E-04

Epoch 14 of 100
  training loss:		5.051147E-04
  validation loss:		4.555948E-04

Epoch 15 of 100
  training loss:		4.277931E-04
  validation loss:		3.892162E-04

Epoch 16 of 100
  training loss:		3.661285E-04
  validation loss:		3.341440E-04

Epoch 17 of 100
  training loss:		3.167962E-04
  validation loss:		2.945475E-04

Epoch 18 of 100
  training loss:		2.809775E-04
  validation loss:		2.595861E-04

Epoch 19 of 100
  training loss:		2.493462E-04
  validation loss:		2.332385E-04

Epoch 20 of 100
  training loss:		2.199381E-04
  validation loss:		2.032578E-04

Epoch 21 of 100
  training loss:		1.933053E-04
  validation loss:		1.785373E-04

Epoch 22 of 100
  training loss:		1.723596E-04
  validation loss:		1.553720E-04

Epoch 23 of 100
  training loss:		1.543349E-04
  validation loss:		1.393531E-04

Epoch 24 of 100
  training loss:		1.358140E-04
  validation loss:		1.232158E-04

Epoch 25 of 100
  training loss:		1.199795E-04
  validation loss:		1.080485E-04

Epoch 26 of 100
  training loss:		1.060039E-04
  validation loss:		9.566666E-05

Epoch 27 of 100
  training loss:		9.169035E-05
  validation loss:		8.225506E-05

Epoch 28 of 100
  training loss:		7.950666E-05
  validation loss:		7.241328E-05

Epoch 29 of 100
  training loss:		7.035172E-05
  validation loss:		6.309213E-05

Epoch 30 of 100
  training loss:		6.135983E-05
  validation loss:		5.550385E-05

Epoch 31 of 100
  training loss:		5.336496E-05
  validation loss:		5.067086E-05

Epoch 32 of 100
  training loss:		4.594055E-05
  validation loss:		4.508684E-05

Epoch 33 of 100
  training loss:		3.942749E-05
  validation loss:		3.518024E-05

Epoch 34 of 100
  training loss:		3.392490E-05
  validation loss:		3.007569E-05

Epoch 35 of 100
  training loss:		2.894515E-05
  validation loss:		2.723056E-05

Epoch 36 of 100
  training loss:		2.478849E-05
  validation loss:		2.159249E-05

Epoch 37 of 100
  training loss:		2.114366E-05
  validation loss:		1.854626E-05

Epoch 38 of 100
  training loss:		1.822225E-05
  validation loss:		1.592841E-05

Epoch 39 of 100
  training loss:		1.545946E-05
  validation loss:		1.393273E-05

Epoch 40 of 100
  training loss:		1.345245E-05
  validation loss:		1.253269E-05

Epoch 41 of 100
  training loss:		1.168880E-05
  validation loss:		1.131779E-05

Epoch 42 of 100
  training loss:		1.030101E-05
  validation loss:		9.591102E-06

Epoch 43 of 100
  training loss:		9.057874E-06
  validation loss:		9.154515E-06

Epoch 44 of 100
  training loss:		8.033855E-06
  validation loss:		8.750018E-06

Epoch 45 of 100
  training loss:		7.005874E-06
  validation loss:		6.679974E-06

Epoch 46 of 100
  training loss:		6.234760E-06
  validation loss:		5.978493E-06

Epoch 47 of 100
  training loss:		5.298828E-06
  validation loss:		5.320770E-06

Epoch 48 of 100
  training loss:		4.724194E-06
  validation loss:		5.390320E-06

Epoch 49 of 100
  training loss:		4.252487E-06
  validation loss:		4.300011E-06

Epoch 50 of 100
  training loss:		3.768294E-06
  validation loss:		4.000982E-06

Epoch 51 of 100
  training loss:		3.362444E-06
  validation loss:		3.638395E-06

Epoch 52 of 100
  training loss:		3.156255E-06
  validation loss:		3.260955E-06

Epoch 53 of 100
  training loss:		2.840878E-06
  validation loss:		3.344906E-06

Epoch 54 of 100
  training loss:		2.616807E-06
  validation loss:		2.897739E-06

Epoch 55 of 100
  training loss:		2.418196E-06
  validation loss:		2.775831E-06

Epoch 56 of 100
  training loss:		2.194092E-06
  validation loss:		2.372319E-06

Epoch 57 of 100
  training loss:		2.027539E-06
  validation loss:		2.256562E-06

Epoch 58 of 100
  training loss:		1.873232E-06
  validation loss:		2.306946E-06

Epoch 59 of 100
  training loss:		1.774144E-06
  validation loss:		2.050586E-06

Epoch 60 of 100
  training loss:		1.657334E-06
  validation loss:		2.129176E-06

Epoch 61 of 100
  training loss:		1.624869E-06
  validation loss:		1.877262E-06

Epoch 62 of 100
  training loss:		1.409159E-06
  validation loss:		1.586028E-06

Epoch 63 of 100
  training loss:		1.281410E-06
  validation loss:		1.541082E-06

Epoch 64 of 100
  training loss:		1.213517E-06
  validation loss:		1.824756E-06

Epoch 65 of 100
  training loss:		1.272944E-06
  validation loss:		1.370252E-06

Epoch 66 of 100
  training loss:		1.026248E-06
  validation loss:		2.314349E-06

Epoch 67 of 100
  training loss:		1.010559E-06
  validation loss:		1.729313E-06

Epoch 68 of 100
  training loss:		9.352916E-07
  validation loss:		1.033993E-06

Epoch 69 of 100
  training loss:		8.418219E-07
  validation loss:		1.020849E-06

Epoch 70 of 100
  training loss:		8.051636E-07
  validation loss:		9.612384E-07

Epoch 71 of 100
  training loss:		7.339547E-07
  validation loss:		1.038459E-06

Epoch 72 of 100
  training loss:		7.374222E-07
  validation loss:		8.571675E-07

Epoch 73 of 100
  training loss:		7.077290E-07
  validation loss:		8.086937E-07

Epoch 74 of 100
  training loss:		6.216708E-07
  validation loss:		8.227456E-07

Epoch 75 of 100
  training loss:		5.583350E-07
  validation loss:		6.625569E-07

Epoch 76 of 100
  training loss:		5.687115E-07
  validation loss:		5.968159E-07

Epoch 77 of 100
  training loss:		5.200682E-07
  validation loss:		7.211066E-07

Epoch 78 of 100
  training loss:		4.944518E-07
  validation loss:		5.741201E-07

Epoch 79 of 100
  training loss:		4.361041E-07
  validation loss:		4.936840E-07

Epoch 80 of 100
  training loss:		4.282874E-07
  validation loss:		6.433707E-07

Epoch 81 of 100
  training loss:		4.273139E-07
  validation loss:		5.404182E-07

Epoch 82 of 100
  training loss:		3.840398E-07
  validation loss:		4.408827E-07

Epoch 83 of 100
  training loss:		3.696656E-07
  validation loss:		3.774813E-07

Epoch 84 of 100
  training loss:		3.243925E-07
  validation loss:		3.451883E-07

Epoch 85 of 100
  training loss:		2.788729E-07
  validation loss:		3.019593E-07

Epoch 86 of 100
  training loss:		2.740905E-07
  validation loss:		2.681633E-07

Epoch 87 of 100
  training loss:		2.895792E-07
  validation loss:		2.477856E-07

Epoch 88 of 100
  training loss:		2.274743E-07
  validation loss:		2.892351E-07

Epoch 89 of 100
  training loss:		2.291678E-07
  validation loss:		2.666196E-07

Epoch 90 of 100
  training loss:		1.892479E-07
  validation loss:		2.150779E-07

Epoch 91 of 100
  training loss:		1.954081E-07
  validation loss:		6.193805E-07

Epoch 92 of 100
  training loss:		1.899579E-07
  validation loss:		2.134805E-07

Epoch 93 of 100
  training loss:		1.630976E-07
  validation loss:		1.659543E-07

Epoch 94 of 100
  training loss:		1.545843E-07
  validation loss:		3.722533E-07

Epoch 95 of 100
  training loss:		1.280523E-07
  validation loss:		1.157429E-07

Epoch 96 of 100
  training loss:		1.306356E-07
  validation loss:		1.380623E-07

Epoch 97 of 100
  training loss:		1.134015E-07
  validation loss:		9.376016E-08

Epoch 98 of 100
  training loss:		1.179415E-07
  validation loss:		1.308289E-07

Epoch 99 of 100
  training loss:		8.735245E-08
  validation loss:		9.850558E-08

Epoch 100 of 100
  training loss:		8.158157E-08
  validation loss:		1.139765E-07

Training RMSE: 2.98563722618e-10
Validation RMSE: 3.30410232962e-10
