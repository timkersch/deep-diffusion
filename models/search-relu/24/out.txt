Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		7.087122E-04
  validation loss:		1.432491E-04

Epoch 2 of 100
  training loss:		4.939825E-05
  validation loss:		1.746045E-05

Epoch 3 of 100
  training loss:		2.694052E-05
  validation loss:		1.030668E-04

Epoch 4 of 100
  training loss:		1.838611E-05
  validation loss:		1.272513E-05

Epoch 5 of 100
  training loss:		1.774296E-05
  validation loss:		2.873850E-05

Epoch 6 of 100
  training loss:		2.933196E-05
  validation loss:		7.923078E-06

Epoch 7 of 100
  training loss:		1.517540E-05
  validation loss:		2.111888E-06

Epoch 8 of 100
  training loss:		1.287992E-05
  validation loss:		3.190666E-06

Epoch 9 of 100
  training loss:		2.248452E-05
  validation loss:		1.792203E-05

Epoch 10 of 100
  training loss:		5.899978E-05
  validation loss:		2.527307E-06

Epoch 11 of 100
  training loss:		4.266985E-06
  validation loss:		1.873081E-06

Epoch 12 of 100
  training loss:		6.375559E-05
  validation loss:		6.593154E-06

Epoch 13 of 100
  training loss:		2.855212E-06
  validation loss:		4.128732E-06

Epoch 14 of 100
  training loss:		2.654138E-06
  validation loss:		3.093640E-05

Epoch 15 of 100
  training loss:		4.873197E-06
  validation loss:		8.219381E-07

Epoch 16 of 100
  training loss:		4.266450E-05
  validation loss:		3.226582E-05

Epoch 17 of 100
  training loss:		5.561195E-06
  validation loss:		1.847931E-06

Epoch 18 of 100
  training loss:		4.164959E-06
  validation loss:		1.174373E-06

Epoch 19 of 100
  training loss:		2.517908E-05
  validation loss:		1.690541E-06

Epoch 20 of 100
  training loss:		2.582781E-06
  validation loss:		9.007697E-06

Epoch 21 of 100
  training loss:		6.055962E-06
  validation loss:		1.259540E-06

Epoch 22 of 100
  training loss:		7.908729E-06
  validation loss:		4.602748E-05

Epoch 23 of 100
  training loss:		8.255281E-06
  validation loss:		5.493385E-07

Epoch 24 of 100
  training loss:		1.419949E-05
  validation loss:		2.999801E-07

Epoch 25 of 100
  training loss:		2.236783E-06
  validation loss:		7.622015E-05

Epoch 26 of 100
  training loss:		1.155581E-05
  validation loss:		6.474772E-06

Epoch 27 of 100
  training loss:		5.180506E-06
  validation loss:		1.464147E-06

Epoch 28 of 100
  training loss:		1.250295E-05
  validation loss:		1.937494E-04

Epoch 29 of 100
  training loss:		2.720907E-05
  validation loss:		1.892576E-07

Epoch 30 of 100
  training loss:		2.877666E-07
  validation loss:		7.465029E-07

Early stopping, val-loss increased over the last 10 epochs from 0.000596241825283 to 0.00215807175925
Training RMSE: 4.13078567832e-10
Validation RMSE: 4.26071166779e-10
