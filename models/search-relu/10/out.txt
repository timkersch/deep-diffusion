Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		6.994949E-03
  validation loss:		1.564977E-04

Epoch 2 of 100
  training loss:		9.859625E-05
  validation loss:		7.065106E-05

Epoch 3 of 100
  training loss:		2.928233E-05
  validation loss:		1.289499E-05

Epoch 4 of 100
  training loss:		9.786378E-06
  validation loss:		4.541839E-06

Epoch 5 of 100
  training loss:		5.500603E-06
  validation loss:		2.103552E-06

Epoch 6 of 100
  training loss:		2.757193E-06
  validation loss:		3.809318E-06

Epoch 7 of 100
  training loss:		4.493012E-06
  validation loss:		1.736560E-06

Epoch 8 of 100
  training loss:		1.481504E-06
  validation loss:		5.378062E-07

Epoch 9 of 100
  training loss:		1.164773E-05
  validation loss:		3.214092E-07

Epoch 10 of 100
  training loss:		7.516415E-06
  validation loss:		2.909774E-07

Epoch 11 of 100
  training loss:		3.999575E-05
  validation loss:		1.315550E-05

Epoch 12 of 100
  training loss:		2.765667E-06
  validation loss:		9.589944E-07

Epoch 13 of 100
  training loss:		1.357573E-05
  validation loss:		2.179973E-07

Epoch 14 of 100
  training loss:		4.050891E-05
  validation loss:		2.928334E-06

Epoch 15 of 100
  training loss:		3.016567E-05
  validation loss:		2.293946E-07

Epoch 16 of 100
  training loss:		1.854333E-06
  validation loss:		4.213091E-06

Epoch 17 of 100
  training loss:		5.958094E-05
  validation loss:		1.241184E-06

Epoch 18 of 100
  training loss:		1.576177E-06
  validation loss:		3.927990E-07

Epoch 19 of 100
  training loss:		2.807057E-06
  validation loss:		4.363116E-06

Epoch 20 of 100
  training loss:		3.701648E-05
  validation loss:		4.409821E-04

Epoch 21 of 100
  training loss:		1.895933E-05
  validation loss:		1.678204E-06

Epoch 22 of 100
  training loss:		8.331733E-06
  validation loss:		9.152126E-07

Epoch 23 of 100
  training loss:		1.573169E-05
  validation loss:		7.591184E-05

Epoch 24 of 100
  training loss:		9.214232E-06
  validation loss:		5.431493E-06

Epoch 25 of 100
  training loss:		4.710530E-05
  validation loss:		4.288569E-04

Epoch 26 of 100
  training loss:		1.998478E-05
  validation loss:		1.477184E-06

Epoch 27 of 100
  training loss:		4.798093E-07
  validation loss:		4.495633E-07

Epoch 28 of 100
  training loss:		9.921540E-06
  validation loss:		2.377883E-07

Epoch 29 of 100
  training loss:		1.014637E-06
  validation loss:		2.766492E-07

Epoch 30 of 100
  training loss:		2.166650E-05
  validation loss:		9.148210E-06

Epoch 31 of 100
  training loss:		1.263743E-06
  validation loss:		1.038815E-05

Epoch 32 of 100
  training loss:		2.916826E-05
  validation loss:		7.476208E-06

Epoch 33 of 100
  training loss:		1.147916E-06
  validation loss:		3.094684E-07

Epoch 34 of 100
  training loss:		2.188004E-06
  validation loss:		2.210514E-06

Epoch 35 of 100
  training loss:		3.990978E-05
  validation loss:		8.857620E-06

Epoch 36 of 100
  training loss:		1.011311E-06
  validation loss:		4.947734E-07

Epoch 37 of 100
  training loss:		4.174122E-07
  validation loss:		1.842013E-07

Epoch 38 of 100
  training loss:		2.545661E-05
  validation loss:		1.043558E-05

Epoch 39 of 100
  training loss:		1.662448E-06
  validation loss:		9.664878E-07

Epoch 40 of 100
  training loss:		6.156586E-07
  validation loss:		5.455285E-07

Epoch 41 of 100
  training loss:		8.816043E-06
  validation loss:		2.429722E-07

Epoch 42 of 100
  training loss:		4.818694E-07
  validation loss:		9.432958E-07

Epoch 43 of 100
  training loss:		5.541196E-05
  validation loss:		3.145491E-06

Epoch 44 of 100
  training loss:		2.230764E-06
  validation loss:		4.257289E-06

Epoch 45 of 100
  training loss:		8.135914E-07
  validation loss:		3.351836E-07

Epoch 46 of 100
  training loss:		9.884218E-07
  validation loss:		4.096837E-07

Epoch 47 of 100
  training loss:		4.186508E-06
  validation loss:		4.544619E-06

Epoch 48 of 100
  training loss:		2.966187E-06
  validation loss:		1.911535E-06

Epoch 49 of 100
  training loss:		4.534414E-06
  validation loss:		8.722418E-07

Epoch 50 of 100
  training loss:		1.162481E-06
  validation loss:		1.316101E-05

Epoch 51 of 100
  training loss:		1.465668E-05
  validation loss:		2.929788E-07

Epoch 52 of 100
  training loss:		1.158580E-07
  validation loss:		1.210910E-08

Epoch 53 of 100
  training loss:		7.867694E-07
  validation loss:		3.837769E-07

Epoch 54 of 100
  training loss:		1.133731E-05
  validation loss:		4.607136E-05

Epoch 55 of 100
  training loss:		3.493088E-06
  validation loss:		7.412607E-08

Epoch 56 of 100
  training loss:		2.795960E-07
  validation loss:		6.095192E-07

Epoch 57 of 100
  training loss:		1.613407E-06
  validation loss:		3.526086E-06

Epoch 58 of 100
  training loss:		7.597703E-06
  validation loss:		2.864772E-07

Epoch 59 of 100
  training loss:		3.684203E-06
  validation loss:		1.536949E-06

Epoch 60 of 100
  training loss:		3.043447E-07
  validation loss:		5.283883E-08

Epoch 61 of 100
  training loss:		2.029357E-05
  validation loss:		3.156110E-06

Epoch 62 of 100
  training loss:		1.842349E-07
  validation loss:		4.183288E-09

Epoch 63 of 100
  training loss:		2.234685E-09
  validation loss:		1.948939E-10

Epoch 64 of 100
  training loss:		2.712723E-09
  validation loss:		2.870546E-09

Epoch 65 of 100
  training loss:		2.723316E-06
  validation loss:		7.246206E-07

Epoch 66 of 100
  training loss:		3.260054E-06
  validation loss:		4.148105E-08

Epoch 67 of 100
  training loss:		2.523412E-07
  validation loss:		9.695713E-08

Epoch 68 of 100
  training loss:		6.722307E-06
  validation loss:		1.266694E-07

Epoch 69 of 100
  training loss:		1.913238E-06
  validation loss:		2.846012E-06

Epoch 70 of 100
  training loss:		4.200545E-06
  validation loss:		3.766586E-09

Epoch 71 of 100
  training loss:		9.387708E-08
  validation loss:		7.324350E-07

Epoch 72 of 100
  training loss:		4.028205E-06
  validation loss:		6.618906E-08

Epoch 73 of 100
  training loss:		2.272196E-06
  validation loss:		1.892691E-09

Epoch 74 of 100
  training loss:		1.205643E-06
  validation loss:		2.730560E-06

Epoch 75 of 100
  training loss:		9.824204E-06
  validation loss:		1.691715E-08

Epoch 76 of 100
  training loss:		4.000053E-08
  validation loss:		3.973085E-09

Epoch 77 of 100
  training loss:		3.974801E-07
  validation loss:		1.248729E-08

Epoch 78 of 100
  training loss:		7.210461E-08
  validation loss:		8.994746E-07

Epoch 79 of 100
  training loss:		6.009628E-06
  validation loss:		1.531363E-07

Epoch 80 of 100
  training loss:		2.544998E-07
  validation loss:		2.512380E-07

Epoch 81 of 100
  training loss:		1.181299E-07
  validation loss:		1.339372E-07

Epoch 82 of 100
  training loss:		5.368888E-06
  validation loss:		3.277813E-08

Epoch 83 of 100
  training loss:		1.339967E-07
  validation loss:		9.712648E-08

Epoch 84 of 100
  training loss:		5.818862E-06
  validation loss:		1.943861E-08

Epoch 85 of 100
  training loss:		2.903651E-09
  validation loss:		1.560237E-11

Epoch 86 of 100
  training loss:		5.292081E-06
  validation loss:		4.762342E-05

Epoch 87 of 100
  training loss:		1.557246E-06
  validation loss:		1.132020E-08

Epoch 88 of 100
  training loss:		4.399951E-09
  validation loss:		8.475614E-09

Epoch 89 of 100
  training loss:		1.345346E-06
  validation loss:		1.159483E-07

Epoch 90 of 100
  training loss:		2.579612E-08
  validation loss:		1.240098E-08

Epoch 91 of 100
  training loss:		5.978564E-06
  validation loss:		1.268342E-07

Epoch 92 of 100
  training loss:		8.975767E-07
  validation loss:		3.729149E-08

Epoch 93 of 100
  training loss:		1.558574E-08
  validation loss:		2.847363E-10

Epoch 94 of 100
  training loss:		1.010283E-05
  validation loss:		3.367004E-07

Epoch 95 of 100
  training loss:		6.282085E-08
  validation loss:		3.744418E-11

Epoch 96 of 100
  training loss:		4.495019E-12
  validation loss:		1.163039E-14

Epoch 97 of 100
  training loss:		3.094409E-15
  validation loss:		3.346218E-15

Epoch 98 of 100
  training loss:		5.508102E-16
  validation loss:		2.960634E-16

Epoch 99 of 100
  training loss:		1.744127E-16
  validation loss:		1.063382E-16

Epoch 100 of 100
  training loss:		7.013117E-17
  validation loss:		4.536962E-17

Training RMSE: 1.82407996188e-14
Validation RMSE: 1.81771302848e-14
