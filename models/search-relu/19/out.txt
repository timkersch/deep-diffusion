Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.393071E-03
  validation loss:		7.912680E-05

Epoch 2 of 100
  training loss:		2.367378E-05
  validation loss:		3.647552E-06

Epoch 3 of 100
  training loss:		4.384093E-06
  validation loss:		8.566009E-06

Epoch 4 of 100
  training loss:		8.483556E-05
  validation loss:		1.673623E-06

Epoch 5 of 100
  training loss:		6.567220E-06
  validation loss:		6.373805E-07

Epoch 6 of 100
  training loss:		5.691862E-05
  validation loss:		4.178309E-06

Epoch 7 of 100
  training loss:		9.543562E-05
  validation loss:		1.558381E-05

Epoch 8 of 100
  training loss:		3.491358E-06
  validation loss:		2.881482E-06

Epoch 9 of 100
  training loss:		1.301292E-05
  validation loss:		2.550397E-06

Epoch 10 of 100
  training loss:		3.763475E-05
  validation loss:		3.152321E-07

Epoch 11 of 100
  training loss:		2.473318E-05
  validation loss:		1.109272E-04

Epoch 12 of 100
  training loss:		3.361387E-05
  validation loss:		8.603467E-07

Epoch 13 of 100
  training loss:		4.335079E-05
  validation loss:		5.968815E-06

Epoch 14 of 100
  training loss:		2.260880E-06
  validation loss:		1.452990E-07

Epoch 15 of 100
  training loss:		6.216336E-05
  validation loss:		2.179005E-06

Epoch 16 of 100
  training loss:		3.838738E-06
  validation loss:		5.320941E-06

Epoch 17 of 100
  training loss:		3.214242E-05
  validation loss:		2.879929E-06

Epoch 18 of 100
  training loss:		2.811095E-06
  validation loss:		2.900113E-05

Epoch 19 of 100
  training loss:		1.364987E-05
  validation loss:		1.019062E-06

Epoch 20 of 100
  training loss:		1.182283E-05
  validation loss:		5.834918E-06

Early stopping, val-loss increased over the last 10 epochs from 0.00157291981147 to 0.00216660344264
Training RMSE: 1.00132624541e-09
Validation RMSE: 9.91837968236e-10
