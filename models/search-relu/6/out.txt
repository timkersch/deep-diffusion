Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.233363E-01
  validation loss:		1.189498E-02

Epoch 2 of 100
  training loss:		5.760194E-03
  validation loss:		4.055711E-03

Epoch 3 of 100
  training loss:		3.429299E-03
  validation loss:		3.041826E-03

Epoch 4 of 100
  training loss:		2.679500E-03
  validation loss:		2.416331E-03

Epoch 5 of 100
  training loss:		2.163425E-03
  validation loss:		1.960947E-03

Epoch 6 of 100
  training loss:		1.744876E-03
  validation loss:		1.580130E-03

Epoch 7 of 100
  training loss:		1.421754E-03
  validation loss:		1.303561E-03

Epoch 8 of 100
  training loss:		1.176576E-03
  validation loss:		1.074136E-03

Epoch 9 of 100
  training loss:		9.802118E-04
  validation loss:		8.962417E-04

Epoch 10 of 100
  training loss:		8.321053E-04
  validation loss:		7.733405E-04

Epoch 11 of 100
  training loss:		7.190540E-04
  validation loss:		6.599888E-04

Epoch 12 of 100
  training loss:		6.230671E-04
  validation loss:		5.758415E-04

Epoch 13 of 100
  training loss:		5.473522E-04
  validation loss:		5.048593E-04

Epoch 14 of 100
  training loss:		4.873963E-04
  validation loss:		4.530617E-04

Epoch 15 of 100
  training loss:		4.394470E-04
  validation loss:		4.043054E-04

Epoch 16 of 100
  training loss:		3.949794E-04
  validation loss:		3.621660E-04

Epoch 17 of 100
  training loss:		3.559995E-04
  validation loss:		3.299094E-04

Epoch 18 of 100
  training loss:		3.212998E-04
  validation loss:		2.979910E-04

Epoch 19 of 100
  training loss:		2.945271E-04
  validation loss:		2.716267E-04

Epoch 20 of 100
  training loss:		2.706146E-04
  validation loss:		2.491077E-04

Epoch 21 of 100
  training loss:		2.477154E-04
  validation loss:		2.282332E-04

Epoch 22 of 100
  training loss:		2.263469E-04
  validation loss:		2.077350E-04

Epoch 23 of 100
  training loss:		2.061696E-04
  validation loss:		1.855896E-04

Epoch 24 of 100
  training loss:		1.862282E-04
  validation loss:		1.671038E-04

Epoch 25 of 100
  training loss:		1.651164E-04
  validation loss:		1.481554E-04

Epoch 26 of 100
  training loss:		1.473197E-04
  validation loss:		1.361588E-04

Epoch 27 of 100
  training loss:		1.310281E-04
  validation loss:		1.140888E-04

Epoch 28 of 100
  training loss:		1.139285E-04
  validation loss:		1.004318E-04

Epoch 29 of 100
  training loss:		9.902803E-05
  validation loss:		8.833351E-05

Epoch 30 of 100
  training loss:		8.501816E-05
  validation loss:		7.710328E-05

Epoch 31 of 100
  training loss:		7.273648E-05
  validation loss:		6.426373E-05

Epoch 32 of 100
  training loss:		6.248056E-05
  validation loss:		5.408412E-05

Epoch 33 of 100
  training loss:		5.326099E-05
  validation loss:		4.763495E-05

Epoch 34 of 100
  training loss:		4.438193E-05
  validation loss:		3.829266E-05

Epoch 35 of 100
  training loss:		3.724349E-05
  validation loss:		3.195500E-05

Epoch 36 of 100
  training loss:		3.133290E-05
  validation loss:		2.720287E-05

Epoch 37 of 100
  training loss:		2.627475E-05
  validation loss:		2.247454E-05

Epoch 38 of 100
  training loss:		2.195045E-05
  validation loss:		1.884743E-05

Epoch 39 of 100
  training loss:		1.813568E-05
  validation loss:		1.584474E-05

Epoch 40 of 100
  training loss:		1.489131E-05
  validation loss:		1.270908E-05

Epoch 41 of 100
  training loss:		1.284001E-05
  validation loss:		1.111795E-05

Epoch 42 of 100
  training loss:		1.063455E-05
  validation loss:		9.674981E-06

Epoch 43 of 100
  training loss:		9.083323E-06
  validation loss:		8.371841E-06

Epoch 44 of 100
  training loss:		8.010901E-06
  validation loss:		7.069949E-06

Epoch 45 of 100
  training loss:		6.650828E-06
  validation loss:		6.621558E-06

Epoch 46 of 100
  training loss:		5.850527E-06
  validation loss:		6.020910E-06

Epoch 47 of 100
  training loss:		5.162855E-06
  validation loss:		4.790113E-06

Epoch 48 of 100
  training loss:		4.206044E-06
  validation loss:		3.795167E-06

Epoch 49 of 100
  training loss:		3.661560E-06
  validation loss:		3.661392E-06

Epoch 50 of 100
  training loss:		3.166142E-06
  validation loss:		3.110913E-06

Epoch 51 of 100
  training loss:		2.846737E-06
  validation loss:		3.028382E-06

Epoch 52 of 100
  training loss:		2.545691E-06
  validation loss:		2.309467E-06

Epoch 53 of 100
  training loss:		2.264759E-06
  validation loss:		2.164878E-06

Epoch 54 of 100
  training loss:		2.134422E-06
  validation loss:		2.535492E-06

Epoch 55 of 100
  training loss:		1.921978E-06
  validation loss:		1.818201E-06

Epoch 56 of 100
  training loss:		1.705039E-06
  validation loss:		1.642932E-06

Epoch 57 of 100
  training loss:		1.595718E-06
  validation loss:		1.528159E-06

Epoch 58 of 100
  training loss:		1.493172E-06
  validation loss:		1.616436E-06

Epoch 59 of 100
  training loss:		1.424976E-06
  validation loss:		1.363371E-06

Epoch 60 of 100
  training loss:		1.285591E-06
  validation loss:		1.500808E-06

Epoch 61 of 100
  training loss:		1.206973E-06
  validation loss:		1.310011E-06

Epoch 62 of 100
  training loss:		1.247719E-06
  validation loss:		1.107456E-06

Epoch 63 of 100
  training loss:		1.019607E-06
  validation loss:		1.263482E-06

Epoch 64 of 100
  training loss:		9.628529E-07
  validation loss:		9.231948E-07

Epoch 65 of 100
  training loss:		9.576531E-07
  validation loss:		8.795089E-07

Epoch 66 of 100
  training loss:		8.724437E-07
  validation loss:		8.778623E-07

Epoch 67 of 100
  training loss:		8.326578E-07
  validation loss:		1.460768E-06

Epoch 68 of 100
  training loss:		8.818609E-07
  validation loss:		9.553544E-07

Epoch 69 of 100
  training loss:		7.173803E-07
  validation loss:		7.752489E-07

Epoch 70 of 100
  training loss:		6.761885E-07
  validation loss:		8.222415E-07

Epoch 71 of 100
  training loss:		7.582570E-07
  validation loss:		6.429013E-07

Epoch 72 of 100
  training loss:		6.203811E-07
  validation loss:		7.029860E-07

Epoch 73 of 100
  training loss:		6.199992E-07
  validation loss:		6.215108E-07

Epoch 74 of 100
  training loss:		5.458403E-07
  validation loss:		5.012833E-07

Epoch 75 of 100
  training loss:		5.278564E-07
  validation loss:		7.742601E-07

Epoch 76 of 100
  training loss:		5.005733E-07
  validation loss:		4.587517E-07

Epoch 77 of 100
  training loss:		4.836930E-07
  validation loss:		4.232856E-07

Epoch 78 of 100
  training loss:		4.498874E-07
  validation loss:		4.005029E-07

Epoch 79 of 100
  training loss:		4.090906E-07
  validation loss:		3.874186E-07

Epoch 80 of 100
  training loss:		4.365799E-07
  validation loss:		1.020109E-06

Epoch 81 of 100
  training loss:		3.920545E-07
  validation loss:		3.948927E-07

Epoch 82 of 100
  training loss:		3.234298E-07
  validation loss:		3.284040E-07

Epoch 83 of 100
  training loss:		3.082235E-07
  validation loss:		2.910472E-07

Epoch 84 of 100
  training loss:		2.949571E-07
  validation loss:		2.618401E-07

Epoch 85 of 100
  training loss:		2.751190E-07
  validation loss:		2.460081E-07

Epoch 86 of 100
  training loss:		2.538564E-07
  validation loss:		2.649844E-07

Epoch 87 of 100
  training loss:		2.320495E-07
  validation loss:		2.675953E-07

Epoch 88 of 100
  training loss:		2.538857E-07
  validation loss:		3.862583E-07

Epoch 89 of 100
  training loss:		1.907684E-07
  validation loss:		1.879292E-07

Epoch 90 of 100
  training loss:		1.782691E-07
  validation loss:		1.571202E-07

Epoch 91 of 100
  training loss:		1.972379E-07
  validation loss:		1.532059E-07

Epoch 92 of 100
  training loss:		1.785757E-07
  validation loss:		1.544973E-07

Epoch 93 of 100
  training loss:		1.405253E-07
  validation loss:		2.520684E-07

Epoch 94 of 100
  training loss:		1.410001E-07
  validation loss:		1.312437E-07

Epoch 95 of 100
  training loss:		9.294508E-08
  validation loss:		6.953114E-08

Epoch 96 of 100
  training loss:		1.042530E-07
  validation loss:		9.478639E-08

Epoch 97 of 100
  training loss:		8.227374E-08
  validation loss:		1.389622E-07

Epoch 98 of 100
  training loss:		7.311738E-08
  validation loss:		5.086294E-08

Epoch 99 of 100
  training loss:		5.518537E-08
  validation loss:		4.241079E-08

Epoch 100 of 100
  training loss:		5.446261E-08
  validation loss:		4.361955E-08

Training RMSE: 1.90233738116e-10
Validation RMSE: 2.04276617509e-10
