Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.918991E-03
  validation loss:		1.271726E-04

Epoch 2 of 100
  training loss:		8.771564E-05
  validation loss:		1.021032E-04

Epoch 3 of 100
  training loss:		3.993220E-05
  validation loss:		1.892927E-05

Epoch 4 of 100
  training loss:		2.116450E-05
  validation loss:		1.746732E-05

Epoch 5 of 100
  training loss:		1.913435E-05
  validation loss:		1.265882E-05

Epoch 6 of 100
  training loss:		7.608230E-06
  validation loss:		4.427861E-06

Epoch 7 of 100
  training loss:		4.587714E-06
  validation loss:		5.807537E-06

Epoch 8 of 100
  training loss:		1.141724E-05
  validation loss:		2.603374E-06

Epoch 9 of 100
  training loss:		2.355461E-05
  validation loss:		1.436795E-06

Epoch 10 of 100
  training loss:		1.171290E-05
  validation loss:		3.316701E-05

Epoch 11 of 100
  training loss:		1.121458E-05
  validation loss:		2.772787E-06

Epoch 12 of 100
  training loss:		1.319145E-05
  validation loss:		2.736005E-05

Epoch 13 of 100
  training loss:		3.115358E-06
  validation loss:		1.598096E-05

Epoch 14 of 100
  training loss:		2.741240E-05
  validation loss:		9.156368E-06

Epoch 15 of 100
  training loss:		6.049244E-06
  validation loss:		1.229041E-05

Epoch 16 of 100
  training loss:		9.599601E-06
  validation loss:		2.219394E-06

Epoch 17 of 100
  training loss:		9.977967E-05
  validation loss:		3.365200E-05

Epoch 18 of 100
  training loss:		9.614016E-06
  validation loss:		4.044336E-07

Epoch 19 of 100
  training loss:		3.437468E-07
  validation loss:		9.694705E-07

Epoch 20 of 100
  training loss:		4.282147E-07
  validation loss:		5.335119E-07

Epoch 21 of 100
  training loss:		8.001211E-07
  validation loss:		2.536300E-07

Epoch 22 of 100
  training loss:		7.481526E-06
  validation loss:		2.516479E-04

Epoch 23 of 100
  training loss:		4.735962E-05
  validation loss:		4.913822E-06

Epoch 24 of 100
  training loss:		3.128106E-06
  validation loss:		2.776593E-07

Epoch 25 of 100
  training loss:		2.123201E-07
  validation loss:		1.022871E-07

Epoch 26 of 100
  training loss:		9.599251E-07
  validation loss:		4.301013E-07

Epoch 27 of 100
  training loss:		3.566298E-05
  validation loss:		5.824782E-07

Epoch 28 of 100
  training loss:		2.127549E-06
  validation loss:		1.071967E-07

Epoch 29 of 100
  training loss:		8.436247E-06
  validation loss:		6.608610E-07

Epoch 30 of 100
  training loss:		3.167151E-06
  validation loss:		9.029799E-07

Early stopping, val-loss increased over the last 10 epochs from 0.000347619972403 to 0.000857600522685
Training RMSE: 7.82473472028e-10
Validation RMSE: 7.97492816988e-10
