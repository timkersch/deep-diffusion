Epoch 1 of 500
  training loss:		1.558774E-02
  validation loss:		1.906964E-03

Epoch 2 of 500
  training loss:		6.613058E-04
  validation loss:		2.623808E-04

Epoch 3 of 500
  training loss:		2.104346E-04
  validation loss:		2.007467E-04

Epoch 4 of 500
  training loss:		1.770663E-04
  validation loss:		3.584113E-04

Epoch 5 of 500
  training loss:		1.427518E-04
  validation loss:		1.078462E-04

Epoch 6 of 500
  training loss:		1.191900E-04
  validation loss:		1.546675E-04

Epoch 7 of 500
  training loss:		1.109760E-04
  validation loss:		1.635958E-04

Epoch 8 of 500
  training loss:		9.350632E-05
  validation loss:		2.843944E-05

Epoch 9 of 500
  training loss:		8.219553E-05
  validation loss:		3.426075E-05

Epoch 10 of 500
  training loss:		7.833891E-05
  validation loss:		1.639359E-04

Epoch 11 of 500
  training loss:		6.983513E-05
  validation loss:		2.371360E-04

Epoch 12 of 500
  training loss:		7.435299E-05
  validation loss:		1.280458E-05

Epoch 13 of 500
  training loss:		6.619444E-05
  validation loss:		3.536836E-05

Epoch 14 of 500
  training loss:		6.342423E-05
  validation loss:		9.094640E-06

Epoch 15 of 500
  training loss:		6.131678E-05
  validation loss:		3.694264E-05

Epoch 16 of 500
  training loss:		6.162444E-05
  validation loss:		8.279267E-06

Epoch 17 of 500
  training loss:		5.843297E-05
  validation loss:		7.942106E-05

Epoch 18 of 500
  training loss:		5.295284E-05
  validation loss:		1.955665E-05

Epoch 19 of 500
  training loss:		5.017795E-05
  validation loss:		1.725772E-04

Epoch 20 of 500
  training loss:		5.583103E-05
  validation loss:		2.657625E-05

Epoch 21 of 500
  training loss:		4.785499E-05
  validation loss:		1.136690E-05

Epoch 22 of 500
  training loss:		4.786752E-05
  validation loss:		1.605613E-04

Epoch 23 of 500
  training loss:		4.917528E-05
  validation loss:		7.212026E-06

Epoch 24 of 500
  training loss:		4.975362E-05
  validation loss:		8.419935E-06

Epoch 25 of 500
  training loss:		4.603262E-05
  validation loss:		1.221255E-05

Epoch 26 of 500
  training loss:		4.554513E-05
  validation loss:		2.142771E-05

Epoch 27 of 500
  training loss:		4.373009E-05
  validation loss:		2.378012E-05

Epoch 28 of 500
  training loss:		4.127174E-05
  validation loss:		1.592348E-05

Epoch 29 of 500
  training loss:		4.208981E-05
  validation loss:		1.479770E-05

Epoch 30 of 500
  training loss:		4.097680E-05
  validation loss:		5.499841E-05

Epoch 31 of 500
  training loss:		3.980168E-05
  validation loss:		2.548878E-05

Epoch 32 of 500
  training loss:		3.646870E-05
  validation loss:		6.730877E-05

Epoch 33 of 500
  training loss:		3.611234E-05
  validation loss:		4.439602E-05

Epoch 34 of 500
  training loss:		3.647507E-05
  validation loss:		9.498218E-05

Epoch 35 of 500
  training loss:		3.733025E-05
  validation loss:		2.923864E-06

Epoch 36 of 500
  training loss:		3.279661E-05
  validation loss:		4.285207E-06

Epoch 37 of 500
  training loss:		3.127370E-05
  validation loss:		3.242816E-06

Epoch 38 of 500
  training loss:		3.342231E-05
  validation loss:		4.941660E-06

Epoch 39 of 500
  training loss:		2.759227E-05
  validation loss:		1.255478E-05

Epoch 40 of 500
  training loss:		2.631792E-05
  validation loss:		6.358811E-06

Epoch 41 of 500
  training loss:		2.848470E-05
  validation loss:		1.025876E-05

Epoch 42 of 500
  training loss:		2.621482E-05
  validation loss:		2.146413E-06

Epoch 43 of 500
  training loss:		2.494805E-05
  validation loss:		3.589765E-06

Epoch 44 of 500
  training loss:		2.881526E-05
  validation loss:		1.919561E-05

Epoch 45 of 500
  training loss:		1.912114E-05
  validation loss:		2.949553E-05

Epoch 46 of 500
  training loss:		2.455164E-05
  validation loss:		4.580615E-06

Epoch 47 of 500
  training loss:		1.924256E-05
  validation loss:		5.883279E-06

Epoch 48 of 500
  training loss:		2.205996E-05
  validation loss:		6.758872E-05

Epoch 49 of 500
  training loss:		1.970639E-05
  validation loss:		1.175010E-05

Epoch 50 of 500
  training loss:		1.726682E-05
  validation loss:		4.107487E-06

Epoch 51 of 500
  training loss:		1.862730E-05
  validation loss:		7.459075E-06

Epoch 52 of 500
  training loss:		2.077069E-05
  validation loss:		1.459112E-05

Epoch 53 of 500
  training loss:		1.481551E-05
  validation loss:		2.423142E-06

Epoch 54 of 500
  training loss:		1.629373E-05
  validation loss:		7.749403E-05

Epoch 55 of 500
  training loss:		1.638673E-05
  validation loss:		2.109738E-05

Epoch 56 of 500
  training loss:		1.415168E-05
  validation loss:		2.370132E-05

Epoch 57 of 500
  training loss:		1.495251E-05
  validation loss:		1.492353E-06

Epoch 58 of 500
  training loss:		1.198317E-05
  validation loss:		2.759326E-05

Epoch 59 of 500
  training loss:		1.488668E-05
  validation loss:		4.161262E-06

Epoch 60 of 500
  training loss:		1.247960E-05
  validation loss:		3.895449E-06

Epoch 61 of 500
  training loss:		1.282667E-05
  validation loss:		1.423152E-06

Epoch 62 of 500
  training loss:		1.033193E-05
  validation loss:		2.072359E-06

Epoch 63 of 500
  training loss:		1.184233E-05
  validation loss:		4.238557E-06

Epoch 64 of 500
  training loss:		1.316026E-05
  validation loss:		6.704955E-06

Epoch 65 of 500
  training loss:		1.124400E-05
  validation loss:		2.167257E-06

Epoch 66 of 500
  training loss:		9.855883E-06
  validation loss:		6.641008E-05

Epoch 67 of 500
  training loss:		8.997006E-06
  validation loss:		2.692983E-06

Epoch 68 of 500
  training loss:		1.083773E-05
  validation loss:		1.136455E-06

Epoch 69 of 500
  training loss:		8.847139E-06
  validation loss:		5.944838E-06

Epoch 70 of 500
  training loss:		8.002927E-06
  validation loss:		5.376624E-06

Epoch 71 of 500
  training loss:		8.938877E-06
  validation loss:		1.682080E-05

Epoch 72 of 500
  training loss:		9.012372E-06
  validation loss:		3.593875E-05

Epoch 73 of 500
  training loss:		6.604308E-06
  validation loss:		1.543572E-06

Epoch 74 of 500
  training loss:		8.166565E-06
  validation loss:		1.151956E-05

Epoch 75 of 500
  training loss:		8.057521E-06
  validation loss:		3.941682E-05

Epoch 76 of 500
  training loss:		6.145087E-06
  validation loss:		3.376206E-06

Epoch 77 of 500
  training loss:		8.436745E-06
  validation loss:		4.090468E-06

Epoch 78 of 500
  training loss:		9.110825E-06
  validation loss:		1.440880E-06

Epoch 79 of 500
  training loss:		5.102351E-06
  validation loss:		8.142460E-06

Epoch 80 of 500
  training loss:		6.125238E-06
  validation loss:		1.509747E-06

Epoch 81 of 500
  training loss:		8.175460E-06
  validation loss:		8.123266E-07

Epoch 82 of 500
  training loss:		5.088755E-06
  validation loss:		6.859452E-07

Epoch 83 of 500
  training loss:		5.529790E-06
  validation loss:		5.647871E-06

Epoch 84 of 500
  training loss:		6.374506E-06
  validation loss:		4.595520E-06

Epoch 85 of 500
  training loss:		4.997496E-06
  validation loss:		2.093111E-06

Epoch 86 of 500
  training loss:		8.048493E-06
  validation loss:		2.967989E-06

Epoch 87 of 500
  training loss:		5.792673E-06
  validation loss:		2.832398E-06

Epoch 88 of 500
  training loss:		5.352343E-06
  validation loss:		1.399986E-06

Epoch 89 of 500
  training loss:		4.596690E-06
  validation loss:		2.533954E-06

Epoch 90 of 500
  training loss:		5.505757E-06
  validation loss:		4.491233E-06

Epoch 91 of 500
  training loss:		4.634837E-06
  validation loss:		4.790491E-07

Epoch 92 of 500
  training loss:		4.281048E-06
  validation loss:		1.625987E-06

Epoch 93 of 500
  training loss:		4.961727E-06
  validation loss:		1.254873E-05

Epoch 94 of 500
  training loss:		4.114206E-06
  validation loss:		2.504348E-06

Epoch 95 of 500
  training loss:		5.431057E-06
  validation loss:		5.899643E-06

Epoch 96 of 500
  training loss:		5.388054E-06
  validation loss:		3.958299E-06

Epoch 97 of 500
  training loss:		7.261422E-06
  validation loss:		3.943937E-06

Epoch 98 of 500
  training loss:		7.442744E-06
  validation loss:		6.205488E-07

Epoch 99 of 500
  training loss:		2.660792E-06
  validation loss:		4.890998E-07

Epoch 100 of 500
  training loss:		5.552079E-06
  validation loss:		1.769368E-06

Epoch 101 of 500
  training loss:		5.606962E-06
  validation loss:		2.653658E-06

Epoch 102 of 500
  training loss:		4.419105E-06
  validation loss:		3.479314E-07

Epoch 103 of 500
  training loss:		5.283350E-06
  validation loss:		3.239092E-05

Epoch 104 of 500
  training loss:		3.198778E-06
  validation loss:		3.621327E-07

Epoch 105 of 500
  training loss:		4.849667E-06
  validation loss:		7.380832E-06

Epoch 106 of 500
  training loss:		4.568752E-06
  validation loss:		8.253075E-07

Epoch 107 of 500
  training loss:		3.210223E-06
  validation loss:		1.450546E-06

Epoch 108 of 500
  training loss:		4.305348E-06
  validation loss:		2.212847E-06

Epoch 109 of 500
  training loss:		4.263561E-06
  validation loss:		2.717533E-07

Epoch 110 of 500
  training loss:		6.044673E-06
  validation loss:		9.581603E-07

Epoch 111 of 500
  training loss:		4.281945E-06
  validation loss:		5.309865E-07

Epoch 112 of 500
  training loss:		3.156811E-06
  validation loss:		3.040196E-06

Epoch 113 of 500
  training loss:		3.736261E-06
  validation loss:		5.307306E-06

Epoch 114 of 500
  training loss:		4.769905E-06
  validation loss:		2.078726E-06

Epoch 115 of 500
  training loss:		5.062669E-06
  validation loss:		6.618470E-06

Epoch 116 of 500
  training loss:		2.849086E-06
  validation loss:		1.726849E-06

Epoch 117 of 500
  training loss:		4.688481E-06
  validation loss:		1.377704E-06

Epoch 118 of 500
  training loss:		3.745230E-06
  validation loss:		3.468222E-07

Epoch 119 of 500
  training loss:		3.139848E-06
  validation loss:		3.457552E-07

Epoch 120 of 500
  training loss:		3.434925E-06
  validation loss:		4.326920E-07

Early stopping, val-loss increased over the last 20 epochs from 0.00109252343118 to 0.0012471418568
Training RMSE: 5.73308271958e-10
Validation RMSE: 5.76949592586e-10
