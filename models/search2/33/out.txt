Epoch 1 of 500
  training loss:		8.915220E-02
  validation loss:		7.367944E-02

Epoch 2 of 500
  training loss:		6.457855E-02
  validation loss:		5.489962E-02

Epoch 3 of 500
  training loss:		4.302482E-02
  validation loss:		3.140698E-02

Epoch 4 of 500
  training loss:		2.243758E-02
  validation loss:		1.535147E-02

Epoch 5 of 500
  training loss:		1.194903E-02
  validation loss:		9.592539E-03

Epoch 6 of 500
  training loss:		8.909690E-03
  validation loss:		8.120839E-03

Epoch 7 of 500
  training loss:		7.937316E-03
  validation loss:		7.404162E-03

Epoch 8 of 500
  training loss:		7.340910E-03
  validation loss:		6.877508E-03

Epoch 9 of 500
  training loss:		6.781595E-03
  validation loss:		6.384318E-03

Epoch 10 of 500
  training loss:		6.262279E-03
  validation loss:		5.788494E-03

Epoch 11 of 500
  training loss:		5.729603E-03
  validation loss:		5.260306E-03

Epoch 12 of 500
  training loss:		5.169020E-03
  validation loss:		4.798655E-03

Epoch 13 of 500
  training loss:		4.661547E-03
  validation loss:		4.346570E-03

Epoch 14 of 500
  training loss:		4.173615E-03
  validation loss:		3.833585E-03

Epoch 15 of 500
  training loss:		3.732173E-03
  validation loss:		3.408822E-03

Epoch 16 of 500
  training loss:		3.331593E-03
  validation loss:		3.079378E-03

Epoch 17 of 500
  training loss:		2.996049E-03
  validation loss:		2.973771E-03

Epoch 18 of 500
  training loss:		2.696093E-03
  validation loss:		2.481100E-03

Epoch 19 of 500
  training loss:		2.443463E-03
  validation loss:		2.259238E-03

Epoch 20 of 500
  training loss:		2.247542E-03
  validation loss:		2.080661E-03

Epoch 21 of 500
  training loss:		2.069217E-03
  validation loss:		1.964534E-03

Epoch 22 of 500
  training loss:		1.907070E-03
  validation loss:		1.788624E-03

Epoch 23 of 500
  training loss:		1.752906E-03
  validation loss:		1.615277E-03

Epoch 24 of 500
  training loss:		1.529982E-03
  validation loss:		1.339207E-03

Epoch 25 of 500
  training loss:		1.232332E-03
  validation loss:		1.078043E-03

Epoch 26 of 500
  training loss:		9.996856E-04
  validation loss:		9.109535E-04

Epoch 27 of 500
  training loss:		8.194081E-04
  validation loss:		7.660620E-04

Epoch 28 of 500
  training loss:		6.988209E-04
  validation loss:		6.854034E-04

Epoch 29 of 500
  training loss:		6.016426E-04
  validation loss:		5.507272E-04

Epoch 30 of 500
  training loss:		5.293735E-04
  validation loss:		4.841475E-04

Epoch 31 of 500
  training loss:		4.621923E-04
  validation loss:		4.454036E-04

Epoch 32 of 500
  training loss:		4.100757E-04
  validation loss:		4.107813E-04

Epoch 33 of 500
  training loss:		3.689414E-04
  validation loss:		3.450811E-04

Epoch 34 of 500
  training loss:		3.288597E-04
  validation loss:		3.032930E-04

Epoch 35 of 500
  training loss:		2.972761E-04
  validation loss:		2.742523E-04

Epoch 36 of 500
  training loss:		2.690381E-04
  validation loss:		2.599976E-04

Epoch 37 of 500
  training loss:		2.443124E-04
  validation loss:		2.266437E-04

Epoch 38 of 500
  training loss:		2.229026E-04
  validation loss:		2.129288E-04

Epoch 39 of 500
  training loss:		2.042225E-04
  validation loss:		1.916013E-04

Epoch 40 of 500
  training loss:		1.943421E-04
  validation loss:		1.989232E-04

Epoch 41 of 500
  training loss:		1.734095E-04
  validation loss:		1.637937E-04

Epoch 42 of 500
  training loss:		1.613213E-04
  validation loss:		1.523109E-04

Epoch 43 of 500
  training loss:		1.503954E-04
  validation loss:		1.598471E-04

Epoch 44 of 500
  training loss:		1.393022E-04
  validation loss:		1.339932E-04

Epoch 45 of 500
  training loss:		1.299165E-04
  validation loss:		1.387107E-04

Epoch 46 of 500
  training loss:		1.201157E-04
  validation loss:		1.172651E-04

Epoch 47 of 500
  training loss:		1.143754E-04
  validation loss:		1.170228E-04

Epoch 48 of 500
  training loss:		1.096255E-04
  validation loss:		1.166674E-04

Epoch 49 of 500
  training loss:		1.008997E-04
  validation loss:		9.859168E-05

Epoch 50 of 500
  training loss:		9.469867E-05
  validation loss:		9.138349E-05

Epoch 51 of 500
  training loss:		8.978154E-05
  validation loss:		8.793201E-05

Epoch 52 of 500
  training loss:		8.531239E-05
  validation loss:		9.154707E-05

Epoch 53 of 500
  training loss:		8.052847E-05
  validation loss:		7.937995E-05

Epoch 54 of 500
  training loss:		7.627792E-05
  validation loss:		8.764746E-05

Epoch 55 of 500
  training loss:		7.475911E-05
  validation loss:		7.982035E-05

Epoch 56 of 500
  training loss:		7.070578E-05
  validation loss:		6.945320E-05

Epoch 57 of 500
  training loss:		6.596916E-05
  validation loss:		6.642682E-05

Epoch 58 of 500
  training loss:		6.583297E-05
  validation loss:		6.749953E-05

Epoch 59 of 500
  training loss:		6.273444E-05
  validation loss:		6.316844E-05

Epoch 60 of 500
  training loss:		5.925013E-05
  validation loss:		5.894453E-05

Epoch 61 of 500
  training loss:		5.708798E-05
  validation loss:		5.463015E-05

Epoch 62 of 500
  training loss:		5.431462E-05
  validation loss:		5.289545E-05

Epoch 63 of 500
  training loss:		5.365488E-05
  validation loss:		5.095529E-05

Epoch 64 of 500
  training loss:		5.068460E-05
  validation loss:		4.969947E-05

Epoch 65 of 500
  training loss:		4.856586E-05
  validation loss:		4.786912E-05

Epoch 66 of 500
  training loss:		4.771035E-05
  validation loss:		4.937270E-05

Epoch 67 of 500
  training loss:		4.640244E-05
  validation loss:		4.615041E-05

Epoch 68 of 500
  training loss:		4.480532E-05
  validation loss:		4.754422E-05

Epoch 69 of 500
  training loss:		4.331726E-05
  validation loss:		4.222398E-05

Epoch 70 of 500
  training loss:		4.340153E-05
  validation loss:		4.158022E-05

Epoch 71 of 500
  training loss:		4.112840E-05
  validation loss:		4.068827E-05

Epoch 72 of 500
  training loss:		4.032257E-05
  validation loss:		3.984132E-05

Epoch 73 of 500
  training loss:		4.015428E-05
  validation loss:		3.951855E-05

Epoch 74 of 500
  training loss:		3.831847E-05
  validation loss:		3.640600E-05

Epoch 75 of 500
  training loss:		3.563545E-05
  validation loss:		3.613761E-05

Epoch 76 of 500
  training loss:		3.617292E-05
  validation loss:		3.890026E-05

Epoch 77 of 500
  training loss:		3.470376E-05
  validation loss:		3.542281E-05

Epoch 78 of 500
  training loss:		3.474251E-05
  validation loss:		3.737743E-05

Epoch 79 of 500
  training loss:		3.312034E-05
  validation loss:		3.159850E-05

Epoch 80 of 500
  training loss:		3.186505E-05
  validation loss:		3.055827E-05

Epoch 81 of 500
  training loss:		3.108705E-05
  validation loss:		3.665217E-05

Epoch 82 of 500
  training loss:		3.075125E-05
  validation loss:		3.150537E-05

Epoch 83 of 500
  training loss:		3.276264E-05
  validation loss:		3.568083E-05

Epoch 84 of 500
  training loss:		2.900466E-05
  validation loss:		2.896358E-05

Epoch 85 of 500
  training loss:		2.823817E-05
  validation loss:		2.931455E-05

Epoch 86 of 500
  training loss:		2.924795E-05
  validation loss:		2.636760E-05

Epoch 87 of 500
  training loss:		2.640562E-05
  validation loss:		2.544577E-05

Epoch 88 of 500
  training loss:		2.848067E-05
  validation loss:		2.525726E-05

Epoch 89 of 500
  training loss:		2.560792E-05
  validation loss:		2.874087E-05

Epoch 90 of 500
  training loss:		2.470672E-05
  validation loss:		2.377953E-05

Epoch 91 of 500
  training loss:		2.526567E-05
  validation loss:		2.444852E-05

Epoch 92 of 500
  training loss:		2.393647E-05
  validation loss:		2.440139E-05

Epoch 93 of 500
  training loss:		2.427445E-05
  validation loss:		2.760363E-05

Epoch 94 of 500
  training loss:		2.395337E-05
  validation loss:		2.264610E-05

Epoch 95 of 500
  training loss:		2.313866E-05
  validation loss:		2.247579E-05

Epoch 96 of 500
  training loss:		2.224727E-05
  validation loss:		2.110468E-05

Epoch 97 of 500
  training loss:		2.183047E-05
  validation loss:		2.051986E-05

Epoch 98 of 500
  training loss:		2.103945E-05
  validation loss:		2.106941E-05

Epoch 99 of 500
  training loss:		2.076955E-05
  validation loss:		2.378980E-05

Epoch 100 of 500
  training loss:		2.159612E-05
  validation loss:		2.415369E-05

Epoch 101 of 500
  training loss:		2.108625E-05
  validation loss:		1.884519E-05

Epoch 102 of 500
  training loss:		2.027311E-05
  validation loss:		1.841149E-05

Epoch 103 of 500
  training loss:		1.946615E-05
  validation loss:		1.825165E-05

Epoch 104 of 500
  training loss:		2.003584E-05
  validation loss:		2.285616E-05

Epoch 105 of 500
  training loss:		1.854500E-05
  validation loss:		1.772986E-05

Epoch 106 of 500
  training loss:		1.884163E-05
  validation loss:		1.854512E-05

Epoch 107 of 500
  training loss:		1.912500E-05
  validation loss:		2.113150E-05

Epoch 108 of 500
  training loss:		1.820452E-05
  validation loss:		1.657140E-05

Epoch 109 of 500
  training loss:		1.875245E-05
  validation loss:		1.624324E-05

Epoch 110 of 500
  training loss:		1.763643E-05
  validation loss:		2.126221E-05

Epoch 111 of 500
  training loss:		1.707128E-05
  validation loss:		2.366906E-05

Epoch 112 of 500
  training loss:		1.648002E-05
  validation loss:		1.564232E-05

Epoch 113 of 500
  training loss:		1.654775E-05
  validation loss:		1.585251E-05

Epoch 114 of 500
  training loss:		1.642346E-05
  validation loss:		1.957809E-05

Epoch 115 of 500
  training loss:		1.611323E-05
  validation loss:		1.511072E-05

Epoch 116 of 500
  training loss:		1.571197E-05
  validation loss:		1.508179E-05

Epoch 117 of 500
  training loss:		1.645042E-05
  validation loss:		2.362921E-05

Epoch 118 of 500
  training loss:		1.578869E-05
  validation loss:		1.389369E-05

Epoch 119 of 500
  training loss:		1.511339E-05
  validation loss:		1.575949E-05

Epoch 120 of 500
  training loss:		1.472591E-05
  validation loss:		1.351123E-05

Epoch 121 of 500
  training loss:		1.546166E-05
  validation loss:		1.330550E-05

Epoch 122 of 500
  training loss:		1.406947E-05
  validation loss:		1.300561E-05

Epoch 123 of 500
  training loss:		1.415170E-05
  validation loss:		1.450905E-05

Epoch 124 of 500
  training loss:		1.321513E-05
  validation loss:		1.259237E-05

Epoch 125 of 500
  training loss:		1.398845E-05
  validation loss:		2.398420E-05

Epoch 126 of 500
  training loss:		1.383924E-05
  validation loss:		1.219806E-05

Epoch 127 of 500
  training loss:		1.365379E-05
  validation loss:		1.373712E-05

Epoch 128 of 500
  training loss:		1.346257E-05
  validation loss:		1.182231E-05

Epoch 129 of 500
  training loss:		1.263843E-05
  validation loss:		1.763159E-05

Epoch 130 of 500
  training loss:		1.230766E-05
  validation loss:		1.149242E-05

Epoch 131 of 500
  training loss:		1.303282E-05
  validation loss:		1.186351E-05

Epoch 132 of 500
  training loss:		1.242696E-05
  validation loss:		1.268113E-05

Epoch 133 of 500
  training loss:		1.210410E-05
  validation loss:		1.098433E-05

Epoch 134 of 500
  training loss:		1.223591E-05
  validation loss:		1.087810E-05

Epoch 135 of 500
  training loss:		1.196613E-05
  validation loss:		1.063898E-05

Epoch 136 of 500
  training loss:		1.236321E-05
  validation loss:		1.049233E-05

Epoch 137 of 500
  training loss:		1.210032E-05
  validation loss:		1.140918E-05

Epoch 138 of 500
  training loss:		1.196340E-05
  validation loss:		1.253946E-05

Epoch 139 of 500
  training loss:		1.147427E-05
  validation loss:		1.003631E-05

Epoch 140 of 500
  training loss:		1.071172E-05
  validation loss:		1.121592E-05

Epoch 141 of 500
  training loss:		1.097344E-05
  validation loss:		9.639344E-06

Epoch 142 of 500
  training loss:		1.092129E-05
  validation loss:		9.814474E-06

Epoch 143 of 500
  training loss:		1.051294E-05
  validation loss:		1.003412E-05

Epoch 144 of 500
  training loss:		1.064864E-05
  validation loss:		9.542280E-06

Epoch 145 of 500
  training loss:		9.790089E-06
  validation loss:		1.009709E-05

Epoch 146 of 500
  training loss:		1.073656E-05
  validation loss:		1.351724E-05

Epoch 147 of 500
  training loss:		1.040920E-05
  validation loss:		1.484739E-05

Epoch 148 of 500
  training loss:		9.799676E-06
  validation loss:		1.274184E-05

Epoch 149 of 500
  training loss:		9.569868E-06
  validation loss:		8.687489E-06

Epoch 150 of 500
  training loss:		1.007339E-05
  validation loss:		1.047786E-05

Epoch 151 of 500
  training loss:		9.250761E-06
  validation loss:		8.557765E-06

Epoch 152 of 500
  training loss:		9.140478E-06
  validation loss:		8.562689E-06

Epoch 153 of 500
  training loss:		9.435808E-06
  validation loss:		9.672827E-06

Epoch 154 of 500
  training loss:		9.232973E-06
  validation loss:		8.333040E-06

Epoch 155 of 500
  training loss:		8.561912E-06
  validation loss:		7.861907E-06

Epoch 156 of 500
  training loss:		9.003187E-06
  validation loss:		1.151664E-05

Epoch 157 of 500
  training loss:		9.970892E-06
  validation loss:		7.828407E-06

Epoch 158 of 500
  training loss:		8.854161E-06
  validation loss:		7.799261E-06

Epoch 159 of 500
  training loss:		8.226644E-06
  validation loss:		8.224563E-06

Epoch 160 of 500
  training loss:		8.869942E-06
  validation loss:		7.601304E-06

Epoch 161 of 500
  training loss:		8.369281E-06
  validation loss:		9.703425E-06

Epoch 162 of 500
  training loss:		8.297490E-06
  validation loss:		1.162683E-05

Epoch 163 of 500
  training loss:		8.645301E-06
  validation loss:		7.860375E-06

Epoch 164 of 500
  training loss:		8.290086E-06
  validation loss:		8.709743E-06

Epoch 165 of 500
  training loss:		8.224834E-06
  validation loss:		7.373027E-06

Epoch 166 of 500
  training loss:		7.738849E-06
  validation loss:		8.784714E-06

Epoch 167 of 500
  training loss:		7.601981E-06
  validation loss:		6.934230E-06

Epoch 168 of 500
  training loss:		7.507672E-06
  validation loss:		6.794497E-06

Epoch 169 of 500
  training loss:		7.350459E-06
  validation loss:		6.602017E-06

Epoch 170 of 500
  training loss:		7.401484E-06
  validation loss:		7.160696E-06

Epoch 171 of 500
  training loss:		7.981237E-06
  validation loss:		8.613987E-06

Epoch 172 of 500
  training loss:		7.554458E-06
  validation loss:		6.663470E-06

Epoch 173 of 500
  training loss:		7.171481E-06
  validation loss:		8.386272E-06

Epoch 174 of 500
  training loss:		7.651918E-06
  validation loss:		8.090314E-06

Epoch 175 of 500
  training loss:		7.099095E-06
  validation loss:		6.130505E-06

Epoch 176 of 500
  training loss:		6.907506E-06
  validation loss:		7.400635E-06

Epoch 177 of 500
  training loss:		6.651645E-06
  validation loss:		6.194598E-06

Epoch 178 of 500
  training loss:		7.323656E-06
  validation loss:		7.682407E-06

Epoch 179 of 500
  training loss:		6.614345E-06
  validation loss:		6.878793E-06

Epoch 180 of 500
  training loss:		6.578284E-06
  validation loss:		1.513827E-05

Epoch 181 of 500
  training loss:		6.608145E-06
  validation loss:		5.768465E-06

Epoch 182 of 500
  training loss:		6.250716E-06
  validation loss:		7.956543E-06

Epoch 183 of 500
  training loss:		6.534512E-06
  validation loss:		1.077661E-05

Epoch 184 of 500
  training loss:		6.232938E-06
  validation loss:		7.439177E-06

Epoch 185 of 500
  training loss:		6.571090E-06
  validation loss:		6.940829E-06

Epoch 186 of 500
  training loss:		6.584398E-06
  validation loss:		5.572049E-06

Epoch 187 of 500
  training loss:		5.569910E-06
  validation loss:		5.789011E-06

Epoch 188 of 500
  training loss:		5.983132E-06
  validation loss:		6.552349E-06

Epoch 189 of 500
  training loss:		6.592558E-06
  validation loss:		5.126516E-06

Epoch 190 of 500
  training loss:		6.177249E-06
  validation loss:		9.070077E-06

Epoch 191 of 500
  training loss:		6.191088E-06
  validation loss:		5.557610E-06

Epoch 192 of 500
  training loss:		5.902189E-06
  validation loss:		4.982945E-06

Epoch 193 of 500
  training loss:		5.329574E-06
  validation loss:		6.841883E-06

Epoch 194 of 500
  training loss:		5.675774E-06
  validation loss:		7.232840E-06

Epoch 195 of 500
  training loss:		5.440868E-06
  validation loss:		4.707117E-06

Epoch 196 of 500
  training loss:		5.542466E-06
  validation loss:		8.031790E-06

Epoch 197 of 500
  training loss:		5.782510E-06
  validation loss:		5.511656E-06

Epoch 198 of 500
  training loss:		5.793170E-06
  validation loss:		5.861123E-06

Epoch 199 of 500
  training loss:		5.068967E-06
  validation loss:		4.866503E-06

Epoch 200 of 500
  training loss:		5.333992E-06
  validation loss:		4.700568E-06

Epoch 201 of 500
  training loss:		5.202397E-06
  validation loss:		5.474401E-06

Epoch 202 of 500
  training loss:		5.246209E-06
  validation loss:		5.452806E-06

Epoch 203 of 500
  training loss:		4.928013E-06
  validation loss:		4.351944E-06

Epoch 204 of 500
  training loss:		4.654124E-06
  validation loss:		4.221607E-06

Epoch 205 of 500
  training loss:		5.520510E-06
  validation loss:		5.378478E-06

Epoch 206 of 500
  training loss:		5.179272E-06
  validation loss:		4.941068E-06

Epoch 207 of 500
  training loss:		4.818216E-06
  validation loss:		4.029527E-06

Epoch 208 of 500
  training loss:		4.507927E-06
  validation loss:		5.070609E-06

Epoch 209 of 500
  training loss:		5.100157E-06
  validation loss:		6.238176E-06

Epoch 210 of 500
  training loss:		4.968308E-06
  validation loss:		4.386433E-06

Epoch 211 of 500
  training loss:		5.178090E-06
  validation loss:		4.913768E-06

Epoch 212 of 500
  training loss:		4.768712E-06
  validation loss:		3.868313E-06

Epoch 213 of 500
  training loss:		4.585980E-06
  validation loss:		3.755576E-06

Epoch 214 of 500
  training loss:		4.732069E-06
  validation loss:		8.072383E-06

Epoch 215 of 500
  training loss:		4.717742E-06
  validation loss:		3.988166E-06

Epoch 216 of 500
  training loss:		4.422658E-06
  validation loss:		3.626464E-06

Epoch 217 of 500
  training loss:		3.954332E-06
  validation loss:		4.038863E-06

Epoch 218 of 500
  training loss:		4.157428E-06
  validation loss:		3.995861E-06

Epoch 219 of 500
  training loss:		4.353646E-06
  validation loss:		3.575723E-06

Epoch 220 of 500
  training loss:		4.364233E-06
  validation loss:		3.610263E-06

Epoch 221 of 500
  training loss:		4.128280E-06
  validation loss:		6.231030E-06

Epoch 222 of 500
  training loss:		4.597350E-06
  validation loss:		3.484149E-06

Epoch 223 of 500
  training loss:		5.031139E-06
  validation loss:		3.323366E-06

Epoch 224 of 500
  training loss:		3.791497E-06
  validation loss:		6.659544E-06

Epoch 225 of 500
  training loss:		4.276968E-06
  validation loss:		4.080739E-06

Epoch 226 of 500
  training loss:		4.292167E-06
  validation loss:		6.491390E-06

Epoch 227 of 500
  training loss:		3.803762E-06
  validation loss:		3.166831E-06

Epoch 228 of 500
  training loss:		3.931279E-06
  validation loss:		3.367082E-06

Epoch 229 of 500
  training loss:		4.006482E-06
  validation loss:		5.624797E-06

Epoch 230 of 500
  training loss:		3.925473E-06
  validation loss:		3.391758E-06

Epoch 231 of 500
  training loss:		3.712232E-06
  validation loss:		3.031151E-06

Epoch 232 of 500
  training loss:		3.840307E-06
  validation loss:		3.372533E-06

Epoch 233 of 500
  training loss:		3.988071E-06
  validation loss:		8.287041E-06

Epoch 234 of 500
  training loss:		4.085934E-06
  validation loss:		6.944987E-06

Epoch 235 of 500
  training loss:		3.510314E-06
  validation loss:		3.235263E-06

Epoch 236 of 500
  training loss:		4.097632E-06
  validation loss:		9.348526E-06

Epoch 237 of 500
  training loss:		3.873355E-06
  validation loss:		2.929069E-06

Epoch 238 of 500
  training loss:		3.693415E-06
  validation loss:		3.747924E-06

Epoch 239 of 500
  training loss:		3.239784E-06
  validation loss:		3.241015E-06

Epoch 240 of 500
  training loss:		3.582913E-06
  validation loss:		3.545422E-06

Early stopping, val-loss increased over the last 15 epochs from 0.000394382024296 to 0.000409052108778
Training RMSE: 1.71478508544e-09
Validation RMSE: 1.76241676843e-09
