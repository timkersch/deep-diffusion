Epoch 1 of 500
  training loss:		7.856145E-02
  validation loss:		3.491109E-02

Epoch 2 of 500
  training loss:		1.030619E-02
  validation loss:		3.313312E-03

Epoch 3 of 500
  training loss:		2.804825E-03
  validation loss:		2.275561E-03

Epoch 4 of 500
  training loss:		2.041866E-03
  validation loss:		1.752662E-03

Epoch 5 of 500
  training loss:		1.616415E-03
  validation loss:		1.451339E-03

Epoch 6 of 500
  training loss:		1.394980E-03
  validation loss:		1.282280E-03

Epoch 7 of 500
  training loss:		1.265722E-03
  validation loss:		1.205411E-03

Epoch 8 of 500
  training loss:		1.191283E-03
  validation loss:		1.142511E-03

Epoch 9 of 500
  training loss:		1.139089E-03
  validation loss:		1.130499E-03

Epoch 10 of 500
  training loss:		1.097866E-03
  validation loss:		1.079081E-03

Epoch 11 of 500
  training loss:		1.064022E-03
  validation loss:		1.038597E-03

Epoch 12 of 500
  training loss:		1.037138E-03
  validation loss:		1.005742E-03

Epoch 13 of 500
  training loss:		1.012247E-03
  validation loss:		9.847954E-04

Epoch 14 of 500
  training loss:		9.948128E-04
  validation loss:		9.763303E-04

Epoch 15 of 500
  training loss:		9.726503E-04
  validation loss:		9.449016E-04

Epoch 16 of 500
  training loss:		9.611775E-04
  validation loss:		9.277962E-04

Epoch 17 of 500
  training loss:		9.379969E-04
  validation loss:		9.145926E-04

Epoch 18 of 500
  training loss:		9.278242E-04
  validation loss:		9.340061E-04

Epoch 19 of 500
  training loss:		9.117374E-04
  validation loss:		8.833216E-04

Epoch 20 of 500
  training loss:		8.945004E-04
  validation loss:		8.718793E-04

Epoch 21 of 500
  training loss:		8.827058E-04
  validation loss:		8.628486E-04

Epoch 22 of 500
  training loss:		8.740248E-04
  validation loss:		8.511850E-04

Epoch 23 of 500
  training loss:		8.624434E-04
  validation loss:		8.472219E-04

Epoch 24 of 500
  training loss:		8.443780E-04
  validation loss:		8.187786E-04

Epoch 25 of 500
  training loss:		8.205655E-04
  validation loss:		7.731372E-04

Epoch 26 of 500
  training loss:		7.230872E-04
  validation loss:		6.572089E-04

Epoch 27 of 500
  training loss:		5.708810E-04
  validation loss:		4.801964E-04

Epoch 28 of 500
  training loss:		4.130700E-04
  validation loss:		3.390532E-04

Epoch 29 of 500
  training loss:		2.942341E-04
  validation loss:		2.495061E-04

Epoch 30 of 500
  training loss:		2.207268E-04
  validation loss:		1.964828E-04

Epoch 31 of 500
  training loss:		1.728771E-04
  validation loss:		1.571647E-04

Epoch 32 of 500
  training loss:		1.423586E-04
  validation loss:		1.362459E-04

Epoch 33 of 500
  training loss:		1.198756E-04
  validation loss:		1.130289E-04

Epoch 34 of 500
  training loss:		1.038063E-04
  validation loss:		1.254674E-04

Epoch 35 of 500
  training loss:		9.190656E-05
  validation loss:		8.674622E-05

Epoch 36 of 500
  training loss:		8.068353E-05
  validation loss:		7.703903E-05

Epoch 37 of 500
  training loss:		7.100270E-05
  validation loss:		6.875386E-05

Epoch 38 of 500
  training loss:		6.628098E-05
  validation loss:		6.197680E-05

Epoch 39 of 500
  training loss:		5.891328E-05
  validation loss:		6.041501E-05

Epoch 40 of 500
  training loss:		5.375316E-05
  validation loss:		5.433349E-05

Epoch 41 of 500
  training loss:		4.975937E-05
  validation loss:		4.810611E-05

Epoch 42 of 500
  training loss:		4.604694E-05
  validation loss:		4.495829E-05

Epoch 43 of 500
  training loss:		4.244905E-05
  validation loss:		4.489426E-05

Epoch 44 of 500
  training loss:		4.033271E-05
  validation loss:		3.955233E-05

Epoch 45 of 500
  training loss:		3.795517E-05
  validation loss:		3.817995E-05

Epoch 46 of 500
  training loss:		3.515986E-05
  validation loss:		3.515036E-05

Epoch 47 of 500
  training loss:		3.344908E-05
  validation loss:		3.250244E-05

Epoch 48 of 500
  training loss:		3.188885E-05
  validation loss:		3.283731E-05

Epoch 49 of 500
  training loss:		3.020749E-05
  validation loss:		2.967263E-05

Epoch 50 of 500
  training loss:		2.908267E-05
  validation loss:		2.783497E-05

Epoch 51 of 500
  training loss:		2.745732E-05
  validation loss:		2.676626E-05

Epoch 52 of 500
  training loss:		2.576522E-05
  validation loss:		2.983116E-05

Epoch 53 of 500
  training loss:		2.516352E-05
  validation loss:		2.486813E-05

Epoch 54 of 500
  training loss:		2.401009E-05
  validation loss:		2.339628E-05

Epoch 55 of 500
  training loss:		2.280607E-05
  validation loss:		2.215104E-05

Epoch 56 of 500
  training loss:		2.205976E-05
  validation loss:		2.214590E-05

Epoch 57 of 500
  training loss:		2.102586E-05
  validation loss:		2.058423E-05

Epoch 58 of 500
  training loss:		1.977570E-05
  validation loss:		1.994799E-05

Epoch 59 of 500
  training loss:		1.946307E-05
  validation loss:		1.938008E-05

Epoch 60 of 500
  training loss:		1.869437E-05
  validation loss:		1.802376E-05

Epoch 61 of 500
  training loss:		1.765436E-05
  validation loss:		1.729719E-05

Epoch 62 of 500
  training loss:		1.765428E-05
  validation loss:		1.672438E-05

Epoch 63 of 500
  training loss:		1.688484E-05
  validation loss:		1.628319E-05

Epoch 64 of 500
  training loss:		1.566838E-05
  validation loss:		1.651513E-05

Epoch 65 of 500
  training loss:		1.542881E-05
  validation loss:		1.506768E-05

Epoch 66 of 500
  training loss:		1.474322E-05
  validation loss:		1.615330E-05

Epoch 67 of 500
  training loss:		1.419895E-05
  validation loss:		1.578162E-05

Epoch 68 of 500
  training loss:		1.377798E-05
  validation loss:		1.323163E-05

Epoch 69 of 500
  training loss:		1.357035E-05
  validation loss:		1.276559E-05

Epoch 70 of 500
  training loss:		1.286296E-05
  validation loss:		1.286780E-05

Epoch 71 of 500
  training loss:		1.228794E-05
  validation loss:		1.450427E-05

Epoch 72 of 500
  training loss:		1.194612E-05
  validation loss:		1.279950E-05

Epoch 73 of 500
  training loss:		1.173185E-05
  validation loss:		1.250442E-05

Epoch 74 of 500
  training loss:		1.175289E-05
  validation loss:		1.083301E-05

Epoch 75 of 500
  training loss:		1.095348E-05
  validation loss:		1.138737E-05

Epoch 76 of 500
  training loss:		1.064967E-05
  validation loss:		1.051405E-05

Epoch 77 of 500
  training loss:		1.025679E-05
  validation loss:		1.000171E-05

Epoch 78 of 500
  training loss:		9.972101E-06
  validation loss:		9.804116E-06

Epoch 79 of 500
  training loss:		9.722042E-06
  validation loss:		9.209774E-06

Epoch 80 of 500
  training loss:		9.401195E-06
  validation loss:		9.772524E-06

Epoch 81 of 500
  training loss:		9.261100E-06
  validation loss:		8.765551E-06

Epoch 82 of 500
  training loss:		8.814284E-06
  validation loss:		9.193576E-06

Epoch 83 of 500
  training loss:		8.567056E-06
  validation loss:		8.178422E-06

Epoch 84 of 500
  training loss:		8.337316E-06
  validation loss:		9.922410E-06

Epoch 85 of 500
  training loss:		8.355631E-06
  validation loss:		7.705214E-06

Epoch 86 of 500
  training loss:		7.759309E-06
  validation loss:		7.488589E-06

Epoch 87 of 500
  training loss:		7.589165E-06
  validation loss:		8.013943E-06

Epoch 88 of 500
  training loss:		7.584826E-06
  validation loss:		8.925817E-06

Epoch 89 of 500
  training loss:		7.532197E-06
  validation loss:		6.895864E-06

Epoch 90 of 500
  training loss:		7.344631E-06
  validation loss:		8.255394E-06

Epoch 91 of 500
  training loss:		7.179130E-06
  validation loss:		7.094806E-06

Epoch 92 of 500
  training loss:		6.551382E-06
  validation loss:		6.751670E-06

Epoch 93 of 500
  training loss:		6.851781E-06
  validation loss:		7.446180E-06

Epoch 94 of 500
  training loss:		6.438201E-06
  validation loss:		6.871849E-06

Epoch 95 of 500
  training loss:		6.293969E-06
  validation loss:		6.232013E-06

Epoch 96 of 500
  training loss:		6.142996E-06
  validation loss:		8.548256E-06

Epoch 97 of 500
  training loss:		6.164998E-06
  validation loss:		5.675392E-06

Epoch 98 of 500
  training loss:		5.712500E-06
  validation loss:		5.553863E-06

Epoch 99 of 500
  training loss:		5.792376E-06
  validation loss:		5.331961E-06

Epoch 100 of 500
  training loss:		5.602620E-06
  validation loss:		5.132955E-06

Epoch 101 of 500
  training loss:		5.724402E-06
  validation loss:		9.187320E-06

Epoch 102 of 500
  training loss:		5.385909E-06
  validation loss:		7.554565E-06

Epoch 103 of 500
  training loss:		5.145537E-06
  validation loss:		4.779452E-06

Epoch 104 of 500
  training loss:		4.970442E-06
  validation loss:		6.383495E-06

Epoch 105 of 500
  training loss:		5.244102E-06
  validation loss:		5.633463E-06

Epoch 106 of 500
  training loss:		4.967734E-06
  validation loss:		4.874868E-06

Epoch 107 of 500
  training loss:		4.715815E-06
  validation loss:		4.678326E-06

Epoch 108 of 500
  training loss:		4.778945E-06
  validation loss:		4.236596E-06

Epoch 109 of 500
  training loss:		4.845910E-06
  validation loss:		4.150704E-06

Epoch 110 of 500
  training loss:		4.561373E-06
  validation loss:		4.943955E-06

Epoch 111 of 500
  training loss:		4.291313E-06
  validation loss:		4.993585E-06

Epoch 112 of 500
  training loss:		4.372970E-06
  validation loss:		4.204101E-06

Epoch 113 of 500
  training loss:		4.267691E-06
  validation loss:		6.524951E-06

Epoch 114 of 500
  training loss:		4.257699E-06
  validation loss:		3.744755E-06

Epoch 115 of 500
  training loss:		4.078926E-06
  validation loss:		5.566656E-06

Epoch 116 of 500
  training loss:		3.792115E-06
  validation loss:		3.613072E-06

Epoch 117 of 500
  training loss:		3.729724E-06
  validation loss:		4.751561E-06

Epoch 118 of 500
  training loss:		3.907792E-06
  validation loss:		3.403651E-06

Epoch 119 of 500
  training loss:		3.896298E-06
  validation loss:		3.442055E-06

Epoch 120 of 500
  training loss:		3.648271E-06
  validation loss:		3.815576E-06

Epoch 121 of 500
  training loss:		3.677507E-06
  validation loss:		3.159318E-06

Epoch 122 of 500
  training loss:		3.286514E-06
  validation loss:		5.014051E-06

Epoch 123 of 500
  training loss:		3.638302E-06
  validation loss:		4.655705E-06

Epoch 124 of 500
  training loss:		3.327702E-06
  validation loss:		3.544937E-06

Epoch 125 of 500
  training loss:		3.301534E-06
  validation loss:		3.224070E-06

Epoch 126 of 500
  training loss:		3.315780E-06
  validation loss:		3.918200E-06

Epoch 127 of 500
  training loss:		3.176586E-06
  validation loss:		2.967973E-06

Epoch 128 of 500
  training loss:		2.906517E-06
  validation loss:		2.690595E-06

Epoch 129 of 500
  training loss:		3.037550E-06
  validation loss:		3.008622E-06

Epoch 130 of 500
  training loss:		3.172735E-06
  validation loss:		2.598590E-06

Epoch 131 of 500
  training loss:		2.977529E-06
  validation loss:		3.179363E-06

Epoch 132 of 500
  training loss:		2.854255E-06
  validation loss:		2.662096E-06

Epoch 133 of 500
  training loss:		2.876092E-06
  validation loss:		3.226929E-06

Epoch 134 of 500
  training loss:		2.941175E-06
  validation loss:		3.293647E-06

Epoch 135 of 500
  training loss:		2.948741E-06
  validation loss:		3.075408E-06

Epoch 136 of 500
  training loss:		2.601334E-06
  validation loss:		2.794766E-06

Epoch 137 of 500
  training loss:		2.658557E-06
  validation loss:		2.337424E-06

Epoch 138 of 500
  training loss:		2.755568E-06
  validation loss:		2.847201E-06

Epoch 139 of 500
  training loss:		2.660229E-06
  validation loss:		3.573021E-06

Epoch 140 of 500
  training loss:		2.686121E-06
  validation loss:		2.722602E-06

Epoch 141 of 500
  training loss:		2.577205E-06
  validation loss:		2.687232E-06

Epoch 142 of 500
  training loss:		2.294770E-06
  validation loss:		3.017806E-06

Epoch 143 of 500
  training loss:		2.516730E-06
  validation loss:		2.119197E-06

Epoch 144 of 500
  training loss:		2.564862E-06
  validation loss:		1.997596E-06

Epoch 145 of 500
  training loss:		2.336862E-06
  validation loss:		1.956206E-06

Epoch 146 of 500
  training loss:		2.248760E-06
  validation loss:		2.002338E-06

Epoch 147 of 500
  training loss:		2.409257E-06
  validation loss:		2.907591E-06

Epoch 148 of 500
  training loss:		2.320657E-06
  validation loss:		2.864185E-06

Epoch 149 of 500
  training loss:		2.210292E-06
  validation loss:		2.103617E-06

Epoch 150 of 500
  training loss:		2.190720E-06
  validation loss:		1.795705E-06

Epoch 151 of 500
  training loss:		2.142526E-06
  validation loss:		1.757986E-06

Epoch 152 of 500
  training loss:		2.072529E-06
  validation loss:		1.718239E-06

Epoch 153 of 500
  training loss:		2.026195E-06
  validation loss:		1.887587E-06

Epoch 154 of 500
  training loss:		1.990154E-06
  validation loss:		1.769925E-06

Epoch 155 of 500
  training loss:		2.080308E-06
  validation loss:		2.225942E-06

Epoch 156 of 500
  training loss:		1.932280E-06
  validation loss:		1.661705E-06

Epoch 157 of 500
  training loss:		2.025254E-06
  validation loss:		1.705749E-06

Epoch 158 of 500
  training loss:		1.973503E-06
  validation loss:		1.728998E-06

Epoch 159 of 500
  training loss:		2.186413E-06
  validation loss:		1.726846E-06

Epoch 160 of 500
  training loss:		1.849851E-06
  validation loss:		1.719511E-06

Epoch 161 of 500
  training loss:		1.792502E-06
  validation loss:		2.496406E-06

Epoch 162 of 500
  training loss:		1.974353E-06
  validation loss:		1.556938E-06

Epoch 163 of 500
  training loss:		1.702141E-06
  validation loss:		1.477936E-06

Epoch 164 of 500
  training loss:		1.839544E-06
  validation loss:		2.265697E-06

Epoch 165 of 500
  training loss:		1.715282E-06
  validation loss:		1.436909E-06

Epoch 166 of 500
  training loss:		1.928624E-06
  validation loss:		1.717392E-06

Epoch 167 of 500
  training loss:		1.708704E-06
  validation loss:		1.735747E-06

Epoch 168 of 500
  training loss:		1.766040E-06
  validation loss:		1.373177E-06

Epoch 169 of 500
  training loss:		1.654645E-06
  validation loss:		1.315175E-06

Epoch 170 of 500
  training loss:		1.668334E-06
  validation loss:		1.550189E-06

Epoch 171 of 500
  training loss:		1.560698E-06
  validation loss:		1.322519E-06

Epoch 172 of 500
  training loss:		1.684977E-06
  validation loss:		1.291898E-06

Epoch 173 of 500
  training loss:		1.644117E-06
  validation loss:		1.273691E-06

Epoch 174 of 500
  training loss:		1.621542E-06
  validation loss:		2.017726E-06

Epoch 175 of 500
  training loss:		1.601596E-06
  validation loss:		1.222711E-06

Epoch 176 of 500
  training loss:		1.594171E-06
  validation loss:		1.654080E-06

Epoch 177 of 500
  training loss:		1.591867E-06
  validation loss:		1.427635E-06

Epoch 178 of 500
  training loss:		1.480814E-06
  validation loss:		1.252327E-06

Epoch 179 of 500
  training loss:		1.558313E-06
  validation loss:		1.345770E-06

Epoch 180 of 500
  training loss:		1.587105E-06
  validation loss:		1.536908E-06

Epoch 181 of 500
  training loss:		1.565241E-06
  validation loss:		1.123316E-06

Epoch 182 of 500
  training loss:		1.576145E-06
  validation loss:		1.219018E-06

Epoch 183 of 500
  training loss:		1.485523E-06
  validation loss:		1.136096E-06

Epoch 184 of 500
  training loss:		1.446822E-06
  validation loss:		1.233387E-06

Epoch 185 of 500
  training loss:		1.426403E-06
  validation loss:		1.231725E-06

Epoch 186 of 500
  training loss:		1.399612E-06
  validation loss:		1.390786E-06

Epoch 187 of 500
  training loss:		1.379564E-06
  validation loss:		1.054373E-06

Epoch 188 of 500
  training loss:		1.342012E-06
  validation loss:		1.106974E-06

Epoch 189 of 500
  training loss:		1.340614E-06
  validation loss:		1.095032E-06

Epoch 190 of 500
  training loss:		1.334648E-06
  validation loss:		1.355806E-06

Epoch 191 of 500
  training loss:		1.282420E-06
  validation loss:		1.031637E-06

Epoch 192 of 500
  training loss:		1.410228E-06
  validation loss:		1.223773E-06

Epoch 193 of 500
  training loss:		1.335001E-06
  validation loss:		1.912132E-06

Epoch 194 of 500
  training loss:		1.308136E-06
  validation loss:		1.454450E-06

Epoch 195 of 500
  training loss:		1.232492E-06
  validation loss:		1.387108E-06

Epoch 196 of 500
  training loss:		1.354511E-06
  validation loss:		9.978799E-07

Epoch 197 of 500
  training loss:		1.384049E-06
  validation loss:		9.760770E-07

Epoch 198 of 500
  training loss:		1.348966E-06
  validation loss:		1.645985E-06

Epoch 199 of 500
  training loss:		1.171045E-06
  validation loss:		9.648481E-07

Epoch 200 of 500
  training loss:		1.161667E-06
  validation loss:		1.124098E-06

Early stopping, val-loss increased over the last 10 epochs from 0.000105129317699 to 0.00011191829022
Training RMSE: 9.64410987427e-10
Validation RMSE: 9.61251170713e-10
