Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		9.294336E-03
  validation loss:		4.444205E-06
Epoch took 10.370s

Epoch 2 of 100
  training loss:		1.041377E-05
  validation loss:		4.221358E-05
Epoch took 10.346s

Epoch 3 of 100
  training loss:		3.263031E-04
  validation loss:		3.379361E-06
Epoch took 9.437s

Epoch 4 of 100
  training loss:		8.600940E-04
  validation loss:		1.087382E-02
Epoch took 9.512s

Epoch 5 of 100
  training loss:		2.376549E-04
  validation loss:		1.077001E-06
Epoch took 10.860s

Epoch 6 of 100
  training loss:		2.336865E-06
  validation loss:		1.794319E-06
Epoch took 9.859s

Epoch 7 of 100
  training loss:		2.420078E-05
  validation loss:		1.310269E-05
Epoch took 10.553s

Epoch 8 of 100
  training loss:		3.873497E-04
  validation loss:		2.665384E-04
Epoch took 8.967s

Epoch 9 of 100
  training loss:		2.893209E-04
  validation loss:		2.086068E-07
Epoch took 9.909s

Epoch 10 of 100
  training loss:		6.254014E-04
  validation loss:		6.150928E-04
Epoch took 9.637s

Epoch 11 of 100
  training loss:		5.941980E-05
  validation loss:		2.282561E-06
Epoch took 9.731s

Epoch 12 of 100
  training loss:		7.210727E-07
  validation loss:		7.637991E-08
Epoch took 10.842s

Epoch 13 of 100
  training loss:		8.967581E-06
  validation loss:		1.818993E-05
Epoch took 10.765s

Epoch 14 of 100
  training loss:		6.375662E-05
  validation loss:		4.869561E-08
Epoch took 10.392s

Epoch 15 of 100
  training loss:		3.974190E-04
  validation loss:		4.634760E-05
Epoch took 11.904s

Epoch 16 of 100
  training loss:		1.677158E-06
  validation loss:		1.729667E-08
Epoch took 10.102s

Epoch 17 of 100
  training loss:		5.351711E-06
  validation loss:		1.963409E-05
Epoch took 10.330s

Epoch 18 of 100
  training loss:		2.580520E-04
  validation loss:		7.503483E-08
Epoch took 10.316s

Epoch 19 of 100
  training loss:		9.158457E-09
  validation loss:		1.882828E-10
Epoch took 10.008s

Epoch 20 of 100
  training loss:		1.600916E-05
  validation loss:		7.355045E-05
Epoch took 11.496s

Epoch 21 of 100
  training loss:		1.307403E-04
  validation loss:		4.212271E-07
Epoch took 10.330s

Epoch 22 of 100
  training loss:		1.919224E-05
  validation loss:		2.167926E-06
Epoch took 11.319s

Epoch 23 of 100
  training loss:		8.447167E-05
  validation loss:		2.809472E-05
Epoch took 11.149s

Epoch 24 of 100
  training loss:		1.463929E-05
  validation loss:		5.056399E-06
Epoch took 10.561s

Epoch 25 of 100
  training loss:		3.793126E-05
  validation loss:		7.602933E-04
Epoch took 10.871s

Epoch 26 of 100
  training loss:		1.422355E-04
  validation loss:		1.307382E-08
Epoch took 12.057s

Epoch 27 of 100
  training loss:		1.082504E-08
  validation loss:		2.990424E-09
Epoch took 9.839s

Epoch 28 of 100
  training loss:		2.862470E-07
  validation loss:		1.379101E-06
Epoch took 10.888s

Epoch 29 of 100
  training loss:		1.255620E-04
  validation loss:		3.164223E-04
Epoch took 10.166s

Epoch 30 of 100
  training loss:		4.855019E-05
  validation loss:		1.815741E-09
Epoch took 10.575s

Epoch 31 of 100
  training loss:		1.004963E-10
  validation loss:		2.435230E-15
Epoch took 10.080s

Epoch 32 of 100
  training loss:		1.669167E-15
  validation loss:		8.625910E-16
Epoch took 11.180s

Epoch 33 of 100
  training loss:		6.833289E-16
  validation loss:		4.317222E-16
Epoch took 10.073s

Epoch 34 of 100
  training loss:		3.330005E-16
  validation loss:		2.010449E-16
Epoch took 10.389s

Epoch 35 of 100
  training loss:		1.528561E-16
  validation loss:		9.198372E-17
Epoch took 9.945s

Epoch 36 of 100
  training loss:		7.522450E-17
  validation loss:		4.603225E-17
Epoch took 9.709s

Epoch 37 of 100
  training loss:		3.737196E-17
  validation loss:		2.239423E-17
Epoch took 11.227s

Epoch 38 of 100
  training loss:		1.844996E-17
  validation loss:		1.438638E-17
Epoch took 9.742s

Epoch 39 of 100
  training loss:		1.001900E-17
  validation loss:		6.046177E-18
Epoch took 12.451s

Epoch 40 of 100
  training loss:		5.042073E-18
  validation loss:		3.429298E-18
Epoch took 10.262s

Epoch 41 of 100
  training loss:		2.687456E-18
  validation loss:		1.681199E-18
Epoch took 10.734s

Epoch 42 of 100
  training loss:		1.429945E-18
  validation loss:		8.991487E-19
Epoch took 10.005s

Epoch 43 of 100
  training loss:		7.739813E-19
  validation loss:		4.714429E-19
Epoch took 10.572s

Epoch 44 of 100
  training loss:		4.092324E-19
  validation loss:		2.482000E-19
Epoch took 11.065s

Epoch 45 of 100
  training loss:		2.207929E-19
  validation loss:		1.389613E-19
Epoch took 10.627s

Epoch 46 of 100
  training loss:		1.114163E-19
  validation loss:		7.051591E-20
Epoch took 10.826s

Epoch 47 of 100
  training loss:		6.247856E-20
  validation loss:		3.812513E-20
Epoch took 9.138s

Epoch 48 of 100
  training loss:		3.330170E-20
  validation loss:		1.972458E-20
Epoch took 11.329s

Epoch 49 of 100
  training loss:		1.753878E-20
  validation loss:		1.010845E-20
Epoch took 10.916s

Epoch 50 of 100
  training loss:		9.192009E-21
  validation loss:		5.296459E-21
Epoch took 9.488s

Epoch 51 of 100
  training loss:		4.862209E-21
  validation loss:		2.701416E-21
Epoch took 10.009s

Epoch 52 of 100
  training loss:		2.706507E-21
  validation loss:		1.602990E-21
Epoch took 9.643s

Epoch 53 of 100
  training loss:		1.528558E-21
  validation loss:		9.405065E-22
Epoch took 9.537s

Epoch 54 of 100
  training loss:		8.691353E-22
  validation loss:		4.883978E-22
Epoch took 10.401s

Epoch 55 of 100
  training loss:		4.871900E-22
  validation loss:		2.939356E-22
Epoch took 10.453s

Epoch 56 of 100
  training loss:		2.918528E-22
  validation loss:		1.765640E-22
Epoch took 10.410s

Epoch 57 of 100
  training loss:		1.668685E-22
  validation loss:		1.028386E-22
Epoch took 10.744s

Epoch 58 of 100
  training loss:		1.000115E-22
  validation loss:		6.093059E-23
Epoch took 10.871s

Epoch 59 of 100
  training loss:		5.753118E-23
  validation loss:		4.558594E-23
Epoch took 9.829s

Epoch 60 of 100
  training loss:		3.523550E-23
  validation loss:		2.116429E-23
Epoch took 11.079s

Epoch 61 of 100
  training loss:		2.106391E-23
  validation loss:		1.306021E-23
Epoch took 11.848s

Epoch 62 of 100
  training loss:		1.301494E-23
  validation loss:		8.757918E-24
Epoch took 11.250s

Epoch 63 of 100
  training loss:		8.277309E-24
  validation loss:		5.458781E-24
Epoch took 10.592s

Epoch 64 of 100
  training loss:		5.593908E-24
  validation loss:		4.537006E-24
Epoch took 10.888s

Epoch 65 of 100
  training loss:		3.276937E-24
  validation loss:		2.164728E-24
Epoch took 10.411s

Epoch 66 of 100
  training loss:		8.167529E-04
  validation loss:		3.354652E-07
Epoch took 10.721s

Epoch 67 of 100
  training loss:		7.575543E-08
  validation loss:		9.183711E-10
Epoch took 10.353s

Epoch 68 of 100
  training loss:		1.892619E-10
  validation loss:		9.143743E-12
Epoch took 10.163s

Epoch 69 of 100
  training loss:		6.390201E-13
  validation loss:		1.012918E-13
Epoch took 10.830s

Epoch 70 of 100
  training loss:		4.363970E-14
  validation loss:		2.054947E-14
Epoch took 11.506s

Epoch 71 of 100
  training loss:		1.172002E-14
  validation loss:		5.523571E-15
Epoch took 9.831s

Epoch 72 of 100
  training loss:		3.248231E-15
  validation loss:		2.171084E-15
Epoch took 11.728s

Epoch 73 of 100
  training loss:		1.384016E-15
  validation loss:		9.125346E-16
Epoch took 11.064s

Epoch 74 of 100
  training loss:		5.858401E-16
  validation loss:		3.882234E-16
Epoch took 10.706s

Epoch 75 of 100
  training loss:		2.669717E-16
  validation loss:		1.841469E-16
Epoch took 10.055s

Epoch 76 of 100
  training loss:		1.123834E-16
  validation loss:		7.981639E-17
Epoch took 10.405s

Epoch 77 of 100
  training loss:		5.254602E-17
  validation loss:		3.601915E-17
Epoch took 10.305s

Epoch 78 of 100
  training loss:		2.461705E-17
  validation loss:		1.756914E-17
Epoch took 10.329s

Epoch 79 of 100
  training loss:		1.130423E-17
  validation loss:		7.825348E-18
Epoch took 11.978s

Epoch 80 of 100
  training loss:		5.480401E-18
  validation loss:		3.898855E-18
Epoch took 10.590s

Epoch 81 of 100
  training loss:		2.758081E-18
  validation loss:		2.039607E-18
Epoch took 10.665s

Epoch 82 of 100
  training loss:		1.444639E-18
  validation loss:		1.077029E-18
Epoch took 11.093s

Epoch 83 of 100
  training loss:		7.677817E-19
  validation loss:		5.634754E-19
Epoch took 9.815s

Epoch 84 of 100
  training loss:		3.602549E-19
  validation loss:		2.780492E-19
Epoch took 11.531s

Epoch 85 of 100
  training loss:		1.781913E-19
  validation loss:		1.285650E-19
Epoch took 10.738s

Epoch 86 of 100
  training loss:		9.673990E-20
  validation loss:		7.792018E-20
Epoch took 11.412s

Epoch 87 of 100
  training loss:		5.513752E-20
  validation loss:		4.675179E-20
Epoch took 9.975s

Epoch 88 of 100
  training loss:		3.219610E-20
  validation loss:		2.736966E-20
Epoch took 10.880s

Epoch 89 of 100
  training loss:		1.870651E-20
  validation loss:		1.381566E-20
Epoch took 10.948s

Epoch 90 of 100
  training loss:		1.021019E-20
  validation loss:		8.727557E-21
Epoch took 10.925s

Epoch 91 of 100
  training loss:		6.869020E-21
  validation loss:		4.860132E-21
Epoch took 9.969s

Epoch 92 of 100
  training loss:		4.177075E-21
  validation loss:		5.840843E-21
Epoch took 9.436s

Epoch 93 of 100
  training loss:		2.528816E-21
  validation loss:		1.708574E-21
Epoch took 10.791s

Epoch 94 of 100
  training loss:		1.312500E-21
  validation loss:		1.014931E-21
Epoch took 11.687s

Epoch 95 of 100
  training loss:		8.587272E-22
  validation loss:		7.019921E-22
Epoch took 10.013s

Epoch 96 of 100
  training loss:		5.120478E-22
  validation loss:		5.458374E-22
Epoch took 10.603s

Epoch 97 of 100
  training loss:		3.086660E-22
  validation loss:		1.839483E-22
Epoch took 12.113s

Epoch 98 of 100
  training loss:		1.702231E-22
  validation loss:		1.135311E-22
Epoch took 9.726s

Epoch 99 of 100
  training loss:		9.530310E-23
  validation loss:		8.061230E-23
Epoch took 10.102s

Epoch 100 of 100
  training loss:		6.404654E-23
  validation loss:		3.348134E-23
Epoch took 10.458s

Training RMSE: 5.52167337719e-12
Validation RMSE: 5.77263053636e-12
