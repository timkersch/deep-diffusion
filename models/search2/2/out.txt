Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		5.315022E-02
  validation loss:		7.624806E-04
Epoch took 12.584s

Epoch 2 of 100
  training loss:		3.447259E-04
  validation loss:		1.554167E-04
Epoch took 11.996s

Epoch 3 of 100
  training loss:		9.408586E-05
  validation loss:		5.316134E-05
Epoch took 12.140s

Epoch 4 of 100
  training loss:		3.279814E-05
  validation loss:		1.965407E-05
Epoch took 13.422s

Epoch 5 of 100
  training loss:		1.057370E-05
  validation loss:		5.971417E-06
Epoch took 13.284s

Epoch 6 of 100
  training loss:		3.106717E-06
  validation loss:		1.628464E-06
Epoch took 12.951s

Epoch 7 of 100
  training loss:		8.377058E-07
  validation loss:		4.153775E-07
Epoch took 12.267s

Epoch 8 of 100
  training loss:		2.056441E-07
  validation loss:		9.600903E-08
Epoch took 12.740s

Epoch 9 of 100
  training loss:		4.528132E-08
  validation loss:		2.059895E-08
Epoch took 12.927s

Epoch 10 of 100
  training loss:		9.426963E-09
  validation loss:		4.415121E-09
Epoch took 12.915s

Epoch 11 of 100
  training loss:		1.981103E-09
  validation loss:		9.201065E-10
Epoch took 12.383s

Epoch 12 of 100
  training loss:		4.438422E-10
  validation loss:		2.178725E-10
Epoch took 12.640s

Epoch 13 of 100
  training loss:		1.053029E-10
  validation loss:		5.816954E-11
Epoch took 12.172s

Epoch 14 of 100
  training loss:		2.987054E-11
  validation loss:		1.807963E-11
Epoch took 12.064s

Epoch 15 of 100
  training loss:		9.851153E-12
  validation loss:		6.512359E-12
Epoch took 12.882s

Epoch 16 of 100
  training loss:		3.551551E-12
  validation loss:		2.364035E-12
Epoch took 12.068s

Epoch 17 of 100
  training loss:		1.334246E-12
  validation loss:		9.708975E-13
Epoch took 12.526s

Epoch 18 of 100
  training loss:		5.562873E-13
  validation loss:		3.871004E-13
Epoch took 13.609s

Epoch 19 of 100
  training loss:		2.237609E-13
  validation loss:		1.670176E-13
Epoch took 11.818s

Epoch 20 of 100
  training loss:		9.564897E-14
  validation loss:		6.941495E-14
Epoch took 12.341s

Epoch 21 of 100
  training loss:		4.215093E-14
  validation loss:		2.770070E-14
Epoch took 12.766s

Epoch 22 of 100
  training loss:		1.725136E-14
  validation loss:		1.264188E-14
Epoch took 12.559s

Epoch 23 of 100
  training loss:		7.637552E-15
  validation loss:		5.678007E-15
Epoch took 12.320s

Epoch 24 of 100
  training loss:		3.543801E-15
  validation loss:		2.527170E-15
Epoch took 12.212s

Epoch 25 of 100
  training loss:		1.564938E-15
  validation loss:		1.176696E-15
Epoch took 12.298s

Epoch 26 of 100
  training loss:		7.163650E-16
  validation loss:		5.277631E-16
Epoch took 12.806s

Epoch 27 of 100
  training loss:		3.320700E-16
  validation loss:		2.456222E-16
Epoch took 11.671s

Epoch 28 of 100
  training loss:		1.544235E-16
  validation loss:		1.148161E-16
Epoch took 13.696s

Epoch 29 of 100
  training loss:		7.244529E-17
  validation loss:		5.284479E-17
Epoch took 12.631s

Epoch 30 of 100
  training loss:		3.380016E-17
  validation loss:		2.514591E-17
Epoch took 13.113s

Epoch 31 of 100
  training loss:		1.613238E-17
  validation loss:		1.201785E-17
Epoch took 12.249s

Epoch 32 of 100
  training loss:		7.972745E-18
  validation loss:		6.274665E-18
Epoch took 12.403s

Epoch 33 of 100
  training loss:		4.144689E-18
  validation loss:		3.183718E-18
Epoch took 12.838s

Epoch 34 of 100
  training loss:		2.156929E-18
  validation loss:		1.582953E-18
Epoch took 11.053s

Epoch 35 of 100
  training loss:		1.056980E-18
  validation loss:		8.283857E-19
Epoch took 12.006s

Epoch 36 of 100
  training loss:		5.731141E-19
  validation loss:		4.235273E-19
Epoch took 14.395s

Epoch 37 of 100
  training loss:		2.968558E-19
  validation loss:		2.454597E-19
Epoch took 10.488s

Epoch 38 of 100
  training loss:		1.561048E-19
  validation loss:		1.159728E-19
Epoch took 12.572s

Epoch 39 of 100
  training loss:		8.146171E-20
  validation loss:		6.566518E-20
Epoch took 13.759s

Epoch 40 of 100
  training loss:		4.539927E-20
  validation loss:		3.423173E-20
Epoch took 13.344s

Epoch 41 of 100
  training loss:		2.359166E-20
  validation loss:		1.897365E-20
Epoch took 12.356s

Epoch 42 of 100
  training loss:		1.361699E-20
  validation loss:		1.033756E-20
Epoch took 11.240s

Epoch 43 of 100
  training loss:		7.748371E-21
  validation loss:		5.856151E-21
Epoch took 12.984s

Epoch 44 of 100
  training loss:		4.260163E-21
  validation loss:		3.726851E-21
Epoch took 12.529s

Epoch 45 of 100
  training loss:		2.625768E-21
  validation loss:		2.060151E-21
Epoch took 11.921s

Epoch 46 of 100
  training loss:		1.594663E-21
  validation loss:		1.338999E-21
Epoch took 12.939s

Epoch 47 of 100
  training loss:		9.693203E-22
  validation loss:		8.546063E-22
Epoch took 13.813s

Epoch 48 of 100
  training loss:		9.320547E-22
  validation loss:		5.492016E-22
Epoch took 12.452s

Epoch 49 of 100
  training loss:		5.474555E-04
  validation loss:		3.368979E-06
Epoch took 11.919s

Epoch 50 of 100
  training loss:		2.016767E-06
  validation loss:		7.254004E-07
Epoch took 12.759s

Epoch 51 of 100
  training loss:		4.536811E-07
  validation loss:		9.216429E-08
Epoch took 11.588s

Epoch 52 of 100
  training loss:		4.931902E-08
  validation loss:		5.936171E-09
Epoch took 12.137s

Epoch 53 of 100
  training loss:		2.890877E-09
  validation loss:		3.510562E-10
Epoch took 11.133s

Epoch 54 of 100
  training loss:		1.300220E-10
  validation loss:		2.075002E-11
Epoch took 12.367s

Epoch 55 of 100
  training loss:		1.155726E-11
  validation loss:		2.585327E-12
Epoch took 10.949s

Epoch 56 of 100
  training loss:		1.829068E-12
  validation loss:		7.219805E-13
Epoch took 12.594s

Epoch 57 of 100
  training loss:		5.616283E-13
  validation loss:		2.418188E-13
Epoch took 11.931s

Epoch 58 of 100
  training loss:		2.027394E-13
  validation loss:		9.844545E-14
Epoch took 12.463s

Epoch 59 of 100
  training loss:		8.063925E-14
  validation loss:		4.687479E-14
Epoch took 12.367s

Epoch 60 of 100
  training loss:		3.304722E-14
  validation loss:		1.660493E-14
Epoch took 12.638s

Epoch 61 of 100
  training loss:		1.477510E-14
  validation loss:		8.038633E-15
Epoch took 11.885s

Epoch 62 of 100
  training loss:		6.869635E-15
  validation loss:		3.559034E-15
Epoch took 13.835s

Epoch 63 of 100
  training loss:		3.244802E-15
  validation loss:		1.727464E-15
Epoch took 13.842s

Epoch 64 of 100
  training loss:		1.522429E-15
  validation loss:		7.819867E-16
Epoch took 12.509s

Epoch 65 of 100
  training loss:		7.174673E-16
  validation loss:		3.827532E-16
Epoch took 13.117s

Epoch 66 of 100
  training loss:		3.589156E-16
  validation loss:		1.959091E-16
Epoch took 13.921s

Epoch 67 of 100
  training loss:		1.766085E-16
  validation loss:		9.291754E-17
Epoch took 12.820s

Epoch 68 of 100
  training loss:		8.728304E-17
  validation loss:		5.708518E-17
Epoch took 12.231s

Epoch 69 of 100
  training loss:		4.171242E-17
  validation loss:		2.856910E-17
Epoch took 11.128s

Epoch 70 of 100
  training loss:		2.099327E-17
  validation loss:		1.272005E-17
Epoch took 11.570s

Epoch 71 of 100
  training loss:		1.042922E-17
  validation loss:		5.594261E-18
Epoch took 13.749s

Epoch 72 of 100
  training loss:		5.039016E-18
  validation loss:		2.584894E-18
Epoch took 13.056s

Epoch 73 of 100
  training loss:		2.382339E-18
  validation loss:		1.231911E-18
Epoch took 12.174s

Epoch 74 of 100
  training loss:		1.160364E-18
  validation loss:		6.317043E-19
Epoch took 12.673s

Epoch 75 of 100
  training loss:		6.130086E-19
  validation loss:		3.470554E-19
Epoch took 13.381s

Epoch 76 of 100
  training loss:		3.154561E-19
  validation loss:		1.693782E-19
Epoch took 12.567s

Epoch 77 of 100
  training loss:		1.690936E-19
  validation loss:		9.332908E-20
Epoch took 12.215s

Epoch 78 of 100
  training loss:		8.628938E-20
  validation loss:		4.648665E-20
Epoch took 12.468s

Epoch 79 of 100
  training loss:		4.712885E-20
  validation loss:		2.726748E-20
Epoch took 12.832s

Epoch 80 of 100
  training loss:		2.600173E-20
  validation loss:		1.393338E-20
Epoch took 12.661s

Epoch 81 of 100
  training loss:		1.396984E-20
  validation loss:		7.417856E-21
Epoch took 12.310s

Epoch 82 of 100
  training loss:		7.246013E-21
  validation loss:		4.263529E-21
Epoch took 12.157s

Epoch 83 of 100
  training loss:		4.031456E-21
  validation loss:		2.176156E-21
Epoch took 12.303s

Epoch 84 of 100
  training loss:		2.188849E-21
  validation loss:		1.458187E-21
Epoch took 11.866s

Epoch 85 of 100
  training loss:		1.184433E-21
  validation loss:		8.893601E-22
Epoch took 11.653s

Epoch 86 of 100
  training loss:		6.384478E-22
  validation loss:		4.055521E-22
Epoch took 12.593s

Epoch 87 of 100
  training loss:		3.753702E-22
  validation loss:		2.753552E-22
Epoch took 12.932s

Epoch 88 of 100
  training loss:		2.129560E-22
  validation loss:		1.437506E-22
Epoch took 12.584s

Epoch 89 of 100
  training loss:		1.296981E-22
  validation loss:		7.388156E-23
Epoch took 12.211s

Epoch 90 of 100
  training loss:		7.984728E-23
  validation loss:		4.829648E-23
Epoch took 12.056s

Epoch 91 of 100
  training loss:		4.773948E-23
  validation loss:		3.214047E-23
Epoch took 12.270s

Epoch 92 of 100
  training loss:		2.923091E-23
  validation loss:		1.885744E-23
Epoch took 13.350s

Epoch 93 of 100
  training loss:		2.047845E-23
  validation loss:		1.381499E-23
Epoch took 12.041s

Epoch 94 of 100
  training loss:		1.414723E-23
  validation loss:		6.524453E-24
Epoch took 11.989s

Epoch 95 of 100
  training loss:		8.966788E-24
  validation loss:		3.973327E-24
Epoch took 11.986s

Epoch 96 of 100
  training loss:		4.835950E-24
  validation loss:		3.452246E-24
Epoch took 11.401s

Epoch 97 of 100
  training loss:		3.514807E-24
  validation loss:		3.938220E-24
Epoch took 12.966s

Epoch 98 of 100
  training loss:		2.895239E-24
  validation loss:		1.738092E-24
Epoch took 13.047s

Epoch 99 of 100
  training loss:		2.137531E-24
  validation loss:		1.260607E-24
Epoch took 12.946s

Epoch 100 of 100
  training loss:		1.283577E-04
  validation loss:		7.509158E-03
Epoch took 13.050s

Training RMSE: 0.088351135899
Validation RMSE: 0.0866415052733
