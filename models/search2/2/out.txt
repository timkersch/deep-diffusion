Epoch 1 of 500
  training loss:		1.067092E-01
  validation loss:		7.418273E-02

Epoch 2 of 500
  training loss:		6.797367E-02
  validation loss:		6.179486E-02

Epoch 3 of 500
  training loss:		5.500409E-02
  validation loss:		4.765156E-02

Epoch 4 of 500
  training loss:		3.968731E-02
  validation loss:		3.194694E-02

Epoch 5 of 500
  training loss:		2.475771E-02
  validation loss:		1.850260E-02

Epoch 6 of 500
  training loss:		1.410499E-02
  validation loss:		1.070549E-02

Epoch 7 of 500
  training loss:		9.152639E-03
  validation loss:		7.922417E-03

Epoch 8 of 500
  training loss:		7.571749E-03
  validation loss:		6.979045E-03

Epoch 9 of 500
  training loss:		6.883211E-03
  validation loss:		6.426790E-03

Epoch 10 of 500
  training loss:		6.362567E-03
  validation loss:		5.933914E-03

Epoch 11 of 500
  training loss:		5.885901E-03
  validation loss:		5.504673E-03

Epoch 12 of 500
  training loss:		5.456478E-03
  validation loss:		5.218690E-03

Epoch 13 of 500
  training loss:		5.045722E-03
  validation loss:		4.690863E-03

Epoch 14 of 500
  training loss:		4.662122E-03
  validation loss:		4.324117E-03

Epoch 15 of 500
  training loss:		4.291068E-03
  validation loss:		3.978454E-03

Epoch 16 of 500
  training loss:		3.957982E-03
  validation loss:		3.669861E-03

Epoch 17 of 500
  training loss:		3.641627E-03
  validation loss:		3.498973E-03

Epoch 18 of 500
  training loss:		3.364382E-03
  validation loss:		3.125083E-03

Epoch 19 of 500
  training loss:		3.117833E-03
  validation loss:		2.911376E-03

Epoch 20 of 500
  training loss:		2.887451E-03
  validation loss:		2.729338E-03

Epoch 21 of 500
  training loss:		2.693538E-03
  validation loss:		2.520509E-03

Epoch 22 of 500
  training loss:		2.510844E-03
  validation loss:		2.371772E-03

Epoch 23 of 500
  training loss:		2.360016E-03
  validation loss:		2.223474E-03

Epoch 24 of 500
  training loss:		2.229421E-03
  validation loss:		2.127033E-03

Epoch 25 of 500
  training loss:		2.106895E-03
  validation loss:		1.999666E-03

Epoch 26 of 500
  training loss:		2.005712E-03
  validation loss:		1.905226E-03

Epoch 27 of 500
  training loss:		1.914476E-03
  validation loss:		1.955807E-03

Epoch 28 of 500
  training loss:		1.836366E-03
  validation loss:		1.765278E-03

Epoch 29 of 500
  training loss:		1.768920E-03
  validation loss:		1.750922E-03

Epoch 30 of 500
  training loss:		1.705894E-03
  validation loss:		1.666756E-03

Epoch 31 of 500
  training loss:		1.647770E-03
  validation loss:		1.611981E-03

Epoch 32 of 500
  training loss:		1.603899E-03
  validation loss:		1.594140E-03

Epoch 33 of 500
  training loss:		1.559335E-03
  validation loss:		1.523879E-03

Epoch 34 of 500
  training loss:		1.523336E-03
  validation loss:		1.484046E-03

Epoch 35 of 500
  training loss:		1.488613E-03
  validation loss:		1.445522E-03

Epoch 36 of 500
  training loss:		1.456896E-03
  validation loss:		1.426376E-03

Epoch 37 of 500
  training loss:		1.426151E-03
  validation loss:		1.381814E-03

Epoch 38 of 500
  training loss:		1.393307E-03
  validation loss:		1.356120E-03

Epoch 39 of 500
  training loss:		1.350596E-03
  validation loss:		1.292562E-03

Epoch 40 of 500
  training loss:		1.281141E-03
  validation loss:		1.245315E-03

Epoch 41 of 500
  training loss:		1.168999E-03
  validation loss:		1.090916E-03

Epoch 42 of 500
  training loss:		1.036023E-03
  validation loss:		9.418719E-04

Epoch 43 of 500
  training loss:		8.937234E-04
  validation loss:		8.128691E-04

Epoch 44 of 500
  training loss:		7.651401E-04
  validation loss:		6.932593E-04

Epoch 45 of 500
  training loss:		6.564214E-04
  validation loss:		5.965761E-04

Epoch 46 of 500
  training loss:		5.686535E-04
  validation loss:		5.236169E-04

Epoch 47 of 500
  training loss:		5.006749E-04
  validation loss:		4.689129E-04

Epoch 48 of 500
  training loss:		4.459432E-04
  validation loss:		4.125968E-04

Epoch 49 of 500
  training loss:		4.001915E-04
  validation loss:		3.742063E-04

Epoch 50 of 500
  training loss:		3.618402E-04
  validation loss:		3.525548E-04

Epoch 51 of 500
  training loss:		3.276995E-04
  validation loss:		3.086867E-04

Epoch 52 of 500
  training loss:		3.007354E-04
  validation loss:		2.815591E-04

Epoch 53 of 500
  training loss:		2.750522E-04
  validation loss:		2.588875E-04

Epoch 54 of 500
  training loss:		2.513179E-04
  validation loss:		2.526668E-04

Epoch 55 of 500
  training loss:		2.325511E-04
  validation loss:		2.203381E-04

Epoch 56 of 500
  training loss:		2.170958E-04
  validation loss:		2.050979E-04

Epoch 57 of 500
  training loss:		2.005846E-04
  validation loss:		1.933083E-04

Epoch 58 of 500
  training loss:		1.876418E-04
  validation loss:		1.794617E-04

Epoch 59 of 500
  training loss:		1.752387E-04
  validation loss:		1.904190E-04

Epoch 60 of 500
  training loss:		1.645472E-04
  validation loss:		1.591962E-04

Epoch 61 of 500
  training loss:		1.543819E-04
  validation loss:		1.784680E-04

Epoch 62 of 500
  training loss:		1.450807E-04
  validation loss:		1.542942E-04

Epoch 63 of 500
  training loss:		1.365443E-04
  validation loss:		1.368034E-04

Epoch 64 of 500
  training loss:		1.296040E-04
  validation loss:		1.259256E-04

Epoch 65 of 500
  training loss:		1.221444E-04
  validation loss:		1.233558E-04

Epoch 66 of 500
  training loss:		1.163626E-04
  validation loss:		1.132856E-04

Epoch 67 of 500
  training loss:		1.102715E-04
  validation loss:		1.075581E-04

Epoch 68 of 500
  training loss:		1.042414E-04
  validation loss:		1.048162E-04

Epoch 69 of 500
  training loss:		1.005405E-04
  validation loss:		1.014884E-04

Epoch 70 of 500
  training loss:		9.459730E-05
  validation loss:		9.310986E-05

Epoch 71 of 500
  training loss:		9.107168E-05
  validation loss:		9.430969E-05

Epoch 72 of 500
  training loss:		8.625298E-05
  validation loss:		8.537835E-05

Epoch 73 of 500
  training loss:		8.288128E-05
  validation loss:		8.312459E-05

Epoch 74 of 500
  training loss:		7.891024E-05
  validation loss:		7.804137E-05

Epoch 75 of 500
  training loss:		7.612230E-05
  validation loss:		7.540468E-05

Epoch 76 of 500
  training loss:		7.342031E-05
  validation loss:		7.391193E-05

Epoch 77 of 500
  training loss:		7.031929E-05
  validation loss:		7.058542E-05

Epoch 78 of 500
  training loss:		6.726958E-05
  validation loss:		6.913348E-05

Epoch 79 of 500
  training loss:		6.470491E-05
  validation loss:		6.912891E-05

Epoch 80 of 500
  training loss:		6.186241E-05
  validation loss:		6.711369E-05

Epoch 81 of 500
  training loss:		6.013498E-05
  validation loss:		6.316431E-05

Epoch 82 of 500
  training loss:		5.808561E-05
  validation loss:		6.020707E-05

Epoch 83 of 500
  training loss:		5.602035E-05
  validation loss:		5.539916E-05

Epoch 84 of 500
  training loss:		5.413778E-05
  validation loss:		5.492816E-05

Epoch 85 of 500
  training loss:		5.211140E-05
  validation loss:		5.277556E-05

Epoch 86 of 500
  training loss:		5.088222E-05
  validation loss:		5.295148E-05

Epoch 87 of 500
  training loss:		4.928787E-05
  validation loss:		5.803338E-05

Epoch 88 of 500
  training loss:		4.774474E-05
  validation loss:		4.747454E-05

Epoch 89 of 500
  training loss:		4.628005E-05
  validation loss:		4.581418E-05

Epoch 90 of 500
  training loss:		4.480818E-05
  validation loss:		4.456930E-05

Epoch 91 of 500
  training loss:		4.410790E-05
  validation loss:		4.363969E-05

Epoch 92 of 500
  training loss:		4.222661E-05
  validation loss:		4.216384E-05

Epoch 93 of 500
  training loss:		4.141938E-05
  validation loss:		4.146409E-05

Epoch 94 of 500
  training loss:		4.052340E-05
  validation loss:		4.007964E-05

Epoch 95 of 500
  training loss:		4.006484E-05
  validation loss:		4.315607E-05

Epoch 96 of 500
  training loss:		3.812741E-05
  validation loss:		3.810452E-05

Epoch 97 of 500
  training loss:		3.763288E-05
  validation loss:		3.771871E-05

Epoch 98 of 500
  training loss:		3.700430E-05
  validation loss:		3.745615E-05

Epoch 99 of 500
  training loss:		3.563610E-05
  validation loss:		3.547663E-05

Epoch 100 of 500
  training loss:		3.517104E-05
  validation loss:		3.693304E-05

Epoch 101 of 500
  training loss:		3.414775E-05
  validation loss:		3.378656E-05

Epoch 102 of 500
  training loss:		3.353159E-05
  validation loss:		3.296363E-05

Epoch 103 of 500
  training loss:		3.272990E-05
  validation loss:		3.215313E-05

Epoch 104 of 500
  training loss:		3.243635E-05
  validation loss:		3.184824E-05

Epoch 105 of 500
  training loss:		3.118110E-05
  validation loss:		3.324934E-05

Epoch 106 of 500
  training loss:		3.068104E-05
  validation loss:		3.042266E-05

Epoch 107 of 500
  training loss:		3.013007E-05
  validation loss:		2.935743E-05

Epoch 108 of 500
  training loss:		2.927805E-05
  validation loss:		3.405522E-05

Epoch 109 of 500
  training loss:		2.885395E-05
  validation loss:		2.942117E-05

Epoch 110 of 500
  training loss:		2.804415E-05
  validation loss:		2.757368E-05

Epoch 111 of 500
  training loss:		2.776300E-05
  validation loss:		2.713211E-05

Epoch 112 of 500
  training loss:		2.703445E-05
  validation loss:		2.768673E-05

Epoch 113 of 500
  training loss:		2.662163E-05
  validation loss:		2.587566E-05

Epoch 114 of 500
  training loss:		2.580837E-05
  validation loss:		3.003391E-05

Epoch 115 of 500
  training loss:		2.534253E-05
  validation loss:		2.726574E-05

Epoch 116 of 500
  training loss:		2.514863E-05
  validation loss:		2.482319E-05

Epoch 117 of 500
  training loss:		2.464584E-05
  validation loss:		2.683112E-05

Epoch 118 of 500
  training loss:		2.406740E-05
  validation loss:		2.355614E-05

Epoch 119 of 500
  training loss:		2.359761E-05
  validation loss:		2.380964E-05

Epoch 120 of 500
  training loss:		2.294033E-05
  validation loss:		3.376096E-05

Epoch 121 of 500
  training loss:		2.257204E-05
  validation loss:		2.208532E-05

Epoch 122 of 500
  training loss:		2.240392E-05
  validation loss:		2.218776E-05

Epoch 123 of 500
  training loss:		2.182992E-05
  validation loss:		2.416682E-05

Epoch 124 of 500
  training loss:		2.156293E-05
  validation loss:		2.566846E-05

Epoch 125 of 500
  training loss:		2.077175E-05
  validation loss:		2.168312E-05

Epoch 126 of 500
  training loss:		2.072996E-05
  validation loss:		2.217297E-05

Epoch 127 of 500
  training loss:		2.058249E-05
  validation loss:		2.138995E-05

Epoch 128 of 500
  training loss:		1.970532E-05
  validation loss:		2.034731E-05

Epoch 129 of 500
  training loss:		1.959262E-05
  validation loss:		1.923607E-05

Epoch 130 of 500
  training loss:		1.907414E-05
  validation loss:		2.021020E-05

Epoch 131 of 500
  training loss:		1.901050E-05
  validation loss:		1.947214E-05

Epoch 132 of 500
  training loss:		1.846399E-05
  validation loss:		1.861504E-05

Epoch 133 of 500
  training loss:		1.815550E-05
  validation loss:		2.205404E-05

Epoch 134 of 500
  training loss:		1.794457E-05
  validation loss:		1.895955E-05

Epoch 135 of 500
  training loss:		1.772205E-05
  validation loss:		1.998592E-05

Epoch 136 of 500
  training loss:		1.757585E-05
  validation loss:		1.675744E-05

Epoch 137 of 500
  training loss:		1.683683E-05
  validation loss:		1.980797E-05

Epoch 138 of 500
  training loss:		1.688933E-05
  validation loss:		1.673977E-05

Epoch 139 of 500
  training loss:		1.656711E-05
  validation loss:		1.909366E-05

Epoch 140 of 500
  training loss:		1.611411E-05
  validation loss:		1.659784E-05

Epoch 141 of 500
  training loss:		1.600981E-05
  validation loss:		1.689756E-05

Epoch 142 of 500
  training loss:		1.594857E-05
  validation loss:		1.540874E-05

Epoch 143 of 500
  training loss:		1.546081E-05
  validation loss:		1.491338E-05

Epoch 144 of 500
  training loss:		1.545152E-05
  validation loss:		1.485758E-05

Epoch 145 of 500
  training loss:		1.509201E-05
  validation loss:		1.458685E-05

Epoch 146 of 500
  training loss:		1.467525E-05
  validation loss:		1.576861E-05

Epoch 147 of 500
  training loss:		1.458230E-05
  validation loss:		1.862953E-05

Epoch 148 of 500
  training loss:		1.414208E-05
  validation loss:		1.386859E-05

Epoch 149 of 500
  training loss:		1.414702E-05
  validation loss:		1.377035E-05

Epoch 150 of 500
  training loss:		1.377955E-05
  validation loss:		1.454736E-05

Epoch 151 of 500
  training loss:		1.372693E-05
  validation loss:		1.324753E-05

Epoch 152 of 500
  training loss:		1.362454E-05
  validation loss:		1.301368E-05

Epoch 153 of 500
  training loss:		1.346516E-05
  validation loss:		1.686355E-05

Epoch 154 of 500
  training loss:		1.320481E-05
  validation loss:		1.327623E-05

Epoch 155 of 500
  training loss:		1.293853E-05
  validation loss:		1.706288E-05

Epoch 156 of 500
  training loss:		1.264187E-05
  validation loss:		1.256104E-05

Epoch 157 of 500
  training loss:		1.273862E-05
  validation loss:		1.398436E-05

Epoch 158 of 500
  training loss:		1.233183E-05
  validation loss:		1.243497E-05

Epoch 159 of 500
  training loss:		1.214825E-05
  validation loss:		1.389277E-05

Epoch 160 of 500
  training loss:		1.209149E-05
  validation loss:		1.157434E-05

Epoch 161 of 500
  training loss:		1.197903E-05
  validation loss:		1.170106E-05

Epoch 162 of 500
  training loss:		1.158052E-05
  validation loss:		1.359304E-05

Epoch 163 of 500
  training loss:		1.158324E-05
  validation loss:		1.113412E-05

Epoch 164 of 500
  training loss:		1.136575E-05
  validation loss:		1.251609E-05

Epoch 165 of 500
  training loss:		1.135071E-05
  validation loss:		1.077394E-05

Epoch 166 of 500
  training loss:		1.104312E-05
  validation loss:		1.091695E-05

Epoch 167 of 500
  training loss:		1.086246E-05
  validation loss:		1.320665E-05

Epoch 168 of 500
  training loss:		1.067373E-05
  validation loss:		1.117186E-05

Epoch 169 of 500
  training loss:		1.047439E-05
  validation loss:		1.083038E-05

Epoch 170 of 500
  training loss:		1.033316E-05
  validation loss:		1.051403E-05

Epoch 171 of 500
  training loss:		1.054584E-05
  validation loss:		9.948970E-06

Epoch 172 of 500
  training loss:		1.020497E-05
  validation loss:		1.336053E-05

Epoch 173 of 500
  training loss:		1.003968E-05
  validation loss:		9.671156E-06

Epoch 174 of 500
  training loss:		1.006208E-05
  validation loss:		1.110005E-05

Epoch 175 of 500
  training loss:		1.001013E-05
  validation loss:		9.477777E-06

Epoch 176 of 500
  training loss:		9.787885E-06
  validation loss:		1.064649E-05

Epoch 177 of 500
  training loss:		9.707314E-06
  validation loss:		9.161110E-06

Epoch 178 of 500
  training loss:		9.398417E-06
  validation loss:		1.033747E-05

Epoch 179 of 500
  training loss:		9.287369E-06
  validation loss:		1.232896E-05

Epoch 180 of 500
  training loss:		9.444362E-06
  validation loss:		9.077909E-06

Epoch 181 of 500
  training loss:		9.129783E-06
  validation loss:		9.145120E-06

Epoch 182 of 500
  training loss:		8.987274E-06
  validation loss:		1.075353E-05

Epoch 183 of 500
  training loss:		8.626597E-06
  validation loss:		8.658819E-06

Epoch 184 of 500
  training loss:		8.845337E-06
  validation loss:		9.838151E-06

Epoch 185 of 500
  training loss:		8.503114E-06
  validation loss:		1.011326E-05

Epoch 186 of 500
  training loss:		8.646321E-06
  validation loss:		8.387046E-06

Epoch 187 of 500
  training loss:		8.432300E-06
  validation loss:		8.067304E-06

Epoch 188 of 500
  training loss:		8.340826E-06
  validation loss:		7.956938E-06

Epoch 189 of 500
  training loss:		8.203990E-06
  validation loss:		7.989134E-06

Epoch 190 of 500
  training loss:		8.087801E-06
  validation loss:		8.071406E-06

Epoch 191 of 500
  training loss:		8.230942E-06
  validation loss:		9.240053E-06

Epoch 192 of 500
  training loss:		7.940375E-06
  validation loss:		7.558304E-06

Epoch 193 of 500
  training loss:		7.852490E-06
  validation loss:		7.590055E-06

Epoch 194 of 500
  training loss:		7.627506E-06
  validation loss:		7.698732E-06

Epoch 195 of 500
  training loss:		7.636502E-06
  validation loss:		7.295343E-06

Epoch 196 of 500
  training loss:		7.565391E-06
  validation loss:		9.228608E-06

Epoch 197 of 500
  training loss:		7.563380E-06
  validation loss:		7.109154E-06

Epoch 198 of 500
  training loss:		7.373101E-06
  validation loss:		7.008337E-06

Epoch 199 of 500
  training loss:		7.375408E-06
  validation loss:		7.656440E-06

Epoch 200 of 500
  training loss:		7.148638E-06
  validation loss:		7.458354E-06

Epoch 201 of 500
  training loss:		7.096002E-06
  validation loss:		6.876173E-06

Epoch 202 of 500
  training loss:		6.918025E-06
  validation loss:		6.863702E-06

Epoch 203 of 500
  training loss:		6.910432E-06
  validation loss:		6.572381E-06

Epoch 204 of 500
  training loss:		6.878958E-06
  validation loss:		6.726140E-06

Epoch 205 of 500
  training loss:		6.719992E-06
  validation loss:		6.721969E-06

Epoch 206 of 500
  training loss:		6.538366E-06
  validation loss:		6.342394E-06

Epoch 207 of 500
  training loss:		6.559508E-06
  validation loss:		6.220653E-06

Epoch 208 of 500
  training loss:		6.567700E-06
  validation loss:		6.491202E-06

Epoch 209 of 500
  training loss:		6.551224E-06
  validation loss:		7.332546E-06

Epoch 210 of 500
  training loss:		6.281412E-06
  validation loss:		6.062850E-06

Epoch 211 of 500
  training loss:		6.280046E-06
  validation loss:		6.071727E-06

Epoch 212 of 500
  training loss:		6.248606E-06
  validation loss:		5.909336E-06

Epoch 213 of 500
  training loss:		6.077073E-06
  validation loss:		6.773557E-06

Epoch 214 of 500
  training loss:		6.198960E-06
  validation loss:		5.790552E-06

Epoch 215 of 500
  training loss:		5.927089E-06
  validation loss:		5.647411E-06

Epoch 216 of 500
  training loss:		5.843261E-06
  validation loss:		5.611741E-06

Epoch 217 of 500
  training loss:		5.797901E-06
  validation loss:		5.713810E-06

Epoch 218 of 500
  training loss:		5.834721E-06
  validation loss:		5.821733E-06

Epoch 219 of 500
  training loss:		5.786064E-06
  validation loss:		5.488043E-06

Epoch 220 of 500
  training loss:		5.583262E-06
  validation loss:		5.397824E-06

Epoch 221 of 500
  training loss:		5.519761E-06
  validation loss:		5.510338E-06

Epoch 222 of 500
  training loss:		5.457561E-06
  validation loss:		6.400522E-06

Epoch 223 of 500
  training loss:		5.431627E-06
  validation loss:		5.170666E-06

Epoch 224 of 500
  training loss:		5.316173E-06
  validation loss:		5.357148E-06

Epoch 225 of 500
  training loss:		5.261372E-06
  validation loss:		5.025809E-06

Epoch 226 of 500
  training loss:		5.263974E-06
  validation loss:		5.155405E-06

Epoch 227 of 500
  training loss:		5.252348E-06
  validation loss:		5.458882E-06

Epoch 228 of 500
  training loss:		5.155952E-06
  validation loss:		5.095042E-06

Epoch 229 of 500
  training loss:		5.134505E-06
  validation loss:		4.940899E-06

Epoch 230 of 500
  training loss:		5.120254E-06
  validation loss:		4.790188E-06

Epoch 231 of 500
  training loss:		4.852363E-06
  validation loss:		4.981404E-06

Epoch 232 of 500
  training loss:		4.905613E-06
  validation loss:		6.062841E-06

Epoch 233 of 500
  training loss:		4.880383E-06
  validation loss:		4.887341E-06

Epoch 234 of 500
  training loss:		4.733633E-06
  validation loss:		4.539009E-06

Epoch 235 of 500
  training loss:		4.712696E-06
  validation loss:		4.472854E-06

Epoch 236 of 500
  training loss:		4.600005E-06
  validation loss:		5.970525E-06

Epoch 237 of 500
  training loss:		4.697540E-06
  validation loss:		7.548073E-06

Epoch 238 of 500
  training loss:		4.599796E-06
  validation loss:		4.292629E-06

Epoch 239 of 500
  training loss:		4.427065E-06
  validation loss:		5.365037E-06

Epoch 240 of 500
  training loss:		4.380965E-06
  validation loss:		4.297906E-06

Epoch 241 of 500
  training loss:		4.424368E-06
  validation loss:		4.240336E-06

Epoch 242 of 500
  training loss:		4.376454E-06
  validation loss:		4.234313E-06

Epoch 243 of 500
  training loss:		4.298153E-06
  validation loss:		4.808931E-06

Epoch 244 of 500
  training loss:		4.243031E-06
  validation loss:		4.031104E-06

Epoch 245 of 500
  training loss:		4.274721E-06
  validation loss:		4.267099E-06

Epoch 246 of 500
  training loss:		4.235133E-06
  validation loss:		4.088940E-06

Epoch 247 of 500
  training loss:		4.168834E-06
  validation loss:		5.359433E-06

Epoch 248 of 500
  training loss:		4.015142E-06
  validation loss:		3.885672E-06

Epoch 249 of 500
  training loss:		3.970449E-06
  validation loss:		3.962803E-06

Epoch 250 of 500
  training loss:		4.040899E-06
  validation loss:		3.914316E-06

Epoch 251 of 500
  training loss:		3.807679E-06
  validation loss:		3.720002E-06

Epoch 252 of 500
  training loss:		3.931839E-06
  validation loss:		3.653244E-06

Epoch 253 of 500
  training loss:		3.906245E-06
  validation loss:		3.753056E-06

Epoch 254 of 500
  training loss:		3.821408E-06
  validation loss:		3.577456E-06

Epoch 255 of 500
  training loss:		3.840165E-06
  validation loss:		3.595444E-06

Epoch 256 of 500
  training loss:		3.650591E-06
  validation loss:		3.757033E-06

Epoch 257 of 500
  training loss:		3.645076E-06
  validation loss:		3.498381E-06

Epoch 258 of 500
  training loss:		3.604091E-06
  validation loss:		5.789942E-06

Epoch 259 of 500
  training loss:		3.694018E-06
  validation loss:		7.227209E-06

Epoch 260 of 500
  training loss:		3.539537E-06
  validation loss:		3.363217E-06

Epoch 261 of 500
  training loss:		3.556313E-06
  validation loss:		4.978229E-06

Epoch 262 of 500
  training loss:		3.464984E-06
  validation loss:		3.639261E-06

Epoch 263 of 500
  training loss:		3.414093E-06
  validation loss:		3.210397E-06

Epoch 264 of 500
  training loss:		3.381184E-06
  validation loss:		3.460652E-06

Epoch 265 of 500
  training loss:		3.332965E-06
  validation loss:		3.128654E-06

Epoch 266 of 500
  training loss:		3.289464E-06
  validation loss:		3.075213E-06

Epoch 267 of 500
  training loss:		3.264552E-06
  validation loss:		3.434463E-06

Epoch 268 of 500
  training loss:		3.230249E-06
  validation loss:		3.157332E-06

Epoch 269 of 500
  training loss:		3.161868E-06
  validation loss:		2.977803E-06

Epoch 270 of 500
  training loss:		3.244906E-06
  validation loss:		3.704936E-06

Epoch 271 of 500
  training loss:		3.138951E-06
  validation loss:		4.367999E-06

Epoch 272 of 500
  training loss:		3.055822E-06
  validation loss:		2.903052E-06

Epoch 273 of 500
  training loss:		3.106407E-06
  validation loss:		4.831798E-06

Epoch 274 of 500
  training loss:		3.079643E-06
  validation loss:		3.671249E-06

Epoch 275 of 500
  training loss:		3.043585E-06
  validation loss:		3.033305E-06

Epoch 276 of 500
  training loss:		2.981507E-06
  validation loss:		2.812316E-06

Epoch 277 of 500
  training loss:		2.979886E-06
  validation loss:		3.711676E-06

Epoch 278 of 500
  training loss:		2.901242E-06
  validation loss:		3.273226E-06

Epoch 279 of 500
  training loss:		2.908236E-06
  validation loss:		2.649557E-06

Epoch 280 of 500
  training loss:		2.854542E-06
  validation loss:		4.987117E-06

Early stopping, val-loss increased over the last 10 epochs from 0.00122727297815 to 0.00127931772175
Training RMSE: 1.53001856872e-09
Validation RMSE: 1.59609272969e-09
