Epoch 1 of 500
  training loss:		7.895306E-02
  validation loss:		3.137339E-02

Epoch 2 of 500
  training loss:		1.676349E-02
  validation loss:		9.269564E-03

Epoch 3 of 500
  training loss:		8.268937E-03
  validation loss:		7.098711E-03

Epoch 4 of 500
  training loss:		6.605999E-03
  validation loss:		5.596326E-03

Epoch 5 of 500
  training loss:		5.095677E-03
  validation loss:		4.226583E-03

Epoch 6 of 500
  training loss:		3.765497E-03
  validation loss:		3.404682E-03

Epoch 7 of 500
  training loss:		2.806903E-03
  validation loss:		2.361954E-03

Epoch 8 of 500
  training loss:		2.209286E-03
  validation loss:		1.979840E-03

Epoch 9 of 500
  training loss:		1.720652E-03
  validation loss:		1.379111E-03

Epoch 10 of 500
  training loss:		1.054221E-03
  validation loss:		7.744597E-04

Epoch 11 of 500
  training loss:		6.808284E-04
  validation loss:		5.424866E-04

Epoch 12 of 500
  training loss:		4.770288E-04
  validation loss:		4.178568E-04

Epoch 13 of 500
  training loss:		3.513495E-04
  validation loss:		2.823983E-04

Epoch 14 of 500
  training loss:		2.672877E-04
  validation loss:		2.183243E-04

Epoch 15 of 500
  training loss:		2.106955E-04
  validation loss:		2.054511E-04

Epoch 16 of 500
  training loss:		1.707135E-04
  validation loss:		1.486497E-04

Epoch 17 of 500
  training loss:		1.444876E-04
  validation loss:		1.295033E-04

Epoch 18 of 500
  training loss:		1.235624E-04
  validation loss:		1.079336E-04

Epoch 19 of 500
  training loss:		1.047754E-04
  validation loss:		1.146547E-04

Epoch 20 of 500
  training loss:		9.037134E-05
  validation loss:		8.492121E-05

Epoch 21 of 500
  training loss:		8.067811E-05
  validation loss:		6.937031E-05

Epoch 22 of 500
  training loss:		7.188057E-05
  validation loss:		6.183625E-05

Epoch 23 of 500
  training loss:		6.390517E-05
  validation loss:		5.817536E-05

Epoch 24 of 500
  training loss:		5.811505E-05
  validation loss:		5.021536E-05

Epoch 25 of 500
  training loss:		5.404162E-05
  validation loss:		4.567781E-05

Epoch 26 of 500
  training loss:		4.861864E-05
  validation loss:		4.235984E-05

Epoch 27 of 500
  training loss:		4.556796E-05
  validation loss:		4.359738E-05

Epoch 28 of 500
  training loss:		4.168053E-05
  validation loss:		3.609295E-05

Epoch 29 of 500
  training loss:		4.021049E-05
  validation loss:		4.517671E-05

Epoch 30 of 500
  training loss:		3.650838E-05
  validation loss:		3.164985E-05

Epoch 31 of 500
  training loss:		3.366897E-05
  validation loss:		2.874542E-05

Epoch 32 of 500
  training loss:		3.215188E-05
  validation loss:		3.594884E-05

Epoch 33 of 500
  training loss:		3.142638E-05
  validation loss:		2.514786E-05

Epoch 34 of 500
  training loss:		2.896529E-05
  validation loss:		2.550666E-05

Epoch 35 of 500
  training loss:		2.774155E-05
  validation loss:		2.283637E-05

Epoch 36 of 500
  training loss:		2.551551E-05
  validation loss:		2.698648E-05

Epoch 37 of 500
  training loss:		2.490553E-05
  validation loss:		5.637920E-05

Epoch 38 of 500
  training loss:		2.380413E-05
  validation loss:		2.685419E-05

Epoch 39 of 500
  training loss:		2.317231E-05
  validation loss:		2.764327E-05

Epoch 40 of 500
  training loss:		2.170697E-05
  validation loss:		1.712232E-05

Epoch 41 of 500
  training loss:		2.019967E-05
  validation loss:		1.654270E-05

Epoch 42 of 500
  training loss:		1.971322E-05
  validation loss:		1.651728E-05

Epoch 43 of 500
  training loss:		1.865968E-05
  validation loss:		2.269174E-05

Epoch 44 of 500
  training loss:		1.887787E-05
  validation loss:		1.629219E-05

Epoch 45 of 500
  training loss:		1.678372E-05
  validation loss:		1.347865E-05

Epoch 46 of 500
  training loss:		1.656686E-05
  validation loss:		1.441021E-05

Epoch 47 of 500
  training loss:		1.623562E-05
  validation loss:		1.530281E-05

Epoch 48 of 500
  training loss:		1.621203E-05
  validation loss:		2.727674E-05

Epoch 49 of 500
  training loss:		1.514318E-05
  validation loss:		1.371372E-05

Epoch 50 of 500
  training loss:		1.408853E-05
  validation loss:		1.132033E-05

Epoch 51 of 500
  training loss:		1.453345E-05
  validation loss:		1.513754E-05

Epoch 52 of 500
  training loss:		1.357546E-05
  validation loss:		1.216256E-05

Epoch 53 of 500
  training loss:		1.345752E-05
  validation loss:		1.140450E-05

Epoch 54 of 500
  training loss:		1.252566E-05
  validation loss:		1.203719E-05

Epoch 55 of 500
  training loss:		1.197203E-05
  validation loss:		9.595494E-06

Epoch 56 of 500
  training loss:		1.202973E-05
  validation loss:		1.256151E-05

Epoch 57 of 500
  training loss:		1.138444E-05
  validation loss:		1.043675E-05

Epoch 58 of 500
  training loss:		1.062224E-05
  validation loss:		9.279012E-06

Epoch 59 of 500
  training loss:		1.105200E-05
  validation loss:		9.405628E-06

Epoch 60 of 500
  training loss:		1.040099E-05
  validation loss:		1.705311E-05

Epoch 61 of 500
  training loss:		1.026926E-05
  validation loss:		9.575622E-06

Epoch 62 of 500
  training loss:		9.524649E-06
  validation loss:		8.180669E-06

Epoch 63 of 500
  training loss:		9.891949E-06
  validation loss:		8.166573E-06

Epoch 64 of 500
  training loss:		9.864137E-06
  validation loss:		1.423921E-05

Epoch 65 of 500
  training loss:		9.277216E-06
  validation loss:		1.029338E-05

Epoch 66 of 500
  training loss:		8.660339E-06
  validation loss:		9.675913E-06

Epoch 67 of 500
  training loss:		8.332342E-06
  validation loss:		8.537060E-06

Epoch 68 of 500
  training loss:		8.283318E-06
  validation loss:		6.035965E-06

Epoch 69 of 500
  training loss:		8.222218E-06
  validation loss:		6.236322E-06

Epoch 70 of 500
  training loss:		8.289523E-06
  validation loss:		7.403895E-06

Epoch 71 of 500
  training loss:		7.240045E-06
  validation loss:		5.314555E-06

Epoch 72 of 500
  training loss:		7.719340E-06
  validation loss:		9.355974E-06

Epoch 73 of 500
  training loss:		7.328108E-06
  validation loss:		5.092346E-06

Epoch 74 of 500
  training loss:		6.785495E-06
  validation loss:		4.856594E-06

Epoch 75 of 500
  training loss:		6.862297E-06
  validation loss:		1.371195E-05

Epoch 76 of 500
  training loss:		6.546115E-06
  validation loss:		6.080697E-06

Epoch 77 of 500
  training loss:		6.581443E-06
  validation loss:		1.728053E-05

Epoch 78 of 500
  training loss:		6.246619E-06
  validation loss:		5.037044E-06

Epoch 79 of 500
  training loss:		6.214625E-06
  validation loss:		5.064494E-06

Epoch 80 of 500
  training loss:		5.638682E-06
  validation loss:		4.054540E-06

Epoch 81 of 500
  training loss:		5.838659E-06
  validation loss:		7.125008E-06

Epoch 82 of 500
  training loss:		5.682892E-06
  validation loss:		6.284785E-06

Epoch 83 of 500
  training loss:		5.740718E-06
  validation loss:		3.772751E-06

Epoch 84 of 500
  training loss:		5.126685E-06
  validation loss:		1.082256E-05

Epoch 85 of 500
  training loss:		5.387695E-06
  validation loss:		8.786099E-06

Epoch 86 of 500
  training loss:		5.254387E-06
  validation loss:		3.686633E-06

Epoch 87 of 500
  training loss:		5.212734E-06
  validation loss:		3.349953E-06

Epoch 88 of 500
  training loss:		5.022962E-06
  validation loss:		4.373932E-06

Epoch 89 of 500
  training loss:		5.044430E-06
  validation loss:		3.236387E-06

Epoch 90 of 500
  training loss:		4.782304E-06
  validation loss:		5.360183E-06

Epoch 91 of 500
  training loss:		4.657613E-06
  validation loss:		3.973170E-06

Epoch 92 of 500
  training loss:		4.388582E-06
  validation loss:		3.902626E-06

Epoch 93 of 500
  training loss:		4.362215E-06
  validation loss:		7.737321E-06

Epoch 94 of 500
  training loss:		4.293100E-06
  validation loss:		2.743935E-06

Epoch 95 of 500
  training loss:		4.016362E-06
  validation loss:		2.582901E-06

Epoch 96 of 500
  training loss:		4.131608E-06
  validation loss:		9.940602E-06

Epoch 97 of 500
  training loss:		4.192283E-06
  validation loss:		4.523905E-06

Epoch 98 of 500
  training loss:		3.950144E-06
  validation loss:		7.332809E-06

Epoch 99 of 500
  training loss:		4.136848E-06
  validation loss:		2.753529E-06

Epoch 100 of 500
  training loss:		3.631742E-06
  validation loss:		2.243965E-06

Epoch 101 of 500
  training loss:		3.671848E-06
  validation loss:		2.342742E-06

Epoch 102 of 500
  training loss:		3.635907E-06
  validation loss:		1.139008E-05

Epoch 103 of 500
  training loss:		3.719140E-06
  validation loss:		2.111836E-06

Epoch 104 of 500
  training loss:		3.458877E-06
  validation loss:		2.405295E-06

Epoch 105 of 500
  training loss:		3.761738E-06
  validation loss:		3.518805E-06

Epoch 106 of 500
  training loss:		3.142760E-06
  validation loss:		1.989973E-06

Epoch 107 of 500
  training loss:		3.348886E-06
  validation loss:		1.998516E-06

Epoch 108 of 500
  training loss:		3.438962E-06
  validation loss:		6.250448E-06

Epoch 109 of 500
  training loss:		2.989494E-06
  validation loss:		2.467428E-06

Epoch 110 of 500
  training loss:		3.214253E-06
  validation loss:		5.112643E-06

Epoch 111 of 500
  training loss:		2.839757E-06
  validation loss:		2.692622E-06

Epoch 112 of 500
  training loss:		3.201988E-06
  validation loss:		2.513458E-06

Epoch 113 of 500
  training loss:		2.920398E-06
  validation loss:		1.615639E-06

Epoch 114 of 500
  training loss:		2.942783E-06
  validation loss:		1.567348E-06

Epoch 115 of 500
  training loss:		3.060892E-06
  validation loss:		2.285150E-06

Epoch 116 of 500
  training loss:		2.810418E-06
  validation loss:		2.609600E-06

Epoch 117 of 500
  training loss:		2.787817E-06
  validation loss:		8.425475E-06

Epoch 118 of 500
  training loss:		2.857257E-06
  validation loss:		5.518804E-06

Epoch 119 of 500
  training loss:		2.721307E-06
  validation loss:		1.516704E-06

Epoch 120 of 500
  training loss:		2.850372E-06
  validation loss:		2.493551E-06

Epoch 121 of 500
  training loss:		2.494918E-06
  validation loss:		2.613978E-06

Epoch 122 of 500
  training loss:		2.535586E-06
  validation loss:		3.285967E-06

Epoch 123 of 500
  training loss:		2.677399E-06
  validation loss:		1.270631E-06

Epoch 124 of 500
  training loss:		2.422147E-06
  validation loss:		3.306729E-06

Epoch 125 of 500
  training loss:		2.413307E-06
  validation loss:		2.716474E-06

Epoch 126 of 500
  training loss:		2.276497E-06
  validation loss:		1.503733E-06

Epoch 127 of 500
  training loss:		2.498349E-06
  validation loss:		1.276206E-06

Epoch 128 of 500
  training loss:		2.320209E-06
  validation loss:		2.224466E-06

Epoch 129 of 500
  training loss:		2.226158E-06
  validation loss:		2.019895E-06

Epoch 130 of 500
  training loss:		2.159049E-06
  validation loss:		1.079033E-06

Epoch 131 of 500
  training loss:		2.396655E-06
  validation loss:		2.039732E-06

Epoch 132 of 500
  training loss:		2.130436E-06
  validation loss:		2.262782E-06

Epoch 133 of 500
  training loss:		2.164117E-06
  validation loss:		1.320094E-06

Epoch 134 of 500
  training loss:		2.432206E-06
  validation loss:		2.918268E-06

Epoch 135 of 500
  training loss:		2.144520E-06
  validation loss:		9.815937E-07

Epoch 136 of 500
  training loss:		2.066365E-06
  validation loss:		1.231841E-06

Epoch 137 of 500
  training loss:		2.059666E-06
  validation loss:		1.064819E-06

Epoch 138 of 500
  training loss:		2.106937E-06
  validation loss:		9.189502E-07

Epoch 139 of 500
  training loss:		2.018544E-06
  validation loss:		1.093843E-06

Epoch 140 of 500
  training loss:		2.058794E-06
  validation loss:		3.289264E-06

Epoch 141 of 500
  training loss:		1.903964E-06
  validation loss:		2.717348E-06

Epoch 142 of 500
  training loss:		1.983686E-06
  validation loss:		5.686349E-06

Epoch 143 of 500
  training loss:		1.841077E-06
  validation loss:		3.697023E-06

Epoch 144 of 500
  training loss:		2.068696E-06
  validation loss:		2.045206E-06

Epoch 145 of 500
  training loss:		1.875481E-06
  validation loss:		8.197369E-07

Epoch 146 of 500
  training loss:		1.899675E-06
  validation loss:		3.227893E-06

Epoch 147 of 500
  training loss:		1.838034E-06
  validation loss:		7.580324E-07

Epoch 148 of 500
  training loss:		1.853471E-06
  validation loss:		7.901309E-07

Epoch 149 of 500
  training loss:		1.752758E-06
  validation loss:		7.367715E-07

Epoch 150 of 500
  training loss:		1.742277E-06
  validation loss:		1.312144E-06

Epoch 151 of 500
  training loss:		1.788362E-06
  validation loss:		8.827519E-07

Epoch 152 of 500
  training loss:		1.763475E-06
  validation loss:		1.665812E-06

Epoch 153 of 500
  training loss:		1.829321E-06
  validation loss:		7.858994E-07

Epoch 154 of 500
  training loss:		1.671797E-06
  validation loss:		7.319935E-07

Epoch 155 of 500
  training loss:		1.737937E-06
  validation loss:		6.749178E-07

Epoch 156 of 500
  training loss:		1.570892E-06
  validation loss:		2.068521E-06

Epoch 157 of 500
  training loss:		1.909329E-06
  validation loss:		1.884289E-06

Epoch 158 of 500
  training loss:		1.713129E-06
  validation loss:		8.164610E-07

Epoch 159 of 500
  training loss:		1.614984E-06
  validation loss:		3.719793E-06

Epoch 160 of 500
  training loss:		1.589891E-06
  validation loss:		1.280187E-06

Epoch 161 of 500
  training loss:		1.615740E-06
  validation loss:		3.582542E-06

Epoch 162 of 500
  training loss:		1.540711E-06
  validation loss:		6.427591E-07

Epoch 163 of 500
  training loss:		1.665977E-06
  validation loss:		6.144147E-07

Epoch 164 of 500
  training loss:		1.690417E-06
  validation loss:		5.794990E-07

Epoch 165 of 500
  training loss:		1.461501E-06
  validation loss:		7.355252E-07

Epoch 166 of 500
  training loss:		1.624117E-06
  validation loss:		6.198600E-07

Epoch 167 of 500
  training loss:		1.412331E-06
  validation loss:		3.581078E-06

Epoch 168 of 500
  training loss:		1.506899E-06
  validation loss:		1.585817E-06

Epoch 169 of 500
  training loss:		1.586045E-06
  validation loss:		5.126325E-07

Epoch 170 of 500
  training loss:		1.499829E-06
  validation loss:		5.392358E-07

Epoch 171 of 500
  training loss:		1.391797E-06
  validation loss:		6.672847E-07

Epoch 172 of 500
  training loss:		1.558500E-06
  validation loss:		9.346459E-07

Epoch 173 of 500
  training loss:		1.412691E-06
  validation loss:		1.627078E-06

Epoch 174 of 500
  training loss:		1.483816E-06
  validation loss:		1.504527E-06

Epoch 175 of 500
  training loss:		1.517955E-06
  validation loss:		1.261411E-06

Epoch 176 of 500
  training loss:		1.449938E-06
  validation loss:		6.402893E-07

Epoch 177 of 500
  training loss:		1.476924E-06
  validation loss:		4.322716E-06

Epoch 178 of 500
  training loss:		1.373194E-06
  validation loss:		3.201734E-06

Epoch 179 of 500
  training loss:		1.453978E-06
  validation loss:		6.213988E-07

Epoch 180 of 500
  training loss:		1.375129E-06
  validation loss:		4.885057E-07

Early stopping, val-loss increased over the last 15 epochs from 0.000486324914145 to 0.000520279959593
Training RMSE: 7.64720765209e-10
Validation RMSE: 7.72322129616e-10
