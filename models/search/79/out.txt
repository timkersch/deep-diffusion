Epoch 1 of 500
  training loss:		8.088146E-04
  validation loss:		1.649572E-09

Epoch 2 of 500
  training loss:		3.085586E-10
  validation loss:		5.323263E-12

Epoch 3 of 500
  training loss:		7.837885E-13
  validation loss:		4.389844E-15

Epoch 4 of 500
  training loss:		2.762869E-15
  validation loss:		3.092642E-15

Epoch 5 of 500
  training loss:		2.572117E-15
  validation loss:		2.558135E-15

Epoch 6 of 500
  training loss:		2.548515E-15
  validation loss:		2.653537E-15

Epoch 7 of 500
  training loss:		2.602980E-15
  validation loss:		2.689817E-15

Epoch 8 of 500
  training loss:		2.642226E-15
  validation loss:		2.558507E-15

Epoch 9 of 500
  training loss:		2.595925E-15
  validation loss:		3.013253E-15

Epoch 10 of 500
  training loss:		2.654551E-15
  validation loss:		2.894094E-15

Epoch 11 of 500
  training loss:		2.702175E-15
  validation loss:		2.558138E-15

Epoch 12 of 500
  training loss:		2.631192E-15
  validation loss:		3.325172E-15

Epoch 13 of 500
  training loss:		2.816963E-15
  validation loss:		2.541083E-15

Epoch 14 of 500
  training loss:		2.914799E-15
  validation loss:		3.088260E-15

Epoch 15 of 500
  training loss:		2.761069E-15
  validation loss:		2.985602E-15

Epoch 16 of 500
  training loss:		2.960194E-15
  validation loss:		2.919837E-15

Epoch 17 of 500
  training loss:		2.863690E-15
  validation loss:		3.383474E-15

Epoch 18 of 500
  training loss:		2.990481E-15
  validation loss:		3.060134E-15

Epoch 19 of 500
  training loss:		3.617000E-15
  validation loss:		4.223223E-15

Epoch 20 of 500
  training loss:		7.198357E-15
  validation loss:		3.573273E-15

Epoch 21 of 500
  training loss:		1.281009E-05
  validation loss:		9.336008E-07

Epoch 22 of 500
  training loss:		4.626988E-08
  validation loss:		2.587755E-14

Epoch 23 of 500
  training loss:		8.616405E-15
  validation loss:		5.976619E-15

Epoch 24 of 500
  training loss:		6.932414E-15
  validation loss:		6.469000E-15

Epoch 25 of 500
  training loss:		7.095053E-15
  validation loss:		7.457135E-15

Epoch 26 of 500
  training loss:		8.325905E-15
  validation loss:		9.724278E-15

Epoch 27 of 500
  training loss:		2.036418E-14
  validation loss:		1.560579E-14

Epoch 28 of 500
  training loss:		4.717336E-06
  validation loss:		5.827557E-10

Epoch 29 of 500
  training loss:		3.689538E-10
  validation loss:		8.560259E-15

Epoch 30 of 500
  training loss:		1.401754E-14
  validation loss:		1.109357E-14

Early stopping, val-loss increased over the last 10 epochs from 1.39296058577e-13 to 4.110407874e-06
Training-set, RMSE: 9.20657594291e-08
Validation-set, RMSE: 9.24829681409e-08
