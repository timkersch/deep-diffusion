Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 500
  training loss:		7.850015E-02
  validation loss:		4.597933E-02

Epoch 2 of 500
  training loss:		1.755052E-02
  validation loss:		5.426109E-03

Epoch 3 of 500
  training loss:		4.458470E-03
  validation loss:		4.060571E-03

Epoch 4 of 500
  training loss:		3.820727E-03
  validation loss:		3.561367E-03

Epoch 5 of 500
  training loss:		3.325889E-03
  validation loss:		3.110977E-03

Epoch 6 of 500
  training loss:		2.927798E-03
  validation loss:		2.751546E-03

Epoch 7 of 500
  training loss:		2.630916E-03
  validation loss:		2.492505E-03

Epoch 8 of 500
  training loss:		2.397805E-03
  validation loss:		2.306179E-03

Epoch 9 of 500
  training loss:		2.240802E-03
  validation loss:		2.159330E-03

Epoch 10 of 500
  training loss:		2.108293E-03
  validation loss:		2.015716E-03

Epoch 11 of 500
  training loss:		1.877977E-03
  validation loss:		1.668630E-03

Epoch 12 of 500
  training loss:		1.363443E-03
  validation loss:		1.062378E-03

Epoch 13 of 500
  training loss:		8.604062E-04
  validation loss:		6.740685E-04

Epoch 14 of 500
  training loss:		5.812032E-04
  validation loss:		4.718666E-04

Epoch 15 of 500
  training loss:		4.390716E-04
  validation loss:		3.715921E-04

Epoch 16 of 500
  training loss:		3.592312E-04
  validation loss:		3.092106E-04

Epoch 17 of 500
  training loss:		3.067211E-04
  validation loss:		2.636181E-04

Epoch 18 of 500
  training loss:		2.636468E-04
  validation loss:		2.311885E-04

Epoch 19 of 500
  training loss:		2.327165E-04
  validation loss:		2.591104E-04

Epoch 20 of 500
  training loss:		2.056500E-04
  validation loss:		1.791379E-04

Epoch 21 of 500
  training loss:		1.814424E-04
  validation loss:		1.612206E-04

Epoch 22 of 500
  training loss:		1.638771E-04
  validation loss:		1.483708E-04

Epoch 23 of 500
  training loss:		1.470310E-04
  validation loss:		1.331199E-04

Epoch 24 of 500
  training loss:		1.378458E-04
  validation loss:		1.214040E-04

Epoch 25 of 500
  training loss:		1.243040E-04
  validation loss:		1.108094E-04

Epoch 26 of 500
  training loss:		1.141839E-04
  validation loss:		1.031998E-04

Epoch 27 of 500
  training loss:		1.042429E-04
  validation loss:		9.994027E-05

Epoch 28 of 500
  training loss:		9.847718E-05
  validation loss:		9.202997E-05

Epoch 29 of 500
  training loss:		9.415035E-05
  validation loss:		8.626517E-05

Epoch 30 of 500
  training loss:		8.480547E-05
  validation loss:		7.986496E-05

Epoch 31 of 500
  training loss:		8.070255E-05
  validation loss:		7.501246E-05

Epoch 32 of 500
  training loss:		7.807154E-05
  validation loss:		7.125843E-05

Epoch 33 of 500
  training loss:		7.251276E-05
  validation loss:		6.793202E-05

Epoch 34 of 500
  training loss:		6.768823E-05
  validation loss:		7.314592E-05

Epoch 35 of 500
  training loss:		6.557784E-05
  validation loss:		6.397123E-05

Epoch 36 of 500
  training loss:		6.087355E-05
  validation loss:		6.638154E-05

Epoch 37 of 500
  training loss:		5.674638E-05
  validation loss:		5.948704E-05

Epoch 38 of 500
  training loss:		5.371335E-05
  validation loss:		4.981669E-05

Epoch 39 of 500
  training loss:		5.051041E-05
  validation loss:		5.824148E-05

Epoch 40 of 500
  training loss:		4.860291E-05
  validation loss:		5.382829E-05

Epoch 41 of 500
  training loss:		4.592626E-05
  validation loss:		4.154304E-05

Epoch 42 of 500
  training loss:		4.341466E-05
  validation loss:		4.311662E-05

Epoch 43 of 500
  training loss:		4.058889E-05
  validation loss:		3.676404E-05

Epoch 44 of 500
  training loss:		3.917451E-05
  validation loss:		3.468768E-05

Epoch 45 of 500
  training loss:		3.658693E-05
  validation loss:		3.520538E-05

Epoch 46 of 500
  training loss:		3.471087E-05
  validation loss:		3.116150E-05

Epoch 47 of 500
  training loss:		3.324295E-05
  validation loss:		2.973072E-05

Epoch 48 of 500
  training loss:		3.129787E-05
  validation loss:		2.817089E-05

Epoch 49 of 500
  training loss:		2.983502E-05
  validation loss:		3.272639E-05

Epoch 50 of 500
  training loss:		2.920165E-05
  validation loss:		3.340267E-05

Epoch 51 of 500
  training loss:		2.793978E-05
  validation loss:		2.482906E-05

Epoch 52 of 500
  training loss:		2.661212E-05
  validation loss:		2.323550E-05

Epoch 53 of 500
  training loss:		2.451685E-05
  validation loss:		2.500184E-05

Epoch 54 of 500
  training loss:		2.369015E-05
  validation loss:		2.118861E-05

Epoch 55 of 500
  training loss:		2.351669E-05
  validation loss:		3.104189E-05

Epoch 56 of 500
  training loss:		2.176467E-05
  validation loss:		2.045385E-05

Epoch 57 of 500
  training loss:		2.204867E-05
  validation loss:		1.865898E-05

Epoch 58 of 500
  training loss:		1.997164E-05
  validation loss:		2.041774E-05

Epoch 59 of 500
  training loss:		1.922315E-05
  validation loss:		1.929561E-05

Epoch 60 of 500
  training loss:		1.904168E-05
  validation loss:		1.692477E-05

Epoch 61 of 500
  training loss:		1.750977E-05
  validation loss:		2.398529E-05

Epoch 62 of 500
  training loss:		1.765225E-05
  validation loss:		2.152218E-05

Epoch 63 of 500
  training loss:		1.713320E-05
  validation loss:		1.491727E-05

Epoch 64 of 500
  training loss:		1.631972E-05
  validation loss:		1.535230E-05

Epoch 65 of 500
  training loss:		1.631926E-05
  validation loss:		1.507567E-05

Epoch 66 of 500
  training loss:		1.559377E-05
  validation loss:		1.842802E-05

Epoch 67 of 500
  training loss:		1.479096E-05
  validation loss:		1.301062E-05

Epoch 68 of 500
  training loss:		1.409088E-05
  validation loss:		1.318636E-05

Epoch 69 of 500
  training loss:		1.436133E-05
  validation loss:		1.315667E-05

Epoch 70 of 500
  training loss:		1.361343E-05
  validation loss:		1.194962E-05

Epoch 71 of 500
  training loss:		1.328828E-05
  validation loss:		1.637231E-05

Epoch 72 of 500
  training loss:		1.269937E-05
  validation loss:		2.086987E-05

Epoch 73 of 500
  training loss:		1.269000E-05
  validation loss:		1.108720E-05

Epoch 74 of 500
  training loss:		1.220232E-05
  validation loss:		1.086511E-05

Epoch 75 of 500
  training loss:		1.217620E-05
  validation loss:		1.055385E-05

Epoch 76 of 500
  training loss:		1.156019E-05
  validation loss:		1.154342E-05

Epoch 77 of 500
  training loss:		1.142984E-05
  validation loss:		1.642633E-05

Epoch 78 of 500
  training loss:		1.092451E-05
  validation loss:		9.769548E-06

Epoch 79 of 500
  training loss:		1.080728E-05
  validation loss:		1.009514E-05

Epoch 80 of 500
  training loss:		1.049216E-05
  validation loss:		1.163581E-05

Epoch 81 of 500
  training loss:		1.021595E-05
  validation loss:		1.087453E-05

Epoch 82 of 500
  training loss:		9.935383E-06
  validation loss:		9.047527E-06

Epoch 83 of 500
  training loss:		1.022545E-05
  validation loss:		8.796512E-06

Epoch 84 of 500
  training loss:		9.271853E-06
  validation loss:		8.750593E-06

Epoch 85 of 500
  training loss:		9.329669E-06
  validation loss:		1.288595E-05

Epoch 86 of 500
  training loss:		9.444058E-06
  validation loss:		8.010184E-06

Epoch 87 of 500
  training loss:		9.054497E-06
  validation loss:		9.931806E-06

Epoch 88 of 500
  training loss:		8.548860E-06
  validation loss:		7.693761E-06

Epoch 89 of 500
  training loss:		8.491251E-06
  validation loss:		7.786153E-06

Epoch 90 of 500
  training loss:		8.709963E-06
  validation loss:		9.203353E-06

Epoch 91 of 500
  training loss:		8.027305E-06
  validation loss:		8.312399E-06

Epoch 92 of 500
  training loss:		7.866926E-06
  validation loss:		8.408018E-06

Epoch 93 of 500
  training loss:		8.297139E-06
  validation loss:		7.416838E-06

Epoch 94 of 500
  training loss:		7.637769E-06
  validation loss:		8.890938E-06

Epoch 95 of 500
  training loss:		7.538481E-06
  validation loss:		7.546571E-06

Epoch 96 of 500
  training loss:		7.436325E-06
  validation loss:		6.827368E-06

Epoch 97 of 500
  training loss:		7.162498E-06
  validation loss:		7.456604E-06

Epoch 98 of 500
  training loss:		7.551612E-06
  validation loss:		6.546768E-06

Epoch 99 of 500
  training loss:		7.352797E-06
  validation loss:		7.226681E-06

Epoch 100 of 500
  training loss:		6.935293E-06
  validation loss:		8.195485E-06

Epoch 101 of 500
  training loss:		7.045425E-06
  validation loss:		9.003825E-06

Epoch 102 of 500
  training loss:		6.824232E-06
  validation loss:		6.400022E-06

Epoch 103 of 500
  training loss:		6.457455E-06
  validation loss:		5.781459E-06

Epoch 104 of 500
  training loss:		6.693289E-06
  validation loss:		6.432919E-06

Epoch 105 of 500
  training loss:		6.376213E-06
  validation loss:		6.964169E-06

Epoch 106 of 500
  training loss:		6.223509E-06
  validation loss:		5.756617E-06

Epoch 107 of 500
  training loss:		6.430799E-06
  validation loss:		5.331299E-06

Epoch 108 of 500
  training loss:		5.932706E-06
  validation loss:		6.654955E-06

Epoch 109 of 500
  training loss:		6.011227E-06
  validation loss:		5.643221E-06

Epoch 110 of 500
  training loss:		6.220474E-06
  validation loss:		5.780615E-06

Epoch 111 of 500
  training loss:		5.914984E-06
  validation loss:		5.902437E-06

Epoch 112 of 500
  training loss:		6.048907E-06
  validation loss:		5.358496E-06

Epoch 113 of 500
  training loss:		5.758024E-06
  validation loss:		7.703967E-06

Epoch 114 of 500
  training loss:		5.815941E-06
  validation loss:		5.504705E-06

Epoch 115 of 500
  training loss:		5.681252E-06
  validation loss:		5.478617E-06

Epoch 116 of 500
  training loss:		5.568638E-06
  validation loss:		4.722608E-06

Epoch 117 of 500
  training loss:		5.579920E-06
  validation loss:		5.275104E-06

Epoch 118 of 500
  training loss:		5.372969E-06
  validation loss:		4.547087E-06

Epoch 119 of 500
  training loss:		5.180396E-06
  validation loss:		4.609603E-06

Epoch 120 of 500
  training loss:		5.161592E-06
  validation loss:		4.581198E-06

Epoch 121 of 500
  training loss:		5.119186E-06
  validation loss:		4.909101E-06

Epoch 122 of 500
  training loss:		5.201861E-06
  validation loss:		4.488379E-06

Epoch 123 of 500
  training loss:		4.930021E-06
  validation loss:		4.400033E-06

Epoch 124 of 500
  training loss:		5.293939E-06
  validation loss:		7.181586E-06

Epoch 125 of 500
  training loss:		5.477367E-06
  validation loss:		4.231290E-06

Epoch 126 of 500
  training loss:		4.503010E-06
  validation loss:		5.053471E-06

Epoch 127 of 500
  training loss:		4.914319E-06
  validation loss:		5.247345E-06

Epoch 128 of 500
  training loss:		4.500380E-06
  validation loss:		5.127483E-06

Epoch 129 of 500
  training loss:		4.900498E-06
  validation loss:		6.337086E-06

Epoch 130 of 500
  training loss:		4.567019E-06
  validation loss:		4.036525E-06

Epoch 131 of 500
  training loss:		4.749696E-06
  validation loss:		4.266635E-06

Epoch 132 of 500
  training loss:		4.231454E-06
  validation loss:		4.414197E-06

Epoch 133 of 500
  training loss:		4.660807E-06
  validation loss:		4.048904E-06

Epoch 134 of 500
  training loss:		4.579497E-06
  validation loss:		4.042017E-06

Epoch 135 of 500
  training loss:		4.566434E-06
  validation loss:		3.984930E-06

Epoch 136 of 500
  training loss:		4.443140E-06
  validation loss:		4.929968E-06

Epoch 137 of 500
  training loss:		4.313589E-06
  validation loss:		3.933710E-06

Epoch 138 of 500
  training loss:		4.108527E-06
  validation loss:		3.594885E-06

Epoch 139 of 500
  training loss:		4.172287E-06
  validation loss:		4.068092E-06

Epoch 140 of 500
  training loss:		4.189229E-06
  validation loss:		3.463027E-06

Epoch 141 of 500
  training loss:		4.046995E-06
  validation loss:		3.640296E-06

Epoch 142 of 500
  training loss:		4.047870E-06
  validation loss:		3.867464E-06

Epoch 143 of 500
  training loss:		3.860889E-06
  validation loss:		5.243912E-06

Epoch 144 of 500
  training loss:		4.241007E-06
  validation loss:		9.604974E-06

Epoch 145 of 500
  training loss:		3.903925E-06
  validation loss:		3.370492E-06

Epoch 146 of 500
  training loss:		4.079585E-06
  validation loss:		4.683922E-06

Epoch 147 of 500
  training loss:		4.226926E-06
  validation loss:		3.971084E-06

Epoch 148 of 500
  training loss:		3.630482E-06
  validation loss:		3.926326E-06

Epoch 149 of 500
  training loss:		4.062620E-06
  validation loss:		3.366900E-06

Epoch 150 of 500
  training loss:		3.648759E-06
  validation loss:		3.033970E-06

Epoch 151 of 500
  training loss:		3.492788E-06
  validation loss:		3.327483E-06

Epoch 152 of 500
  training loss:		3.553490E-06
  validation loss:		3.320645E-06

Epoch 153 of 500
  training loss:		3.763220E-06
  validation loss:		3.178636E-06

Epoch 154 of 500
  training loss:		3.317483E-06
  validation loss:		5.483973E-06

Epoch 155 of 500
  training loss:		3.804460E-06
  validation loss:		7.440695E-06

Epoch 156 of 500
  training loss:		3.432115E-06
  validation loss:		3.681257E-06

Epoch 157 of 500
  training loss:		3.343044E-06
  validation loss:		3.871136E-06

Epoch 158 of 500
  training loss:		3.628980E-06
  validation loss:		2.912810E-06

Epoch 159 of 500
  training loss:		3.508816E-06
  validation loss:		4.316203E-06

Epoch 160 of 500
  training loss:		3.435272E-06
  validation loss:		4.260479E-06

Epoch 161 of 500
  training loss:		3.274511E-06
  validation loss:		3.761995E-06

Epoch 162 of 500
  training loss:		3.422839E-06
  validation loss:		4.048800E-06

Epoch 163 of 500
  training loss:		3.358983E-06
  validation loss:		4.035195E-06

Epoch 164 of 500
  training loss:		3.082561E-06
  validation loss:		3.136930E-06

Epoch 165 of 500
  training loss:		3.470494E-06
  validation loss:		3.190998E-06

Epoch 166 of 500
  training loss:		2.948222E-06
  validation loss:		2.650630E-06

Epoch 167 of 500
  training loss:		3.256615E-06
  validation loss:		3.250590E-06

Epoch 168 of 500
  training loss:		3.402348E-06
  validation loss:		4.556909E-06

Epoch 169 of 500
  training loss:		3.182347E-06
  validation loss:		3.651221E-06

Epoch 170 of 500
  training loss:		3.012910E-06
  validation loss:		3.676288E-06

Epoch 171 of 500
  training loss:		2.967059E-06
  validation loss:		2.484632E-06

Epoch 172 of 500
  training loss:		3.087768E-06
  validation loss:		2.894432E-06

Epoch 173 of 500
  training loss:		3.269545E-06
  validation loss:		2.462781E-06

Epoch 174 of 500
  training loss:		2.920644E-06
  validation loss:		5.106219E-06

Epoch 175 of 500
  training loss:		2.920122E-06
  validation loss:		2.736833E-06

Epoch 176 of 500
  training loss:		3.049000E-06
  validation loss:		2.878280E-06

Epoch 177 of 500
  training loss:		2.839677E-06
  validation loss:		5.706384E-06

Epoch 178 of 500
  training loss:		3.183061E-06
  validation loss:		2.297587E-06

Epoch 179 of 500
  training loss:		2.874640E-06
  validation loss:		3.289605E-06

Epoch 180 of 500
  training loss:		2.861683E-06
  validation loss:		2.311590E-06

Epoch 181 of 500
  training loss:		2.662262E-06
  validation loss:		2.239473E-06

Epoch 182 of 500
  training loss:		2.986959E-06
  validation loss:		2.170477E-06

Epoch 183 of 500
  training loss:		3.029084E-06
  validation loss:		2.155055E-06

Epoch 184 of 500
  training loss:		2.474819E-06
  validation loss:		2.430547E-06

Epoch 185 of 500
  training loss:		3.060641E-06
  validation loss:		2.093119E-06

Epoch 186 of 500
  training loss:		2.393399E-06
  validation loss:		2.205355E-06

Epoch 187 of 500
  training loss:		2.692723E-06
  validation loss:		2.383044E-06

Epoch 188 of 500
  training loss:		2.741557E-06
  validation loss:		2.892474E-06

Epoch 189 of 500
  training loss:		2.659039E-06
  validation loss:		2.601581E-06

Epoch 190 of 500
  training loss:		2.422789E-06
  validation loss:		1.993803E-06

Epoch 191 of 500
  training loss:		2.639671E-06
  validation loss:		2.211108E-06

Epoch 192 of 500
  training loss:		2.631834E-06
  validation loss:		4.368530E-06

Epoch 193 of 500
  training loss:		2.560090E-06
  validation loss:		2.093086E-06

Epoch 194 of 500
  training loss:		2.393611E-06
  validation loss:		7.644773E-06

Epoch 195 of 500
  training loss:		2.746884E-06
  validation loss:		1.884759E-06

Epoch 196 of 500
  training loss:		2.849993E-06
  validation loss:		2.782307E-06

Epoch 197 of 500
  training loss:		2.266879E-06
  validation loss:		3.284670E-06

Epoch 198 of 500
  training loss:		2.745592E-06
  validation loss:		2.175321E-06

Epoch 199 of 500
  training loss:		2.275371E-06
  validation loss:		5.258741E-06

Epoch 200 of 500
  training loss:		2.560789E-06
  validation loss:		3.735663E-06

Epoch 201 of 500
  training loss:		2.324771E-06
  validation loss:		2.281489E-06

Epoch 202 of 500
  training loss:		2.611171E-06
  validation loss:		1.823808E-06

Epoch 203 of 500
  training loss:		2.286246E-06
  validation loss:		2.060648E-06

Epoch 204 of 500
  training loss:		2.228749E-06
  validation loss:		2.554597E-06

Epoch 205 of 500
  training loss:		2.179252E-06
  validation loss:		3.302006E-06

Epoch 206 of 500
  training loss:		2.358629E-06
  validation loss:		3.080982E-06

Epoch 207 of 500
  training loss:		2.118933E-06
  validation loss:		1.818800E-06

Epoch 208 of 500
  training loss:		2.227127E-06
  validation loss:		1.763079E-06

Epoch 209 of 500
  training loss:		2.138565E-06
  validation loss:		1.736364E-06

Epoch 210 of 500
  training loss:		2.481673E-06
  validation loss:		8.161401E-06

Epoch 211 of 500
  training loss:		2.241009E-06
  validation loss:		2.167434E-06

Epoch 212 of 500
  training loss:		2.226460E-06
  validation loss:		1.607085E-06

Epoch 213 of 500
  training loss:		2.104778E-06
  validation loss:		6.586301E-06

Epoch 214 of 500
  training loss:		2.051464E-06
  validation loss:		2.826060E-06

Epoch 215 of 500
  training loss:		1.955748E-06
  validation loss:		1.722473E-06

Epoch 216 of 500
  training loss:		2.318046E-06
  validation loss:		1.753725E-06

Epoch 217 of 500
  training loss:		2.060549E-06
  validation loss:		1.997433E-06

Epoch 218 of 500
  training loss:		2.147601E-06
  validation loss:		3.532522E-06

Epoch 219 of 500
  training loss:		2.065853E-06
  validation loss:		1.823328E-06

Epoch 220 of 500
  training loss:		2.395940E-06
  validation loss:		3.315866E-06

Epoch 221 of 500
  training loss:		1.833508E-06
  validation loss:		1.665719E-06

Epoch 222 of 500
  training loss:		1.997946E-06
  validation loss:		2.221378E-06

Epoch 223 of 500
  training loss:		2.130510E-06
  validation loss:		1.845534E-06

Epoch 224 of 500
  training loss:		1.932779E-06
  validation loss:		2.233525E-06

Epoch 225 of 500
  training loss:		1.922156E-06
  validation loss:		2.269033E-06

Epoch 226 of 500
  training loss:		2.209576E-06
  validation loss:		1.615782E-06

Epoch 227 of 500
  training loss:		1.828899E-06
  validation loss:		2.248299E-06

Epoch 228 of 500
  training loss:		1.979389E-06
  validation loss:		1.614048E-06

Epoch 229 of 500
  training loss:		1.833156E-06
  validation loss:		1.356307E-06

Epoch 230 of 500
  training loss:		1.837107E-06
  validation loss:		2.514168E-06

Epoch 231 of 500
  training loss:		1.935851E-06
  validation loss:		2.082951E-06

Epoch 232 of 500
  training loss:		1.953559E-06
  validation loss:		1.714005E-06

Epoch 233 of 500
  training loss:		1.873310E-06
  validation loss:		1.530388E-06

Epoch 234 of 500
  training loss:		1.786952E-06
  validation loss:		1.540380E-06

Epoch 235 of 500
  training loss:		1.684875E-06
  validation loss:		1.308973E-06

Epoch 236 of 500
  training loss:		2.130215E-06
  validation loss:		2.148356E-06

Epoch 237 of 500
  training loss:		1.810199E-06
  validation loss:		1.241022E-06

Epoch 238 of 500
  training loss:		1.691709E-06
  validation loss:		2.078941E-06

Epoch 239 of 500
  training loss:		1.774126E-06
  validation loss:		1.965827E-06

Epoch 240 of 500
  training loss:		1.926068E-06
  validation loss:		1.532024E-06

Epoch 241 of 500
  training loss:		1.689643E-06
  validation loss:		4.551930E-06

Epoch 242 of 500
  training loss:		1.923329E-06
  validation loss:		1.389655E-06

Epoch 243 of 500
  training loss:		1.601473E-06
  validation loss:		1.994018E-06

Epoch 244 of 500
  training loss:		1.707976E-06
  validation loss:		2.829786E-06

Epoch 245 of 500
  training loss:		1.880550E-06
  validation loss:		1.182823E-06

Epoch 246 of 500
  training loss:		1.729802E-06
  validation loss:		4.042066E-06

Epoch 247 of 500
  training loss:		1.632411E-06
  validation loss:		2.573316E-06

Epoch 248 of 500
  training loss:		1.757558E-06
  validation loss:		1.924989E-06

Epoch 249 of 500
  training loss:		1.545545E-06
  validation loss:		1.120938E-06

Epoch 250 of 500
  training loss:		1.779701E-06
  validation loss:		1.110206E-06

Epoch 251 of 500
  training loss:		1.598910E-06
  validation loss:		3.102908E-06

Epoch 252 of 500
  training loss:		1.631623E-06
  validation loss:		1.176570E-06

Epoch 253 of 500
  training loss:		1.952421E-06
  validation loss:		2.187075E-06

Epoch 254 of 500
  training loss:		1.577465E-06
  validation loss:		1.093771E-06

Epoch 255 of 500
  training loss:		1.617636E-06
  validation loss:		1.121298E-06

Epoch 256 of 500
  training loss:		1.481638E-06
  validation loss:		1.099521E-06

Epoch 257 of 500
  training loss:		1.562221E-06
  validation loss:		1.087911E-06

Epoch 258 of 500
  training loss:		1.758574E-06
  validation loss:		1.572992E-06

Epoch 259 of 500
  training loss:		1.587331E-06
  validation loss:		1.380326E-06

Epoch 260 of 500
  training loss:		1.552782E-06
  validation loss:		1.738170E-06

Early stopping, val-loss increased over the last 20 epochs from 0.00012119797646 to 0.000126324888095
Training RMSE: 1.10696834887e-09
Validation RMSE: 1.15149449639e-09
