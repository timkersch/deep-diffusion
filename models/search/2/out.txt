Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 500
  training loss:		8.706439E-02
  validation loss:		8.008333E-02

Epoch 2 of 500
  training loss:		7.108418E-02
  validation loss:		6.094301E-02

Epoch 3 of 500
  training loss:		4.983714E-02
  validation loss:		3.876582E-02

Epoch 4 of 500
  training loss:		2.873788E-02
  validation loss:		2.021598E-02

Epoch 5 of 500
  training loss:		1.458041E-02
  validation loss:		1.080153E-02

Epoch 6 of 500
  training loss:		9.130320E-03
  validation loss:		8.165463E-03

Epoch 7 of 500
  training loss:		7.728881E-03
  validation loss:		7.317348E-03

Epoch 8 of 500
  training loss:		7.036973E-03
  validation loss:		6.723340E-03

Epoch 9 of 500
  training loss:		6.490351E-03
  validation loss:		6.177593E-03

Epoch 10 of 500
  training loss:		5.981829E-03
  validation loss:		5.681566E-03

Epoch 11 of 500
  training loss:		5.488177E-03
  validation loss:		5.271414E-03

Epoch 12 of 500
  training loss:		5.019239E-03
  validation loss:		4.768815E-03

Epoch 13 of 500
  training loss:		4.584694E-03
  validation loss:		4.402753E-03

Epoch 14 of 500
  training loss:		4.180329E-03
  validation loss:		3.955726E-03

Epoch 15 of 500
  training loss:		3.809320E-03
  validation loss:		3.662231E-03

Epoch 16 of 500
  training loss:		3.466011E-03
  validation loss:		3.297732E-03

Epoch 17 of 500
  training loss:		3.167838E-03
  validation loss:		3.028338E-03

Epoch 18 of 500
  training loss:		2.894984E-03
  validation loss:		2.754665E-03

Epoch 19 of 500
  training loss:		2.667113E-03
  validation loss:		2.598109E-03

Epoch 20 of 500
  training loss:		2.468135E-03
  validation loss:		2.378123E-03

Epoch 21 of 500
  training loss:		2.299313E-03
  validation loss:		2.195457E-03

Epoch 22 of 500
  training loss:		2.153729E-03
  validation loss:		2.094123E-03

Epoch 23 of 500
  training loss:		2.032215E-03
  validation loss:		1.997263E-03

Epoch 24 of 500
  training loss:		1.926334E-03
  validation loss:		1.853317E-03

Epoch 25 of 500
  training loss:		1.828526E-03
  validation loss:		1.787057E-03

Epoch 26 of 500
  training loss:		1.756235E-03
  validation loss:		1.696219E-03

Epoch 27 of 500
  training loss:		1.684863E-03
  validation loss:		1.694467E-03

Epoch 28 of 500
  training loss:		1.622731E-03
  validation loss:		1.607985E-03

Epoch 29 of 500
  training loss:		1.564346E-03
  validation loss:		1.508035E-03

Epoch 30 of 500
  training loss:		1.478633E-03
  validation loss:		1.409062E-03

Epoch 31 of 500
  training loss:		1.345706E-03
  validation loss:		1.262318E-03

Epoch 32 of 500
  training loss:		1.170395E-03
  validation loss:		1.057355E-03

Epoch 33 of 500
  training loss:		9.832328E-04
  validation loss:		9.424225E-04

Epoch 34 of 500
  training loss:		8.230486E-04
  validation loss:		7.315051E-04

Epoch 35 of 500
  training loss:		6.932940E-04
  validation loss:		6.840774E-04

Epoch 36 of 500
  training loss:		5.917278E-04
  validation loss:		5.307327E-04

Epoch 37 of 500
  training loss:		5.154036E-04
  validation loss:		4.623585E-04

Epoch 38 of 500
  training loss:		4.488085E-04
  validation loss:		4.071298E-04

Epoch 39 of 500
  training loss:		3.979581E-04
  validation loss:		3.608262E-04

Epoch 40 of 500
  training loss:		3.566031E-04
  validation loss:		3.412009E-04

Epoch 41 of 500
  training loss:		3.198337E-04
  validation loss:		2.921221E-04

Epoch 42 of 500
  training loss:		2.891359E-04
  validation loss:		2.682401E-04

Epoch 43 of 500
  training loss:		2.635172E-04
  validation loss:		2.437994E-04

Epoch 44 of 500
  training loss:		2.399472E-04
  validation loss:		2.218948E-04

Epoch 45 of 500
  training loss:		2.201220E-04
  validation loss:		2.143998E-04

Epoch 46 of 500
  training loss:		2.027197E-04
  validation loss:		1.925730E-04

Epoch 47 of 500
  training loss:		1.885165E-04
  validation loss:		1.750049E-04

Epoch 48 of 500
  training loss:		1.738143E-04
  validation loss:		1.628872E-04

Epoch 49 of 500
  training loss:		1.625613E-04
  validation loss:		1.666471E-04

Epoch 50 of 500
  training loss:		1.513478E-04
  validation loss:		1.445493E-04

Epoch 51 of 500
  training loss:		1.427948E-04
  validation loss:		1.386914E-04

Epoch 52 of 500
  training loss:		1.337833E-04
  validation loss:		1.263560E-04

Epoch 53 of 500
  training loss:		1.265168E-04
  validation loss:		1.231609E-04

Epoch 54 of 500
  training loss:		1.179226E-04
  validation loss:		1.114497E-04

Epoch 55 of 500
  training loss:		1.126230E-04
  validation loss:		1.054743E-04

Epoch 56 of 500
  training loss:		1.062531E-04
  validation loss:		1.032212E-04

Epoch 57 of 500
  training loss:		1.004316E-04
  validation loss:		9.531517E-05

Epoch 58 of 500
  training loss:		9.558751E-05
  validation loss:		9.231945E-05

Epoch 59 of 500
  training loss:		9.056554E-05
  validation loss:		9.093874E-05

Epoch 60 of 500
  training loss:		8.628153E-05
  validation loss:		8.109413E-05

Epoch 61 of 500
  training loss:		8.159632E-05
  validation loss:		7.714956E-05

Epoch 62 of 500
  training loss:		7.813613E-05
  validation loss:		7.327893E-05

Epoch 63 of 500
  training loss:		7.457920E-05
  validation loss:		8.854686E-05

Epoch 64 of 500
  training loss:		7.117025E-05
  validation loss:		6.687711E-05

Epoch 65 of 500
  training loss:		6.835530E-05
  validation loss:		6.392332E-05

Epoch 66 of 500
  training loss:		6.544847E-05
  validation loss:		6.144841E-05

Epoch 67 of 500
  training loss:		6.314150E-05
  validation loss:		6.495033E-05

Epoch 68 of 500
  training loss:		6.086191E-05
  validation loss:		5.699592E-05

Epoch 69 of 500
  training loss:		5.811984E-05
  validation loss:		5.427689E-05

Epoch 70 of 500
  training loss:		5.666745E-05
  validation loss:		5.334159E-05

Epoch 71 of 500
  training loss:		5.386295E-05
  validation loss:		5.277345E-05

Epoch 72 of 500
  training loss:		5.258380E-05
  validation loss:		4.934720E-05

Epoch 73 of 500
  training loss:		5.069631E-05
  validation loss:		5.772318E-05

Epoch 74 of 500
  training loss:		4.888837E-05
  validation loss:		4.537518E-05

Epoch 75 of 500
  training loss:		4.714824E-05
  validation loss:		4.991263E-05

Epoch 76 of 500
  training loss:		4.602137E-05
  validation loss:		4.264004E-05

Epoch 77 of 500
  training loss:		4.450901E-05
  validation loss:		4.124518E-05

Epoch 78 of 500
  training loss:		4.301390E-05
  validation loss:		5.228665E-05

Epoch 79 of 500
  training loss:		4.186421E-05
  validation loss:		3.876385E-05

Epoch 80 of 500
  training loss:		4.054370E-05
  validation loss:		3.791607E-05

Epoch 81 of 500
  training loss:		3.961616E-05
  validation loss:		3.803422E-05

Epoch 82 of 500
  training loss:		3.811427E-05
  validation loss:		3.629035E-05

Epoch 83 of 500
  training loss:		3.748967E-05
  validation loss:		3.563226E-05

Epoch 84 of 500
  training loss:		3.644220E-05
  validation loss:		3.404988E-05

Epoch 85 of 500
  training loss:		3.492923E-05
  validation loss:		3.345427E-05

Epoch 86 of 500
  training loss:		3.441624E-05
  validation loss:		3.607609E-05

Epoch 87 of 500
  training loss:		3.342025E-05
  validation loss:		3.200780E-05

Epoch 88 of 500
  training loss:		3.212269E-05
  validation loss:		3.565464E-05

Epoch 89 of 500
  training loss:		3.179057E-05
  validation loss:		2.956040E-05

Epoch 90 of 500
  training loss:		3.099744E-05
  validation loss:		2.946959E-05

Epoch 91 of 500
  training loss:		3.030659E-05
  validation loss:		2.799203E-05

Epoch 92 of 500
  training loss:		2.946495E-05
  validation loss:		2.710217E-05

Epoch 93 of 500
  training loss:		2.843580E-05
  validation loss:		2.688040E-05

Epoch 94 of 500
  training loss:		2.834165E-05
  validation loss:		2.590246E-05

Epoch 95 of 500
  training loss:		2.727735E-05
  validation loss:		2.544947E-05

Epoch 96 of 500
  training loss:		2.680368E-05
  validation loss:		2.550546E-05

Epoch 97 of 500
  training loss:		2.640055E-05
  validation loss:		2.548106E-05

Epoch 98 of 500
  training loss:		2.565891E-05
  validation loss:		2.346748E-05

Epoch 99 of 500
  training loss:		2.497676E-05
  validation loss:		2.482573E-05

Epoch 100 of 500
  training loss:		2.442530E-05
  validation loss:		2.285781E-05

Epoch 101 of 500
  training loss:		2.392498E-05
  validation loss:		2.243182E-05

Epoch 102 of 500
  training loss:		2.326999E-05
  validation loss:		2.195410E-05

Epoch 103 of 500
  training loss:		2.293950E-05
  validation loss:		2.235140E-05

Epoch 104 of 500
  training loss:		2.265091E-05
  validation loss:		2.046386E-05

Epoch 105 of 500
  training loss:		2.212304E-05
  validation loss:		2.040415E-05

Epoch 106 of 500
  training loss:		2.157229E-05
  validation loss:		2.558719E-05

Epoch 107 of 500
  training loss:		2.085950E-05
  validation loss:		2.169344E-05

Epoch 108 of 500
  training loss:		2.061700E-05
  validation loss:		1.967539E-05

Epoch 109 of 500
  training loss:		2.027440E-05
  validation loss:		1.847110E-05

Epoch 110 of 500
  training loss:		1.996286E-05
  validation loss:		1.848394E-05

Epoch 111 of 500
  training loss:		1.954350E-05
  validation loss:		1.787646E-05

Epoch 112 of 500
  training loss:		1.901472E-05
  validation loss:		1.863868E-05

Epoch 113 of 500
  training loss:		1.866223E-05
  validation loss:		1.854086E-05

Epoch 114 of 500
  training loss:		1.826865E-05
  validation loss:		1.680313E-05

Epoch 115 of 500
  training loss:		1.816183E-05
  validation loss:		2.431757E-05

Epoch 116 of 500
  training loss:		1.776526E-05
  validation loss:		1.618365E-05

Epoch 117 of 500
  training loss:		1.724035E-05
  validation loss:		1.822354E-05

Epoch 118 of 500
  training loss:		1.706100E-05
  validation loss:		1.681699E-05

Epoch 119 of 500
  training loss:		1.665264E-05
  validation loss:		1.520793E-05

Epoch 120 of 500
  training loss:		1.645173E-05
  validation loss:		1.502093E-05

Epoch 121 of 500
  training loss:		1.599251E-05
  validation loss:		1.474163E-05

Epoch 122 of 500
  training loss:		1.566352E-05
  validation loss:		1.933564E-05

Epoch 123 of 500
  training loss:		1.556733E-05
  validation loss:		1.442444E-05

Epoch 124 of 500
  training loss:		1.541629E-05
  validation loss:		1.432786E-05

Epoch 125 of 500
  training loss:		1.505405E-05
  validation loss:		1.375872E-05

Epoch 126 of 500
  training loss:		1.455930E-05
  validation loss:		1.386658E-05

Epoch 127 of 500
  training loss:		1.449767E-05
  validation loss:		1.340441E-05

Epoch 128 of 500
  training loss:		1.429991E-05
  validation loss:		1.353136E-05

Epoch 129 of 500
  training loss:		1.395005E-05
  validation loss:		1.279279E-05

Epoch 130 of 500
  training loss:		1.379061E-05
  validation loss:		1.268030E-05

Epoch 131 of 500
  training loss:		1.382108E-05
  validation loss:		1.246962E-05

Epoch 132 of 500
  training loss:		1.345783E-05
  validation loss:		1.275492E-05

Epoch 133 of 500
  training loss:		1.303741E-05
  validation loss:		1.404210E-05

Epoch 134 of 500
  training loss:		1.307888E-05
  validation loss:		1.519369E-05

Epoch 135 of 500
  training loss:		1.261599E-05
  validation loss:		1.153419E-05

Epoch 136 of 500
  training loss:		1.240545E-05
  validation loss:		1.141207E-05

Epoch 137 of 500
  training loss:		1.240191E-05
  validation loss:		1.201728E-05

Epoch 138 of 500
  training loss:		1.219901E-05
  validation loss:		1.130075E-05

Epoch 139 of 500
  training loss:		1.199719E-05
  validation loss:		1.083036E-05

Epoch 140 of 500
  training loss:		1.187984E-05
  validation loss:		1.158252E-05

Epoch 141 of 500
  training loss:		1.157535E-05
  validation loss:		1.067821E-05

Epoch 142 of 500
  training loss:		1.145598E-05
  validation loss:		1.193547E-05

Epoch 143 of 500
  training loss:		1.136485E-05
  validation loss:		1.016202E-05

Epoch 144 of 500
  training loss:		1.106224E-05
  validation loss:		1.178820E-05

Epoch 145 of 500
  training loss:		1.097617E-05
  validation loss:		1.044136E-05

Epoch 146 of 500
  training loss:		1.064139E-05
  validation loss:		9.813281E-06

Epoch 147 of 500
  training loss:		1.049022E-05
  validation loss:		9.933958E-06

Epoch 148 of 500
  training loss:		1.030216E-05
  validation loss:		9.411849E-06

Epoch 149 of 500
  training loss:		1.021178E-05
  validation loss:		1.048374E-05

Epoch 150 of 500
  training loss:		1.026318E-05
  validation loss:		1.425616E-05

Epoch 151 of 500
  training loss:		9.978702E-06
  validation loss:		1.164863E-05

Epoch 152 of 500
  training loss:		9.774642E-06
  validation loss:		9.749273E-06

Epoch 153 of 500
  training loss:		9.455638E-06
  validation loss:		9.107514E-06

Epoch 154 of 500
  training loss:		9.560565E-06
  validation loss:		1.039125E-05

Epoch 155 of 500
  training loss:		9.438757E-06
  validation loss:		9.027822E-06

Epoch 156 of 500
  training loss:		9.187168E-06
  validation loss:		8.916627E-06

Epoch 157 of 500
  training loss:		9.193183E-06
  validation loss:		8.477849E-06

Epoch 158 of 500
  training loss:		8.983535E-06
  validation loss:		8.443697E-06

Epoch 159 of 500
  training loss:		8.784194E-06
  validation loss:		1.010801E-05

Epoch 160 of 500
  training loss:		8.625130E-06
  validation loss:		9.895689E-06

Epoch 161 of 500
  training loss:		8.619934E-06
  validation loss:		8.205599E-06

Epoch 162 of 500
  training loss:		8.460817E-06
  validation loss:		1.126801E-05

Epoch 163 of 500
  training loss:		8.328298E-06
  validation loss:		7.583813E-06

Epoch 164 of 500
  training loss:		8.212319E-06
  validation loss:		7.470442E-06

Epoch 165 of 500
  training loss:		8.071861E-06
  validation loss:		7.701528E-06

Epoch 166 of 500
  training loss:		8.047993E-06
  validation loss:		7.140872E-06

Epoch 167 of 500
  training loss:		7.925560E-06
  validation loss:		9.757283E-06

Epoch 168 of 500
  training loss:		7.750373E-06
  validation loss:		8.561590E-06

Epoch 169 of 500
  training loss:		7.664972E-06
  validation loss:		7.155695E-06

Epoch 170 of 500
  training loss:		7.614182E-06
  validation loss:		6.858528E-06

Epoch 171 of 500
  training loss:		7.458720E-06
  validation loss:		6.719098E-06

Epoch 172 of 500
  training loss:		7.347950E-06
  validation loss:		6.562148E-06

Epoch 173 of 500
  training loss:		7.293920E-06
  validation loss:		6.529616E-06

Epoch 174 of 500
  training loss:		7.172675E-06
  validation loss:		6.849033E-06

Epoch 175 of 500
  training loss:		7.000190E-06
  validation loss:		7.465971E-06

Epoch 176 of 500
  training loss:		7.046402E-06
  validation loss:		6.417951E-06

Epoch 177 of 500
  training loss:		6.829132E-06
  validation loss:		6.390477E-06

Epoch 178 of 500
  training loss:		6.795546E-06
  validation loss:		6.430727E-06

Epoch 179 of 500
  training loss:		6.674842E-06
  validation loss:		6.207797E-06

Epoch 180 of 500
  training loss:		6.575945E-06
  validation loss:		5.904588E-06

Epoch 181 of 500
  training loss:		6.452142E-06
  validation loss:		7.373152E-06

Epoch 182 of 500
  training loss:		6.451463E-06
  validation loss:		8.311820E-06

Epoch 183 of 500
  training loss:		6.290242E-06
  validation loss:		5.802994E-06

Epoch 184 of 500
  training loss:		6.271928E-06
  validation loss:		5.548613E-06

Epoch 185 of 500
  training loss:		6.062702E-06
  validation loss:		5.463480E-06

Epoch 186 of 500
  training loss:		6.124901E-06
  validation loss:		5.903872E-06

Epoch 187 of 500
  training loss:		6.035246E-06
  validation loss:		5.352372E-06

Epoch 188 of 500
  training loss:		5.861529E-06
  validation loss:		5.361837E-06

Epoch 189 of 500
  training loss:		5.894400E-06
  validation loss:		5.840784E-06

Epoch 190 of 500
  training loss:		5.698428E-06
  validation loss:		6.239910E-06

Epoch 191 of 500
  training loss:		5.576394E-06
  validation loss:		5.600817E-06

Epoch 192 of 500
  training loss:		5.673571E-06
  validation loss:		5.396081E-06

Epoch 193 of 500
  training loss:		5.463777E-06
  validation loss:		4.883786E-06

Epoch 194 of 500
  training loss:		5.441553E-06
  validation loss:		7.471222E-06

Epoch 195 of 500
  training loss:		5.307949E-06
  validation loss:		4.772329E-06

Epoch 196 of 500
  training loss:		5.303891E-06
  validation loss:		5.446665E-06

Epoch 197 of 500
  training loss:		5.173878E-06
  validation loss:		4.617263E-06

Epoch 198 of 500
  training loss:		5.242856E-06
  validation loss:		5.099155E-06

Epoch 199 of 500
  training loss:		5.088580E-06
  validation loss:		4.669699E-06

Epoch 200 of 500
  training loss:		4.914533E-06
  validation loss:		4.431101E-06

Epoch 201 of 500
  training loss:		4.847384E-06
  validation loss:		4.733160E-06

Epoch 202 of 500
  training loss:		4.933281E-06
  validation loss:		4.303531E-06

Epoch 203 of 500
  training loss:		4.925364E-06
  validation loss:		4.840189E-06

Epoch 204 of 500
  training loss:		4.645738E-06
  validation loss:		4.795341E-06

Epoch 205 of 500
  training loss:		4.736486E-06
  validation loss:		4.435856E-06

Epoch 206 of 500
  training loss:		4.724144E-06
  validation loss:		4.106273E-06

Epoch 207 of 500
  training loss:		4.540514E-06
  validation loss:		4.147061E-06

Epoch 208 of 500
  training loss:		4.484398E-06
  validation loss:		4.046247E-06

Epoch 209 of 500
  training loss:		4.446075E-06
  validation loss:		4.163291E-06

Epoch 210 of 500
  training loss:		4.373513E-06
  validation loss:		3.901421E-06

Epoch 211 of 500
  training loss:		4.411041E-06
  validation loss:		3.912244E-06

Epoch 212 of 500
  training loss:		4.287107E-06
  validation loss:		4.742268E-06

Epoch 213 of 500
  training loss:		4.197995E-06
  validation loss:		5.089147E-06

Epoch 214 of 500
  training loss:		4.166910E-06
  validation loss:		4.281229E-06

Epoch 215 of 500
  training loss:		4.116424E-06
  validation loss:		3.757138E-06

Epoch 216 of 500
  training loss:		4.126234E-06
  validation loss:		3.648057E-06

Epoch 217 of 500
  training loss:		3.996186E-06
  validation loss:		3.926266E-06

Epoch 218 of 500
  training loss:		4.009611E-06
  validation loss:		3.462947E-06

Epoch 219 of 500
  training loss:		3.920230E-06
  validation loss:		4.031887E-06

Epoch 220 of 500
  training loss:		3.834558E-06
  validation loss:		4.122401E-06

Epoch 221 of 500
  training loss:		3.800889E-06
  validation loss:		4.005210E-06

Epoch 222 of 500
  training loss:		3.706999E-06
  validation loss:		3.848406E-06

Epoch 223 of 500
  training loss:		3.675711E-06
  validation loss:		3.348231E-06

Epoch 224 of 500
  training loss:		3.590125E-06
  validation loss:		3.186621E-06

Epoch 225 of 500
  training loss:		3.605721E-06
  validation loss:		5.537402E-06

Epoch 226 of 500
  training loss:		3.488869E-06
  validation loss:		3.147805E-06

Epoch 227 of 500
  training loss:		3.599777E-06
  validation loss:		3.111889E-06

Epoch 228 of 500
  training loss:		3.438798E-06
  validation loss:		3.005990E-06

Epoch 229 of 500
  training loss:		3.474620E-06
  validation loss:		6.054839E-06

Epoch 230 of 500
  training loss:		3.396253E-06
  validation loss:		2.926829E-06

Epoch 231 of 500
  training loss:		3.307880E-06
  validation loss:		2.911313E-06

Epoch 232 of 500
  training loss:		3.308577E-06
  validation loss:		3.422249E-06

Epoch 233 of 500
  training loss:		3.254014E-06
  validation loss:		2.845641E-06

Epoch 234 of 500
  training loss:		3.180965E-06
  validation loss:		3.506106E-06

Epoch 235 of 500
  training loss:		3.157861E-06
  validation loss:		2.716729E-06

Epoch 236 of 500
  training loss:		3.135720E-06
  validation loss:		2.845793E-06

Epoch 237 of 500
  training loss:		3.083249E-06
  validation loss:		2.714194E-06

Epoch 238 of 500
  training loss:		3.083627E-06
  validation loss:		3.554925E-06

Epoch 239 of 500
  training loss:		3.053142E-06
  validation loss:		2.667825E-06

Epoch 240 of 500
  training loss:		2.984315E-06
  validation loss:		2.812023E-06

Epoch 241 of 500
  training loss:		3.015309E-06
  validation loss:		2.966573E-06

Epoch 242 of 500
  training loss:		2.878273E-06
  validation loss:		3.672962E-06

Epoch 243 of 500
  training loss:		2.921952E-06
  validation loss:		2.454465E-06

Epoch 244 of 500
  training loss:		2.852772E-06
  validation loss:		2.499241E-06

Epoch 245 of 500
  training loss:		2.809140E-06
  validation loss:		2.854989E-06

Epoch 246 of 500
  training loss:		2.801997E-06
  validation loss:		2.382024E-06

Epoch 247 of 500
  training loss:		2.724001E-06
  validation loss:		2.762968E-06

Epoch 248 of 500
  training loss:		2.684957E-06
  validation loss:		2.313890E-06

Epoch 249 of 500
  training loss:		2.673885E-06
  validation loss:		2.399141E-06

Epoch 250 of 500
  training loss:		2.703850E-06
  validation loss:		2.455973E-06

Epoch 251 of 500
  training loss:		2.540664E-06
  validation loss:		2.206682E-06

Epoch 252 of 500
  training loss:		2.600407E-06
  validation loss:		2.180343E-06

Epoch 253 of 500
  training loss:		2.512907E-06
  validation loss:		2.701602E-06

Epoch 254 of 500
  training loss:		2.486656E-06
  validation loss:		2.617775E-06

Epoch 255 of 500
  training loss:		2.565250E-06
  validation loss:		2.342919E-06

Epoch 256 of 500
  training loss:		2.437422E-06
  validation loss:		2.134962E-06

Epoch 257 of 500
  training loss:		2.465774E-06
  validation loss:		2.114362E-06

Epoch 258 of 500
  training loss:		2.383356E-06
  validation loss:		2.040133E-06

Epoch 259 of 500
  training loss:		2.352635E-06
  validation loss:		2.054702E-06

Epoch 260 of 500
  training loss:		2.332339E-06
  validation loss:		2.948407E-06

Epoch 261 of 500
  training loss:		2.375164E-06
  validation loss:		2.653911E-06

Epoch 262 of 500
  training loss:		2.266618E-06
  validation loss:		1.960798E-06

Epoch 263 of 500
  training loss:		2.200383E-06
  validation loss:		1.984777E-06

Epoch 264 of 500
  training loss:		2.224219E-06
  validation loss:		1.879426E-06

Epoch 265 of 500
  training loss:		2.220021E-06
  validation loss:		1.849756E-06

Epoch 266 of 500
  training loss:		2.224070E-06
  validation loss:		1.984185E-06

Epoch 267 of 500
  training loss:		2.200650E-06
  validation loss:		1.839113E-06

Epoch 268 of 500
  training loss:		2.107333E-06
  validation loss:		1.862162E-06

Epoch 269 of 500
  training loss:		2.046204E-06
  validation loss:		1.881441E-06

Epoch 270 of 500
  training loss:		2.088818E-06
  validation loss:		1.806982E-06

Epoch 271 of 500
  training loss:		2.036873E-06
  validation loss:		1.723748E-06

Epoch 272 of 500
  training loss:		2.031187E-06
  validation loss:		1.690629E-06

Epoch 273 of 500
  training loss:		2.025548E-06
  validation loss:		1.710889E-06

Epoch 274 of 500
  training loss:		1.969177E-06
  validation loss:		1.740533E-06

Epoch 275 of 500
  training loss:		1.966184E-06
  validation loss:		1.628964E-06

Epoch 276 of 500
  training loss:		1.931566E-06
  validation loss:		1.998989E-06

Epoch 277 of 500
  training loss:		1.928669E-06
  validation loss:		1.638665E-06

Epoch 278 of 500
  training loss:		1.926101E-06
  validation loss:		1.849659E-06

Epoch 279 of 500
  training loss:		1.861900E-06
  validation loss:		2.777894E-06

Epoch 280 of 500
  training loss:		1.853371E-06
  validation loss:		1.544495E-06

Epoch 281 of 500
  training loss:		1.856281E-06
  validation loss:		2.071419E-06

Epoch 282 of 500
  training loss:		1.764654E-06
  validation loss:		1.531351E-06

Epoch 283 of 500
  training loss:		1.759524E-06
  validation loss:		1.519488E-06

Epoch 284 of 500
  training loss:		1.812210E-06
  validation loss:		1.869455E-06

Epoch 285 of 500
  training loss:		1.774176E-06
  validation loss:		1.486136E-06

Epoch 286 of 500
  training loss:		1.705312E-06
  validation loss:		3.923496E-06

Epoch 287 of 500
  training loss:		1.707404E-06
  validation loss:		1.538981E-06

Epoch 288 of 500
  training loss:		1.640710E-06
  validation loss:		1.516603E-06

Epoch 289 of 500
  training loss:		1.703140E-06
  validation loss:		1.378393E-06

Epoch 290 of 500
  training loss:		1.635886E-06
  validation loss:		1.375761E-06

Epoch 291 of 500
  training loss:		1.706988E-06
  validation loss:		1.363876E-06

Epoch 292 of 500
  training loss:		1.582698E-06
  validation loss:		1.433173E-06

Epoch 293 of 500
  training loss:		1.595573E-06
  validation loss:		1.326776E-06

Epoch 294 of 500
  training loss:		1.593706E-06
  validation loss:		1.298218E-06

Epoch 295 of 500
  training loss:		1.542418E-06
  validation loss:		2.182191E-06

Epoch 296 of 500
  training loss:		1.556632E-06
  validation loss:		1.731562E-06

Epoch 297 of 500
  training loss:		1.552580E-06
  validation loss:		1.784770E-06

Epoch 298 of 500
  training loss:		1.554781E-06
  validation loss:		1.440338E-06

Epoch 299 of 500
  training loss:		1.436774E-06
  validation loss:		1.655632E-06

Epoch 300 of 500
  training loss:		1.483964E-06
  validation loss:		1.221678E-06

Epoch 301 of 500
  training loss:		1.478856E-06
  validation loss:		1.193143E-06

Epoch 302 of 500
  training loss:		1.424858E-06
  validation loss:		1.359377E-06

Epoch 303 of 500
  training loss:		1.456298E-06
  validation loss:		1.455223E-06

Epoch 304 of 500
  training loss:		1.419086E-06
  validation loss:		1.195411E-06

Epoch 305 of 500
  training loss:		1.399904E-06
  validation loss:		1.754065E-06

Epoch 306 of 500
  training loss:		1.433833E-06
  validation loss:		1.131037E-06

Epoch 307 of 500
  training loss:		1.376640E-06
  validation loss:		1.127897E-06

Epoch 308 of 500
  training loss:		1.340553E-06
  validation loss:		1.113588E-06

Epoch 309 of 500
  training loss:		1.317160E-06
  validation loss:		1.413653E-06

Epoch 310 of 500
  training loss:		1.335702E-06
  validation loss:		1.100734E-06

Epoch 311 of 500
  training loss:		1.301313E-06
  validation loss:		1.147322E-06

Epoch 312 of 500
  training loss:		1.343985E-06
  validation loss:		1.070758E-06

Epoch 313 of 500
  training loss:		1.287538E-06
  validation loss:		1.602702E-06

Epoch 314 of 500
  training loss:		1.308771E-06
  validation loss:		1.323290E-06

Epoch 315 of 500
  training loss:		1.280728E-06
  validation loss:		1.119519E-06

Epoch 316 of 500
  training loss:		1.268956E-06
  validation loss:		1.071124E-06

Epoch 317 of 500
  training loss:		1.248937E-06
  validation loss:		1.847100E-06

Epoch 318 of 500
  training loss:		1.231525E-06
  validation loss:		9.894838E-07

Epoch 319 of 500
  training loss:		1.201889E-06
  validation loss:		1.126812E-06

Epoch 320 of 500
  training loss:		1.182861E-06
  validation loss:		1.000316E-06

Epoch 321 of 500
  training loss:		1.236940E-06
  validation loss:		1.344369E-06

Epoch 322 of 500
  training loss:		1.196695E-06
  validation loss:		1.252135E-06

Epoch 323 of 500
  training loss:		1.167881E-06
  validation loss:		1.080816E-06

Epoch 324 of 500
  training loss:		1.195817E-06
  validation loss:		1.718110E-06

Epoch 325 of 500
  training loss:		1.201661E-06
  validation loss:		9.215730E-07

Epoch 326 of 500
  training loss:		1.147493E-06
  validation loss:		9.056729E-07

Epoch 327 of 500
  training loss:		1.083532E-06
  validation loss:		9.174818E-07

Epoch 328 of 500
  training loss:		1.102257E-06
  validation loss:		1.433888E-06

Epoch 329 of 500
  training loss:		1.092791E-06
  validation loss:		1.429448E-06

Epoch 330 of 500
  training loss:		1.119900E-06
  validation loss:		1.298158E-06

Early stopping, val-loss increased over the last 10 epochs from 0.000325908258299 to 0.000325993778336
Training RMSE: 1.16729883674e-09
Validation RMSE: 1.17211830982e-09
