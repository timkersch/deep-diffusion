Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 500
  training loss:		3.701260E-02
  validation loss:		3.025613E-03

Epoch 2 of 500
  training loss:		2.716107E-03
  validation loss:		2.491053E-03

Epoch 3 of 500
  training loss:		2.309167E-03
  validation loss:		2.218672E-03

Epoch 4 of 500
  training loss:		2.059694E-03
  validation loss:		1.993107E-03

Epoch 5 of 500
  training loss:		1.762098E-03
  validation loss:		1.345344E-03

Epoch 6 of 500
  training loss:		8.290613E-04
  validation loss:		4.862491E-04

Epoch 7 of 500
  training loss:		3.936999E-04
  validation loss:		2.975241E-04

Epoch 8 of 500
  training loss:		2.669237E-04
  validation loss:		2.180825E-04

Epoch 9 of 500
  training loss:		1.955229E-04
  validation loss:		1.623548E-04

Epoch 10 of 500
  training loss:		1.515881E-04
  validation loss:		1.378241E-04

Epoch 11 of 500
  training loss:		1.230848E-04
  validation loss:		1.123992E-04

Epoch 12 of 500
  training loss:		1.026386E-04
  validation loss:		9.384244E-05

Epoch 13 of 500
  training loss:		8.974825E-05
  validation loss:		8.261685E-05

Epoch 14 of 500
  training loss:		7.873349E-05
  validation loss:		7.308761E-05

Epoch 15 of 500
  training loss:		6.949426E-05
  validation loss:		6.968550E-05

Epoch 16 of 500
  training loss:		6.221359E-05
  validation loss:		6.646961E-05

Epoch 17 of 500
  training loss:		5.598235E-05
  validation loss:		4.977182E-05

Epoch 18 of 500
  training loss:		4.902893E-05
  validation loss:		4.389583E-05

Epoch 19 of 500
  training loss:		4.344402E-05
  validation loss:		3.921158E-05

Epoch 20 of 500
  training loss:		3.876480E-05
  validation loss:		3.517350E-05

Epoch 21 of 500
  training loss:		3.386603E-05
  validation loss:		3.299826E-05

Epoch 22 of 500
  training loss:		3.036703E-05
  validation loss:		2.824277E-05

Epoch 23 of 500
  training loss:		2.715846E-05
  validation loss:		2.432640E-05

Epoch 24 of 500
  training loss:		2.405139E-05
  validation loss:		2.401294E-05

Epoch 25 of 500
  training loss:		2.204266E-05
  validation loss:		2.030979E-05

Epoch 26 of 500
  training loss:		2.005025E-05
  validation loss:		1.782776E-05

Epoch 27 of 500
  training loss:		1.813700E-05
  validation loss:		1.603068E-05

Epoch 28 of 500
  training loss:		1.651247E-05
  validation loss:		1.501476E-05

Epoch 29 of 500
  training loss:		1.509177E-05
  validation loss:		1.323752E-05

Epoch 30 of 500
  training loss:		1.396415E-05
  validation loss:		1.378182E-05

Epoch 31 of 500
  training loss:		1.297168E-05
  validation loss:		1.133776E-05

Epoch 32 of 500
  training loss:		1.213632E-05
  validation loss:		1.145873E-05

Epoch 33 of 500
  training loss:		1.120711E-05
  validation loss:		1.005755E-05

Epoch 34 of 500
  training loss:		1.054647E-05
  validation loss:		9.856308E-06

Epoch 35 of 500
  training loss:		1.020980E-05
  validation loss:		1.202290E-05

Epoch 36 of 500
  training loss:		9.269475E-06
  validation loss:		8.768484E-06

Epoch 37 of 500
  training loss:		8.732943E-06
  validation loss:		7.956680E-06

Epoch 38 of 500
  training loss:		8.432492E-06
  validation loss:		9.191057E-06

Epoch 39 of 500
  training loss:		8.100415E-06
  validation loss:		7.408006E-06

Epoch 40 of 500
  training loss:		7.442223E-06
  validation loss:		7.487554E-06

Epoch 41 of 500
  training loss:		7.231621E-06
  validation loss:		1.063861E-05

Epoch 42 of 500
  training loss:		7.050661E-06
  validation loss:		8.205370E-06

Epoch 43 of 500
  training loss:		6.774799E-06
  validation loss:		6.015484E-06

Epoch 44 of 500
  training loss:		6.331743E-06
  validation loss:		6.982506E-06

Epoch 45 of 500
  training loss:		6.107475E-06
  validation loss:		5.440090E-06

Epoch 46 of 500
  training loss:		5.918425E-06
  validation loss:		5.506746E-06

Epoch 47 of 500
  training loss:		5.505380E-06
  validation loss:		5.096423E-06

Epoch 48 of 500
  training loss:		5.504353E-06
  validation loss:		4.964790E-06

Epoch 49 of 500
  training loss:		5.322257E-06
  validation loss:		4.717569E-06

Epoch 50 of 500
  training loss:		5.159612E-06
  validation loss:		4.973229E-06

Epoch 51 of 500
  training loss:		4.948248E-06
  validation loss:		4.622689E-06

Epoch 52 of 500
  training loss:		4.856757E-06
  validation loss:		4.938948E-06

Epoch 53 of 500
  training loss:		4.493239E-06
  validation loss:		4.174003E-06

Epoch 54 of 500
  training loss:		4.526464E-06
  validation loss:		4.109044E-06

Epoch 55 of 500
  training loss:		4.118870E-06
  validation loss:		3.912834E-06

Epoch 56 of 500
  training loss:		4.214283E-06
  validation loss:		3.731673E-06

Epoch 57 of 500
  training loss:		4.076385E-06
  validation loss:		3.690905E-06

Epoch 58 of 500
  training loss:		4.067740E-06
  validation loss:		3.466971E-06

Epoch 59 of 500
  training loss:		3.913044E-06
  validation loss:		3.395356E-06

Epoch 60 of 500
  training loss:		3.645355E-06
  validation loss:		3.337130E-06

Epoch 61 of 500
  training loss:		3.772466E-06
  validation loss:		3.205850E-06

Epoch 62 of 500
  training loss:		3.532584E-06
  validation loss:		8.097574E-06

Epoch 63 of 500
  training loss:		3.459660E-06
  validation loss:		4.523586E-06

Epoch 64 of 500
  training loss:		3.282094E-06
  validation loss:		4.262937E-06

Epoch 65 of 500
  training loss:		3.371021E-06
  validation loss:		5.177333E-06

Epoch 66 of 500
  training loss:		3.212021E-06
  validation loss:		2.789267E-06

Epoch 67 of 500
  training loss:		3.056974E-06
  validation loss:		4.186276E-06

Epoch 68 of 500
  training loss:		3.067981E-06
  validation loss:		3.105804E-06

Epoch 69 of 500
  training loss:		2.790414E-06
  validation loss:		4.130135E-06

Epoch 70 of 500
  training loss:		2.889854E-06
  validation loss:		3.110080E-06

Epoch 71 of 500
  training loss:		2.761987E-06
  validation loss:		2.526560E-06

Epoch 72 of 500
  training loss:		2.779121E-06
  validation loss:		2.319127E-06

Epoch 73 of 500
  training loss:		2.541368E-06
  validation loss:		2.792734E-06

Epoch 74 of 500
  training loss:		2.624041E-06
  validation loss:		2.641014E-06

Epoch 75 of 500
  training loss:		2.533873E-06
  validation loss:		2.149813E-06

Epoch 76 of 500
  training loss:		2.607315E-06
  validation loss:		2.371806E-06

Epoch 77 of 500
  training loss:		2.385060E-06
  validation loss:		4.717519E-06

Epoch 78 of 500
  training loss:		2.256328E-06
  validation loss:		1.989979E-06

Epoch 79 of 500
  training loss:		2.361726E-06
  validation loss:		2.268189E-06

Epoch 80 of 500
  training loss:		2.225272E-06
  validation loss:		2.425899E-06

Epoch 81 of 500
  training loss:		2.230314E-06
  validation loss:		1.850453E-06

Epoch 82 of 500
  training loss:		2.118376E-06
  validation loss:		2.329387E-06

Epoch 83 of 500
  training loss:		2.109924E-06
  validation loss:		2.108822E-06

Epoch 84 of 500
  training loss:		2.173966E-06
  validation loss:		1.868860E-06

Epoch 85 of 500
  training loss:		1.992659E-06
  validation loss:		1.768686E-06

Epoch 86 of 500
  training loss:		1.918831E-06
  validation loss:		2.371721E-06

Epoch 87 of 500
  training loss:		1.852504E-06
  validation loss:		1.618652E-06

Epoch 88 of 500
  training loss:		1.944333E-06
  validation loss:		2.645641E-06

Epoch 89 of 500
  training loss:		1.874775E-06
  validation loss:		1.812612E-06

Epoch 90 of 500
  training loss:		1.821071E-06
  validation loss:		1.584151E-06

Epoch 91 of 500
  training loss:		1.755459E-06
  validation loss:		1.554652E-06

Epoch 92 of 500
  training loss:		1.682874E-06
  validation loss:		1.413538E-06

Epoch 93 of 500
  training loss:		1.774193E-06
  validation loss:		1.350961E-06

Epoch 94 of 500
  training loss:		1.711596E-06
  validation loss:		1.354817E-06

Epoch 95 of 500
  training loss:		1.625315E-06
  validation loss:		1.626577E-06

Epoch 96 of 500
  training loss:		1.565028E-06
  validation loss:		1.413577E-06

Epoch 97 of 500
  training loss:		1.603090E-06
  validation loss:		3.818657E-06

Epoch 98 of 500
  training loss:		1.424555E-06
  validation loss:		2.059914E-06

Epoch 99 of 500
  training loss:		1.560591E-06
  validation loss:		1.907397E-06

Epoch 100 of 500
  training loss:		1.429251E-06
  validation loss:		1.204711E-06

Epoch 101 of 500
  training loss:		1.456968E-06
  validation loss:		2.068483E-06

Epoch 102 of 500
  training loss:		1.309826E-06
  validation loss:		1.253530E-06

Epoch 103 of 500
  training loss:		1.416989E-06
  validation loss:		1.233360E-06

Epoch 104 of 500
  training loss:		1.220328E-06
  validation loss:		1.466037E-06

Epoch 105 of 500
  training loss:		1.386633E-06
  validation loss:		1.323436E-06

Epoch 106 of 500
  training loss:		1.320576E-06
  validation loss:		1.885119E-06

Epoch 107 of 500
  training loss:		1.242375E-06
  validation loss:		9.839692E-07

Epoch 108 of 500
  training loss:		1.254490E-06
  validation loss:		1.438799E-06

Epoch 109 of 500
  training loss:		1.254777E-06
  validation loss:		1.960102E-06

Epoch 110 of 500
  training loss:		1.212247E-06
  validation loss:		1.128290E-06

Epoch 111 of 500
  training loss:		1.075968E-06
  validation loss:		9.444843E-07

Epoch 112 of 500
  training loss:		1.112830E-06
  validation loss:		1.129675E-06

Epoch 113 of 500
  training loss:		1.171755E-06
  validation loss:		8.695409E-07

Epoch 114 of 500
  training loss:		1.067485E-06
  validation loss:		1.139979E-06

Epoch 115 of 500
  training loss:		1.101894E-06
  validation loss:		1.726763E-06

Epoch 116 of 500
  training loss:		1.052086E-06
  validation loss:		2.813673E-06

Epoch 117 of 500
  training loss:		1.059675E-06
  validation loss:		7.585959E-07

Epoch 118 of 500
  training loss:		1.082466E-06
  validation loss:		1.758208E-06

Epoch 119 of 500
  training loss:		9.200158E-07
  validation loss:		1.264227E-06

Epoch 120 of 500
  training loss:		1.091418E-06
  validation loss:		9.662242E-07

Epoch 121 of 500
  training loss:		1.047375E-06
  validation loss:		8.930670E-07

Epoch 122 of 500
  training loss:		9.384252E-07
  validation loss:		1.008359E-06

Epoch 123 of 500
  training loss:		9.264439E-07
  validation loss:		7.033039E-07

Epoch 124 of 500
  training loss:		9.275040E-07
  validation loss:		1.156682E-06

Epoch 125 of 500
  training loss:		8.714773E-07
  validation loss:		1.485122E-06

Epoch 126 of 500
  training loss:		8.474611E-07
  validation loss:		9.052765E-07

Epoch 127 of 500
  training loss:		9.303293E-07
  validation loss:		6.275578E-07

Epoch 128 of 500
  training loss:		8.361892E-07
  validation loss:		5.996082E-07

Epoch 129 of 500
  training loss:		8.385102E-07
  validation loss:		7.500845E-07

Epoch 130 of 500
  training loss:		8.946676E-07
  validation loss:		5.636300E-07

Epoch 131 of 500
  training loss:		8.988567E-07
  validation loss:		8.632363E-07

Epoch 132 of 500
  training loss:		7.438977E-07
  validation loss:		1.227810E-06

Epoch 133 of 500
  training loss:		7.858765E-07
  validation loss:		7.407184E-07

Epoch 134 of 500
  training loss:		7.665470E-07
  validation loss:		6.981086E-07

Epoch 135 of 500
  training loss:		8.341478E-07
  validation loss:		1.974631E-06

Epoch 136 of 500
  training loss:		7.197030E-07
  validation loss:		1.182746E-06

Epoch 137 of 500
  training loss:		7.221854E-07
  validation loss:		7.021500E-07

Epoch 138 of 500
  training loss:		8.425737E-07
  validation loss:		5.138473E-07

Epoch 139 of 500
  training loss:		6.861755E-07
  validation loss:		6.588000E-07

Epoch 140 of 500
  training loss:		7.471816E-07
  validation loss:		7.669112E-07

Epoch 141 of 500
  training loss:		6.894592E-07
  validation loss:		1.291645E-06

Epoch 142 of 500
  training loss:		7.308531E-07
  validation loss:		5.164320E-07

Epoch 143 of 500
  training loss:		6.672137E-07
  validation loss:		5.075455E-07

Epoch 144 of 500
  training loss:		6.680453E-07
  validation loss:		1.393604E-06

Epoch 145 of 500
  training loss:		7.497354E-07
  validation loss:		5.056870E-07

Epoch 146 of 500
  training loss:		5.989427E-07
  validation loss:		5.424560E-07

Epoch 147 of 500
  training loss:		6.630415E-07
  validation loss:		3.976859E-07

Epoch 148 of 500
  training loss:		6.609572E-07
  validation loss:		1.132640E-06

Epoch 149 of 500
  training loss:		6.376243E-07
  validation loss:		5.681783E-07

Epoch 150 of 500
  training loss:		5.527028E-07
  validation loss:		3.946073E-07

Epoch 151 of 500
  training loss:		5.881796E-07
  validation loss:		4.299296E-07

Epoch 152 of 500
  training loss:		5.886698E-07
  validation loss:		3.779138E-07

Epoch 153 of 500
  training loss:		7.027198E-07
  validation loss:		5.942166E-07

Epoch 154 of 500
  training loss:		5.902353E-07
  validation loss:		3.517985E-07

Epoch 155 of 500
  training loss:		6.074594E-07
  validation loss:		1.592319E-06

Epoch 156 of 500
  training loss:		6.344739E-07
  validation loss:		6.049730E-07

Epoch 157 of 500
  training loss:		5.274334E-07
  validation loss:		5.700002E-07

Epoch 158 of 500
  training loss:		5.419920E-07
  validation loss:		3.450155E-07

Epoch 159 of 500
  training loss:		5.109910E-07
  validation loss:		1.011584E-06

Epoch 160 of 500
  training loss:		5.548107E-07
  validation loss:		3.409457E-07

Epoch 161 of 500
  training loss:		5.468659E-07
  validation loss:		3.021412E-07

Epoch 162 of 500
  training loss:		5.327684E-07
  validation loss:		7.899193E-07

Epoch 163 of 500
  training loss:		5.162866E-07
  validation loss:		4.350307E-07

Epoch 164 of 500
  training loss:		5.936881E-07
  validation loss:		5.569496E-07

Epoch 165 of 500
  training loss:		4.620298E-07
  validation loss:		3.822508E-07

Epoch 166 of 500
  training loss:		5.159207E-07
  validation loss:		6.575940E-07

Epoch 167 of 500
  training loss:		4.754687E-07
  validation loss:		1.125297E-06

Epoch 168 of 500
  training loss:		5.385232E-07
  validation loss:		7.634091E-07

Epoch 169 of 500
  training loss:		4.452003E-07
  validation loss:		4.533755E-07

Epoch 170 of 500
  training loss:		4.698994E-07
  validation loss:		9.187813E-07

Epoch 171 of 500
  training loss:		4.701844E-07
  validation loss:		3.294238E-07

Epoch 172 of 500
  training loss:		4.984757E-07
  validation loss:		2.824079E-07

Epoch 173 of 500
  training loss:		4.833439E-07
  validation loss:		3.045059E-07

Epoch 174 of 500
  training loss:		5.227446E-07
  validation loss:		2.704559E-07

Epoch 175 of 500
  training loss:		4.897147E-07
  validation loss:		2.532769E-07

Epoch 176 of 500
  training loss:		4.725743E-07
  validation loss:		1.445474E-06

Epoch 177 of 500
  training loss:		4.167684E-07
  validation loss:		1.531839E-06

Epoch 178 of 500
  training loss:		4.956060E-07
  validation loss:		2.418743E-07

Epoch 179 of 500
  training loss:		3.877224E-07
  validation loss:		3.140790E-07

Epoch 180 of 500
  training loss:		4.571788E-07
  validation loss:		2.818046E-07

Epoch 181 of 500
  training loss:		4.541419E-07
  validation loss:		2.152365E-07

Epoch 182 of 500
  training loss:		4.258131E-07
  validation loss:		2.495873E-07

Epoch 183 of 500
  training loss:		4.285497E-07
  validation loss:		2.382578E-07

Epoch 184 of 500
  training loss:		4.376007E-07
  validation loss:		7.105497E-07

Epoch 185 of 500
  training loss:		4.506632E-07
  validation loss:		8.053122E-07

Epoch 186 of 500
  training loss:		4.458320E-07
  validation loss:		2.281429E-07

Epoch 187 of 500
  training loss:		4.026643E-07
  validation loss:		3.032032E-07

Epoch 188 of 500
  training loss:		3.908244E-07
  validation loss:		1.197766E-06

Epoch 189 of 500
  training loss:		3.789590E-07
  validation loss:		1.817495E-07

Epoch 190 of 500
  training loss:		4.137708E-07
  validation loss:		1.909791E-07

Epoch 191 of 500
  training loss:		3.860936E-07
  validation loss:		2.266255E-07

Epoch 192 of 500
  training loss:		3.829294E-07
  validation loss:		2.373695E-07

Epoch 193 of 500
  training loss:		4.189643E-07
  validation loss:		1.730110E-07

Epoch 194 of 500
  training loss:		4.357437E-07
  validation loss:		2.357326E-06

Epoch 195 of 500
  training loss:		4.114685E-07
  validation loss:		1.834839E-07

Epoch 196 of 500
  training loss:		3.200809E-07
  validation loss:		2.784630E-07

Epoch 197 of 500
  training loss:		3.348723E-07
  validation loss:		3.847393E-07

Epoch 198 of 500
  training loss:		4.013398E-07
  validation loss:		3.311604E-07

Epoch 199 of 500
  training loss:		3.671072E-07
  validation loss:		1.162728E-06

Epoch 200 of 500
  training loss:		4.088520E-07
  validation loss:		2.726608E-07

Epoch 201 of 500
  training loss:		3.587158E-07
  validation loss:		6.168765E-07

Epoch 202 of 500
  training loss:		4.323213E-07
  validation loss:		1.089100E-06

Epoch 203 of 500
  training loss:		3.539967E-07
  validation loss:		2.066384E-07

Epoch 204 of 500
  training loss:		3.178463E-07
  validation loss:		7.826328E-07

Epoch 205 of 500
  training loss:		4.030576E-07
  validation loss:		1.865749E-07

Epoch 206 of 500
  training loss:		3.478468E-07
  validation loss:		1.557014E-07

Epoch 207 of 500
  training loss:		3.542542E-07
  validation loss:		5.052740E-07

Epoch 208 of 500
  training loss:		3.517221E-07
  validation loss:		2.105506E-07

Epoch 209 of 500
  training loss:		3.858174E-07
  validation loss:		1.614270E-07

Epoch 210 of 500
  training loss:		3.302637E-07
  validation loss:		3.109139E-07

Epoch 211 of 500
  training loss:		3.361381E-07
  validation loss:		1.339827E-07

Epoch 212 of 500
  training loss:		3.187464E-07
  validation loss:		1.723483E-07

Epoch 213 of 500
  training loss:		3.469397E-07
  validation loss:		1.583700E-07

Epoch 214 of 500
  training loss:		3.245008E-07
  validation loss:		2.037625E-07

Epoch 215 of 500
  training loss:		3.525595E-07
  validation loss:		1.145635E-06

Epoch 216 of 500
  training loss:		3.299462E-07
  validation loss:		4.655011E-07

Epoch 217 of 500
  training loss:		3.294826E-07
  validation loss:		1.694385E-07

Epoch 218 of 500
  training loss:		3.372348E-07
  validation loss:		3.865449E-07

Epoch 219 of 500
  training loss:		3.282514E-07
  validation loss:		2.428145E-07

Epoch 220 of 500
  training loss:		3.205011E-07
  validation loss:		2.920593E-07

Epoch 221 of 500
  training loss:		3.632089E-07
  validation loss:		1.166315E-07

Epoch 222 of 500
  training loss:		3.013986E-07
  validation loss:		1.107302E-07

Epoch 223 of 500
  training loss:		3.659602E-07
  validation loss:		1.147223E-07

Epoch 224 of 500
  training loss:		2.969249E-07
  validation loss:		2.113568E-07

Epoch 225 of 500
  training loss:		3.301603E-07
  validation loss:		1.147916E-07

Epoch 226 of 500
  training loss:		2.995527E-07
  validation loss:		1.527152E-07

Epoch 227 of 500
  training loss:		3.236182E-07
  validation loss:		1.193067E-07

Epoch 228 of 500
  training loss:		2.733351E-07
  validation loss:		1.900973E-07

Epoch 229 of 500
  training loss:		3.004275E-07
  validation loss:		1.333831E-07

Epoch 230 of 500
  training loss:		3.554565E-07
  validation loss:		2.079569E-07

Epoch 231 of 500
  training loss:		3.243948E-07
  validation loss:		1.923082E-07

Epoch 232 of 500
  training loss:		2.935132E-07
  validation loss:		1.185330E-07

Epoch 233 of 500
  training loss:		3.087310E-07
  validation loss:		4.221298E-07

Epoch 234 of 500
  training loss:		3.132992E-07
  validation loss:		5.828624E-07

Epoch 235 of 500
  training loss:		3.315404E-07
  validation loss:		4.739727E-07

Epoch 236 of 500
  training loss:		3.323439E-07
  validation loss:		3.706801E-07

Epoch 237 of 500
  training loss:		2.662740E-07
  validation loss:		4.582848E-07

Epoch 238 of 500
  training loss:		2.754412E-07
  validation loss:		1.301928E-06

Epoch 239 of 500
  training loss:		3.328114E-07
  validation loss:		5.674711E-07

Epoch 240 of 500
  training loss:		2.805758E-07
  validation loss:		1.334991E-07

Epoch 241 of 500
  training loss:		2.683067E-07
  validation loss:		1.482500E-07

Epoch 242 of 500
  training loss:		3.279205E-07
  validation loss:		9.829195E-08

Epoch 243 of 500
  training loss:		2.813308E-07
  validation loss:		2.001158E-07

Epoch 244 of 500
  training loss:		3.049003E-07
  validation loss:		1.319237E-06

Epoch 245 of 500
  training loss:		3.150126E-07
  validation loss:		1.081528E-07

Epoch 246 of 500
  training loss:		2.648596E-07
  validation loss:		8.300358E-08

Epoch 247 of 500
  training loss:		2.573989E-07
  validation loss:		1.822653E-07

Epoch 248 of 500
  training loss:		3.271268E-07
  validation loss:		8.766452E-08

Epoch 249 of 500
  training loss:		2.865527E-07
  validation loss:		1.897032E-07

Epoch 250 of 500
  training loss:		2.657740E-07
  validation loss:		2.300614E-07

Epoch 251 of 500
  training loss:		2.658054E-07
  validation loss:		1.706715E-07

Epoch 252 of 500
  training loss:		2.783554E-07
  validation loss:		1.388274E-07

Epoch 253 of 500
  training loss:		2.357352E-07
  validation loss:		1.156495E-07

Epoch 254 of 500
  training loss:		3.152239E-07
  validation loss:		4.797895E-07

Epoch 255 of 500
  training loss:		2.601474E-07
  validation loss:		8.808654E-08

Epoch 256 of 500
  training loss:		3.288716E-07
  validation loss:		3.855779E-07

Epoch 257 of 500
  training loss:		2.999262E-07
  validation loss:		1.691168E-07

Epoch 258 of 500
  training loss:		2.261635E-07
  validation loss:		5.198115E-07

Epoch 259 of 500
  training loss:		2.595589E-07
  validation loss:		1.610382E-07

Epoch 260 of 500
  training loss:		3.094099E-07
  validation loss:		7.969445E-08

Epoch 261 of 500
  training loss:		2.602207E-07
  validation loss:		1.173031E-07

Epoch 262 of 500
  training loss:		3.171774E-07
  validation loss:		7.636978E-08

Epoch 263 of 500
  training loss:		2.435008E-07
  validation loss:		1.125196E-07

Epoch 264 of 500
  training loss:		2.772334E-07
  validation loss:		1.726546E-07

Epoch 265 of 500
  training loss:		2.239444E-07
  validation loss:		3.928054E-07

Epoch 266 of 500
  training loss:		2.928344E-07
  validation loss:		1.039014E-07

Epoch 267 of 500
  training loss:		2.613864E-07
  validation loss:		2.024903E-07

Epoch 268 of 500
  training loss:		2.416799E-07
  validation loss:		1.385878E-06

Epoch 269 of 500
  training loss:		3.094175E-07
  validation loss:		8.818409E-08

Epoch 270 of 500
  training loss:		2.561270E-07
  validation loss:		8.045605E-08

Epoch 271 of 500
  training loss:		2.404622E-07
  validation loss:		4.366883E-07

Epoch 272 of 500
  training loss:		3.052379E-07
  validation loss:		2.650461E-07

Epoch 273 of 500
  training loss:		2.501096E-07
  validation loss:		1.422363E-07

Epoch 274 of 500
  training loss:		2.727007E-07
  validation loss:		5.157422E-07

Epoch 275 of 500
  training loss:		2.463827E-07
  validation loss:		3.316431E-07

Epoch 276 of 500
  training loss:		2.539812E-07
  validation loss:		1.676416E-07

Epoch 277 of 500
  training loss:		2.705933E-07
  validation loss:		3.767403E-07

Epoch 278 of 500
  training loss:		2.747774E-07
  validation loss:		3.009020E-07

Epoch 279 of 500
  training loss:		2.596861E-07
  validation loss:		1.616404E-07

Epoch 280 of 500
  training loss:		3.193258E-07
  validation loss:		2.318159E-07

Early stopping, val-loss increased over the last 20 epochs from 3.27030588557e-05 to 3.73735492656e-05
Training RMSE: 3.95229693932e-10
Validation RMSE: 3.93754722695e-10
