Epoch 1 of 500
  training loss:		2.025765E-02
  validation loss:		1.382099E-07

Epoch 2 of 500
  training loss:		5.064205E-08
  validation loss:		9.318809E-09

Epoch 3 of 500
  training loss:		3.439454E-09
  validation loss:		1.605977E-09

Epoch 4 of 500
  training loss:		1.412803E-09
  validation loss:		1.392785E-09

Epoch 5 of 500
  training loss:		1.295284E-09
  validation loss:		1.299199E-09

Epoch 6 of 500
  training loss:		1.190386E-09
  validation loss:		1.199106E-09

Epoch 7 of 500
  training loss:		1.075106E-09
  validation loss:		1.041564E-09

Epoch 8 of 500
  training loss:		9.489002E-10
  validation loss:		9.089069E-10

Epoch 9 of 500
  training loss:		8.192100E-10
  validation loss:		7.771756E-10

Epoch 10 of 500
  training loss:		6.936438E-10
  validation loss:		6.453651E-10

Epoch 11 of 500
  training loss:		5.656418E-10
  validation loss:		5.171564E-10

Epoch 12 of 500
  training loss:		4.472454E-10
  validation loss:		4.046188E-10

Epoch 13 of 500
  training loss:		3.426161E-10
  validation loss:		3.009347E-10

Epoch 14 of 500
  training loss:		2.484768E-10
  validation loss:		2.128280E-10

Epoch 15 of 500
  training loss:		1.754714E-10
  validation loss:		1.501646E-10

Epoch 16 of 500
  training loss:		1.171353E-10
  validation loss:		9.891780E-11

Epoch 17 of 500
  training loss:		7.437437E-11
  validation loss:		5.767019E-11

Epoch 18 of 500
  training loss:		4.512438E-11
  validation loss:		3.532096E-11

Epoch 19 of 500
  training loss:		2.710635E-11
  validation loss:		2.184322E-11

Epoch 20 of 500
  training loss:		1.722421E-11
  validation loss:		1.290629E-11

Epoch 21 of 500
  training loss:		1.072953E-11
  validation loss:		8.454424E-12

Epoch 22 of 500
  training loss:		7.585889E-12
  validation loss:		5.982577E-12

Epoch 23 of 500
  training loss:		5.871533E-12
  validation loss:		5.720221E-12

Epoch 24 of 500
  training loss:		4.653676E-12
  validation loss:		3.820329E-12

Epoch 25 of 500
  training loss:		3.716799E-12
  validation loss:		4.546564E-12

Epoch 26 of 500
  training loss:		3.188769E-12
  validation loss:		5.443280E-12

Epoch 27 of 500
  training loss:		1.626181E-11
  validation loss:		7.740679E-10

Epoch 28 of 500
  training loss:		9.849423E-07
  validation loss:		2.521549E-09

Epoch 29 of 500
  training loss:		1.029724E-06
  validation loss:		3.452411E-08

Epoch 30 of 500
  training loss:		1.466452E-06
  validation loss:		1.322793E-08

Early stopping, val-loss increased over the last 10 epochs from 1.59487766116e-08 to 4.49518316631e-07
Training-set, RMSE: 0.000185811297773
Validation-set, RMSE: 0.000185790573645
