Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 500
  training loss:		1.710636E-01
  validation loss:		7.987683E-02

Epoch 2 of 500
  training loss:		7.065874E-02
  validation loss:		6.034396E-02

Epoch 3 of 500
  training loss:		4.926466E-02
  validation loss:		3.800565E-02

Epoch 4 of 500
  training loss:		2.765096E-02
  validation loss:		1.828275E-02

Epoch 5 of 500
  training loss:		1.182030E-02
  validation loss:		7.088245E-03

Epoch 6 of 500
  training loss:		5.018144E-03
  validation loss:		3.934708E-03

Epoch 7 of 500
  training loss:		3.607243E-03
  validation loss:		3.435427E-03

Epoch 8 of 500
  training loss:		3.324876E-03
  validation loss:		3.232793E-03

Epoch 9 of 500
  training loss:		3.137250E-03
  validation loss:		3.065175E-03

Epoch 10 of 500
  training loss:		2.980295E-03
  validation loss:		2.925502E-03

Epoch 11 of 500
  training loss:		2.846939E-03
  validation loss:		2.800979E-03

Epoch 12 of 500
  training loss:		2.731933E-03
  validation loss:		2.695941E-03

Epoch 13 of 500
  training loss:		2.637037E-03
  validation loss:		2.605537E-03

Epoch 14 of 500
  training loss:		2.550555E-03
  validation loss:		2.563951E-03

Epoch 15 of 500
  training loss:		2.476100E-03
  validation loss:		2.451696E-03

Epoch 16 of 500
  training loss:		2.406314E-03
  validation loss:		2.393802E-03

Epoch 17 of 500
  training loss:		2.345094E-03
  validation loss:		2.346118E-03

Epoch 18 of 500
  training loss:		2.289243E-03
  validation loss:		2.278612E-03

Epoch 19 of 500
  training loss:		2.242399E-03
  validation loss:		2.230571E-03

Epoch 20 of 500
  training loss:		2.200362E-03
  validation loss:		2.203547E-03

Epoch 21 of 500
  training loss:		2.159705E-03
  validation loss:		2.148224E-03

Epoch 22 of 500
  training loss:		2.122791E-03
  validation loss:		2.136374E-03

Epoch 23 of 500
  training loss:		2.085381E-03
  validation loss:		2.075954E-03

Epoch 24 of 500
  training loss:		2.056054E-03
  validation loss:		2.048070E-03

Epoch 25 of 500
  training loss:		2.023853E-03
  validation loss:		2.033029E-03

Epoch 26 of 500
  training loss:		1.995492E-03
  validation loss:		2.012220E-03

Epoch 27 of 500
  training loss:		1.968210E-03
  validation loss:		1.962032E-03

Epoch 28 of 500
  training loss:		1.944682E-03
  validation loss:		1.938685E-03

Epoch 29 of 500
  training loss:		1.919561E-03
  validation loss:		1.911644E-03

Epoch 30 of 500
  training loss:		1.894840E-03
  validation loss:		1.891707E-03

Epoch 31 of 500
  training loss:		1.866377E-03
  validation loss:		1.852642E-03

Epoch 32 of 500
  training loss:		1.826699E-03
  validation loss:		1.802029E-03

Epoch 33 of 500
  training loss:		1.761129E-03
  validation loss:		1.716293E-03

Epoch 34 of 500
  training loss:		1.649767E-03
  validation loss:		1.578178E-03

Epoch 35 of 500
  training loss:		1.492006E-03
  validation loss:		1.401281E-03

Epoch 36 of 500
  training loss:		1.296440E-03
  validation loss:		1.205022E-03

Epoch 37 of 500
  training loss:		1.088761E-03
  validation loss:		9.787287E-04

Epoch 38 of 500
  training loss:		8.928805E-04
  validation loss:		7.889834E-04

Epoch 39 of 500
  training loss:		7.246848E-04
  validation loss:		6.369184E-04

Epoch 40 of 500
  training loss:		5.931468E-04
  validation loss:		5.222540E-04

Epoch 41 of 500
  training loss:		4.946262E-04
  validation loss:		4.401680E-04

Epoch 42 of 500
  training loss:		4.253382E-04
  validation loss:		3.805602E-04

Epoch 43 of 500
  training loss:		3.727111E-04
  validation loss:		3.352841E-04

Epoch 44 of 500
  training loss:		3.338462E-04
  validation loss:		3.132238E-04

Epoch 45 of 500
  training loss:		3.023314E-04
  validation loss:		2.746170E-04

Epoch 46 of 500
  training loss:		2.761349E-04
  validation loss:		2.505088E-04

Epoch 47 of 500
  training loss:		2.545029E-04
  validation loss:		2.312222E-04

Epoch 48 of 500
  training loss:		2.351406E-04
  validation loss:		2.237899E-04

Epoch 49 of 500
  training loss:		2.189248E-04
  validation loss:		1.984764E-04

Epoch 50 of 500
  training loss:		2.026983E-04
  validation loss:		1.867461E-04

Epoch 51 of 500
  training loss:		1.891323E-04
  validation loss:		1.790685E-04

Epoch 52 of 500
  training loss:		1.772992E-04
  validation loss:		1.627892E-04

Epoch 53 of 500
  training loss:		1.663064E-04
  validation loss:		1.541366E-04

Epoch 54 of 500
  training loss:		1.562334E-04
  validation loss:		1.461420E-04

Epoch 55 of 500
  training loss:		1.472239E-04
  validation loss:		1.354045E-04

Epoch 56 of 500
  training loss:		1.394784E-04
  validation loss:		1.353881E-04

Epoch 57 of 500
  training loss:		1.316652E-04
  validation loss:		1.270827E-04

Epoch 58 of 500
  training loss:		1.255419E-04
  validation loss:		1.189677E-04

Epoch 59 of 500
  training loss:		1.192576E-04
  validation loss:		1.144106E-04

Epoch 60 of 500
  training loss:		1.141702E-04
  validation loss:		1.065807E-04

Epoch 61 of 500
  training loss:		1.089666E-04
  validation loss:		1.117045E-04

Epoch 62 of 500
  training loss:		1.046989E-04
  validation loss:		9.819279E-05

Epoch 63 of 500
  training loss:		1.008383E-04
  validation loss:		9.415292E-05

Epoch 64 of 500
  training loss:		9.659643E-05
  validation loss:		9.114795E-05

Epoch 65 of 500
  training loss:		9.276367E-05
  validation loss:		9.138667E-05

Epoch 66 of 500
  training loss:		9.017543E-05
  validation loss:		8.449566E-05

Epoch 67 of 500
  training loss:		8.647399E-05
  validation loss:		8.168199E-05

Epoch 68 of 500
  training loss:		8.415965E-05
  validation loss:		7.918730E-05

Epoch 69 of 500
  training loss:		8.147035E-05
  validation loss:		7.689822E-05

Epoch 70 of 500
  training loss:		7.862643E-05
  validation loss:		8.139584E-05

Epoch 71 of 500
  training loss:		7.618044E-05
  validation loss:		8.281544E-05

Epoch 72 of 500
  training loss:		7.411244E-05
  validation loss:		7.275303E-05

Epoch 73 of 500
  training loss:		7.172533E-05
  validation loss:		6.824492E-05

Epoch 74 of 500
  training loss:		6.981031E-05
  validation loss:		6.720165E-05

Epoch 75 of 500
  training loss:		6.775584E-05
  validation loss:		6.808832E-05

Epoch 76 of 500
  training loss:		6.596776E-05
  validation loss:		6.398330E-05

Epoch 77 of 500
  training loss:		6.415220E-05
  validation loss:		6.394351E-05

Epoch 78 of 500
  training loss:		6.248290E-05
  validation loss:		6.281966E-05

Epoch 79 of 500
  training loss:		6.074628E-05
  validation loss:		5.787272E-05

Epoch 80 of 500
  training loss:		5.921859E-05
  validation loss:		5.656841E-05

Epoch 81 of 500
  training loss:		5.733038E-05
  validation loss:		5.538441E-05

Epoch 82 of 500
  training loss:		5.616624E-05
  validation loss:		5.358258E-05

Epoch 83 of 500
  training loss:		5.453370E-05
  validation loss:		5.464366E-05

Epoch 84 of 500
  training loss:		5.313133E-05
  validation loss:		5.255115E-05

Epoch 85 of 500
  training loss:		5.171742E-05
  validation loss:		5.116139E-05

Epoch 86 of 500
  training loss:		5.054773E-05
  validation loss:		4.975116E-05

Epoch 87 of 500
  training loss:		4.923998E-05
  validation loss:		5.484124E-05

Epoch 88 of 500
  training loss:		4.791022E-05
  validation loss:		5.003593E-05

Epoch 89 of 500
  training loss:		4.658190E-05
  validation loss:		4.495994E-05

Epoch 90 of 500
  training loss:		4.565567E-05
  validation loss:		4.349302E-05

Epoch 91 of 500
  training loss:		4.466984E-05
  validation loss:		4.346630E-05

Epoch 92 of 500
  training loss:		4.350278E-05
  validation loss:		4.708398E-05

Epoch 93 of 500
  training loss:		4.209273E-05
  validation loss:		4.059358E-05

Epoch 94 of 500
  training loss:		4.117820E-05
  validation loss:		3.959478E-05

Epoch 95 of 500
  training loss:		4.023393E-05
  validation loss:		3.964313E-05

Epoch 96 of 500
  training loss:		3.895263E-05
  validation loss:		3.777435E-05

Epoch 97 of 500
  training loss:		3.786671E-05
  validation loss:		3.669845E-05

Epoch 98 of 500
  training loss:		3.728906E-05
  validation loss:		3.568357E-05

Epoch 99 of 500
  training loss:		3.609831E-05
  validation loss:		3.468950E-05

Epoch 100 of 500
  training loss:		3.545461E-05
  validation loss:		3.415419E-05

Epoch 101 of 500
  training loss:		3.474717E-05
  validation loss:		3.296558E-05

Epoch 102 of 500
  training loss:		3.370036E-05
  validation loss:		3.246133E-05

Epoch 103 of 500
  training loss:		3.298656E-05
  validation loss:		3.140388E-05

Epoch 104 of 500
  training loss:		3.229732E-05
  validation loss:		3.068661E-05

Epoch 105 of 500
  training loss:		3.140527E-05
  validation loss:		3.011372E-05

Epoch 106 of 500
  training loss:		3.057239E-05
  validation loss:		3.005642E-05

Epoch 107 of 500
  training loss:		3.003917E-05
  validation loss:		2.861734E-05

Epoch 108 of 500
  training loss:		2.940172E-05
  validation loss:		2.794275E-05

Epoch 109 of 500
  training loss:		2.874742E-05
  validation loss:		2.883752E-05

Epoch 110 of 500
  training loss:		2.807767E-05
  validation loss:		2.883858E-05

Epoch 111 of 500
  training loss:		2.740915E-05
  validation loss:		2.862369E-05

Epoch 112 of 500
  training loss:		2.680949E-05
  validation loss:		2.619552E-05

Epoch 113 of 500
  training loss:		2.610444E-05
  validation loss:		2.499269E-05

Epoch 114 of 500
  training loss:		2.563876E-05
  validation loss:		2.645501E-05

Epoch 115 of 500
  training loss:		2.502980E-05
  validation loss:		2.433917E-05

Epoch 116 of 500
  training loss:		2.447530E-05
  validation loss:		2.366985E-05

Epoch 117 of 500
  training loss:		2.413756E-05
  validation loss:		2.308950E-05

Epoch 118 of 500
  training loss:		2.360227E-05
  validation loss:		2.283818E-05

Epoch 119 of 500
  training loss:		2.308486E-05
  validation loss:		2.217472E-05

Epoch 120 of 500
  training loss:		2.254701E-05
  validation loss:		2.166937E-05

Epoch 121 of 500
  training loss:		2.202117E-05
  validation loss:		2.138600E-05

Epoch 122 of 500
  training loss:		2.173031E-05
  validation loss:		2.171369E-05

Epoch 123 of 500
  training loss:		2.128497E-05
  validation loss:		2.028880E-05

Epoch 124 of 500
  training loss:		2.084291E-05
  validation loss:		2.011122E-05

Epoch 125 of 500
  training loss:		2.046339E-05
  validation loss:		2.024483E-05

Epoch 126 of 500
  training loss:		2.018763E-05
  validation loss:		1.912568E-05

Epoch 127 of 500
  training loss:		1.960451E-05
  validation loss:		1.914364E-05

Epoch 128 of 500
  training loss:		1.916257E-05
  validation loss:		2.239246E-05

Epoch 129 of 500
  training loss:		1.882806E-05
  validation loss:		1.802065E-05

Epoch 130 of 500
  training loss:		1.855203E-05
  validation loss:		1.764130E-05

Epoch 131 of 500
  training loss:		1.826739E-05
  validation loss:		2.099064E-05

Epoch 132 of 500
  training loss:		1.770145E-05
  validation loss:		1.718758E-05

Epoch 133 of 500
  training loss:		1.757112E-05
  validation loss:		1.956711E-05

Epoch 134 of 500
  training loss:		1.716935E-05
  validation loss:		1.655649E-05

Epoch 135 of 500
  training loss:		1.697679E-05
  validation loss:		1.609846E-05

Epoch 136 of 500
  training loss:		1.660537E-05
  validation loss:		1.610840E-05

Epoch 137 of 500
  training loss:		1.639939E-05
  validation loss:		1.559456E-05

Epoch 138 of 500
  training loss:		1.605802E-05
  validation loss:		1.583686E-05

Epoch 139 of 500
  training loss:		1.571806E-05
  validation loss:		1.514397E-05

Epoch 140 of 500
  training loss:		1.552184E-05
  validation loss:		1.506597E-05

Epoch 141 of 500
  training loss:		1.524771E-05
  validation loss:		1.451744E-05

Epoch 142 of 500
  training loss:		1.495464E-05
  validation loss:		1.476435E-05

Epoch 143 of 500
  training loss:		1.458053E-05
  validation loss:		1.414026E-05

Epoch 144 of 500
  training loss:		1.434522E-05
  validation loss:		1.383104E-05

Epoch 145 of 500
  training loss:		1.419971E-05
  validation loss:		1.352428E-05

Epoch 146 of 500
  training loss:		1.404307E-05
  validation loss:		1.333709E-05

Epoch 147 of 500
  training loss:		1.391716E-05
  validation loss:		1.348450E-05

Epoch 148 of 500
  training loss:		1.350242E-05
  validation loss:		1.291993E-05

Epoch 149 of 500
  training loss:		1.328211E-05
  validation loss:		1.271855E-05

Epoch 150 of 500
  training loss:		1.322377E-05
  validation loss:		1.264316E-05

Epoch 151 of 500
  training loss:		1.287118E-05
  validation loss:		1.244010E-05

Epoch 152 of 500
  training loss:		1.271266E-05
  validation loss:		1.233162E-05

Epoch 153 of 500
  training loss:		1.256912E-05
  validation loss:		1.201827E-05

Epoch 154 of 500
  training loss:		1.226479E-05
  validation loss:		1.353326E-05

Epoch 155 of 500
  training loss:		1.212910E-05
  validation loss:		1.166974E-05

Epoch 156 of 500
  training loss:		1.194986E-05
  validation loss:		1.147589E-05

Epoch 157 of 500
  training loss:		1.188696E-05
  validation loss:		1.373781E-05

Epoch 158 of 500
  training loss:		1.156777E-05
  validation loss:		1.117083E-05

Epoch 159 of 500
  training loss:		1.141805E-05
  validation loss:		1.146186E-05

Epoch 160 of 500
  training loss:		1.129255E-05
  validation loss:		1.090681E-05

Epoch 161 of 500
  training loss:		1.118305E-05
  validation loss:		1.124394E-05

Epoch 162 of 500
  training loss:		1.091813E-05
  validation loss:		1.060320E-05

Epoch 163 of 500
  training loss:		1.083892E-05
  validation loss:		1.062162E-05

Epoch 164 of 500
  training loss:		1.061453E-05
  validation loss:		1.023766E-05

Epoch 165 of 500
  training loss:		1.044596E-05
  validation loss:		1.018667E-05

Epoch 166 of 500
  training loss:		1.033554E-05
  validation loss:		1.127535E-05

Epoch 167 of 500
  training loss:		1.026441E-05
  validation loss:		9.830433E-06

Epoch 168 of 500
  training loss:		1.008763E-05
  validation loss:		1.037701E-05

Epoch 169 of 500
  training loss:		9.853480E-06
  validation loss:		9.882697E-06

Epoch 170 of 500
  training loss:		9.804033E-06
  validation loss:		1.104809E-05

Epoch 171 of 500
  training loss:		9.641316E-06
  validation loss:		9.754911E-06

Epoch 172 of 500
  training loss:		9.528714E-06
  validation loss:		9.432664E-06

Epoch 173 of 500
  training loss:		9.462202E-06
  validation loss:		9.122436E-06

Epoch 174 of 500
  training loss:		9.305266E-06
  validation loss:		8.988879E-06

Epoch 175 of 500
  training loss:		9.185188E-06
  validation loss:		8.873996E-06

Epoch 176 of 500
  training loss:		9.019973E-06
  validation loss:		9.003873E-06

Epoch 177 of 500
  training loss:		8.991333E-06
  validation loss:		8.675886E-06

Epoch 178 of 500
  training loss:		8.883155E-06
  validation loss:		9.183989E-06

Epoch 179 of 500
  training loss:		8.685819E-06
  validation loss:		8.573290E-06

Epoch 180 of 500
  training loss:		8.570728E-06
  validation loss:		8.354898E-06

Epoch 181 of 500
  training loss:		8.561879E-06
  validation loss:		8.442843E-06

Epoch 182 of 500
  training loss:		8.457475E-06
  validation loss:		8.157579E-06

Epoch 183 of 500
  training loss:		8.260369E-06
  validation loss:		8.218117E-06

Epoch 184 of 500
  training loss:		8.243400E-06
  validation loss:		9.562979E-06

Epoch 185 of 500
  training loss:		8.123412E-06
  validation loss:		9.451898E-06

Epoch 186 of 500
  training loss:		7.995480E-06
  validation loss:		8.373407E-06

Epoch 187 of 500
  training loss:		7.941555E-06
  validation loss:		9.551009E-06

Epoch 188 of 500
  training loss:		7.805421E-06
  validation loss:		8.130866E-06

Epoch 189 of 500
  training loss:		7.863425E-06
  validation loss:		7.521118E-06

Epoch 190 of 500
  training loss:		7.642818E-06
  validation loss:		8.868628E-06

Epoch 191 of 500
  training loss:		7.605676E-06
  validation loss:		7.444519E-06

Epoch 192 of 500
  training loss:		7.578686E-06
  validation loss:		7.403734E-06

Epoch 193 of 500
  training loss:		7.377484E-06
  validation loss:		9.560696E-06

Epoch 194 of 500
  training loss:		7.418738E-06
  validation loss:		7.486846E-06

Epoch 195 of 500
  training loss:		7.235032E-06
  validation loss:		7.367855E-06

Epoch 196 of 500
  training loss:		7.201265E-06
  validation loss:		7.309080E-06

Epoch 197 of 500
  training loss:		7.065227E-06
  validation loss:		7.063162E-06

Epoch 198 of 500
  training loss:		7.083097E-06
  validation loss:		6.828039E-06

Epoch 199 of 500
  training loss:		6.948079E-06
  validation loss:		7.145776E-06

Epoch 200 of 500
  training loss:		6.864305E-06
  validation loss:		6.948265E-06

Epoch 201 of 500
  training loss:		6.819374E-06
  validation loss:		7.506712E-06

Epoch 202 of 500
  training loss:		6.749963E-06
  validation loss:		6.664059E-06

Epoch 203 of 500
  training loss:		6.646979E-06
  validation loss:		6.562213E-06

Epoch 204 of 500
  training loss:		6.615191E-06
  validation loss:		6.713982E-06

Epoch 205 of 500
  training loss:		6.534611E-06
  validation loss:		6.427412E-06

Epoch 206 of 500
  training loss:		6.440776E-06
  validation loss:		6.409683E-06

Epoch 207 of 500
  training loss:		6.418950E-06
  validation loss:		7.138766E-06

Epoch 208 of 500
  training loss:		6.358321E-06
  validation loss:		6.236652E-06

Epoch 209 of 500
  training loss:		6.276698E-06
  validation loss:		6.187888E-06

Epoch 210 of 500
  training loss:		6.208910E-06
  validation loss:		6.324417E-06

Epoch 211 of 500
  training loss:		6.293003E-06
  validation loss:		7.136012E-06

Epoch 212 of 500
  training loss:		6.125455E-06
  validation loss:		8.082258E-06

Epoch 213 of 500
  training loss:		6.057381E-06
  validation loss:		6.002285E-06

Epoch 214 of 500
  training loss:		6.037171E-06
  validation loss:		6.842297E-06

Epoch 215 of 500
  training loss:		5.917830E-06
  validation loss:		5.937987E-06

Epoch 216 of 500
  training loss:		5.885944E-06
  validation loss:		5.796088E-06

Epoch 217 of 500
  training loss:		5.838577E-06
  validation loss:		5.927645E-06

Epoch 218 of 500
  training loss:		5.837482E-06
  validation loss:		5.687548E-06

Epoch 219 of 500
  training loss:		5.725254E-06
  validation loss:		5.898203E-06

Epoch 220 of 500
  training loss:		5.735935E-06
  validation loss:		6.819255E-06

Epoch 221 of 500
  training loss:		5.559175E-06
  validation loss:		5.754614E-06

Epoch 222 of 500
  training loss:		5.539089E-06
  validation loss:		6.337720E-06

Epoch 223 of 500
  training loss:		5.458415E-06
  validation loss:		7.006865E-06

Epoch 224 of 500
  training loss:		5.450050E-06
  validation loss:		5.376575E-06

Epoch 225 of 500
  training loss:		5.452171E-06
  validation loss:		6.689139E-06

Epoch 226 of 500
  training loss:		5.288937E-06
  validation loss:		5.397358E-06

Epoch 227 of 500
  training loss:		5.376259E-06
  validation loss:		5.293711E-06

Epoch 228 of 500
  training loss:		5.280767E-06
  validation loss:		6.255339E-06

Epoch 229 of 500
  training loss:		5.230771E-06
  validation loss:		5.280595E-06

Epoch 230 of 500
  training loss:		5.171408E-06
  validation loss:		5.325784E-06

Epoch 231 of 500
  training loss:		5.128153E-06
  validation loss:		5.106778E-06

Epoch 232 of 500
  training loss:		5.066712E-06
  validation loss:		5.029302E-06

Epoch 233 of 500
  training loss:		5.074442E-06
  validation loss:		5.075728E-06

Epoch 234 of 500
  training loss:		5.027253E-06
  validation loss:		4.907740E-06

Epoch 235 of 500
  training loss:		4.967217E-06
  validation loss:		4.904634E-06

Epoch 236 of 500
  training loss:		4.972636E-06
  validation loss:		4.974874E-06

Epoch 237 of 500
  training loss:		4.918038E-06
  validation loss:		5.033454E-06

Epoch 238 of 500
  training loss:		4.887633E-06
  validation loss:		4.980301E-06

Epoch 239 of 500
  training loss:		4.860109E-06
  validation loss:		4.803847E-06

Epoch 240 of 500
  training loss:		4.821582E-06
  validation loss:		4.741745E-06

Epoch 241 of 500
  training loss:		4.753106E-06
  validation loss:		4.949891E-06

Epoch 242 of 500
  training loss:		4.743347E-06
  validation loss:		4.705761E-06

Epoch 243 of 500
  training loss:		4.620345E-06
  validation loss:		4.592820E-06

Epoch 244 of 500
  training loss:		4.557936E-06
  validation loss:		4.548840E-06

Epoch 245 of 500
  training loss:		4.571100E-06
  validation loss:		4.545505E-06

Epoch 246 of 500
  training loss:		4.580415E-06
  validation loss:		5.454326E-06

Epoch 247 of 500
  training loss:		4.505243E-06
  validation loss:		4.443910E-06

Epoch 248 of 500
  training loss:		4.458351E-06
  validation loss:		5.049549E-06

Epoch 249 of 500
  training loss:		4.421979E-06
  validation loss:		5.044819E-06

Epoch 250 of 500
  training loss:		4.382732E-06
  validation loss:		4.347725E-06

Epoch 251 of 500
  training loss:		4.386044E-06
  validation loss:		5.083937E-06

Epoch 252 of 500
  training loss:		4.335297E-06
  validation loss:		4.711804E-06

Epoch 253 of 500
  training loss:		4.323922E-06
  validation loss:		5.248548E-06

Epoch 254 of 500
  training loss:		4.317808E-06
  validation loss:		4.992377E-06

Epoch 255 of 500
  training loss:		4.222977E-06
  validation loss:		4.230602E-06

Epoch 256 of 500
  training loss:		4.168878E-06
  validation loss:		4.472576E-06

Epoch 257 of 500
  training loss:		4.197008E-06
  validation loss:		4.428165E-06

Epoch 258 of 500
  training loss:		4.147577E-06
  validation loss:		5.301816E-06

Epoch 259 of 500
  training loss:		4.140470E-06
  validation loss:		4.315586E-06

Epoch 260 of 500
  training loss:		4.044191E-06
  validation loss:		4.069183E-06

Epoch 261 of 500
  training loss:		4.033957E-06
  validation loss:		4.150656E-06

Epoch 262 of 500
  training loss:		4.023130E-06
  validation loss:		4.104680E-06

Epoch 263 of 500
  training loss:		4.010841E-06
  validation loss:		4.052860E-06

Epoch 264 of 500
  training loss:		3.936280E-06
  validation loss:		4.030594E-06

Epoch 265 of 500
  training loss:		3.912965E-06
  validation loss:		3.884911E-06

Epoch 266 of 500
  training loss:		3.886298E-06
  validation loss:		4.621810E-06

Epoch 267 of 500
  training loss:		3.851570E-06
  validation loss:		5.754513E-06

Epoch 268 of 500
  training loss:		3.867167E-06
  validation loss:		3.837034E-06

Epoch 269 of 500
  training loss:		3.826717E-06
  validation loss:		4.841172E-06

Epoch 270 of 500
  training loss:		3.835792E-06
  validation loss:		3.944676E-06

Epoch 271 of 500
  training loss:		3.758980E-06
  validation loss:		3.719082E-06

Epoch 272 of 500
  training loss:		3.701194E-06
  validation loss:		4.238728E-06

Epoch 273 of 500
  training loss:		3.712052E-06
  validation loss:		3.760050E-06

Epoch 274 of 500
  training loss:		3.658484E-06
  validation loss:		3.647211E-06

Epoch 275 of 500
  training loss:		3.672154E-06
  validation loss:		4.536926E-06

Epoch 276 of 500
  training loss:		3.677721E-06
  validation loss:		3.690989E-06

Epoch 277 of 500
  training loss:		3.578177E-06
  validation loss:		3.871798E-06

Epoch 278 of 500
  training loss:		3.573772E-06
  validation loss:		4.272308E-06

Epoch 279 of 500
  training loss:		3.534999E-06
  validation loss:		3.824920E-06

Epoch 280 of 500
  training loss:		3.532432E-06
  validation loss:		3.787366E-06

Epoch 281 of 500
  training loss:		3.460759E-06
  validation loss:		3.535250E-06

Epoch 282 of 500
  training loss:		3.441418E-06
  validation loss:		3.435884E-06

Epoch 283 of 500
  training loss:		3.416864E-06
  validation loss:		4.498458E-06

Epoch 284 of 500
  training loss:		3.428771E-06
  validation loss:		3.892510E-06

Epoch 285 of 500
  training loss:		3.418180E-06
  validation loss:		3.361835E-06

Epoch 286 of 500
  training loss:		3.344164E-06
  validation loss:		3.689579E-06

Epoch 287 of 500
  training loss:		3.400553E-06
  validation loss:		3.470998E-06

Epoch 288 of 500
  training loss:		3.352782E-06
  validation loss:		3.318646E-06

Epoch 289 of 500
  training loss:		3.303943E-06
  validation loss:		3.357435E-06

Epoch 290 of 500
  training loss:		3.309881E-06
  validation loss:		3.702993E-06

Epoch 291 of 500
  training loss:		3.238257E-06
  validation loss:		4.006668E-06

Epoch 292 of 500
  training loss:		3.298974E-06
  validation loss:		3.199722E-06

Epoch 293 of 500
  training loss:		3.155734E-06
  validation loss:		3.304623E-06

Epoch 294 of 500
  training loss:		3.226422E-06
  validation loss:		3.436208E-06

Epoch 295 of 500
  training loss:		3.221519E-06
  validation loss:		3.291034E-06

Epoch 296 of 500
  training loss:		3.190515E-06
  validation loss:		3.202903E-06

Epoch 297 of 500
  training loss:		3.119503E-06
  validation loss:		4.051747E-06

Epoch 298 of 500
  training loss:		3.120315E-06
  validation loss:		3.153203E-06

Epoch 299 of 500
  training loss:		3.078237E-06
  validation loss:		3.152067E-06

Epoch 300 of 500
  training loss:		3.055191E-06
  validation loss:		3.159904E-06

Epoch 301 of 500
  training loss:		3.048370E-06
  validation loss:		3.070210E-06

Epoch 302 of 500
  training loss:		2.988708E-06
  validation loss:		2.992378E-06

Epoch 303 of 500
  training loss:		2.984710E-06
  validation loss:		3.146482E-06

Epoch 304 of 500
  training loss:		2.987579E-06
  validation loss:		2.986526E-06

Epoch 305 of 500
  training loss:		2.999711E-06
  validation loss:		3.366892E-06

Epoch 306 of 500
  training loss:		2.953619E-06
  validation loss:		3.028076E-06

Epoch 307 of 500
  training loss:		2.950045E-06
  validation loss:		2.976606E-06

Epoch 308 of 500
  training loss:		2.911272E-06
  validation loss:		2.876884E-06

Epoch 309 of 500
  training loss:		2.873350E-06
  validation loss:		2.921000E-06

Epoch 310 of 500
  training loss:		2.866379E-06
  validation loss:		2.843277E-06

Epoch 311 of 500
  training loss:		2.869423E-06
  validation loss:		2.867616E-06

Epoch 312 of 500
  training loss:		2.866181E-06
  validation loss:		4.341659E-06

Epoch 313 of 500
  training loss:		2.828928E-06
  validation loss:		2.903744E-06

Epoch 314 of 500
  training loss:		2.775103E-06
  validation loss:		2.771285E-06

Epoch 315 of 500
  training loss:		2.810438E-06
  validation loss:		2.752744E-06

Epoch 316 of 500
  training loss:		2.745870E-06
  validation loss:		3.244549E-06

Epoch 317 of 500
  training loss:		2.749132E-06
  validation loss:		2.765646E-06

Epoch 318 of 500
  training loss:		2.685602E-06
  validation loss:		3.257229E-06

Epoch 319 of 500
  training loss:		2.715327E-06
  validation loss:		3.822651E-06

Epoch 320 of 500
  training loss:		2.690326E-06
  validation loss:		2.771939E-06

Early stopping, val-loss increased over the last 10 epochs from 0.000800520781509 to 0.000834725119249
Training RMSE: 1.85809223982e-09
Validation RMSE: 1.9153362675e-09
