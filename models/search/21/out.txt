Epoch 1 of 500
  training loss:		8.789097E-02
  validation loss:		8.294998E-02

Epoch 2 of 500
  training loss:		7.530622E-02
  validation loss:		6.767092E-02

Epoch 3 of 500
  training loss:		5.810081E-02
  validation loss:		4.868757E-02

Epoch 4 of 500
  training loss:		3.899366E-02
  validation loss:		2.996030E-02

Epoch 5 of 500
  training loss:		2.253168E-02
  validation loss:		1.638964E-02

Epoch 6 of 500
  training loss:		1.267148E-02
  validation loss:		1.011427E-02

Epoch 7 of 500
  training loss:		8.953501E-03
  validation loss:		8.251672E-03

Epoch 8 of 500
  training loss:		7.814484E-03
  validation loss:		7.498566E-03

Epoch 9 of 500
  training loss:		7.199300E-03
  validation loss:		6.985090E-03

Epoch 10 of 500
  training loss:		6.692046E-03
  validation loss:		6.463077E-03

Epoch 11 of 500
  training loss:		6.227097E-03
  validation loss:		6.017078E-03

Epoch 12 of 500
  training loss:		5.787974E-03
  validation loss:		5.611596E-03

Epoch 13 of 500
  training loss:		5.366247E-03
  validation loss:		5.306002E-03

Epoch 14 of 500
  training loss:		4.967773E-03
  validation loss:		4.812144E-03

Epoch 15 of 500
  training loss:		4.604092E-03
  validation loss:		4.414209E-03

Epoch 16 of 500
  training loss:		4.253399E-03
  validation loss:		4.070181E-03

Epoch 17 of 500
  training loss:		3.925467E-03
  validation loss:		3.826769E-03

Epoch 18 of 500
  training loss:		3.627576E-03
  validation loss:		3.485686E-03

Epoch 19 of 500
  training loss:		3.351723E-03
  validation loss:		3.216170E-03

Epoch 20 of 500
  training loss:		3.109876E-03
  validation loss:		3.042017E-03

Epoch 21 of 500
  training loss:		2.890538E-03
  validation loss:		2.802601E-03

Epoch 22 of 500
  training loss:		2.690489E-03
  validation loss:		2.571750E-03

Epoch 23 of 500
  training loss:		2.515518E-03
  validation loss:		2.413660E-03

Epoch 24 of 500
  training loss:		2.361987E-03
  validation loss:		2.260324E-03

Epoch 25 of 500
  training loss:		2.222889E-03
  validation loss:		2.132948E-03

Epoch 26 of 500
  training loss:		2.106677E-03
  validation loss:		2.023776E-03

Epoch 27 of 500
  training loss:		2.008900E-03
  validation loss:		1.923543E-03

Epoch 28 of 500
  training loss:		1.910787E-03
  validation loss:		1.852138E-03

Epoch 29 of 500
  training loss:		1.833778E-03
  validation loss:		1.767518E-03

Epoch 30 of 500
  training loss:		1.764335E-03
  validation loss:		1.705844E-03

Epoch 31 of 500
  training loss:		1.703597E-03
  validation loss:		1.773732E-03

Epoch 32 of 500
  training loss:		1.642318E-03
  validation loss:		1.582177E-03

Epoch 33 of 500
  training loss:		1.580107E-03
  validation loss:		1.615158E-03

Epoch 34 of 500
  training loss:		1.503408E-03
  validation loss:		1.433479E-03

Epoch 35 of 500
  training loss:		1.388413E-03
  validation loss:		1.291372E-03

Epoch 36 of 500
  training loss:		1.232734E-03
  validation loss:		1.132274E-03

Epoch 37 of 500
  training loss:		1.063825E-03
  validation loss:		9.617897E-04

Epoch 38 of 500
  training loss:		9.060217E-04
  validation loss:		8.220353E-04

Epoch 39 of 500
  training loss:		7.766581E-04
  validation loss:		7.107880E-04

Epoch 40 of 500
  training loss:		6.749152E-04
  validation loss:		6.233520E-04

Epoch 41 of 500
  training loss:		5.940803E-04
  validation loss:		5.473659E-04

Epoch 42 of 500
  training loss:		5.302242E-04
  validation loss:		4.891787E-04

Epoch 43 of 500
  training loss:		4.746801E-04
  validation loss:		4.599585E-04

Epoch 44 of 500
  training loss:		4.264445E-04
  validation loss:		4.010183E-04

Epoch 45 of 500
  training loss:		3.855216E-04
  validation loss:		3.625166E-04

Epoch 46 of 500
  training loss:		3.506603E-04
  validation loss:		3.285753E-04

Epoch 47 of 500
  training loss:		3.200099E-04
  validation loss:		2.971322E-04

Epoch 48 of 500
  training loss:		2.939096E-04
  validation loss:		2.987956E-04

Epoch 49 of 500
  training loss:		2.703282E-04
  validation loss:		2.523736E-04

Epoch 50 of 500
  training loss:		2.506010E-04
  validation loss:		2.393495E-04

Epoch 51 of 500
  training loss:		2.304777E-04
  validation loss:		2.280304E-04

Epoch 52 of 500
  training loss:		2.162963E-04
  validation loss:		1.998407E-04

Epoch 53 of 500
  training loss:		2.010925E-04
  validation loss:		1.863287E-04

Epoch 54 of 500
  training loss:		1.880008E-04
  validation loss:		1.754252E-04

Epoch 55 of 500
  training loss:		1.764308E-04
  validation loss:		1.640154E-04

Epoch 56 of 500
  training loss:		1.667685E-04
  validation loss:		1.631101E-04

Epoch 57 of 500
  training loss:		1.565349E-04
  validation loss:		1.497671E-04

Epoch 58 of 500
  training loss:		1.478258E-04
  validation loss:		1.401371E-04

Epoch 59 of 500
  training loss:		1.391049E-04
  validation loss:		1.349352E-04

Epoch 60 of 500
  training loss:		1.332228E-04
  validation loss:		1.224573E-04

Epoch 61 of 500
  training loss:		1.254536E-04
  validation loss:		1.171917E-04

Epoch 62 of 500
  training loss:		1.195333E-04
  validation loss:		1.104358E-04

Epoch 63 of 500
  training loss:		1.137143E-04
  validation loss:		1.080536E-04

Epoch 64 of 500
  training loss:		1.083554E-04
  validation loss:		1.015766E-04

Epoch 65 of 500
  training loss:		1.033701E-04
  validation loss:		9.646311E-05

Epoch 66 of 500
  training loss:		9.861838E-05
  validation loss:		9.109517E-05

Epoch 67 of 500
  training loss:		9.446037E-05
  validation loss:		8.970942E-05

Epoch 68 of 500
  training loss:		9.021565E-05
  validation loss:		9.817072E-05

Epoch 69 of 500
  training loss:		8.644330E-05
  validation loss:		8.026667E-05

Epoch 70 of 500
  training loss:		8.269904E-05
  validation loss:		7.893674E-05

Epoch 71 of 500
  training loss:		7.924283E-05
  validation loss:		8.317732E-05

Epoch 72 of 500
  training loss:		7.608724E-05
  validation loss:		7.100226E-05

Epoch 73 of 500
  training loss:		7.373089E-05
  validation loss:		6.836976E-05

Epoch 74 of 500
  training loss:		7.044382E-05
  validation loss:		6.484192E-05

Epoch 75 of 500
  training loss:		6.813872E-05
  validation loss:		6.775333E-05

Epoch 76 of 500
  training loss:		6.587856E-05
  validation loss:		6.439931E-05

Epoch 77 of 500
  training loss:		6.292881E-05
  validation loss:		7.242316E-05

Epoch 78 of 500
  training loss:		6.128730E-05
  validation loss:		5.677882E-05

Epoch 79 of 500
  training loss:		5.879992E-05
  validation loss:		5.935138E-05

Epoch 80 of 500
  training loss:		5.702248E-05
  validation loss:		5.329609E-05

Epoch 81 of 500
  training loss:		5.510053E-05
  validation loss:		5.576445E-05

Epoch 82 of 500
  training loss:		5.310412E-05
  validation loss:		5.352695E-05

Epoch 83 of 500
  training loss:		5.227354E-05
  validation loss:		4.951067E-05

Epoch 84 of 500
  training loss:		5.029719E-05
  validation loss:		4.949332E-05

Epoch 85 of 500
  training loss:		4.925133E-05
  validation loss:		4.531840E-05

Epoch 86 of 500
  training loss:		4.772595E-05
  validation loss:		4.567126E-05

Epoch 87 of 500
  training loss:		4.637869E-05
  validation loss:		4.322380E-05

Epoch 88 of 500
  training loss:		4.534533E-05
  validation loss:		4.482046E-05

Epoch 89 of 500
  training loss:		4.398807E-05
  validation loss:		4.560980E-05

Epoch 90 of 500
  training loss:		4.297263E-05
  validation loss:		4.253156E-05

Epoch 91 of 500
  training loss:		4.154578E-05
  validation loss:		4.069923E-05

Epoch 92 of 500
  training loss:		4.091927E-05
  validation loss:		3.764328E-05

Epoch 93 of 500
  training loss:		3.999093E-05
  validation loss:		3.971674E-05

Epoch 94 of 500
  training loss:		3.902134E-05
  validation loss:		4.488872E-05

Epoch 95 of 500
  training loss:		3.761611E-05
  validation loss:		4.305043E-05

Epoch 96 of 500
  training loss:		3.753965E-05
  validation loss:		3.454264E-05

Epoch 97 of 500
  training loss:		3.645735E-05
  validation loss:		3.443985E-05

Epoch 98 of 500
  training loss:		3.565625E-05
  validation loss:		3.344101E-05

Epoch 99 of 500
  training loss:		3.478368E-05
  validation loss:		3.254931E-05

Epoch 100 of 500
  training loss:		3.403899E-05
  validation loss:		3.373773E-05

Epoch 101 of 500
  training loss:		3.329441E-05
  validation loss:		3.176411E-05

Epoch 102 of 500
  training loss:		3.229766E-05
  validation loss:		3.081028E-05

Epoch 103 of 500
  training loss:		3.189316E-05
  validation loss:		2.939011E-05

Epoch 104 of 500
  training loss:		3.151340E-05
  validation loss:		2.872543E-05

Epoch 105 of 500
  training loss:		3.097312E-05
  validation loss:		2.871589E-05

Epoch 106 of 500
  training loss:		2.997216E-05
  validation loss:		3.042909E-05

Epoch 107 of 500
  training loss:		2.936313E-05
  validation loss:		3.043732E-05

Epoch 108 of 500
  training loss:		2.864845E-05
  validation loss:		2.758057E-05

Epoch 109 of 500
  training loss:		2.844654E-05
  validation loss:		2.614935E-05

Epoch 110 of 500
  training loss:		2.792364E-05
  validation loss:		2.544018E-05

Epoch 111 of 500
  training loss:		2.765492E-05
  validation loss:		2.513521E-05

Epoch 112 of 500
  training loss:		2.634996E-05
  validation loss:		2.561122E-05

Epoch 113 of 500
  training loss:		2.601973E-05
  validation loss:		2.417321E-05

Epoch 114 of 500
  training loss:		2.565910E-05
  validation loss:		2.406278E-05

Epoch 115 of 500
  training loss:		2.536209E-05
  validation loss:		2.306351E-05

Epoch 116 of 500
  training loss:		2.443697E-05
  validation loss:		2.533576E-05

Epoch 117 of 500
  training loss:		2.413000E-05
  validation loss:		2.262308E-05

Epoch 118 of 500
  training loss:		2.391227E-05
  validation loss:		2.263769E-05

Epoch 119 of 500
  training loss:		2.342842E-05
  validation loss:		2.513632E-05

Epoch 120 of 500
  training loss:		2.304754E-05
  validation loss:		2.106591E-05

Epoch 121 of 500
  training loss:		2.256495E-05
  validation loss:		2.231109E-05

Epoch 122 of 500
  training loss:		2.247227E-05
  validation loss:		2.349590E-05

Epoch 123 of 500
  training loss:		2.182223E-05
  validation loss:		2.145814E-05

Epoch 124 of 500
  training loss:		2.140075E-05
  validation loss:		1.996792E-05

Epoch 125 of 500
  training loss:		2.096220E-05
  validation loss:		1.980515E-05

Epoch 126 of 500
  training loss:		2.048368E-05
  validation loss:		1.957304E-05

Epoch 127 of 500
  training loss:		2.003506E-05
  validation loss:		2.256455E-05

Epoch 128 of 500
  training loss:		1.997977E-05
  validation loss:		1.843989E-05

Epoch 129 of 500
  training loss:		1.939864E-05
  validation loss:		1.767447E-05

Epoch 130 of 500
  training loss:		1.930471E-05
  validation loss:		1.836175E-05

Epoch 131 of 500
  training loss:		1.880419E-05
  validation loss:		1.703054E-05

Epoch 132 of 500
  training loss:		1.836828E-05
  validation loss:		1.817775E-05

Epoch 133 of 500
  training loss:		1.839112E-05
  validation loss:		1.646869E-05

Epoch 134 of 500
  training loss:		1.811757E-05
  validation loss:		1.980245E-05

Epoch 135 of 500
  training loss:		1.759562E-05
  validation loss:		1.861741E-05

Epoch 136 of 500
  training loss:		1.752533E-05
  validation loss:		2.024642E-05

Epoch 137 of 500
  training loss:		1.740880E-05
  validation loss:		1.542286E-05

Epoch 138 of 500
  training loss:		1.691192E-05
  validation loss:		1.854035E-05

Epoch 139 of 500
  training loss:		1.677992E-05
  validation loss:		1.782871E-05

Epoch 140 of 500
  training loss:		1.663585E-05
  validation loss:		1.534755E-05

Epoch 141 of 500
  training loss:		1.609874E-05
  validation loss:		1.490118E-05

Epoch 142 of 500
  training loss:		1.580310E-05
  validation loss:		1.434495E-05

Epoch 143 of 500
  training loss:		1.563772E-05
  validation loss:		1.535471E-05

Epoch 144 of 500
  training loss:		1.550141E-05
  validation loss:		1.522715E-05

Epoch 145 of 500
  training loss:		1.507914E-05
  validation loss:		1.344341E-05

Epoch 146 of 500
  training loss:		1.486085E-05
  validation loss:		1.355237E-05

Epoch 147 of 500
  training loss:		1.476339E-05
  validation loss:		1.353750E-05

Epoch 148 of 500
  training loss:		1.446553E-05
  validation loss:		1.499770E-05

Epoch 149 of 500
  training loss:		1.447042E-05
  validation loss:		1.309222E-05

Epoch 150 of 500
  training loss:		1.426478E-05
  validation loss:		1.254488E-05

Epoch 151 of 500
  training loss:		1.378874E-05
  validation loss:		1.370103E-05

Epoch 152 of 500
  training loss:		1.369773E-05
  validation loss:		1.244459E-05

Epoch 153 of 500
  training loss:		1.355977E-05
  validation loss:		1.189312E-05

Epoch 154 of 500
  training loss:		1.339330E-05
  validation loss:		1.398146E-05

Epoch 155 of 500
  training loss:		1.312282E-05
  validation loss:		1.169642E-05

Epoch 156 of 500
  training loss:		1.276672E-05
  validation loss:		1.165067E-05

Epoch 157 of 500
  training loss:		1.257130E-05
  validation loss:		1.119630E-05

Epoch 158 of 500
  training loss:		1.266517E-05
  validation loss:		1.651543E-05

Epoch 159 of 500
  training loss:		1.246383E-05
  validation loss:		1.094366E-05

Epoch 160 of 500
  training loss:		1.221376E-05
  validation loss:		1.065605E-05

Epoch 161 of 500
  training loss:		1.200249E-05
  validation loss:		1.063003E-05

Epoch 162 of 500
  training loss:		1.181233E-05
  validation loss:		1.326512E-05

Epoch 163 of 500
  training loss:		1.176730E-05
  validation loss:		1.135136E-05

Epoch 164 of 500
  training loss:		1.161293E-05
  validation loss:		1.085145E-05

Epoch 165 of 500
  training loss:		1.139496E-05
  validation loss:		9.891185E-06

Epoch 166 of 500
  training loss:		1.138190E-05
  validation loss:		9.836864E-06

Epoch 167 of 500
  training loss:		1.112283E-05
  validation loss:		1.272248E-05

Epoch 168 of 500
  training loss:		1.079739E-05
  validation loss:		1.896782E-05

Epoch 169 of 500
  training loss:		1.086488E-05
  validation loss:		9.693762E-06

Epoch 170 of 500
  training loss:		1.063797E-05
  validation loss:		9.658079E-06

Epoch 171 of 500
  training loss:		1.063572E-05
  validation loss:		1.010094E-05

Epoch 172 of 500
  training loss:		1.050234E-05
  validation loss:		9.024261E-06

Epoch 173 of 500
  training loss:		1.027447E-05
  validation loss:		1.077412E-05

Epoch 174 of 500
  training loss:		9.992865E-06
  validation loss:		1.190980E-05

Epoch 175 of 500
  training loss:		9.931134E-06
  validation loss:		8.693875E-06

Epoch 176 of 500
  training loss:		9.878602E-06
  validation loss:		8.501076E-06

Epoch 177 of 500
  training loss:		9.597065E-06
  validation loss:		8.400208E-06

Epoch 178 of 500
  training loss:		9.599847E-06
  validation loss:		8.209082E-06

Epoch 179 of 500
  training loss:		9.417334E-06
  validation loss:		8.227733E-06

Epoch 180 of 500
  training loss:		9.528169E-06
  validation loss:		8.217481E-06

Epoch 181 of 500
  training loss:		9.379785E-06
  validation loss:		7.942083E-06

Epoch 182 of 500
  training loss:		9.032530E-06
  validation loss:		7.824034E-06

Epoch 183 of 500
  training loss:		8.983904E-06
  validation loss:		7.827499E-06

Epoch 184 of 500
  training loss:		8.921359E-06
  validation loss:		7.733161E-06

Epoch 185 of 500
  training loss:		8.707966E-06
  validation loss:		8.069152E-06

Epoch 186 of 500
  training loss:		8.625486E-06
  validation loss:		7.496458E-06

Epoch 187 of 500
  training loss:		8.597185E-06
  validation loss:		8.483698E-06

Epoch 188 of 500
  training loss:		8.449544E-06
  validation loss:		1.037953E-05

Epoch 189 of 500
  training loss:		8.370407E-06
  validation loss:		7.780306E-06

Epoch 190 of 500
  training loss:		8.180661E-06
  validation loss:		7.490058E-06

Epoch 191 of 500
  training loss:		8.053026E-06
  validation loss:		8.053624E-06

Epoch 192 of 500
  training loss:		8.161398E-06
  validation loss:		6.910784E-06

Epoch 193 of 500
  training loss:		7.972335E-06
  validation loss:		7.542105E-06

Epoch 194 of 500
  training loss:		7.960001E-06
  validation loss:		6.790374E-06

Epoch 195 of 500
  training loss:		7.768486E-06
  validation loss:		7.213974E-06

Epoch 196 of 500
  training loss:		7.686523E-06
  validation loss:		6.395073E-06

Epoch 197 of 500
  training loss:		7.577410E-06
  validation loss:		6.355351E-06

Epoch 198 of 500
  training loss:		7.565869E-06
  validation loss:		6.241339E-06

Epoch 199 of 500
  training loss:		7.456354E-06
  validation loss:		6.237735E-06

Epoch 200 of 500
  training loss:		7.302547E-06
  validation loss:		6.184289E-06

Epoch 201 of 500
  training loss:		7.169415E-06
  validation loss:		6.082240E-06

Epoch 202 of 500
  training loss:		7.016846E-06
  validation loss:		6.755965E-06

Epoch 203 of 500
  training loss:		7.058086E-06
  validation loss:		6.225226E-06

Epoch 204 of 500
  training loss:		6.963531E-06
  validation loss:		5.797112E-06

Epoch 205 of 500
  training loss:		6.779504E-06
  validation loss:		7.472224E-06

Epoch 206 of 500
  training loss:		6.882655E-06
  validation loss:		5.869066E-06

Epoch 207 of 500
  training loss:		6.761665E-06
  validation loss:		6.059684E-06

Epoch 208 of 500
  training loss:		6.585171E-06
  validation loss:		7.998847E-06

Epoch 209 of 500
  training loss:		6.545801E-06
  validation loss:		5.476444E-06

Epoch 210 of 500
  training loss:		6.480704E-06
  validation loss:		1.000093E-05

Epoch 211 of 500
  training loss:		6.346744E-06
  validation loss:		5.969001E-06

Epoch 212 of 500
  training loss:		6.304410E-06
  validation loss:		5.270714E-06

Epoch 213 of 500
  training loss:		6.079996E-06
  validation loss:		5.103249E-06

Epoch 214 of 500
  training loss:		6.160531E-06
  validation loss:		5.053844E-06

Epoch 215 of 500
  training loss:		6.015805E-06
  validation loss:		5.036164E-06

Epoch 216 of 500
  training loss:		5.989057E-06
  validation loss:		5.058991E-06

Epoch 217 of 500
  training loss:		5.855237E-06
  validation loss:		4.905283E-06

Epoch 218 of 500
  training loss:		5.969787E-06
  validation loss:		5.180971E-06

Epoch 219 of 500
  training loss:		5.902973E-06
  validation loss:		5.796878E-06

Epoch 220 of 500
  training loss:		5.767629E-06
  validation loss:		4.651279E-06

Epoch 221 of 500
  training loss:		5.620401E-06
  validation loss:		4.605033E-06

Epoch 222 of 500
  training loss:		5.535382E-06
  validation loss:		4.579956E-06

Epoch 223 of 500
  training loss:		5.402530E-06
  validation loss:		4.457272E-06

Epoch 224 of 500
  training loss:		5.508887E-06
  validation loss:		4.591276E-06

Epoch 225 of 500
  training loss:		5.332873E-06
  validation loss:		4.579447E-06

Epoch 226 of 500
  training loss:		5.384467E-06
  validation loss:		4.313494E-06

Epoch 227 of 500
  training loss:		5.257164E-06
  validation loss:		4.793832E-06

Epoch 228 of 500
  training loss:		5.182395E-06
  validation loss:		4.184524E-06

Epoch 229 of 500
  training loss:		5.050356E-06
  validation loss:		4.344684E-06

Epoch 230 of 500
  training loss:		5.005804E-06
  validation loss:		4.351011E-06

Epoch 231 of 500
  training loss:		4.988504E-06
  validation loss:		4.041797E-06

Epoch 232 of 500
  training loss:		5.069894E-06
  validation loss:		4.254943E-06

Epoch 233 of 500
  training loss:		4.920454E-06
  validation loss:		3.993522E-06

Epoch 234 of 500
  training loss:		4.859430E-06
  validation loss:		6.063723E-06

Epoch 235 of 500
  training loss:		4.886923E-06
  validation loss:		4.531682E-06

Epoch 236 of 500
  training loss:		4.703165E-06
  validation loss:		8.429180E-06

Epoch 237 of 500
  training loss:		4.760858E-06
  validation loss:		3.881646E-06

Epoch 238 of 500
  training loss:		4.578209E-06
  validation loss:		3.941124E-06

Epoch 239 of 500
  training loss:		4.576204E-06
  validation loss:		3.667179E-06

Epoch 240 of 500
  training loss:		4.510755E-06
  validation loss:		4.368911E-06

Early stopping, val-loss increased over the last 10 epochs from 0.00158145870414 to 0.00166523185582
Training-set, RMSE: 1.95872683262e-09
Validation-set, RMSE: 1.87536141147e-09
