Epoch 1 of 500
  training loss:		2.856007E-01
  validation loss:		1.157389E-03

Epoch 2 of 500
  training loss:		5.768053E-04
  validation loss:		1.258200E-04

Epoch 3 of 500
  training loss:		3.141663E-05
  validation loss:		7.327456E-06

Epoch 4 of 500
  training loss:		6.444088E-06
  validation loss:		6.104864E-06

Epoch 5 of 500
  training loss:		5.223310E-06
  validation loss:		4.599079E-06

Epoch 6 of 500
  training loss:		3.579882E-06
  validation loss:		2.789663E-06

Epoch 7 of 500
  training loss:		1.818291E-06
  validation loss:		1.103364E-06

Epoch 8 of 500
  training loss:		5.688142E-07
  validation loss:		2.313401E-07

Epoch 9 of 500
  training loss:		9.830064E-08
  validation loss:		3.594552E-08

Epoch 10 of 500
  training loss:		1.961318E-08
  validation loss:		9.984657E-09

Epoch 11 of 500
  training loss:		6.581699E-09
  validation loss:		4.119026E-09

Epoch 12 of 500
  training loss:		2.847413E-09
  validation loss:		1.532009E-09

Epoch 13 of 500
  training loss:		2.032217E-09
  validation loss:		2.153100E-09

Epoch 14 of 500
  training loss:		8.750610E-09
  validation loss:		7.951344E-10

Epoch 15 of 500
  training loss:		1.728983E-08
  validation loss:		3.247694E-09

Epoch 16 of 500
  training loss:		1.629569E-08
  validation loss:		5.568676E-09

Epoch 17 of 500
  training loss:		1.670270E-08
  validation loss:		1.710564E-08

Epoch 18 of 500
  training loss:		1.668254E-08
  validation loss:		1.759139E-08

Epoch 19 of 500
  training loss:		1.586896E-08
  validation loss:		1.036673E-09

Epoch 20 of 500
  training loss:		1.614670E-08
  validation loss:		1.792552E-08

Epoch 21 of 500
  training loss:		1.654751E-08
  validation loss:		2.022261E-07

Epoch 22 of 500
  training loss:		1.604084E-08
  validation loss:		2.905932E-08

Epoch 23 of 500
  training loss:		1.636616E-08
  validation loss:		1.382957E-07

Epoch 24 of 500
  training loss:		1.628546E-08
  validation loss:		3.061007E-09

Epoch 25 of 500
  training loss:		1.632160E-08
  validation loss:		8.678005E-10

Epoch 26 of 500
  training loss:		1.609418E-08
  validation loss:		2.763726E-08

Epoch 27 of 500
  training loss:		1.630814E-08
  validation loss:		6.378714E-09

Epoch 28 of 500
  training loss:		1.657014E-08
  validation loss:		1.718186E-09

Epoch 29 of 500
  training loss:		1.674220E-08
  validation loss:		2.707134E-09

Epoch 30 of 500
  training loss:		1.592582E-08
  validation loss:		3.816232E-10

Early stopping, val-loss increased over the last 10 epochs from 2.5089425218e-06 to 1.4555350034e-05
Training-set, RMSE: 5.1997896118e-05
Validation-set, RMSE: 5.20320252235e-05
