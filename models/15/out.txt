Epoch 1 of 250
  example target:		2.735347E-03
  example prediction:		2.108832E-01
  training loss:		8.817518E-02
  validation loss:		9.004055E-02

Epoch 2 of 250
  example target:		2.983466E-01
  example prediction:		2.396408E-01
  training loss:		8.832415E-02
  validation loss:		8.891989E-02

Epoch 3 of 250
  example target:		1.403356E-02
  example prediction:		1.471105E-01
  training loss:		6.403410E-02
  validation loss:		1.878084E-02

Epoch 4 of 250
  example target:		2.112001E-02
  example prediction:		5.349244E-02
  training loss:		5.020790E-03
  validation loss:		2.677709E-03

Epoch 5 of 250
  example target:		1.645437E-02
  example prediction:		4.300708E-02
  training loss:		2.562175E-03
  validation loss:		2.534935E-03

Epoch 6 of 250
  example target:		3.831306E-02
  example prediction:		8.421610E-02
  training loss:		2.430616E-03
  validation loss:		2.410429E-03

Epoch 7 of 250
  example target:		1.000000E+00
  example prediction:		9.220821E-01
  training loss:		2.308338E-03
  validation loss:		2.287169E-03

Epoch 8 of 250
  example target:		7.433516E-01
  example prediction:		7.934408E-01
  training loss:		2.198447E-03
  validation loss:		2.184308E-03

Epoch 9 of 250
  example target:		6.964043E-02
  example prediction:		6.987650E-02
  training loss:		2.100462E-03
  validation loss:		2.076240E-03

Epoch 10 of 250
  example target:		2.735347E-03
  example prediction:		6.979822E-02
  training loss:		2.016767E-03
  validation loss:		1.997972E-03

Epoch 11 of 250
  example target:		3.297330E-01
  example prediction:		2.645370E-01
  training loss:		1.939666E-03
  validation loss:		1.921696E-03

Epoch 12 of 250
  example target:		9.711442E-01
  example prediction:		9.397056E-01
  training loss:		1.870320E-03
  validation loss:		1.860977E-03

Epoch 13 of 250
  example target:		2.506635E-02
  example prediction:		5.594975E-02
  training loss:		1.814246E-03
  validation loss:		1.811674E-03

Epoch 14 of 250
  example target:		1.702205E-02
  example prediction:		7.462183E-02
  training loss:		1.764821E-03
  validation loss:		1.748088E-03

Epoch 15 of 250
  example target:		9.711442E-01
  example prediction:		9.462860E-01
  training loss:		1.715452E-03
  validation loss:		1.707203E-03

Epoch 16 of 250
  example target:		6.402986E-01
  example prediction:		6.661128E-01
  training loss:		1.677826E-03
  validation loss:		1.664001E-03

Epoch 17 of 250
  example target:		3.831306E-02
  example prediction:		7.156347E-02
  training loss:		1.638698E-03
  validation loss:		1.628900E-03

Epoch 18 of 250
  example target:		6.077772E-02
  example prediction:		2.284454E-02
  training loss:		1.600955E-03
  validation loss:		1.585583E-03

Epoch 19 of 250
  example target:		7.433516E-01
  example prediction:		7.941565E-01
  training loss:		1.570388E-03
  validation loss:		1.552625E-03

Epoch 20 of 250
  example target:		3.297330E-01
  example prediction:		2.701573E-01
  training loss:		1.537403E-03
  validation loss:		1.547231E-03

Epoch 21 of 250
  example target:		3.016191E-01
  example prediction:		2.166194E-01
  training loss:		1.511887E-03
  validation loss:		1.495833E-03

Epoch 22 of 250
  example target:		1.071292E-01
  example prediction:		5.467769E-02
  training loss:		1.480598E-03
  validation loss:		1.459916E-03

Epoch 23 of 250
  example target:		1.958275E-02
  example prediction:		5.461867E-02
  training loss:		1.459691E-03
  validation loss:		1.438338E-03

Epoch 24 of 250
  example target:		6.077772E-02
  example prediction:		1.602353E-02
  training loss:		1.431564E-03
  validation loss:		1.405126E-03

Epoch 25 of 250
  example target:		6.449202E-01
  example prediction:		6.764177E-01
  training loss:		1.408503E-03
  validation loss:		1.384666E-03

Epoch 26 of 250
  example target:		3.372446E-01
  example prediction:		2.812365E-01
  training loss:		1.386237E-03
  validation loss:		1.391472E-03

Epoch 27 of 250
  example target:		1.000000E+00
  example prediction:		9.663645E-01
  training loss:		1.364575E-03
  validation loss:		1.340335E-03

Epoch 28 of 250
  example target:		3.982057E-02
  example prediction:		2.528012E-02
  training loss:		1.341564E-03
  validation loss:		1.323319E-03

Epoch 29 of 250
  example target:		2.984942E-02
  example prediction:		6.400875E-02
  training loss:		1.319455E-03
  validation loss:		1.312641E-03

Epoch 30 of 250
  example target:		7.433516E-01
  example prediction:		7.976735E-01
  training loss:		1.295785E-03
  validation loss:		1.285586E-03

Epoch 31 of 250
  example target:		2.457999E-01
  example prediction:		1.968525E-01
  training loss:		1.272630E-03
  validation loss:		1.244718E-03

Epoch 32 of 250
  example target:		2.735347E-03
  example prediction:		6.224937E-02
  training loss:		1.230829E-03
  validation loss:		1.191238E-03

Epoch 33 of 250
  example target:		3.016191E-01
  example prediction:		2.310951E-01
  training loss:		1.164977E-03
  validation loss:		1.099151E-03

Epoch 34 of 250
  example target:		1.414259E-01
  example prediction:		1.802040E-01
  training loss:		1.066361E-03
  validation loss:		9.892470E-04

Epoch 35 of 250
  example target:		5.847623E-02
  example prediction:		2.977401E-02
  training loss:		9.568797E-04
  validation loss:		8.914092E-04

Epoch 36 of 250
  example target:		2.457999E-01
  example prediction:		2.156991E-01
  training loss:		8.496330E-04
  validation loss:		7.671931E-04

Epoch 37 of 250
  example target:		3.831306E-02
  example prediction:		5.616008E-02
  training loss:		7.483062E-04
  validation loss:		6.709401E-04

Epoch 38 of 250
  example target:		0.000000E+00
  example prediction:		7.332112E-03
  training loss:		6.612517E-04
  validation loss:		5.927739E-04

Epoch 39 of 250
  example target:		1.645437E-02
  example prediction:		3.896716E-02
  training loss:		5.900003E-04
  validation loss:		5.305401E-04

Epoch 40 of 250
  example target:		1.403356E-02
  example prediction:		1.437016E-02
  training loss:		5.261707E-04
  validation loss:		4.722620E-04

Epoch 41 of 250
  example target:		1.645437E-02
  example prediction:		4.042930E-02
  training loss:		4.730589E-04
  validation loss:		4.244738E-04

Epoch 42 of 250
  example target:		1.645437E-02
  example prediction:		3.937473E-02
  training loss:		4.258144E-04
  validation loss:		3.840371E-04

Epoch 43 of 250
  example target:		2.785667E-02
  example prediction:		2.454931E-02
  training loss:		3.888178E-04
  validation loss:		3.469787E-04

Epoch 44 of 250
  example target:		7.433516E-01
  example prediction:		7.555811E-01
  training loss:		3.523009E-04
  validation loss:		3.171933E-04

Epoch 45 of 250
  example target:		1.403356E-02
  example prediction:		1.194531E-02
  training loss:		3.247908E-04
  validation loss:		2.970646E-04

Epoch 46 of 250
  example target:		3.372446E-01
  example prediction:		3.370716E-01
  training loss:		2.993157E-04
  validation loss:		2.722773E-04

Epoch 47 of 250
  example target:		2.112001E-02
  example prediction:		4.051936E-02
  training loss:		2.793548E-04
  validation loss:		2.600219E-04

Epoch 48 of 250
  example target:		3.083971E-02
  example prediction:		3.230010E-02
  training loss:		2.604962E-04
  validation loss:		2.389060E-04

Epoch 49 of 250
  example target:		3.372446E-01
  example prediction:		3.392861E-01
  training loss:		2.474009E-04
  validation loss:		2.247999E-04

Epoch 50 of 250
  example target:		3.083971E-02
  example prediction:		2.976496E-02
  training loss:		2.331794E-04
  validation loss:		2.146347E-04

Epoch 51 of 250
  example target:		2.112001E-02
  example prediction:		3.591682E-02
  training loss:		2.230070E-04
  validation loss:		2.064786E-04

Epoch 52 of 250
  example target:		2.457999E-01
  example prediction:		2.335123E-01
  training loss:		2.125644E-04
  validation loss:		1.992568E-04

Epoch 53 of 250
  example target:		2.984942E-02
  example prediction:		4.694576E-02
  training loss:		2.054972E-04
  validation loss:		1.958965E-04

Epoch 54 of 250
  example target:		6.449202E-01
  example prediction:		6.364315E-01
  training loss:		1.996162E-04
  validation loss:		1.847712E-04

Epoch 55 of 250
  example target:		6.449202E-01
  example prediction:		6.360494E-01
  training loss:		1.928231E-04
  validation loss:		1.785808E-04

Epoch 56 of 250
  example target:		2.457999E-01
  example prediction:		2.343814E-01
  training loss:		1.866291E-04
  validation loss:		1.740097E-04

Epoch 57 of 250
  example target:		4.026011E-02
  example prediction:		4.837753E-02
  training loss:		1.803844E-04
  validation loss:		1.695412E-04

Epoch 58 of 250
  example target:		5.004843E-02
  example prediction:		5.329870E-02
  training loss:		1.785736E-04
  validation loss:		1.661886E-04

Epoch 59 of 250
  example target:		3.372446E-01
  example prediction:		3.444548E-01
  training loss:		1.740930E-04
  validation loss:		1.698477E-04

Epoch 60 of 250
  example target:		1.645437E-02
  example prediction:		2.974726E-02
  training loss:		1.694535E-04
  validation loss:		1.591076E-04

Epoch 61 of 250
  example target:		7.612945E-02
  example prediction:		7.752040E-02
  training loss:		1.638870E-04
  validation loss:		1.546329E-04

Epoch 62 of 250
  example target:		2.785667E-02
  example prediction:		2.985157E-02
  training loss:		1.604981E-04
  validation loss:		1.510457E-04

Epoch 63 of 250
  example target:		1.414259E-01
  example prediction:		1.270274E-01
  training loss:		1.598941E-04
  validation loss:		1.496940E-04

Epoch 64 of 250
  example target:		2.735347E-03
  example prediction:		1.299986E-02
  training loss:		1.536800E-04
  validation loss:		1.464773E-04

Epoch 65 of 250
  example target:		2.319687E-01
  example prediction:		2.375955E-01
  training loss:		1.500672E-04
  validation loss:		1.432853E-04

Epoch 66 of 250
  example target:		6.137065E-02
  example prediction:		4.548470E-02
  training loss:		1.478076E-04
  validation loss:		1.386161E-04

Epoch 67 of 250
  example target:		3.982057E-02
  example prediction:		3.592625E-02
  training loss:		1.446375E-04
  validation loss:		1.358111E-04

Epoch 68 of 250
  example target:		6.077772E-02
  example prediction:		2.733656E-02
  training loss:		1.410410E-04
  validation loss:		1.331020E-04

Epoch 69 of 250
  example target:		4.026011E-02
  example prediction:		4.936981E-02
  training loss:		1.378836E-04
  validation loss:		1.320170E-04

Epoch 70 of 250
  example target:		2.319687E-01
  example prediction:		2.356106E-01
  training loss:		1.349854E-04
  validation loss:		1.284478E-04

Epoch 71 of 250
  example target:		1.886472E-02
  example prediction:		1.637364E-02
  training loss:		1.317526E-04
  validation loss:		1.257837E-04

Epoch 72 of 250
  example target:		7.612945E-02
  example prediction:		7.582233E-02
  training loss:		1.290333E-04
  validation loss:		1.249751E-04

Epoch 73 of 250
  example target:		3.982057E-02
  example prediction:		3.821557E-02
  training loss:		1.285862E-04
  validation loss:		1.255606E-04

Epoch 74 of 250
  example target:		2.187258E-02
  example prediction:		3.202585E-02
  training loss:		1.241629E-04
  validation loss:		1.176298E-04

Epoch 75 of 250
  example target:		1.071292E-01
  example prediction:		9.774240E-02
  training loss:		1.210030E-04
  validation loss:		1.181390E-04

Epoch 76 of 250
  example target:		3.372446E-01
  example prediction:		3.418752E-01
  training loss:		1.197848E-04
  validation loss:		1.151683E-04

Epoch 77 of 250
  example target:		2.457999E-01
  example prediction:		2.426730E-01
  training loss:		1.173110E-04
  validation loss:		1.157931E-04

Epoch 78 of 250
  example target:		5.004843E-02
  example prediction:		5.097962E-02
  training loss:		1.138155E-04
  validation loss:		1.076245E-04

Epoch 79 of 250
  example target:		1.886472E-02
  example prediction:		1.532879E-02
  training loss:		1.106708E-04
  validation loss:		1.050018E-04

Epoch 80 of 250
  example target:		2.457999E-01
  example prediction:		2.424915E-01
  training loss:		1.085070E-04
  validation loss:		1.059820E-04

Epoch 81 of 250
  example target:		3.372446E-01
  example prediction:		3.405535E-01
  training loss:		1.060071E-04
  validation loss:		1.019390E-04

Epoch 82 of 250
  example target:		5.004843E-02
  example prediction:		5.005117E-02
  training loss:		1.033138E-04
  validation loss:		9.851968E-05

Epoch 83 of 250
  example target:		2.983466E-01
  example prediction:		3.075143E-01
  training loss:		1.023151E-04
  validation loss:		9.958050E-05

Epoch 84 of 250
  example target:		7.433516E-01
  example prediction:		7.461048E-01
  training loss:		1.001525E-04
  validation loss:		9.455540E-05

Epoch 85 of 250
  example target:		5.004843E-02
  example prediction:		5.098420E-02
  training loss:		9.776228E-05
  validation loss:		9.328165E-05

Epoch 86 of 250
  example target:		0.000000E+00
  example prediction:		2.713444E-03
  training loss:		9.468412E-05
  validation loss:		9.030015E-05

Epoch 87 of 250
  example target:		6.964043E-02
  example prediction:		5.837746E-02
  training loss:		9.252766E-05
  validation loss:		8.905310E-05

Epoch 88 of 250
  example target:		6.077772E-02
  example prediction:		3.590035E-02
  training loss:		9.043968E-05
  validation loss:		8.645077E-05

Epoch 89 of 250
  example target:		6.964043E-02
  example prediction:		6.144354E-02
  training loss:		8.954044E-05
  validation loss:		8.716532E-05

Epoch 90 of 250
  example target:		6.964043E-02
  example prediction:		5.936025E-02
  training loss:		8.769422E-05
  validation loss:		8.226724E-05

Epoch 91 of 250
  example target:		1.886472E-02
  example prediction:		1.484770E-02
  training loss:		8.468217E-05
  validation loss:		8.079624E-05

Epoch 92 of 250
  example target:		6.077772E-02
  example prediction:		3.715127E-02
  training loss:		8.315566E-05
  validation loss:		7.907635E-05

Epoch 93 of 250
  example target:		1.886472E-02
  example prediction:		1.451113E-02
  training loss:		8.139655E-05
  validation loss:		7.764657E-05

Epoch 94 of 250
  example target:		2.506635E-02
  example prediction:		1.189977E-02
  training loss:		8.035608E-05
  validation loss:		7.605917E-05

Epoch 95 of 250
  example target:		5.004843E-02
  example prediction:		5.271117E-02
  training loss:		7.787962E-05
  validation loss:		9.033559E-05

Epoch 96 of 250
  example target:		1.071292E-01
  example prediction:		1.016912E-01
  training loss:		7.655648E-05
  validation loss:		7.285896E-05

Epoch 97 of 250
  example target:		3.297330E-01
  example prediction:		3.211757E-01
  training loss:		7.466130E-05
  validation loss:		7.043028E-05

Epoch 98 of 250
  example target:		1.000000E+00
  example prediction:		1.003156E+00
  training loss:		7.295299E-05
  validation loss:		6.939229E-05

Epoch 99 of 250
  example target:		2.457999E-01
  example prediction:		2.454825E-01
  training loss:		7.066045E-05
  validation loss:		6.841436E-05

Epoch 100 of 250
  example target:		0.000000E+00
  example prediction:		-2.121399E-03
  training loss:		7.009203E-05
  validation loss:		7.492609E-05

Epoch 101 of 250
  example target:		6.402986E-01
  example prediction:		6.403874E-01
  training loss:		6.883516E-05
  validation loss:		6.505922E-05

Epoch 102 of 250
  example target:		0.000000E+00
  example prediction:		-1.787774E-03
  training loss:		6.664167E-05
  validation loss:		6.739817E-05

Epoch 103 of 250
  example target:		2.735347E-03
  example prediction:		9.427246E-03
  training loss:		6.526412E-05
  validation loss:		6.278711E-05

Epoch 104 of 250
  example target:		2.983466E-01
  example prediction:		2.978682E-01
  training loss:		6.424991E-05
  validation loss:		6.324366E-05

Epoch 105 of 250
  example target:		7.433516E-01
  example prediction:		7.462056E-01
  training loss:		6.187636E-05
  validation loss:		5.998449E-05

Epoch 106 of 250
  example target:		2.506635E-02
  example prediction:		1.068420E-02
  training loss:		6.233602E-05
  validation loss:		6.079560E-05

Epoch 107 of 250
  example target:		1.414259E-01
  example prediction:		1.274806E-01
  training loss:		5.991468E-05
  validation loss:		5.835100E-05

Epoch 108 of 250
  example target:		9.711442E-01
  example prediction:		9.670085E-01
  training loss:		5.839550E-05
  validation loss:		5.615559E-05

Epoch 109 of 250
  example target:		3.372446E-01
  example prediction:		3.368427E-01
  training loss:		5.757716E-05
  validation loss:		5.536611E-05

Epoch 110 of 250
  example target:		1.071292E-01
  example prediction:		1.015568E-01
  training loss:		5.634449E-05
  validation loss:		5.745020E-05

Epoch 111 of 250
  example target:		1.645437E-02
  example prediction:		2.258818E-02
  training loss:		5.529150E-05
  validation loss:		5.807005E-05

Epoch 112 of 250
  example target:		3.372446E-01
  example prediction:		3.405205E-01
  training loss:		5.395344E-05
  validation loss:		5.969672E-05

Epoch 113 of 250
  example target:		0.000000E+00
  example prediction:		-4.148793E-04
  training loss:		5.341354E-05
  validation loss:		5.152739E-05

Epoch 114 of 250
  example target:		0.000000E+00
  example prediction:		-1.315333E-03
  training loss:		5.093863E-05
  validation loss:		4.953296E-05

Epoch 115 of 250
  example target:		1.886472E-02
  example prediction:		1.433883E-02
  training loss:		4.981506E-05
  validation loss:		5.038934E-05

Epoch 116 of 250
  example target:		5.847623E-02
  example prediction:		5.617216E-02
  training loss:		4.885285E-05
  validation loss:		4.782076E-05

Epoch 117 of 250
  example target:		6.964043E-02
  example prediction:		6.418740E-02
  training loss:		4.806058E-05
  validation loss:		4.638364E-05

Epoch 118 of 250
  example target:		1.000000E+00
  example prediction:		1.001718E+00
  training loss:		4.719337E-05
  validation loss:		4.621114E-05

Epoch 119 of 250
  example target:		2.457999E-01
  example prediction:		2.477198E-01
  training loss:		4.695771E-05
  validation loss:		4.513148E-05

Epoch 120 of 250
  example target:		1.886472E-02
  example prediction:		1.416896E-02
  training loss:		4.499869E-05
  validation loss:		4.434811E-05

Epoch 121 of 250
  example target:		2.319687E-01
  example prediction:		2.413192E-01
  training loss:		4.421235E-05
  validation loss:		4.298925E-05

Epoch 122 of 250
  example target:		2.735347E-03
  example prediction:		7.397805E-03
  training loss:		4.319472E-05
  validation loss:		4.237760E-05

Epoch 123 of 250
  example target:		3.982057E-02
  example prediction:		3.700521E-02
  training loss:		4.268068E-05
  validation loss:		4.090537E-05

Epoch 124 of 250
  example target:		3.083971E-02
  example prediction:		2.901576E-02
  training loss:		4.111206E-05
  validation loss:		4.133390E-05

Epoch 125 of 250
  example target:		2.984942E-02
  example prediction:		3.269694E-02
  training loss:		4.040429E-05
  validation loss:		3.936375E-05

Epoch 126 of 250
  example target:		2.187258E-02
  example prediction:		2.713741E-02
  training loss:		3.914957E-05
  validation loss:		3.852192E-05

Epoch 127 of 250
  example target:		3.016191E-01
  example prediction:		3.048901E-01
  training loss:		3.907032E-05
  validation loss:		3.759784E-05

Epoch 128 of 250
  example target:		2.735347E-03
  example prediction:		4.954292E-03
  training loss:		3.838766E-05
  validation loss:		3.761751E-05

Epoch 129 of 250
  example target:		2.983466E-01
  example prediction:		2.967310E-01
  training loss:		3.749286E-05
  validation loss:		3.842940E-05

Epoch 130 of 250
  example target:		9.711442E-01
  example prediction:		9.692267E-01
  training loss:		3.610954E-05
  validation loss:		3.642177E-05

Epoch 131 of 250
  example target:		8.434618E-01
  example prediction:		8.407518E-01
  training loss:		3.503162E-05
  validation loss:		3.528387E-05

Epoch 132 of 250
  example target:		5.004843E-02
  example prediction:		4.793135E-02
  training loss:		3.461297E-05
  validation loss:		3.471799E-05

Epoch 133 of 250
  example target:		3.372446E-01
  example prediction:		3.384947E-01
  training loss:		3.380091E-05
  validation loss:		3.462107E-05

Epoch 134 of 250
  example target:		5.004843E-02
  example prediction:		5.016158E-02
  training loss:		3.300400E-05
  validation loss:		3.252004E-05

Epoch 135 of 250
  example target:		1.702205E-02
  example prediction:		2.787258E-02
  training loss:		3.215568E-05
  validation loss:		3.141486E-05

Epoch 136 of 250
  example target:		2.983466E-01
  example prediction:		2.929642E-01
  training loss:		3.174676E-05
  validation loss:		3.275986E-05

Epoch 137 of 250
  example target:		3.016191E-01
  example prediction:		3.038832E-01
  training loss:		3.084315E-05
  validation loss:		2.988262E-05

Epoch 138 of 250
  example target:		3.083971E-02
  example prediction:		3.109159E-02
  training loss:		3.036312E-05
  validation loss:		3.003012E-05

Epoch 139 of 250
  example target:		3.372446E-01
  example prediction:		3.373275E-01
  training loss:		2.943130E-05
  validation loss:		2.859983E-05

Epoch 140 of 250
  example target:		7.433516E-01
  example prediction:		7.437148E-01
  training loss:		2.890946E-05
  validation loss:		2.783384E-05

Epoch 141 of 250
  example target:		2.735347E-03
  example prediction:		5.086089E-03
  training loss:		2.788731E-05
  validation loss:		2.726248E-05

Epoch 142 of 250
  example target:		1.958275E-02
  example prediction:		2.272991E-02
  training loss:		2.751972E-05
  validation loss:		2.785978E-05

Epoch 143 of 250
  example target:		6.137065E-02
  example prediction:		5.713973E-02
  training loss:		2.669571E-05
  validation loss:		2.622926E-05

Epoch 144 of 250
  example target:		1.886472E-02
  example prediction:		1.364193E-02
  training loss:		2.631857E-05
  validation loss:		2.539876E-05

Epoch 145 of 250
  example target:		6.449202E-01
  example prediction:		6.458898E-01
  training loss:		2.545842E-05
  validation loss:		2.595648E-05

Epoch 146 of 250
  example target:		4.026011E-02
  example prediction:		4.492373E-02
  training loss:		2.576857E-05
  validation loss:		2.838022E-05

Epoch 147 of 250
  example target:		8.434618E-01
  example prediction:		8.451228E-01
  training loss:		2.469066E-05
  validation loss:		2.540113E-05

Epoch 148 of 250
  example target:		7.253521E-01
  example prediction:		7.266905E-01
  training loss:		2.422450E-05
  validation loss:		2.321122E-05

Epoch 149 of 250
  example target:		2.984942E-02
  example prediction:		2.951375E-02
  training loss:		2.345819E-05
  validation loss:		2.263520E-05

Epoch 150 of 250
  example target:		3.083971E-02
  example prediction:		2.933663E-02
  training loss:		2.280459E-05
  validation loss:		2.562795E-05

Epoch 151 of 250
  example target:		3.016191E-01
  example prediction:		3.050741E-01
  training loss:		2.255895E-05
  validation loss:		2.242166E-05

Epoch 152 of 250
  example target:		8.434618E-01
  example prediction:		8.394013E-01
  training loss:		2.231129E-05
  validation loss:		2.426390E-05

Epoch 153 of 250
  example target:		1.645437E-02
  example prediction:		2.036568E-02
  training loss:		2.146415E-05
  validation loss:		2.087879E-05

Epoch 154 of 250
  example target:		6.077772E-02
  example prediction:		5.297288E-02
  training loss:		2.084035E-05
  validation loss:		2.285149E-05

Epoch 155 of 250
  example target:		2.983466E-01
  example prediction:		2.937603E-01
  training loss:		2.068741E-05
  validation loss:		2.042131E-05

Epoch 156 of 250
  example target:		6.270856E-01
  example prediction:		6.284042E-01
  training loss:		2.014446E-05
  validation loss:		1.984771E-05

Epoch 157 of 250
  example target:		2.319687E-01
  example prediction:		2.399693E-01
  training loss:		1.942944E-05
  validation loss:		2.073410E-05

Epoch 158 of 250
  example target:		2.506635E-02
  example prediction:		1.844612E-02
  training loss:		1.917268E-05
  validation loss:		1.932680E-05

Epoch 159 of 250
  example target:		2.984942E-02
  example prediction:		2.907026E-02
  training loss:		1.890185E-05
  validation loss:		1.880984E-05

Epoch 160 of 250
  example target:		1.958275E-02
  example prediction:		2.347032E-02
  training loss:		1.903045E-05
  validation loss:		1.840273E-05

Epoch 161 of 250
  example target:		9.711442E-01
  example prediction:		9.714753E-01
  training loss:		1.927210E-05
  validation loss:		1.823084E-05

Epoch 162 of 250
  example target:		2.735347E-03
  example prediction:		3.245681E-03
  training loss:		1.865160E-05
  validation loss:		1.724345E-05

Epoch 163 of 250
  example target:		1.414259E-01
  example prediction:		1.348675E-01
  training loss:		1.719087E-05
  validation loss:		1.691405E-05

Epoch 164 of 250
  example target:		2.785667E-02
  example prediction:		3.035429E-02
  training loss:		1.687352E-05
  validation loss:		1.654731E-05

Epoch 165 of 250
  example target:		2.735347E-03
  example prediction:		2.183126E-03
  training loss:		1.744991E-05
  validation loss:		1.897650E-05

Epoch 166 of 250
  example target:		1.414259E-01
  example prediction:		1.353712E-01
  training loss:		1.631767E-05
  validation loss:		1.597394E-05

Epoch 167 of 250
  example target:		8.434618E-01
  example prediction:		8.426231E-01
  training loss:		1.582480E-05
  validation loss:		1.563764E-05

Epoch 168 of 250
  example target:		1.645437E-02
  example prediction:		1.789251E-02
  training loss:		1.657339E-05
  validation loss:		1.948726E-05

Epoch 169 of 250
  example target:		0.000000E+00
  example prediction:		-1.243372E-03
  training loss:		1.559210E-05
  validation loss:		1.521524E-05

Epoch 170 of 250
  example target:		6.077772E-02
  example prediction:		5.398419E-02
  training loss:		1.538842E-05
  validation loss:		1.545618E-05

Epoch 171 of 250
  example target:		3.297330E-01
  example prediction:		3.239344E-01
  training loss:		1.485901E-05
  validation loss:		1.686581E-05

Epoch 172 of 250
  example target:		3.831306E-02
  example prediction:		5.028565E-02
  training loss:		1.504012E-05
  validation loss:		1.449374E-05

Epoch 173 of 250
  example target:		9.711442E-01
  example prediction:		9.686044E-01
  training loss:		1.468413E-05
  validation loss:		1.408218E-05

Epoch 174 of 250
  example target:		1.304502E-01
  example prediction:		1.282225E-01
  training loss:		1.413219E-05
  validation loss:		1.383776E-05

Epoch 175 of 250
  example target:		2.735347E-03
  example prediction:		1.703739E-03
  training loss:		1.384025E-05
  validation loss:		1.442089E-05

Epoch 176 of 250
  example target:		6.449202E-01
  example prediction:		6.458603E-01
  training loss:		1.392065E-05
  validation loss:		1.367798E-05

Epoch 177 of 250
  example target:		2.187258E-02
  example prediction:		2.561171E-02
  training loss:		1.360339E-05
  validation loss:		1.296375E-05

Epoch 178 of 250
  example target:		3.831306E-02
  example prediction:		4.997404E-02
  training loss:		1.323577E-05
  validation loss:		1.385860E-05

Epoch 179 of 250
  example target:		8.434618E-01
  example prediction:		8.416851E-01
  training loss:		1.313836E-05
  validation loss:		1.265942E-05

Epoch 180 of 250
  example target:		3.083971E-02
  example prediction:		3.074392E-02
  training loss:		1.253102E-05
  validation loss:		1.281822E-05

Epoch 181 of 250
  example target:		3.016191E-01
  example prediction:		3.049989E-01
  training loss:		1.236087E-05
  validation loss:		1.368324E-05

Epoch 182 of 250
  example target:		3.297330E-01
  example prediction:		3.251118E-01
  training loss:		1.226692E-05
  validation loss:		1.224191E-05

Epoch 183 of 250
  example target:		2.112001E-02
  example prediction:		2.363134E-02
  training loss:		1.212957E-05
  validation loss:		1.160100E-05

Epoch 184 of 250
  example target:		3.372446E-01
  example prediction:		3.369309E-01
  training loss:		1.173391E-05
  validation loss:		1.188804E-05

Epoch 185 of 250
  example target:		1.886472E-02
  example prediction:		1.485333E-02
  training loss:		1.215454E-05
  validation loss:		1.124387E-05

Epoch 186 of 250
  example target:		3.831306E-02
  example prediction:		4.898644E-02
  training loss:		1.195842E-05
  validation loss:		1.198605E-05

Epoch 187 of 250
  example target:		1.304502E-01
  example prediction:		1.269718E-01
  training loss:		1.124227E-05
  validation loss:		1.215250E-05

Epoch 188 of 250
  example target:		6.270856E-01
  example prediction:		6.289837E-01
  training loss:		1.116712E-05
  validation loss:		1.059153E-05

Epoch 189 of 250
  example target:		1.645437E-02
  example prediction:		1.783189E-02
  training loss:		1.135388E-05
  validation loss:		1.144830E-05

Epoch 190 of 250
  example target:		5.847623E-02
  example prediction:		5.802809E-02
  training loss:		1.045249E-05
  validation loss:		1.054892E-05

Epoch 191 of 250
  example target:		9.711442E-01
  example prediction:		9.691050E-01
  training loss:		1.072424E-05
  validation loss:		1.020628E-05

Epoch 192 of 250
  example target:		3.982057E-02
  example prediction:		3.580531E-02
  training loss:		1.060808E-05
  validation loss:		9.937431E-06

Epoch 193 of 250
  example target:		2.984942E-02
  example prediction:		2.690542E-02
  training loss:		1.023973E-05
  validation loss:		9.893550E-06

Epoch 194 of 250
  example target:		1.645437E-02
  example prediction:		1.818798E-02
  training loss:		1.009289E-05
  validation loss:		9.616216E-06

Epoch 195 of 250
  example target:		2.112001E-02
  example prediction:		2.441952E-02
  training loss:		9.712903E-06
  validation loss:		1.004219E-05

Epoch 196 of 250
  example target:		6.270856E-01
  example prediction:		6.294586E-01
  training loss:		9.583503E-06
  validation loss:		9.599703E-06

Epoch 197 of 250
  example target:		8.434618E-01
  example prediction:		8.414675E-01
  training loss:		9.318012E-06
  validation loss:		9.580753E-06

Epoch 198 of 250
  example target:		6.449202E-01
  example prediction:		6.439446E-01
  training loss:		1.000108E-05
  validation loss:		9.285491E-06

Epoch 199 of 250
  example target:		3.982057E-02
  example prediction:		3.557329E-02
  training loss:		9.117488E-06
  validation loss:		9.073540E-06

Epoch 200 of 250
  example target:		3.083971E-02
  example prediction:		3.019631E-02
  training loss:		9.325702E-06
  validation loss:		9.056226E-06

Epoch 201 of 250
  example target:		6.449202E-01
  example prediction:		6.432049E-01
  training loss:		9.024268E-06
  validation loss:		9.820617E-06

Epoch 202 of 250
  example target:		6.270856E-01
  example prediction:		6.293866E-01
  training loss:		8.643828E-06
  validation loss:		9.061330E-06

Epoch 203 of 250
  example target:		8.434618E-01
  example prediction:		8.422564E-01
  training loss:		8.467269E-06
  validation loss:		8.272886E-06

Epoch 204 of 250
  example target:		0.000000E+00
  example prediction:		-9.595520E-04
  training loss:		8.580697E-06
  validation loss:		8.221907E-06

Epoch 205 of 250
  example target:		3.982057E-02
  example prediction:		3.524914E-02
  training loss:		8.649952E-06
  validation loss:		8.837997E-06

Epoch 206 of 250
  example target:		9.711442E-01
  example prediction:		9.709521E-01
  training loss:		8.221335E-06
  validation loss:		7.959011E-06

Epoch 207 of 250
  example target:		1.645437E-02
  example prediction:		1.806959E-02
  training loss:		8.309687E-06
  validation loss:		7.892574E-06

Epoch 208 of 250
  example target:		6.402986E-01
  example prediction:		6.401666E-01
  training loss:		7.830000E-06
  validation loss:		7.607595E-06

Epoch 209 of 250
  example target:		5.004843E-02
  example prediction:		4.941033E-02
  training loss:		7.596872E-06
  validation loss:		8.401611E-06

Epoch 210 of 250
  example target:		6.449202E-01
  example prediction:		6.443104E-01
  training loss:		8.224380E-06
  validation loss:		7.561686E-06

Epoch 211 of 250
  example target:		1.414259E-01
  example prediction:		1.369332E-01
  training loss:		7.552332E-06
  validation loss:		8.301588E-06

Epoch 212 of 250
  example target:		2.319687E-01
  example prediction:		2.380932E-01
  training loss:		7.591647E-06
  validation loss:		7.280999E-06

Epoch 213 of 250
  example target:		3.372446E-01
  example prediction:		3.358681E-01
  training loss:		7.351241E-06
  validation loss:		7.541358E-06

Epoch 214 of 250
  example target:		6.137065E-02
  example prediction:		6.252695E-02
  training loss:		7.321294E-06
  validation loss:		7.522392E-06

Epoch 215 of 250
  example target:		3.083971E-02
  example prediction:		3.061124E-02
  training loss:		6.962230E-06
  validation loss:		6.779045E-06

Epoch 216 of 250
  example target:		2.319687E-01
  example prediction:		2.379514E-01
  training loss:		7.086086E-06
  validation loss:		6.887830E-06

Epoch 217 of 250
  example target:		1.958275E-02
  example prediction:		2.211703E-02
  training loss:		6.796932E-06
  validation loss:		7.101019E-06

Epoch 218 of 250
  example target:		1.886472E-02
  example prediction:		1.608498E-02
  training loss:		6.958127E-06
  validation loss:		6.678653E-06

Epoch 219 of 250
  example target:		3.831306E-02
  example prediction:		4.532443E-02
  training loss:		6.610693E-06
  validation loss:		6.364243E-06

Epoch 220 of 250
  example target:		2.457999E-01
  example prediction:		2.468398E-01
  training loss:		6.887832E-06
  validation loss:		6.439254E-06

Epoch 221 of 250
  example target:		1.886472E-02
  example prediction:		1.557611E-02
  training loss:		6.628477E-06
  validation loss:		6.156033E-06

Epoch 222 of 250
  example target:		1.886472E-02
  example prediction:		1.681659E-02
  training loss:		6.650532E-06
  validation loss:		7.507382E-06

Epoch 223 of 250
  example target:		7.253521E-01
  example prediction:		7.267017E-01
  training loss:		6.355249E-06
  validation loss:		6.278938E-06

Epoch 224 of 250
  example target:		2.506635E-02
  example prediction:		2.230435E-02
  training loss:		6.484454E-06
  validation loss:		5.956751E-06

Epoch 225 of 250
  example target:		3.016191E-01
  example prediction:		3.027240E-01
  training loss:		6.272644E-06
  validation loss:		5.946356E-06

Epoch 226 of 250
  example target:		3.016191E-01
  example prediction:		3.044506E-01
  training loss:		5.961299E-06
  validation loss:		7.494786E-06

Epoch 227 of 250
  example target:		5.847623E-02
  example prediction:		5.719990E-02
  training loss:		6.639361E-06
  validation loss:		7.067315E-06

Epoch 228 of 250
  example target:		2.319687E-01
  example prediction:		2.378536E-01
  training loss:		5.706289E-06
  validation loss:		5.554079E-06

Epoch 229 of 250
  example target:		3.372446E-01
  example prediction:		3.368772E-01
  training loss:		5.880859E-06
  validation loss:		5.672991E-06

Epoch 230 of 250
  example target:		9.711442E-01
  example prediction:		9.683701E-01
  training loss:		5.622097E-06
  validation loss:		6.662531E-06

Epoch 231 of 250
  example target:		2.457999E-01
  example prediction:		2.470632E-01
  training loss:		5.824263E-06
  validation loss:		5.317344E-06

Epoch 232 of 250
  example target:		7.612945E-02
  example prediction:		7.390338E-02
  training loss:		5.368455E-06
  validation loss:		5.462665E-06

Epoch 233 of 250
  example target:		6.449202E-01
  example prediction:		6.450923E-01
  training loss:		5.470698E-06
  validation loss:		5.232383E-06

Epoch 234 of 250
  example target:		3.016191E-01
  example prediction:		3.027410E-01
  training loss:		5.481417E-06
  validation loss:		5.278576E-06

Epoch 235 of 250
  example target:		6.402986E-01
  example prediction:		6.392205E-01
  training loss:		5.217130E-06
  validation loss:		5.451993E-06

Epoch 236 of 250
  example target:		1.702205E-02
  example prediction:		2.041452E-02
  training loss:		5.204157E-06
  validation loss:		5.485265E-06

Epoch 237 of 250
  example target:		2.785667E-02
  example prediction:		2.768460E-02
  training loss:		5.316313E-06
  validation loss:		4.913892E-06

Epoch 238 of 250
  example target:		9.711442E-01
  example prediction:		9.704373E-01
  training loss:		5.177419E-06
  validation loss:		4.929009E-06

Epoch 239 of 250
  example target:		3.982057E-02
  example prediction:		3.540947E-02
  training loss:		5.449112E-06
  validation loss:		6.150287E-06

Epoch 240 of 250
  example target:		1.403356E-02
  example prediction:		1.527836E-02
  training loss:		4.987152E-06
  validation loss:		5.694020E-06

Epoch 241 of 250
  example target:		1.403356E-02
  example prediction:		1.426545E-02
  training loss:		4.912832E-06
  validation loss:		4.628926E-06

Epoch 242 of 250
  example target:		2.187258E-02
  example prediction:		2.445763E-02
  training loss:		4.787073E-06
  validation loss:		4.971473E-06

Epoch 243 of 250
  example target:		1.403356E-02
  example prediction:		1.454127E-02
  training loss:		4.703743E-06
  validation loss:		4.571395E-06

Epoch 244 of 250
  example target:		6.964043E-02
  example prediction:		7.115817E-02
  training loss:		4.724595E-06
  validation loss:		4.833896E-06

Epoch 245 of 250
  example target:		3.083971E-02
  example prediction:		3.064431E-02
  training loss:		4.814870E-06
  validation loss:		4.660078E-06

Epoch 246 of 250
  example target:		7.433516E-01
  example prediction:		7.445770E-01
  training loss:		4.472038E-06
  validation loss:		4.858585E-06

Epoch 247 of 250
  example target:		7.253521E-01
  example prediction:		7.238431E-01
  training loss:		4.408178E-06
  validation loss:		6.726445E-06

Epoch 248 of 250
  example target:		9.711442E-01
  example prediction:		9.697075E-01
  training loss:		4.650094E-06
  validation loss:		4.312847E-06

Epoch 249 of 250
  example target:		3.831306E-02
  example prediction:		4.281941E-02
  training loss:		4.293730E-06
  validation loss:		4.421710E-06

Epoch 250 of 250
  example target:		3.982057E-02
  example prediction:		3.695256E-02
  training loss:		4.339787E-06
  validation loss:		5.044463E-06

Test-set, Scaled RMSE: 0.00222599178511
Test-set, Original RMSE: 2.07131473426e-09
