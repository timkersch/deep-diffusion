Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 500
  training loss:		4.216909E-01
  validation loss:		1.194547E-01
Epoch took 0.261s

Epoch 2 of 500
  training loss:		9.954948E-02
  validation loss:		8.606201E-02
Epoch took 0.238s

Epoch 3 of 500
  training loss:		8.101921E-02
  validation loss:		7.349693E-02
Epoch took 0.231s

Epoch 4 of 500
  training loss:		7.152333E-02
  validation loss:		6.505695E-02
Epoch took 0.231s

Epoch 5 of 500
  training loss:		6.489786E-02
  validation loss:		6.000976E-02
Epoch took 0.231s

Epoch 6 of 500
  training loss:		5.971912E-02
  validation loss:		5.440633E-02
Epoch took 0.231s

Epoch 7 of 500
  training loss:		5.606000E-02
  validation loss:		5.095977E-02
Epoch took 0.231s

Epoch 8 of 500
  training loss:		5.250855E-02
  validation loss:		4.776053E-02
Epoch took 0.231s

Epoch 9 of 500
  training loss:		4.984722E-02
  validation loss:		4.565454E-02
Epoch took 0.231s

Epoch 10 of 500
  training loss:		4.765092E-02
  validation loss:		4.433440E-02
Epoch took 0.231s

Epoch 11 of 500
  training loss:		4.543382E-02
  validation loss:		4.189686E-02
Epoch took 0.231s

Epoch 12 of 500
  training loss:		4.414943E-02
  validation loss:		3.995085E-02
Epoch took 0.231s

Epoch 13 of 500
  training loss:		4.246884E-02
  validation loss:		3.878633E-02
Epoch took 0.231s

Epoch 14 of 500
  training loss:		4.113766E-02
  validation loss:		3.757836E-02
Epoch took 0.231s

Epoch 15 of 500
  training loss:		3.982869E-02
  validation loss:		3.687265E-02
Epoch took 0.231s

Epoch 16 of 500
  training loss:		3.917790E-02
  validation loss:		3.501842E-02
Epoch took 0.231s

Epoch 17 of 500
  training loss:		3.787175E-02
  validation loss:		3.433111E-02
Epoch took 0.231s

Epoch 18 of 500
  training loss:		3.717847E-02
  validation loss:		3.384322E-02
Epoch took 0.231s

Epoch 19 of 500
  training loss:		3.639188E-02
  validation loss:		3.310912E-02
Epoch took 0.231s

Epoch 20 of 500
  training loss:		3.605340E-02
  validation loss:		3.376678E-02
Epoch took 0.231s

Epoch 21 of 500
  training loss:		3.519880E-02
  validation loss:		3.223785E-02
Epoch took 0.231s

Epoch 22 of 500
  training loss:		3.460212E-02
  validation loss:		3.163214E-02
Epoch took 0.231s

Epoch 23 of 500
  training loss:		3.424866E-02
  validation loss:		3.146574E-02
Epoch took 0.231s

Epoch 24 of 500
  training loss:		3.403283E-02
  validation loss:		3.091343E-02
Epoch took 0.231s

Epoch 25 of 500
  training loss:		3.348072E-02
  validation loss:		3.181491E-02
Epoch took 0.231s

Epoch 26 of 500
  training loss:		3.291077E-02
  validation loss:		3.028984E-02
Epoch took 0.231s

Epoch 27 of 500
  training loss:		3.268092E-02
  validation loss:		3.069924E-02
Epoch took 0.231s

Epoch 28 of 500
  training loss:		3.259806E-02
  validation loss:		3.001769E-02
Epoch took 0.231s

Epoch 29 of 500
  training loss:		3.231998E-02
  validation loss:		2.955123E-02
Epoch took 0.231s

Epoch 30 of 500
  training loss:		3.188881E-02
  validation loss:		2.953656E-02
Epoch took 0.231s

Epoch 31 of 500
  training loss:		3.184125E-02
  validation loss:		2.938667E-02
Epoch took 0.231s

Epoch 32 of 500
  training loss:		3.182957E-02
  validation loss:		2.899016E-02
Epoch took 0.231s

Epoch 33 of 500
  training loss:		3.128946E-02
  validation loss:		2.866856E-02
Epoch took 0.231s

Epoch 34 of 500
  training loss:		3.106044E-02
  validation loss:		2.962279E-02
Epoch took 0.231s

Epoch 35 of 500
  training loss:		3.115977E-02
  validation loss:		2.834968E-02
Epoch took 0.231s

Epoch 36 of 500
  training loss:		3.095178E-02
  validation loss:		2.855127E-02
Epoch took 0.231s

Epoch 37 of 500
  training loss:		3.079467E-02
  validation loss:		2.858528E-02
Epoch took 0.231s

Epoch 38 of 500
  training loss:		3.051048E-02
  validation loss:		2.821099E-02
Epoch took 0.231s

Epoch 39 of 500
  training loss:		3.065901E-02
  validation loss:		2.822924E-02
Epoch took 0.231s

Epoch 40 of 500
  training loss:		3.036257E-02
  validation loss:		2.835109E-02
Epoch took 0.231s

Epoch 41 of 500
  training loss:		3.057542E-02
  validation loss:		2.866729E-02
Epoch took 0.231s

Epoch 42 of 500
  training loss:		3.014665E-02
  validation loss:		2.794182E-02
Epoch took 0.231s

Epoch 43 of 500
  training loss:		3.030981E-02
  validation loss:		2.852083E-02
Epoch took 0.231s

Epoch 44 of 500
  training loss:		3.024719E-02
  validation loss:		2.838013E-02
Epoch took 0.231s

Epoch 45 of 500
  training loss:		2.987102E-02
  validation loss:		2.775594E-02
Epoch took 0.231s

Epoch 46 of 500
  training loss:		2.992009E-02
  validation loss:		2.815086E-02
Epoch took 0.231s

Epoch 47 of 500
  training loss:		2.983437E-02
  validation loss:		2.812237E-02
Epoch took 0.231s

Epoch 48 of 500
  training loss:		2.982985E-02
  validation loss:		2.799523E-02
Epoch took 0.231s

Epoch 49 of 500
  training loss:		2.963429E-02
  validation loss:		2.764704E-02
Epoch took 0.231s

Epoch 50 of 500
  training loss:		2.975500E-02
  validation loss:		2.805560E-02
Epoch took 0.231s

Epoch 51 of 500
  training loss:		2.944998E-02
  validation loss:		2.779249E-02
Epoch took 0.231s

Epoch 52 of 500
  training loss:		2.972459E-02
  validation loss:		2.867691E-02
Epoch took 0.231s

Epoch 53 of 500
  training loss:		2.959058E-02
  validation loss:		2.782006E-02
Epoch took 0.231s

Epoch 54 of 500
  training loss:		2.944070E-02
  validation loss:		2.778284E-02
Epoch took 0.231s

Epoch 55 of 500
  training loss:		2.930029E-02
  validation loss:		2.773810E-02
Epoch took 0.231s

Epoch 56 of 500
  training loss:		2.930228E-02
  validation loss:		2.853969E-02
Epoch took 0.231s

Epoch 57 of 500
  training loss:		2.925393E-02
  validation loss:		2.772519E-02
Epoch took 0.231s

Epoch 58 of 500
  training loss:		2.933860E-02
  validation loss:		2.814574E-02
Epoch took 0.231s

Epoch 59 of 500
  training loss:		2.910939E-02
  validation loss:		2.726679E-02
Epoch took 0.231s

Epoch 60 of 500
  training loss:		2.901096E-02
  validation loss:		2.768224E-02
Epoch took 0.231s

Epoch 61 of 500
  training loss:		2.910014E-02
  validation loss:		2.857819E-02
Epoch took 0.231s

Epoch 62 of 500
  training loss:		2.899669E-02
  validation loss:		2.824752E-02
Epoch took 0.231s

Epoch 63 of 500
  training loss:		2.880836E-02
  validation loss:		2.729005E-02
Epoch took 0.231s

Epoch 64 of 500
  training loss:		2.889986E-02
  validation loss:		2.757744E-02
Epoch took 0.231s

Epoch 65 of 500
  training loss:		2.901258E-02
  validation loss:		2.838957E-02
Epoch took 0.231s

Epoch 66 of 500
  training loss:		2.875460E-02
  validation loss:		2.808744E-02
Epoch took 0.231s

Epoch 67 of 500
  training loss:		2.887214E-02
  validation loss:		2.751834E-02
Epoch took 0.231s

Epoch 68 of 500
  training loss:		2.863790E-02
  validation loss:		2.736847E-02
Epoch took 0.231s

Epoch 69 of 500
  training loss:		2.864766E-02
  validation loss:		2.733762E-02
Epoch took 0.231s

Epoch 70 of 500
  training loss:		2.871033E-02
  validation loss:		2.725106E-02
Epoch took 0.231s

Epoch 71 of 500
  training loss:		2.863661E-02
  validation loss:		2.703400E-02
Epoch took 0.232s

Epoch 72 of 500
  training loss:		2.852885E-02
  validation loss:		2.726272E-02
Epoch took 0.231s

Epoch 73 of 500
  training loss:		2.863602E-02
  validation loss:		2.721670E-02
Epoch took 0.231s

Epoch 74 of 500
  training loss:		2.871130E-02
  validation loss:		2.687218E-02
Epoch took 0.231s

Epoch 75 of 500
  training loss:		2.851246E-02
  validation loss:		2.782468E-02
Epoch took 0.231s

Epoch 76 of 500
  training loss:		2.845155E-02
  validation loss:		2.681596E-02
Epoch took 0.231s

Epoch 77 of 500
  training loss:		2.855223E-02
  validation loss:		2.701503E-02
Epoch took 0.231s

Epoch 78 of 500
  training loss:		2.859344E-02
  validation loss:		2.773412E-02
Epoch took 0.231s

Epoch 79 of 500
  training loss:		2.841980E-02
  validation loss:		2.699190E-02
Epoch took 0.231s

Epoch 80 of 500
  training loss:		2.843701E-02
  validation loss:		2.728492E-02
Epoch took 0.231s

Epoch 81 of 500
  training loss:		2.824244E-02
  validation loss:		2.698253E-02
Epoch took 0.231s

Epoch 82 of 500
  training loss:		2.829258E-02
  validation loss:		2.684097E-02
Epoch took 0.231s

Epoch 83 of 500
  training loss:		2.829002E-02
  validation loss:		2.763533E-02
Epoch took 0.231s

Epoch 84 of 500
  training loss:		2.833596E-02
  validation loss:		2.825048E-02
Epoch took 0.231s

Epoch 85 of 500
  training loss:		2.833254E-02
  validation loss:		2.768728E-02
Epoch took 0.231s

Epoch 86 of 500
  training loss:		2.828896E-02
  validation loss:		2.738222E-02
Epoch took 0.231s

Epoch 87 of 500
  training loss:		2.825960E-02
  validation loss:		2.712491E-02
Epoch took 0.231s

Epoch 88 of 500
  training loss:		2.828314E-02
  validation loss:		2.714459E-02
Epoch took 0.231s

Epoch 89 of 500
  training loss:		2.816293E-02
  validation loss:		2.699528E-02
Epoch took 0.231s

Epoch 90 of 500
  training loss:		2.822673E-02
  validation loss:		2.715677E-02
Epoch took 0.231s

Epoch 91 of 500
  training loss:		2.818641E-02
  validation loss:		2.745162E-02
Epoch took 0.231s

Epoch 92 of 500
  training loss:		2.800429E-02
  validation loss:		2.740276E-02
Epoch took 0.231s

Epoch 93 of 500
  training loss:		2.801053E-02
  validation loss:		2.725482E-02
Epoch took 0.231s

Epoch 94 of 500
  training loss:		2.816375E-02
  validation loss:		2.710906E-02
Epoch took 0.231s

Epoch 95 of 500
  training loss:		2.817098E-02
  validation loss:		2.703710E-02
Epoch took 0.231s

Epoch 96 of 500
  training loss:		2.805558E-02
  validation loss:		2.674960E-02
Epoch took 0.231s

Epoch 97 of 500
  training loss:		2.816270E-02
  validation loss:		2.657677E-02
Epoch took 0.231s

Epoch 98 of 500
  training loss:		2.802114E-02
  validation loss:		2.687865E-02
Epoch took 0.231s

Epoch 99 of 500
  training loss:		2.814137E-02
  validation loss:		2.743430E-02
Epoch took 0.231s

Epoch 100 of 500
  training loss:		2.802753E-02
  validation loss:		2.727361E-02
Epoch took 0.231s

Epoch 101 of 500
  training loss:		2.811731E-02
  validation loss:		2.706001E-02
Epoch took 0.231s

Epoch 102 of 500
  training loss:		2.804178E-02
  validation loss:		2.729625E-02
Epoch took 0.231s

Epoch 103 of 500
  training loss:		2.796160E-02
  validation loss:		2.695379E-02
Epoch took 0.231s

Epoch 104 of 500
  training loss:		2.781076E-02
  validation loss:		2.674278E-02
Epoch took 0.231s

Epoch 105 of 500
  training loss:		2.789695E-02
  validation loss:		2.684008E-02
Epoch took 0.231s

Epoch 106 of 500
  training loss:		2.787305E-02
  validation loss:		2.709804E-02
Epoch took 0.231s

Epoch 107 of 500
  training loss:		2.789972E-02
  validation loss:		2.701926E-02
Epoch took 0.231s

Epoch 108 of 500
  training loss:		2.794207E-02
  validation loss:		2.655951E-02
Epoch took 0.231s

Epoch 109 of 500
  training loss:		2.784693E-02
  validation loss:		2.681648E-02
Epoch took 0.231s

Epoch 110 of 500
  training loss:		2.801494E-02
  validation loss:		2.692081E-02
Epoch took 0.231s

Epoch 111 of 500
  training loss:		2.770972E-02
  validation loss:		2.671963E-02
Epoch took 0.231s

Epoch 112 of 500
  training loss:		2.781073E-02
  validation loss:		2.693070E-02
Epoch took 0.231s

Epoch 113 of 500
  training loss:		2.785605E-02
  validation loss:		2.669269E-02
Epoch took 0.231s

Epoch 114 of 500
  training loss:		2.798189E-02
  validation loss:		2.678920E-02
Epoch took 0.231s

Epoch 115 of 500
  training loss:		2.781241E-02
  validation loss:		2.682210E-02
Epoch took 0.231s

Epoch 116 of 500
  training loss:		2.781548E-02
  validation loss:		2.695568E-02
Epoch took 0.231s

Epoch 117 of 500
  training loss:		2.790747E-02
  validation loss:		2.686998E-02
Epoch took 0.231s

Epoch 118 of 500
  training loss:		2.775242E-02
  validation loss:		2.756148E-02
Epoch took 0.231s

Epoch 119 of 500
  training loss:		2.765513E-02
  validation loss:		2.696872E-02
Epoch took 0.231s

Epoch 120 of 500
  training loss:		2.756819E-02
  validation loss:		2.642751E-02
Epoch took 0.231s

Epoch 121 of 500
  training loss:		2.767704E-02
  validation loss:		2.679314E-02
Epoch took 0.231s

Epoch 122 of 500
  training loss:		2.781712E-02
  validation loss:		2.687583E-02
Epoch took 0.231s

Epoch 123 of 500
  training loss:		2.763220E-02
  validation loss:		2.682830E-02
Epoch took 0.231s

Epoch 124 of 500
  training loss:		2.776664E-02
  validation loss:		2.674893E-02
Epoch took 0.231s

Epoch 125 of 500
  training loss:		2.774964E-02
  validation loss:		2.716986E-02
Epoch took 0.231s

Epoch 126 of 500
  training loss:		2.786378E-02
  validation loss:		2.686002E-02
Epoch took 0.231s

Epoch 127 of 500
  training loss:		2.767770E-02
  validation loss:		2.664347E-02
Epoch took 0.231s

Epoch 128 of 500
  training loss:		2.762312E-02
  validation loss:		2.676583E-02
Epoch took 0.231s

Epoch 129 of 500
  training loss:		2.763976E-02
  validation loss:		2.719375E-02
Epoch took 0.231s

Epoch 130 of 500
  training loss:		2.771967E-02
  validation loss:		2.666930E-02
Epoch took 0.231s

Epoch 131 of 500
  training loss:		2.774270E-02
  validation loss:		2.685461E-02
Epoch took 0.231s

Epoch 132 of 500
  training loss:		2.768002E-02
  validation loss:		2.708404E-02
Epoch took 0.231s

Epoch 133 of 500
  training loss:		2.774824E-02
  validation loss:		2.670640E-02
Epoch took 0.231s

Epoch 134 of 500
  training loss:		2.769229E-02
  validation loss:		2.723155E-02
Epoch took 0.231s

Epoch 135 of 500
  training loss:		2.765235E-02
  validation loss:		2.722892E-02
Epoch took 0.231s

Early stopping, val-loss increased over the last 15 epochs from 0.0268767861734 to 0.0269102642695
Saving model from epoch 120
Training MSE: 2.49183e-14
Validation MSE: 2.53984e-14
Training R2: 0.736327837022
Validation R2: 0.730235874957
