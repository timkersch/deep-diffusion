Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		2.986653E-01
  validation loss:		2.683781E-01
Epoch took 0.246s

Epoch 2 of 300
  training loss:		2.536793E-01
  validation loss:		2.338935E-01
Epoch took 0.246s

Epoch 3 of 300
  training loss:		2.242666E-01
  validation loss:		2.073540E-01
Epoch took 0.246s

Epoch 4 of 300
  training loss:		2.021939E-01
  validation loss:		1.990169E-01
Epoch took 0.246s

Epoch 5 of 300
  training loss:		1.873927E-01
  validation loss:		1.842680E-01
Epoch took 0.246s

Epoch 6 of 300
  training loss:		1.733854E-01
  validation loss:		1.721837E-01
Epoch took 0.246s

Epoch 7 of 300
  training loss:		1.623931E-01
  validation loss:		1.566727E-01
Epoch took 0.246s

Epoch 8 of 300
  training loss:		1.540017E-01
  validation loss:		1.488112E-01
Epoch took 0.246s

Epoch 9 of 300
  training loss:		1.454925E-01
  validation loss:		1.418369E-01
Epoch took 0.246s

Epoch 10 of 300
  training loss:		1.394252E-01
  validation loss:		1.370607E-01
Epoch took 0.246s

Epoch 11 of 300
  training loss:		1.371222E-01
  validation loss:		1.482676E-01
Epoch took 0.246s

Epoch 12 of 300
  training loss:		1.336378E-01
  validation loss:		1.311637E-01
Epoch took 0.246s

Epoch 13 of 300
  training loss:		1.296593E-01
  validation loss:		1.269689E-01
Epoch took 0.246s

Epoch 14 of 300
  training loss:		1.265815E-01
  validation loss:		1.254209E-01
Epoch took 0.246s

Epoch 15 of 300
  training loss:		1.238183E-01
  validation loss:		1.258421E-01
Epoch took 0.246s

Epoch 16 of 300
  training loss:		1.251577E-01
  validation loss:		1.243438E-01
Epoch took 0.246s

Epoch 17 of 300
  training loss:		1.217301E-01
  validation loss:		1.182656E-01
Epoch took 0.246s

Epoch 18 of 300
  training loss:		1.202641E-01
  validation loss:		1.151387E-01
Epoch took 0.246s

Epoch 19 of 300
  training loss:		1.199333E-01
  validation loss:		1.195297E-01
Epoch took 0.246s

Epoch 20 of 300
  training loss:		1.184909E-01
  validation loss:		1.239571E-01
Epoch took 0.246s

Epoch 21 of 300
  training loss:		1.181228E-01
  validation loss:		1.238317E-01
Epoch took 0.246s

Epoch 22 of 300
  training loss:		1.169603E-01
  validation loss:		1.186262E-01
Epoch took 0.246s

Epoch 23 of 300
  training loss:		1.147693E-01
  validation loss:		1.158639E-01
Epoch took 0.246s

Epoch 24 of 300
  training loss:		1.158817E-01
  validation loss:		1.173984E-01
Epoch took 0.246s

Epoch 25 of 300
  training loss:		1.156560E-01
  validation loss:		1.155946E-01
Epoch took 0.246s

Epoch 26 of 300
  training loss:		1.150024E-01
  validation loss:		1.136610E-01
Epoch took 0.246s

Epoch 27 of 300
  training loss:		1.154212E-01
  validation loss:		1.139223E-01
Epoch took 0.246s

Epoch 28 of 300
  training loss:		1.144751E-01
  validation loss:		1.148563E-01
Epoch took 0.246s

Epoch 29 of 300
  training loss:		1.136163E-01
  validation loss:		1.165783E-01
Epoch took 0.246s

Epoch 30 of 300
  training loss:		1.145341E-01
  validation loss:		1.154460E-01
Epoch took 0.246s

Epoch 31 of 300
  training loss:		1.129790E-01
  validation loss:		1.131144E-01
Epoch took 0.246s

Epoch 32 of 300
  training loss:		1.125099E-01
  validation loss:		1.126673E-01
Epoch took 0.248s

Epoch 33 of 300
  training loss:		1.125972E-01
  validation loss:		1.100398E-01
Epoch took 0.246s

Epoch 34 of 300
  training loss:		1.123618E-01
  validation loss:		1.145812E-01
Epoch took 0.246s

Epoch 35 of 300
  training loss:		1.122270E-01
  validation loss:		1.106343E-01
Epoch took 0.246s

Epoch 36 of 300
  training loss:		1.120770E-01
  validation loss:		1.126798E-01
Epoch took 0.246s

Epoch 37 of 300
  training loss:		1.108180E-01
  validation loss:		1.135236E-01
Epoch took 0.248s

Epoch 38 of 300
  training loss:		1.111290E-01
  validation loss:		1.144988E-01
Epoch took 0.246s

Epoch 39 of 300
  training loss:		1.122052E-01
  validation loss:		1.206541E-01
Epoch took 0.246s

Epoch 40 of 300
  training loss:		1.113352E-01
  validation loss:		1.204425E-01
Epoch took 0.246s

Epoch 41 of 300
  training loss:		1.105428E-01
  validation loss:		1.099241E-01
Epoch took 0.246s

Epoch 42 of 300
  training loss:		1.100453E-01
  validation loss:		1.086934E-01
Epoch took 0.246s

Epoch 43 of 300
  training loss:		1.114653E-01
  validation loss:		1.099023E-01
Epoch took 0.246s

Epoch 44 of 300
  training loss:		1.111639E-01
  validation loss:		1.104442E-01
Epoch took 0.246s

Epoch 45 of 300
  training loss:		1.104048E-01
  validation loss:		1.090292E-01
Epoch took 0.246s

Epoch 46 of 300
  training loss:		1.094030E-01
  validation loss:		1.070753E-01
Epoch took 0.246s

Epoch 47 of 300
  training loss:		1.100108E-01
  validation loss:		1.088601E-01
Epoch took 0.246s

Epoch 48 of 300
  training loss:		1.094173E-01
  validation loss:		1.106156E-01
Epoch took 0.246s

Epoch 49 of 300
  training loss:		1.100588E-01
  validation loss:		1.092580E-01
Epoch took 0.246s

Epoch 50 of 300
  training loss:		1.097338E-01
  validation loss:		1.107801E-01
Epoch took 0.246s

Epoch 51 of 300
  training loss:		1.096837E-01
  validation loss:		1.147725E-01
Epoch took 0.246s

Epoch 52 of 300
  training loss:		1.098262E-01
  validation loss:		1.076180E-01
Epoch took 0.246s

Epoch 53 of 300
  training loss:		1.089083E-01
  validation loss:		1.102080E-01
Epoch took 0.246s

Epoch 54 of 300
  training loss:		1.090880E-01
  validation loss:		1.105630E-01
Epoch took 0.246s

Epoch 55 of 300
  training loss:		1.089493E-01
  validation loss:		1.088370E-01
Epoch took 0.246s

Epoch 56 of 300
  training loss:		1.089458E-01
  validation loss:		1.094027E-01
Epoch took 0.246s

Epoch 57 of 300
  training loss:		1.096968E-01
  validation loss:		1.114743E-01
Epoch took 0.246s

Epoch 58 of 300
  training loss:		1.087845E-01
  validation loss:		1.108530E-01
Epoch took 0.246s

Epoch 59 of 300
  training loss:		1.086529E-01
  validation loss:		1.090402E-01
Epoch took 0.246s

Epoch 60 of 300
  training loss:		1.077713E-01
  validation loss:		1.076614E-01
Epoch took 0.246s

Epoch 61 of 300
  training loss:		1.077268E-01
  validation loss:		1.098310E-01
Epoch took 0.246s

Epoch 62 of 300
  training loss:		1.090278E-01
  validation loss:		1.081886E-01
Epoch took 0.246s

Epoch 63 of 300
  training loss:		1.083295E-01
  validation loss:		1.082182E-01
Epoch took 0.246s

Epoch 64 of 300
  training loss:		1.079590E-01
  validation loss:		1.095252E-01
Epoch took 0.246s

Epoch 65 of 300
  training loss:		1.083336E-01
  validation loss:		1.117999E-01
Epoch took 0.246s

Epoch 66 of 300
  training loss:		1.085941E-01
  validation loss:		1.081719E-01
Epoch took 0.246s

Epoch 67 of 300
  training loss:		1.077977E-01
  validation loss:		1.069926E-01
Epoch took 0.246s

Epoch 68 of 300
  training loss:		1.075304E-01
  validation loss:		1.122345E-01
Epoch took 0.246s

Epoch 69 of 300
  training loss:		1.083315E-01
  validation loss:		1.094650E-01
Epoch took 0.246s

Epoch 70 of 300
  training loss:		1.079386E-01
  validation loss:		1.082435E-01
Epoch took 0.246s

Epoch 71 of 300
  training loss:		1.077181E-01
  validation loss:		1.069676E-01
Epoch took 0.246s

Epoch 72 of 300
  training loss:		1.078503E-01
  validation loss:		1.070216E-01
Epoch took 0.246s

Epoch 73 of 300
  training loss:		1.073757E-01
  validation loss:		1.057565E-01
Epoch took 0.246s

Epoch 74 of 300
  training loss:		1.076352E-01
  validation loss:		1.109934E-01
Epoch took 0.246s

Epoch 75 of 300
  training loss:		1.080912E-01
  validation loss:		1.084129E-01
Epoch took 0.246s

Epoch 76 of 300
  training loss:		1.075820E-01
  validation loss:		1.066415E-01
Epoch took 0.246s

Epoch 77 of 300
  training loss:		1.069626E-01
  validation loss:		1.056151E-01
Epoch took 0.246s

Epoch 78 of 300
  training loss:		1.076235E-01
  validation loss:		1.087456E-01
Epoch took 0.246s

Epoch 79 of 300
  training loss:		1.072413E-01
  validation loss:		1.068781E-01
Epoch took 0.246s

Epoch 80 of 300
  training loss:		1.071654E-01
  validation loss:		1.070839E-01
Epoch took 0.246s

Epoch 81 of 300
  training loss:		1.071685E-01
  validation loss:		1.058938E-01
Epoch took 0.246s

Epoch 82 of 300
  training loss:		1.072185E-01
  validation loss:		1.083770E-01
Epoch took 0.246s

Epoch 83 of 300
  training loss:		1.074957E-01
  validation loss:		1.129901E-01
Epoch took 0.246s

Epoch 84 of 300
  training loss:		1.069063E-01
  validation loss:		1.061486E-01
Epoch took 0.246s

Epoch 85 of 300
  training loss:		1.069230E-01
  validation loss:		1.079142E-01
Epoch took 0.246s

Epoch 86 of 300
  training loss:		1.067520E-01
  validation loss:		1.109146E-01
Epoch took 0.246s

Epoch 87 of 300
  training loss:		1.066797E-01
  validation loss:		1.071865E-01
Epoch took 0.246s

Epoch 88 of 300
  training loss:		1.067402E-01
  validation loss:		1.063476E-01
Epoch took 0.246s

Epoch 89 of 300
  training loss:		1.064582E-01
  validation loss:		1.074893E-01
Epoch took 0.246s

Epoch 90 of 300
  training loss:		1.071008E-01
  validation loss:		1.062180E-01
Epoch took 0.246s

Epoch 91 of 300
  training loss:		1.067377E-01
  validation loss:		1.056971E-01
Epoch took 0.246s

Epoch 92 of 300
  training loss:		1.066107E-01
  validation loss:		1.065460E-01
Epoch took 0.246s

Epoch 93 of 300
  training loss:		1.064275E-01
  validation loss:		1.078867E-01
Epoch took 0.246s

Epoch 94 of 300
  training loss:		1.071183E-01
  validation loss:		1.070694E-01
Epoch took 0.246s

Epoch 95 of 300
  training loss:		1.067515E-01
  validation loss:		1.063430E-01
Epoch took 0.246s

Epoch 96 of 300
  training loss:		1.062745E-01
  validation loss:		1.084503E-01
Epoch took 0.246s

Epoch 97 of 300
  training loss:		1.063948E-01
  validation loss:		1.083492E-01
Epoch took 0.246s

Epoch 98 of 300
  training loss:		1.065604E-01
  validation loss:		1.064110E-01
Epoch took 0.246s

Epoch 99 of 300
  training loss:		1.061124E-01
  validation loss:		1.054508E-01
Epoch took 0.246s

Epoch 100 of 300
  training loss:		1.062833E-01
  validation loss:		1.060723E-01
Epoch took 0.246s

Epoch 101 of 300
  training loss:		1.066986E-01
  validation loss:		1.055894E-01
Epoch took 0.246s

Epoch 102 of 300
  training loss:		1.057903E-01
  validation loss:		1.063056E-01
Epoch took 0.246s

Epoch 103 of 300
  training loss:		1.066543E-01
  validation loss:		1.072404E-01
Epoch took 0.246s

Epoch 104 of 300
  training loss:		1.063060E-01
  validation loss:		1.060040E-01
Epoch took 0.246s

Epoch 105 of 300
  training loss:		1.065426E-01
  validation loss:		1.060519E-01
Epoch took 0.246s

Epoch 106 of 300
  training loss:		1.062636E-01
  validation loss:		1.067721E-01
Epoch took 0.246s

Epoch 107 of 300
  training loss:		1.059543E-01
  validation loss:		1.079186E-01
Epoch took 0.246s

Epoch 108 of 300
  training loss:		1.061827E-01
  validation loss:		1.067371E-01
Epoch took 0.246s

Epoch 109 of 300
  training loss:		1.061838E-01
  validation loss:		1.067408E-01
Epoch took 0.246s

Epoch 110 of 300
  training loss:		1.062201E-01
  validation loss:		1.066374E-01
Epoch took 0.246s

Epoch 111 of 300
  training loss:		1.059780E-01
  validation loss:		1.055308E-01
Epoch took 0.246s

Epoch 112 of 300
  training loss:		1.058965E-01
  validation loss:		1.073722E-01
Epoch took 0.246s

Epoch 113 of 300
  training loss:		1.058750E-01
  validation loss:		1.063448E-01
Epoch took 0.246s

Epoch 114 of 300
  training loss:		1.062895E-01
  validation loss:		1.080250E-01
Epoch took 0.246s

Epoch 115 of 300
  training loss:		1.056571E-01
  validation loss:		1.072545E-01
Epoch took 0.246s

Epoch 116 of 300
  training loss:		1.059497E-01
  validation loss:		1.051466E-01
Epoch took 0.246s

Epoch 117 of 300
  training loss:		1.055468E-01
  validation loss:		1.058413E-01
Epoch took 0.246s

Epoch 118 of 300
  training loss:		1.057637E-01
  validation loss:		1.058539E-01
Epoch took 0.246s

Epoch 119 of 300
  training loss:		1.055665E-01
  validation loss:		1.062315E-01
Epoch took 0.246s

Epoch 120 of 300
  training loss:		1.054748E-01
  validation loss:		1.094199E-01
Epoch took 0.246s

Epoch 121 of 300
  training loss:		1.053701E-01
  validation loss:		1.054579E-01
Epoch took 0.246s

Epoch 122 of 300
  training loss:		1.057260E-01
  validation loss:		1.054573E-01
Epoch took 0.246s

Epoch 123 of 300
  training loss:		1.053934E-01
  validation loss:		1.054092E-01
Epoch took 0.246s

Epoch 124 of 300
  training loss:		1.056843E-01
  validation loss:		1.074354E-01
Epoch took 0.246s

Epoch 125 of 300
  training loss:		1.055216E-01
  validation loss:		1.060648E-01
Epoch took 0.246s

Epoch 126 of 300
  training loss:		1.058270E-01
  validation loss:		1.059461E-01
Epoch took 0.246s

Epoch 127 of 300
  training loss:		1.054847E-01
  validation loss:		1.049391E-01
Epoch took 0.246s

Epoch 128 of 300
  training loss:		1.052554E-01
  validation loss:		1.049760E-01
Epoch took 0.246s

Epoch 129 of 300
  training loss:		1.054138E-01
  validation loss:		1.060991E-01
Epoch took 0.246s

Epoch 130 of 300
  training loss:		1.056219E-01
  validation loss:		1.058354E-01
Epoch took 0.246s

Epoch 131 of 300
  training loss:		1.057050E-01
  validation loss:		1.073365E-01
Epoch took 0.246s

Epoch 132 of 300
  training loss:		1.053737E-01
  validation loss:		1.062336E-01
Epoch took 0.246s

Epoch 133 of 300
  training loss:		1.053369E-01
  validation loss:		1.059474E-01
Epoch took 0.246s

Epoch 134 of 300
  training loss:		1.051510E-01
  validation loss:		1.056028E-01
Epoch took 0.245s

Epoch 135 of 300
  training loss:		1.054218E-01
  validation loss:		1.064314E-01
Epoch took 0.245s

Epoch 136 of 300
  training loss:		1.050604E-01
  validation loss:		1.048727E-01
Epoch took 0.245s

Epoch 137 of 300
  training loss:		1.055249E-01
  validation loss:		1.052305E-01
Epoch took 0.245s

Epoch 138 of 300
  training loss:		1.054118E-01
  validation loss:		1.055117E-01
Epoch took 0.245s

Epoch 139 of 300
  training loss:		1.055915E-01
  validation loss:		1.066378E-01
Epoch took 0.246s

Epoch 140 of 300
  training loss:		1.048862E-01
  validation loss:		1.062635E-01
Epoch took 0.246s

Epoch 141 of 300
  training loss:		1.051981E-01
  validation loss:		1.061550E-01
Epoch took 0.246s

Epoch 142 of 300
  training loss:		1.051817E-01
  validation loss:		1.051929E-01
Epoch took 0.245s

Epoch 143 of 300
  training loss:		1.057894E-01
  validation loss:		1.052255E-01
Epoch took 0.245s

Epoch 144 of 300
  training loss:		1.049066E-01
  validation loss:		1.055700E-01
Epoch took 0.246s

Epoch 145 of 300
  training loss:		1.052642E-01
  validation loss:		1.048283E-01
Epoch took 0.246s

Epoch 146 of 300
  training loss:		1.052896E-01
  validation loss:		1.054482E-01
Epoch took 0.245s

Epoch 147 of 300
  training loss:		1.051402E-01
  validation loss:		1.055324E-01
Epoch took 0.245s

Epoch 148 of 300
  training loss:		1.050970E-01
  validation loss:		1.053906E-01
Epoch took 0.246s

Epoch 149 of 300
  training loss:		1.048137E-01
  validation loss:		1.049283E-01
Epoch took 0.246s

Epoch 150 of 300
  training loss:		1.051240E-01
  validation loss:		1.061134E-01
Epoch took 0.246s

Epoch 151 of 300
  training loss:		1.050987E-01
  validation loss:		1.051274E-01
Epoch took 0.245s

Epoch 152 of 300
  training loss:		1.048228E-01
  validation loss:		1.047248E-01
Epoch took 0.245s

Epoch 153 of 300
  training loss:		1.046230E-01
  validation loss:		1.052823E-01
Epoch took 0.246s

Epoch 154 of 300
  training loss:		1.049095E-01
  validation loss:		1.054983E-01
Epoch took 0.245s

Epoch 155 of 300
  training loss:		1.050925E-01
  validation loss:		1.058516E-01
Epoch took 0.245s

Epoch 156 of 300
  training loss:		1.048467E-01
  validation loss:		1.049867E-01
Epoch took 0.245s

Epoch 157 of 300
  training loss:		1.046513E-01
  validation loss:		1.053394E-01
Epoch took 0.246s

Epoch 158 of 300
  training loss:		1.049037E-01
  validation loss:		1.049535E-01
Epoch took 0.245s

Epoch 159 of 300
  training loss:		1.045921E-01
  validation loss:		1.059342E-01
Epoch took 0.245s

Epoch 160 of 300
  training loss:		1.048832E-01
  validation loss:		1.055259E-01
Epoch took 0.246s

Epoch 161 of 300
  training loss:		1.047320E-01
  validation loss:		1.049395E-01
Epoch took 0.246s

Epoch 162 of 300
  training loss:		1.049060E-01
  validation loss:		1.052542E-01
Epoch took 0.246s

Epoch 163 of 300
  training loss:		1.049264E-01
  validation loss:		1.053911E-01
Epoch took 0.246s

Epoch 164 of 300
  training loss:		1.050385E-01
  validation loss:		1.058815E-01
Epoch took 0.245s

Epoch 165 of 300
  training loss:		1.044279E-01
  validation loss:		1.046396E-01
Epoch took 0.246s

Epoch 166 of 300
  training loss:		1.047831E-01
  validation loss:		1.051657E-01
Epoch took 0.246s

Epoch 167 of 300
  training loss:		1.045944E-01
  validation loss:		1.052964E-01
Epoch took 0.246s

Epoch 168 of 300
  training loss:		1.045431E-01
  validation loss:		1.050170E-01
Epoch took 0.246s

Epoch 169 of 300
  training loss:		1.049803E-01
  validation loss:		1.047223E-01
Epoch took 0.246s

Epoch 170 of 300
  training loss:		1.045064E-01
  validation loss:		1.047503E-01
Epoch took 0.245s

Epoch 171 of 300
  training loss:		1.047798E-01
  validation loss:		1.054242E-01
Epoch took 0.246s

Epoch 172 of 300
  training loss:		1.042884E-01
  validation loss:		1.046601E-01
Epoch took 0.246s

Epoch 173 of 300
  training loss:		1.049078E-01
  validation loss:		1.049364E-01
Epoch took 0.246s

Epoch 174 of 300
  training loss:		1.048721E-01
  validation loss:		1.049716E-01
Epoch took 0.246s

Epoch 175 of 300
  training loss:		1.047768E-01
  validation loss:		1.050517E-01
Epoch took 0.246s

Epoch 176 of 300
  training loss:		1.045101E-01
  validation loss:		1.044276E-01
Epoch took 0.246s

Epoch 177 of 300
  training loss:		1.043145E-01
  validation loss:		1.050259E-01
Epoch took 0.246s

Epoch 178 of 300
  training loss:		1.047106E-01
  validation loss:		1.039647E-01
Epoch took 0.246s

Epoch 179 of 300
  training loss:		1.043854E-01
  validation loss:		1.057982E-01
Epoch took 0.246s

Epoch 180 of 300
  training loss:		1.047530E-01
  validation loss:		1.055847E-01
Epoch took 0.246s

Epoch 181 of 300
  training loss:		1.045138E-01
  validation loss:		1.041416E-01
Epoch took 0.246s

Epoch 182 of 300
  training loss:		1.043844E-01
  validation loss:		1.044837E-01
Epoch took 0.246s

Epoch 183 of 300
  training loss:		1.046871E-01
  validation loss:		1.050505E-01
Epoch took 0.245s

Epoch 184 of 300
  training loss:		1.051255E-01
  validation loss:		1.055289E-01
Epoch took 0.246s

Epoch 185 of 300
  training loss:		1.044277E-01
  validation loss:		1.043007E-01
Epoch took 0.246s

Epoch 186 of 300
  training loss:		1.044697E-01
  validation loss:		1.050940E-01
Epoch took 0.246s

Epoch 187 of 300
  training loss:		1.044140E-01
  validation loss:		1.044313E-01
Epoch took 0.246s

Epoch 188 of 300
  training loss:		1.045750E-01
  validation loss:		1.062202E-01
Epoch took 0.246s

Epoch 189 of 300
  training loss:		1.044330E-01
  validation loss:		1.046567E-01
Epoch took 0.246s

Epoch 190 of 300
  training loss:		1.043300E-01
  validation loss:		1.047895E-01
Epoch took 0.246s

Epoch 191 of 300
  training loss:		1.043254E-01
  validation loss:		1.060499E-01
Epoch took 0.246s

Epoch 192 of 300
  training loss:		1.043722E-01
  validation loss:		1.048106E-01
Epoch took 0.245s

Epoch 193 of 300
  training loss:		1.047235E-01
  validation loss:		1.062824E-01
Epoch took 0.246s

Epoch 194 of 300
  training loss:		1.042611E-01
  validation loss:		1.045058E-01
Epoch took 0.246s

Epoch 195 of 300
  training loss:		1.042643E-01
  validation loss:		1.046505E-01
Epoch took 0.246s

Epoch 196 of 300
  training loss:		1.042926E-01
  validation loss:		1.052069E-01
Epoch took 0.246s

Epoch 197 of 300
  training loss:		1.041830E-01
  validation loss:		1.050968E-01
Epoch took 0.246s

Epoch 198 of 300
  training loss:		1.045584E-01
  validation loss:		1.048879E-01
Epoch took 0.246s

Epoch 199 of 300
  training loss:		1.043267E-01
  validation loss:		1.061312E-01
Epoch took 0.246s

Epoch 200 of 300
  training loss:		1.042648E-01
  validation loss:		1.043116E-01
Epoch took 0.246s

Epoch 201 of 300
  training loss:		1.044795E-01
  validation loss:		1.042551E-01
Epoch took 0.246s

Epoch 202 of 300
  training loss:		1.041382E-01
  validation loss:		1.044399E-01
Epoch took 0.246s

Epoch 203 of 300
  training loss:		1.041926E-01
  validation loss:		1.054434E-01
Epoch took 0.246s

Epoch 204 of 300
  training loss:		1.040436E-01
  validation loss:		1.048981E-01
Epoch took 0.246s

Epoch 205 of 300
  training loss:		1.044308E-01
  validation loss:		1.054251E-01
Epoch took 0.246s

Epoch 206 of 300
  training loss:		1.043747E-01
  validation loss:		1.051364E-01
Epoch took 0.246s

Epoch 207 of 300
  training loss:		1.041079E-01
  validation loss:		1.053460E-01
Epoch took 0.247s

Epoch 208 of 300
  training loss:		1.042926E-01
  validation loss:		1.042642E-01
Epoch took 0.246s

Epoch 209 of 300
  training loss:		1.040391E-01
  validation loss:		1.045895E-01
Epoch took 0.246s

Epoch 210 of 300
  training loss:		1.041154E-01
  validation loss:		1.049581E-01
Epoch took 0.246s

Epoch 211 of 300
  training loss:		1.040135E-01
  validation loss:		1.053520E-01
Epoch took 0.246s

Epoch 212 of 300
  training loss:		1.042507E-01
  validation loss:		1.039192E-01
Epoch took 0.246s

Epoch 213 of 300
  training loss:		1.042914E-01
  validation loss:		1.053582E-01
Epoch took 0.246s

Epoch 214 of 300
  training loss:		1.042913E-01
  validation loss:		1.059607E-01
Epoch took 0.246s

Epoch 215 of 300
  training loss:		1.042492E-01
  validation loss:		1.042826E-01
Epoch took 0.246s

Epoch 216 of 300
  training loss:		1.039748E-01
  validation loss:		1.045070E-01
Epoch took 0.246s

Epoch 217 of 300
  training loss:		1.041903E-01
  validation loss:		1.052694E-01
Epoch took 0.246s

Epoch 218 of 300
  training loss:		1.041078E-01
  validation loss:		1.043476E-01
Epoch took 0.246s

Epoch 219 of 300
  training loss:		1.040620E-01
  validation loss:		1.040048E-01
Epoch took 0.246s

Epoch 220 of 300
  training loss:		1.040338E-01
  validation loss:		1.050843E-01
Epoch took 0.246s

Epoch 221 of 300
  training loss:		1.042226E-01
  validation loss:		1.050373E-01
Epoch took 0.246s

Epoch 222 of 300
  training loss:		1.041410E-01
  validation loss:		1.042182E-01
Epoch took 0.246s

Epoch 223 of 300
  training loss:		1.040699E-01
  validation loss:		1.065730E-01
Epoch took 0.246s

Epoch 224 of 300
  training loss:		1.043766E-01
  validation loss:		1.043317E-01
Epoch took 0.246s

Epoch 225 of 300
  training loss:		1.040862E-01
  validation loss:		1.038595E-01
Epoch took 0.246s

Epoch 226 of 300
  training loss:		1.042150E-01
  validation loss:		1.049056E-01
Epoch took 0.246s

Epoch 227 of 300
  training loss:		1.041094E-01
  validation loss:		1.059776E-01
Epoch took 0.246s

Epoch 228 of 300
  training loss:		1.040401E-01
  validation loss:		1.043581E-01
Epoch took 0.246s

Epoch 229 of 300
  training loss:		1.036039E-01
  validation loss:		1.043107E-01
Epoch took 0.246s

Epoch 230 of 300
  training loss:		1.038776E-01
  validation loss:		1.049693E-01
Epoch took 0.246s

Epoch 231 of 300
  training loss:		1.041247E-01
  validation loss:		1.045253E-01
Epoch took 0.246s

Epoch 232 of 300
  training loss:		1.038715E-01
  validation loss:		1.044364E-01
Epoch took 0.246s

Epoch 233 of 300
  training loss:		1.036378E-01
  validation loss:		1.042494E-01
Epoch took 0.246s

Epoch 234 of 300
  training loss:		1.038132E-01
  validation loss:		1.044011E-01
Epoch took 0.246s

Epoch 235 of 300
  training loss:		1.041121E-01
  validation loss:		1.040158E-01
Epoch took 0.246s

Epoch 236 of 300
  training loss:		1.042039E-01
  validation loss:		1.042005E-01
Epoch took 0.246s

Epoch 237 of 300
  training loss:		1.039048E-01
  validation loss:		1.045757E-01
Epoch took 0.246s

Epoch 238 of 300
  training loss:		1.039057E-01
  validation loss:		1.044758E-01
Epoch took 0.246s

Epoch 239 of 300
  training loss:		1.044752E-01
  validation loss:		1.043550E-01
Epoch took 0.246s

Epoch 240 of 300
  training loss:		1.037857E-01
  validation loss:		1.039091E-01
Epoch took 0.246s

Epoch 241 of 300
  training loss:		1.038225E-01
  validation loss:		1.043549E-01
Epoch took 0.246s

Epoch 242 of 300
  training loss:		1.036560E-01
  validation loss:		1.044223E-01
Epoch took 0.246s

Epoch 243 of 300
  training loss:		1.043226E-01
  validation loss:		1.048331E-01
Epoch took 0.246s

Epoch 244 of 300
  training loss:		1.039562E-01
  validation loss:		1.049204E-01
Epoch took 0.246s

Epoch 245 of 300
  training loss:		1.039027E-01
  validation loss:		1.050098E-01
Epoch took 0.246s

Epoch 246 of 300
  training loss:		1.038306E-01
  validation loss:		1.046951E-01
Epoch took 0.246s

Epoch 247 of 300
  training loss:		1.038683E-01
  validation loss:		1.047247E-01
Epoch took 0.246s

Epoch 248 of 300
  training loss:		1.038221E-01
  validation loss:		1.043331E-01
Epoch took 0.246s

Epoch 249 of 300
  training loss:		1.037577E-01
  validation loss:		1.050049E-01
Epoch took 0.246s

Epoch 250 of 300
  training loss:		1.038973E-01
  validation loss:		1.040718E-01
Epoch took 0.246s

Epoch 251 of 300
  training loss:		1.037704E-01
  validation loss:		1.037208E-01
Epoch took 0.246s

Epoch 252 of 300
  training loss:		1.037473E-01
  validation loss:		1.039671E-01
Epoch took 0.246s

Epoch 253 of 300
  training loss:		1.036500E-01
  validation loss:		1.045227E-01
Epoch took 0.246s

Epoch 254 of 300
  training loss:		1.038210E-01
  validation loss:		1.041814E-01
Epoch took 0.246s

Epoch 255 of 300
  training loss:		1.035995E-01
  validation loss:		1.047827E-01
Epoch took 0.246s

Epoch 256 of 300
  training loss:		1.039116E-01
  validation loss:		1.042296E-01
Epoch took 0.246s

Epoch 257 of 300
  training loss:		1.036065E-01
  validation loss:		1.044935E-01
Epoch took 0.246s

Epoch 258 of 300
  training loss:		1.038274E-01
  validation loss:		1.049746E-01
Epoch took 0.246s

Epoch 259 of 300
  training loss:		1.036540E-01
  validation loss:		1.045151E-01
Epoch took 0.246s

Epoch 260 of 300
  training loss:		1.037249E-01
  validation loss:		1.038335E-01
Epoch took 0.246s

Epoch 261 of 300
  training loss:		1.039159E-01
  validation loss:		1.038058E-01
Epoch took 0.246s

Epoch 262 of 300
  training loss:		1.037515E-01
  validation loss:		1.057145E-01
Epoch took 0.246s

Epoch 263 of 300
  training loss:		1.039896E-01
  validation loss:		1.037606E-01
Epoch took 0.246s

Epoch 264 of 300
  training loss:		1.037440E-01
  validation loss:		1.034977E-01
Epoch took 0.246s

Epoch 265 of 300
  training loss:		1.035025E-01
  validation loss:		1.045848E-01
Epoch took 0.246s

Epoch 266 of 300
  training loss:		1.038159E-01
  validation loss:		1.045905E-01
Epoch took 0.246s

Epoch 267 of 300
  training loss:		1.036000E-01
  validation loss:		1.043455E-01
Epoch took 0.246s

Epoch 268 of 300
  training loss:		1.034700E-01
  validation loss:		1.034022E-01
Epoch took 0.246s

Epoch 269 of 300
  training loss:		1.036674E-01
  validation loss:		1.036407E-01
Epoch took 0.246s

Epoch 270 of 300
  training loss:		1.037880E-01
  validation loss:		1.041113E-01
Epoch took 0.246s

Epoch 271 of 300
  training loss:		1.037523E-01
  validation loss:		1.048993E-01
Epoch took 0.246s

Epoch 272 of 300
  training loss:		1.036031E-01
  validation loss:		1.035801E-01
Epoch took 0.246s

Epoch 273 of 300
  training loss:		1.038097E-01
  validation loss:		1.045586E-01
Epoch took 0.246s

Epoch 274 of 300
  training loss:		1.039649E-01
  validation loss:		1.038037E-01
Epoch took 0.246s

Epoch 275 of 300
  training loss:		1.036948E-01
  validation loss:		1.043633E-01
Epoch took 0.246s

Epoch 276 of 300
  training loss:		1.036395E-01
  validation loss:		1.045530E-01
Epoch took 0.246s

Epoch 277 of 300
  training loss:		1.037527E-01
  validation loss:		1.037298E-01
Epoch took 0.246s

Epoch 278 of 300
  training loss:		1.037201E-01
  validation loss:		1.042954E-01
Epoch took 0.246s

Epoch 279 of 300
  training loss:		1.036333E-01
  validation loss:		1.033901E-01
Epoch took 0.246s

Epoch 280 of 300
  training loss:		1.037301E-01
  validation loss:		1.047164E-01
Epoch took 0.246s

Epoch 281 of 300
  training loss:		1.035790E-01
  validation loss:		1.045163E-01
Epoch took 0.246s

Epoch 282 of 300
  training loss:		1.037319E-01
  validation loss:		1.048833E-01
Epoch took 0.246s

Epoch 283 of 300
  training loss:		1.037355E-01
  validation loss:		1.041867E-01
Epoch took 0.246s

Epoch 284 of 300
  training loss:		1.035061E-01
  validation loss:		1.041253E-01
Epoch took 0.246s

Epoch 285 of 300
  training loss:		1.035690E-01
  validation loss:		1.039689E-01
Epoch took 0.246s

Epoch 286 of 300
  training loss:		1.034926E-01
  validation loss:		1.047260E-01
Epoch took 0.246s

Epoch 287 of 300
  training loss:		1.036468E-01
  validation loss:		1.042792E-01
Epoch took 0.246s

Epoch 288 of 300
  training loss:		1.035347E-01
  validation loss:		1.044335E-01
Epoch took 0.246s

Epoch 289 of 300
  training loss:		1.033843E-01
  validation loss:		1.043754E-01
Epoch took 0.246s

Epoch 290 of 300
  training loss:		1.038586E-01
  validation loss:		1.037483E-01
Epoch took 0.246s

Epoch 291 of 300
  training loss:		1.037054E-01
  validation loss:		1.051697E-01
Epoch took 0.246s

Epoch 292 of 300
  training loss:		1.035242E-01
  validation loss:		1.041211E-01
Epoch took 0.246s

Epoch 293 of 300
  training loss:		1.032293E-01
  validation loss:		1.042474E-01
Epoch took 0.246s

Epoch 294 of 300
  training loss:		1.034480E-01
  validation loss:		1.039798E-01
Epoch took 0.246s

Epoch 295 of 300
  training loss:		1.034894E-01
  validation loss:		1.037092E-01
Epoch took 0.246s

Epoch 296 of 300
  training loss:		1.035119E-01
  validation loss:		1.035106E-01
Epoch took 0.246s

Epoch 297 of 300
  training loss:		1.034105E-01
  validation loss:		1.044222E-01
Epoch took 0.246s

Epoch 298 of 300
  training loss:		1.036821E-01
  validation loss:		1.037176E-01
Epoch took 0.246s

Epoch 299 of 300
  training loss:		1.033190E-01
  validation loss:		1.040440E-01
Epoch took 0.246s

Epoch 300 of 300
  training loss:		1.035244E-01
  validation loss:		1.037011E-01
Epoch took 0.246s

Early stopping, val-loss increased over the last 20 epochs from 0.104167162378 to 0.104193280396
Saving model from epoch 280
Training MSE: 2.47989e-14
Validation MSE: 2.50802e-14
Training R2: 0.737068583238
Validation R2: 0.732246728661
