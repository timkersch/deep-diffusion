Training network with 56340 training samples and 18780 validation samples
Epoch 1 of 300
  training loss:		3.036747E-01
  validation loss:		2.773270E-01
Epoch took 0.245s

Epoch 2 of 300
  training loss:		2.626871E-01
  validation loss:		2.499436E-01
Epoch took 0.246s

Epoch 3 of 300
  training loss:		2.389164E-01
  validation loss:		2.352915E-01
Epoch took 0.246s

Epoch 4 of 300
  training loss:		2.198210E-01
  validation loss:		2.108923E-01
Epoch took 0.245s

Epoch 5 of 300
  training loss:		2.013149E-01
  validation loss:		1.892742E-01
Epoch took 0.245s

Epoch 6 of 300
  training loss:		1.877639E-01
  validation loss:		1.833119E-01
Epoch took 0.245s

Epoch 7 of 300
  training loss:		1.771380E-01
  validation loss:		1.758213E-01
Epoch took 0.245s

Epoch 8 of 300
  training loss:		1.687782E-01
  validation loss:		1.628593E-01
Epoch took 0.245s

Epoch 9 of 300
  training loss:		1.603145E-01
  validation loss:		1.612066E-01
Epoch took 0.245s

Epoch 10 of 300
  training loss:		1.542335E-01
  validation loss:		1.481217E-01
Epoch took 0.245s

Epoch 11 of 300
  training loss:		1.482911E-01
  validation loss:		1.462108E-01
Epoch took 0.245s

Epoch 12 of 300
  training loss:		1.434907E-01
  validation loss:		1.478054E-01
Epoch took 0.245s

Epoch 13 of 300
  training loss:		1.402313E-01
  validation loss:		1.364021E-01
Epoch took 0.245s

Epoch 14 of 300
  training loss:		1.380196E-01
  validation loss:		1.344634E-01
Epoch took 0.245s

Epoch 15 of 300
  training loss:		1.319841E-01
  validation loss:		1.306375E-01
Epoch took 0.245s

Epoch 16 of 300
  training loss:		1.305348E-01
  validation loss:		1.306737E-01
Epoch took 0.245s

Epoch 17 of 300
  training loss:		1.295530E-01
  validation loss:		1.268472E-01
Epoch took 0.245s

Epoch 18 of 300
  training loss:		1.261524E-01
  validation loss:		1.265527E-01
Epoch took 0.245s

Epoch 19 of 300
  training loss:		1.237838E-01
  validation loss:		1.254441E-01
Epoch took 0.245s

Epoch 20 of 300
  training loss:		1.243730E-01
  validation loss:		1.255934E-01
Epoch took 0.246s

Epoch 21 of 300
  training loss:		1.222489E-01
  validation loss:		1.177168E-01
Epoch took 0.245s

Epoch 22 of 300
  training loss:		1.219607E-01
  validation loss:		1.259673E-01
Epoch took 0.247s

Epoch 23 of 300
  training loss:		1.206301E-01
  validation loss:		1.189188E-01
Epoch took 0.246s

Epoch 24 of 300
  training loss:		1.189111E-01
  validation loss:		1.167882E-01
Epoch took 0.245s

Epoch 25 of 300
  training loss:		1.183735E-01
  validation loss:		1.161671E-01
Epoch took 0.245s

Epoch 26 of 300
  training loss:		1.169969E-01
  validation loss:		1.195576E-01
Epoch took 0.245s

Epoch 27 of 300
  training loss:		1.172837E-01
  validation loss:		1.183623E-01
Epoch took 0.245s

Epoch 28 of 300
  training loss:		1.163953E-01
  validation loss:		1.104071E-01
Epoch took 0.247s

Epoch 29 of 300
  training loss:		1.167404E-01
  validation loss:		1.110327E-01
Epoch took 0.246s

Epoch 30 of 300
  training loss:		1.159233E-01
  validation loss:		1.157943E-01
Epoch took 0.245s

Epoch 31 of 300
  training loss:		1.162142E-01
  validation loss:		1.195129E-01
Epoch took 0.245s

Epoch 32 of 300
  training loss:		1.140225E-01
  validation loss:		1.147555E-01
Epoch took 0.245s

Epoch 33 of 300
  training loss:		1.150992E-01
  validation loss:		1.110730E-01
Epoch took 0.245s

Epoch 34 of 300
  training loss:		1.139527E-01
  validation loss:		1.147478E-01
Epoch took 0.245s

Epoch 35 of 300
  training loss:		1.144259E-01
  validation loss:		1.144191E-01
Epoch took 0.245s

Epoch 36 of 300
  training loss:		1.133249E-01
  validation loss:		1.121127E-01
Epoch took 0.245s

Epoch 37 of 300
  training loss:		1.134742E-01
  validation loss:		1.121598E-01
Epoch took 0.245s

Epoch 38 of 300
  training loss:		1.130532E-01
  validation loss:		1.111599E-01
Epoch took 0.245s

Epoch 39 of 300
  training loss:		1.135031E-01
  validation loss:		1.128312E-01
Epoch took 0.245s

Epoch 40 of 300
  training loss:		1.135453E-01
  validation loss:		1.103265E-01
Epoch took 0.245s

Epoch 41 of 300
  training loss:		1.118774E-01
  validation loss:		1.095704E-01
Epoch took 0.245s

Epoch 42 of 300
  training loss:		1.125360E-01
  validation loss:		1.158651E-01
Epoch took 0.245s

Epoch 43 of 300
  training loss:		1.122278E-01
  validation loss:		1.170537E-01
Epoch took 0.245s

Epoch 44 of 300
  training loss:		1.106876E-01
  validation loss:		1.113038E-01
Epoch took 0.245s

Epoch 45 of 300
  training loss:		1.118688E-01
  validation loss:		1.102753E-01
Epoch took 0.245s

Epoch 46 of 300
  training loss:		1.121269E-01
  validation loss:		1.124482E-01
Epoch took 0.245s

Epoch 47 of 300
  training loss:		1.111576E-01
  validation loss:		1.124413E-01
Epoch took 0.245s

Epoch 48 of 300
  training loss:		1.118064E-01
  validation loss:		1.132995E-01
Epoch took 0.245s

Epoch 49 of 300
  training loss:		1.114937E-01
  validation loss:		1.133621E-01
Epoch took 0.245s

Epoch 50 of 300
  training loss:		1.107740E-01
  validation loss:		1.113136E-01
Epoch took 0.245s

Epoch 51 of 300
  training loss:		1.107427E-01
  validation loss:		1.085541E-01
Epoch took 0.245s

Epoch 52 of 300
  training loss:		1.105924E-01
  validation loss:		1.137667E-01
Epoch took 0.245s

Epoch 53 of 300
  training loss:		1.109001E-01
  validation loss:		1.088114E-01
Epoch took 0.245s

Epoch 54 of 300
  training loss:		1.103225E-01
  validation loss:		1.088033E-01
Epoch took 0.245s

Epoch 55 of 300
  training loss:		1.110425E-01
  validation loss:		1.080448E-01
Epoch took 0.245s

Epoch 56 of 300
  training loss:		1.104036E-01
  validation loss:		1.091468E-01
Epoch took 0.245s

Epoch 57 of 300
  training loss:		1.094629E-01
  validation loss:		1.116228E-01
Epoch took 0.245s

Epoch 58 of 300
  training loss:		1.098476E-01
  validation loss:		1.075788E-01
Epoch took 0.245s

Epoch 59 of 300
  training loss:		1.095494E-01
  validation loss:		1.083955E-01
Epoch took 0.245s

Epoch 60 of 300
  training loss:		1.102774E-01
  validation loss:		1.087712E-01
Epoch took 0.245s

Epoch 61 of 300
  training loss:		1.098059E-01
  validation loss:		1.069419E-01
Epoch took 0.246s

Epoch 62 of 300
  training loss:		1.100749E-01
  validation loss:		1.106368E-01
Epoch took 0.245s

Epoch 63 of 300
  training loss:		1.096470E-01
  validation loss:		1.076514E-01
Epoch took 0.245s

Epoch 64 of 300
  training loss:		1.092380E-01
  validation loss:		1.124958E-01
Epoch took 0.245s

Epoch 65 of 300
  training loss:		1.100930E-01
  validation loss:		1.102750E-01
Epoch took 0.245s

Epoch 66 of 300
  training loss:		1.099720E-01
  validation loss:		1.087023E-01
Epoch took 0.245s

Epoch 67 of 300
  training loss:		1.086121E-01
  validation loss:		1.123756E-01
Epoch took 0.245s

Epoch 68 of 300
  training loss:		1.092554E-01
  validation loss:		1.094638E-01
Epoch took 0.245s

Epoch 69 of 300
  training loss:		1.093894E-01
  validation loss:		1.110810E-01
Epoch took 0.245s

Epoch 70 of 300
  training loss:		1.089802E-01
  validation loss:		1.096277E-01
Epoch took 0.245s

Epoch 71 of 300
  training loss:		1.088266E-01
  validation loss:		1.135783E-01
Epoch took 0.245s

Epoch 72 of 300
  training loss:		1.089518E-01
  validation loss:		1.110599E-01
Epoch took 0.245s

Epoch 73 of 300
  training loss:		1.093368E-01
  validation loss:		1.101067E-01
Epoch took 0.245s

Epoch 74 of 300
  training loss:		1.087966E-01
  validation loss:		1.090292E-01
Epoch took 0.245s

Epoch 75 of 300
  training loss:		1.083079E-01
  validation loss:		1.086883E-01
Epoch took 0.245s

Epoch 76 of 300
  training loss:		1.083558E-01
  validation loss:		1.098407E-01
Epoch took 0.245s

Epoch 77 of 300
  training loss:		1.077253E-01
  validation loss:		1.077370E-01
Epoch took 0.245s

Epoch 78 of 300
  training loss:		1.084292E-01
  validation loss:		1.079955E-01
Epoch took 0.245s

Epoch 79 of 300
  training loss:		1.084441E-01
  validation loss:		1.101767E-01
Epoch took 0.245s

Epoch 80 of 300
  training loss:		1.087094E-01
  validation loss:		1.079936E-01
Epoch took 0.245s

Epoch 81 of 300
  training loss:		1.087967E-01
  validation loss:		1.105575E-01
Epoch took 0.245s

Epoch 82 of 300
  training loss:		1.081395E-01
  validation loss:		1.070964E-01
Epoch took 0.245s

Epoch 83 of 300
  training loss:		1.086515E-01
  validation loss:		1.120530E-01
Epoch took 0.245s

Epoch 84 of 300
  training loss:		1.081813E-01
  validation loss:		1.061645E-01
Epoch took 0.245s

Epoch 85 of 300
  training loss:		1.077938E-01
  validation loss:		1.066320E-01
Epoch took 0.245s

Epoch 86 of 300
  training loss:		1.078797E-01
  validation loss:		1.080492E-01
Epoch took 0.245s

Epoch 87 of 300
  training loss:		1.076571E-01
  validation loss:		1.071551E-01
Epoch took 0.245s

Epoch 88 of 300
  training loss:		1.076016E-01
  validation loss:		1.066947E-01
Epoch took 0.245s

Epoch 89 of 300
  training loss:		1.080025E-01
  validation loss:		1.100949E-01
Epoch took 0.245s

Epoch 90 of 300
  training loss:		1.083982E-01
  validation loss:		1.085200E-01
Epoch took 0.245s

Epoch 91 of 300
  training loss:		1.080146E-01
  validation loss:		1.075556E-01
Epoch took 0.245s

Epoch 92 of 300
  training loss:		1.073685E-01
  validation loss:		1.061987E-01
Epoch took 0.245s

Epoch 93 of 300
  training loss:		1.081122E-01
  validation loss:		1.068550E-01
Epoch took 0.245s

Epoch 94 of 300
  training loss:		1.075428E-01
  validation loss:		1.140671E-01
Epoch took 0.245s

Epoch 95 of 300
  training loss:		1.075655E-01
  validation loss:		1.120722E-01
Epoch took 0.245s

Epoch 96 of 300
  training loss:		1.075185E-01
  validation loss:		1.058073E-01
Epoch took 0.245s

Epoch 97 of 300
  training loss:		1.070352E-01
  validation loss:		1.066617E-01
Epoch took 0.245s

Epoch 98 of 300
  training loss:		1.065957E-01
  validation loss:		1.089744E-01
Epoch took 0.245s

Epoch 99 of 300
  training loss:		1.076024E-01
  validation loss:		1.074187E-01
Epoch took 0.245s

Epoch 100 of 300
  training loss:		1.070696E-01
  validation loss:		1.092283E-01
Epoch took 0.245s

Epoch 101 of 300
  training loss:		1.074862E-01
  validation loss:		1.095156E-01
Epoch took 0.245s

Epoch 102 of 300
  training loss:		1.067655E-01
  validation loss:		1.090977E-01
Epoch took 0.245s

Epoch 103 of 300
  training loss:		1.073898E-01
  validation loss:		1.083321E-01
Epoch took 0.245s

Epoch 104 of 300
  training loss:		1.075477E-01
  validation loss:		1.077853E-01
Epoch took 0.245s

Epoch 105 of 300
  training loss:		1.068108E-01
  validation loss:		1.069849E-01
Epoch took 0.245s

Epoch 106 of 300
  training loss:		1.068436E-01
  validation loss:		1.079732E-01
Epoch took 0.245s

Epoch 107 of 300
  training loss:		1.072517E-01
  validation loss:		1.070835E-01
Epoch took 0.245s

Epoch 108 of 300
  training loss:		1.067785E-01
  validation loss:		1.071288E-01
Epoch took 0.245s

Epoch 109 of 300
  training loss:		1.072664E-01
  validation loss:		1.085049E-01
Epoch took 0.245s

Epoch 110 of 300
  training loss:		1.067557E-01
  validation loss:		1.080232E-01
Epoch took 0.245s

Epoch 111 of 300
  training loss:		1.064208E-01
  validation loss:		1.070421E-01
Epoch took 0.245s

Epoch 112 of 300
  training loss:		1.069564E-01
  validation loss:		1.074716E-01
Epoch took 0.245s

Epoch 113 of 300
  training loss:		1.068574E-01
  validation loss:		1.085799E-01
Epoch took 0.245s

Epoch 114 of 300
  training loss:		1.063846E-01
  validation loss:		1.054663E-01
Epoch took 0.245s

Epoch 115 of 300
  training loss:		1.066882E-01
  validation loss:		1.099062E-01
Epoch took 0.245s

Epoch 116 of 300
  training loss:		1.065878E-01
  validation loss:		1.076380E-01
Epoch took 0.245s

Epoch 117 of 300
  training loss:		1.066289E-01
  validation loss:		1.072622E-01
Epoch took 0.245s

Epoch 118 of 300
  training loss:		1.065744E-01
  validation loss:		1.066354E-01
Epoch took 0.245s

Epoch 119 of 300
  training loss:		1.066701E-01
  validation loss:		1.061135E-01
Epoch took 0.245s

Epoch 120 of 300
  training loss:		1.062769E-01
  validation loss:		1.064457E-01
Epoch took 0.245s

Epoch 121 of 300
  training loss:		1.063889E-01
  validation loss:		1.059395E-01
Epoch took 0.245s

Epoch 122 of 300
  training loss:		1.062880E-01
  validation loss:		1.058206E-01
Epoch took 0.245s

Epoch 123 of 300
  training loss:		1.066446E-01
  validation loss:		1.050599E-01
Epoch took 0.245s

Epoch 124 of 300
  training loss:		1.064442E-01
  validation loss:		1.071457E-01
Epoch took 0.245s

Epoch 125 of 300
  training loss:		1.064116E-01
  validation loss:		1.073619E-01
Epoch took 0.245s

Epoch 126 of 300
  training loss:		1.059759E-01
  validation loss:		1.086066E-01
Epoch took 0.245s

Epoch 127 of 300
  training loss:		1.065749E-01
  validation loss:		1.064389E-01
Epoch took 0.245s

Epoch 128 of 300
  training loss:		1.060235E-01
  validation loss:		1.059445E-01
Epoch took 0.245s

Epoch 129 of 300
  training loss:		1.064139E-01
  validation loss:		1.062301E-01
Epoch took 0.245s

Epoch 130 of 300
  training loss:		1.060341E-01
  validation loss:		1.068542E-01
Epoch took 0.245s

Epoch 131 of 300
  training loss:		1.063224E-01
  validation loss:		1.060481E-01
Epoch took 0.245s

Epoch 132 of 300
  training loss:		1.062892E-01
  validation loss:		1.067679E-01
Epoch took 0.245s

Epoch 133 of 300
  training loss:		1.061409E-01
  validation loss:		1.082492E-01
Epoch took 0.245s

Epoch 134 of 300
  training loss:		1.064419E-01
  validation loss:		1.067106E-01
Epoch took 0.245s

Epoch 135 of 300
  training loss:		1.059577E-01
  validation loss:		1.066071E-01
Epoch took 0.245s

Epoch 136 of 300
  training loss:		1.061059E-01
  validation loss:		1.066550E-01
Epoch took 0.245s

Epoch 137 of 300
  training loss:		1.063638E-01
  validation loss:		1.057170E-01
Epoch took 0.245s

Epoch 138 of 300
  training loss:		1.058924E-01
  validation loss:		1.059941E-01
Epoch took 0.245s

Epoch 139 of 300
  training loss:		1.061015E-01
  validation loss:		1.056832E-01
Epoch took 0.245s

Epoch 140 of 300
  training loss:		1.061485E-01
  validation loss:		1.063501E-01
Epoch took 0.245s

Epoch 141 of 300
  training loss:		1.058481E-01
  validation loss:		1.061533E-01
Epoch took 0.245s

Epoch 142 of 300
  training loss:		1.058187E-01
  validation loss:		1.064458E-01
Epoch took 0.245s

Epoch 143 of 300
  training loss:		1.061446E-01
  validation loss:		1.093172E-01
Epoch took 0.245s

Epoch 144 of 300
  training loss:		1.060823E-01
  validation loss:		1.078110E-01
Epoch took 0.245s

Epoch 145 of 300
  training loss:		1.059141E-01
  validation loss:		1.056766E-01
Epoch took 0.245s

Epoch 146 of 300
  training loss:		1.061603E-01
  validation loss:		1.068831E-01
Epoch took 0.245s

Epoch 147 of 300
  training loss:		1.060779E-01
  validation loss:		1.056024E-01
Epoch took 0.245s

Epoch 148 of 300
  training loss:		1.055084E-01
  validation loss:		1.065127E-01
Epoch took 0.246s

Epoch 149 of 300
  training loss:		1.057673E-01
  validation loss:		1.067360E-01
Epoch took 0.245s

Epoch 150 of 300
  training loss:		1.058821E-01
  validation loss:		1.092657E-01
Epoch took 0.245s

Epoch 151 of 300
  training loss:		1.057461E-01
  validation loss:		1.081836E-01
Epoch took 0.245s

Epoch 152 of 300
  training loss:		1.060383E-01
  validation loss:		1.055325E-01
Epoch took 0.245s

Epoch 153 of 300
  training loss:		1.057276E-01
  validation loss:		1.062635E-01
Epoch took 0.245s

Epoch 154 of 300
  training loss:		1.056340E-01
  validation loss:		1.070364E-01
Epoch took 0.245s

Epoch 155 of 300
  training loss:		1.054297E-01
  validation loss:		1.081131E-01
Epoch took 0.245s

Epoch 156 of 300
  training loss:		1.056682E-01
  validation loss:		1.061611E-01
Epoch took 0.245s

Epoch 157 of 300
  training loss:		1.059198E-01
  validation loss:		1.063391E-01
Epoch took 0.245s

Epoch 158 of 300
  training loss:		1.055125E-01
  validation loss:		1.071058E-01
Epoch took 0.245s

Epoch 159 of 300
  training loss:		1.058139E-01
  validation loss:		1.073395E-01
Epoch took 0.245s

Epoch 160 of 300
  training loss:		1.058631E-01
  validation loss:		1.057773E-01
Epoch took 0.245s

Early stopping, val-loss increased over the last 20 epochs from 0.106509219605 to 0.106912786812
Saving model from epoch 140
Training MSE: 2.52762e-14
Validation MSE: 2.55337e-14
Training R2: 0.732008248189
Validation R2: 0.727405635124
