Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.133139E-01
  validation loss:		7.751767E-02
Epoch took 8.847s

Epoch 2 of 100
  training loss:		7.048436E-02
  validation loss:		6.368583E-02
Epoch took 8.091s

Epoch 3 of 100
  training loss:		6.034276E-02
  validation loss:		5.596348E-02
Epoch took 9.181s

Epoch 4 of 100
  training loss:		5.389474E-02
  validation loss:		5.059158E-02
Epoch took 8.039s

Epoch 5 of 100
  training loss:		4.931919E-02
  validation loss:		4.685391E-02
Epoch took 7.532s

Epoch 6 of 100
  training loss:		4.585909E-02
  validation loss:		4.388411E-02
Epoch took 8.591s

Epoch 7 of 100
  training loss:		4.312202E-02
  validation loss:		4.199778E-02
Epoch took 8.982s

Epoch 8 of 100
  training loss:		4.108265E-02
  validation loss:		3.966829E-02
Epoch took 8.718s

Epoch 9 of 100
  training loss:		3.937308E-02
  validation loss:		3.827100E-02
Epoch took 8.489s

Epoch 10 of 100
  training loss:		3.784724E-02
  validation loss:		3.765401E-02
Epoch took 7.535s

Epoch 11 of 100
  training loss:		3.677457E-02
  validation loss:		3.578496E-02
Epoch took 7.885s

Epoch 12 of 100
  training loss:		3.572832E-02
  validation loss:		3.491777E-02
Epoch took 8.772s

Epoch 13 of 100
  training loss:		3.493474E-02
  validation loss:		3.446633E-02
Epoch took 9.387s

Epoch 14 of 100
  training loss:		3.418857E-02
  validation loss:		3.492687E-02
Epoch took 8.363s

Epoch 15 of 100
  training loss:		3.354130E-02
  validation loss:		3.309737E-02
Epoch took 7.709s

Epoch 16 of 100
  training loss:		3.295224E-02
  validation loss:		3.266256E-02
Epoch took 7.123s

Epoch 17 of 100
  training loss:		3.247458E-02
  validation loss:		3.258326E-02
Epoch took 8.200s

Epoch 18 of 100
  training loss:		3.199260E-02
  validation loss:		3.198341E-02
Epoch took 8.300s

Epoch 19 of 100
  training loss:		3.166515E-02
  validation loss:		3.142801E-02
Epoch took 9.519s

Epoch 20 of 100
  training loss:		3.140013E-02
  validation loss:		3.100065E-02
Epoch took 9.442s

Epoch 21 of 100
  training loss:		3.106535E-02
  validation loss:		3.089762E-02
Epoch took 8.530s

Epoch 22 of 100
  training loss:		3.066781E-02
  validation loss:		3.067070E-02
Epoch took 8.670s

Epoch 23 of 100
  training loss:		3.048040E-02
  validation loss:		3.031714E-02
Epoch took 8.622s

Epoch 24 of 100
  training loss:		3.026135E-02
  validation loss:		2.983077E-02
Epoch took 8.624s

Epoch 25 of 100
  training loss:		3.012591E-02
  validation loss:		2.968037E-02
Epoch took 7.828s

Epoch 26 of 100
  training loss:		2.979655E-02
  validation loss:		2.955130E-02
Epoch took 7.851s

Epoch 27 of 100
  training loss:		2.961025E-02
  validation loss:		2.959013E-02
Epoch took 8.515s

Epoch 28 of 100
  training loss:		2.941188E-02
  validation loss:		2.932328E-02
Epoch took 9.007s

Epoch 29 of 100
  training loss:		2.922439E-02
  validation loss:		2.877627E-02
Epoch took 8.909s

Epoch 30 of 100
  training loss:		2.910199E-02
  validation loss:		2.910783E-02
Epoch took 8.497s

Epoch 31 of 100
  training loss:		2.894413E-02
  validation loss:		2.902179E-02
Epoch took 7.964s

Epoch 32 of 100
  training loss:		2.883582E-02
  validation loss:		2.848852E-02
Epoch took 7.700s

Epoch 33 of 100
  training loss:		2.861329E-02
  validation loss:		2.839851E-02
Epoch took 8.690s

Epoch 34 of 100
  training loss:		2.849900E-02
  validation loss:		2.884297E-02
Epoch took 8.653s

Epoch 35 of 100
  training loss:		2.836417E-02
  validation loss:		2.814907E-02
Epoch took 9.403s

Epoch 36 of 100
  training loss:		2.829211E-02
  validation loss:		2.796635E-02
Epoch took 9.593s

Epoch 37 of 100
  training loss:		2.814235E-02
  validation loss:		2.805702E-02
Epoch took 8.355s

Epoch 38 of 100
  training loss:		2.811447E-02
  validation loss:		2.803690E-02
Epoch took 8.011s

Epoch 39 of 100
  training loss:		2.799515E-02
  validation loss:		2.788936E-02
Epoch took 8.934s

Epoch 40 of 100
  training loss:		2.790369E-02
  validation loss:		2.760089E-02
Epoch took 8.943s

Epoch 41 of 100
  training loss:		2.781435E-02
  validation loss:		2.746830E-02
Epoch took 8.715s

Epoch 42 of 100
  training loss:		2.779114E-02
  validation loss:		2.750105E-02
Epoch took 9.028s

Epoch 43 of 100
  training loss:		2.773323E-02
  validation loss:		2.771154E-02
Epoch took 8.618s

Epoch 44 of 100
  training loss:		2.753007E-02
  validation loss:		2.776991E-02
Epoch took 8.705s

Epoch 45 of 100
  training loss:		2.749743E-02
  validation loss:		2.769605E-02
Epoch took 8.973s

Epoch 46 of 100
  training loss:		2.747633E-02
  validation loss:		2.724512E-02
Epoch took 9.026s

Epoch 47 of 100
  training loss:		2.733498E-02
  validation loss:		2.713475E-02
Epoch took 9.020s

Epoch 48 of 100
  training loss:		2.726088E-02
  validation loss:		2.726784E-02
Epoch took 8.255s

Epoch 49 of 100
  training loss:		2.726390E-02
  validation loss:		2.703580E-02
Epoch took 7.827s

Epoch 50 of 100
  training loss:		2.717341E-02
  validation loss:		2.736336E-02
Epoch took 8.353s

Epoch 51 of 100
  training loss:		2.720146E-02
  validation loss:		2.689213E-02
Epoch took 7.970s

Epoch 52 of 100
  training loss:		2.707654E-02
  validation loss:		2.697443E-02
Epoch took 8.734s

Epoch 53 of 100
  training loss:		2.709198E-02
  validation loss:		2.820102E-02
Epoch took 9.232s

Epoch 54 of 100
  training loss:		2.699967E-02
  validation loss:		2.783346E-02
Epoch took 8.623s

Epoch 55 of 100
  training loss:		2.699408E-02
  validation loss:		2.729942E-02
Epoch took 10.006s

Epoch 56 of 100
  training loss:		2.696756E-02
  validation loss:		2.720799E-02
Epoch took 8.935s

Epoch 57 of 100
  training loss:		2.703180E-02
  validation loss:		2.685850E-02
Epoch took 8.973s

Epoch 58 of 100
  training loss:		2.681976E-02
  validation loss:		2.699127E-02
Epoch took 10.013s

Epoch 59 of 100
  training loss:		2.682634E-02
  validation loss:		2.715203E-02
Epoch took 8.208s

Epoch 60 of 100
  training loss:		2.683804E-02
  validation loss:		2.689397E-02
Epoch took 8.277s

Epoch 61 of 100
  training loss:		2.671537E-02
  validation loss:		2.660797E-02
Epoch took 7.939s

Epoch 62 of 100
  training loss:		2.675494E-02
  validation loss:		2.736701E-02
Epoch took 8.589s

Epoch 63 of 100
  training loss:		2.683116E-02
  validation loss:		2.671670E-02
Epoch took 8.770s

Epoch 64 of 100
  training loss:		2.667921E-02
  validation loss:		2.657686E-02
Epoch took 9.210s

Epoch 65 of 100
  training loss:		2.672803E-02
  validation loss:		2.663611E-02
Epoch took 8.404s

Epoch 66 of 100
  training loss:		2.671495E-02
  validation loss:		2.655073E-02
Epoch took 8.071s

Epoch 67 of 100
  training loss:		2.665895E-02
  validation loss:		2.672859E-02
Epoch took 8.620s

Epoch 68 of 100
  training loss:		2.656716E-02
  validation loss:		2.660621E-02
Epoch took 9.010s

Epoch 69 of 100
  training loss:		2.659318E-02
  validation loss:		2.661646E-02
Epoch took 8.395s

Epoch 70 of 100
  training loss:		2.652789E-02
  validation loss:		2.671113E-02
Epoch took 9.438s

Epoch 71 of 100
  training loss:		2.661227E-02
  validation loss:		2.668070E-02
Epoch took 8.013s

Epoch 72 of 100
  training loss:		2.649635E-02
  validation loss:		2.651823E-02
Epoch took 8.104s

Epoch 73 of 100
  training loss:		2.649179E-02
  validation loss:		2.636509E-02
Epoch took 7.962s

Epoch 74 of 100
  training loss:		2.644507E-02
  validation loss:		2.664547E-02
Epoch took 8.702s

Epoch 75 of 100
  training loss:		2.649928E-02
  validation loss:		2.652208E-02
Epoch took 8.856s

Epoch 76 of 100
  training loss:		2.650139E-02
  validation loss:		2.643892E-02
Epoch took 7.874s

Epoch 77 of 100
  training loss:		2.637088E-02
  validation loss:		2.645070E-02
Epoch took 8.802s

Epoch 78 of 100
  training loss:		2.639179E-02
  validation loss:		2.635034E-02
Epoch took 8.922s

Epoch 79 of 100
  training loss:		2.641467E-02
  validation loss:		2.654067E-02
Epoch took 8.590s

Epoch 80 of 100
  training loss:		2.635795E-02
  validation loss:		2.647116E-02
Epoch took 9.961s

Epoch 81 of 100
  training loss:		2.637098E-02
  validation loss:		2.639236E-02
Epoch took 8.752s

Epoch 82 of 100
  training loss:		2.644629E-02
  validation loss:		2.646151E-02
Epoch took 8.603s

Epoch 83 of 100
  training loss:		2.638872E-02
  validation loss:		2.628103E-02
Epoch took 9.652s

Epoch 84 of 100
  training loss:		2.639993E-02
  validation loss:		2.642027E-02
Epoch took 8.677s

Epoch 85 of 100
  training loss:		2.633914E-02
  validation loss:		2.624829E-02
Epoch took 8.201s

Epoch 86 of 100
  training loss:		2.626792E-02
  validation loss:		2.692165E-02
Epoch took 8.718s

Epoch 87 of 100
  training loss:		2.642903E-02
  validation loss:		2.628463E-02
Epoch took 8.948s

Epoch 88 of 100
  training loss:		2.622888E-02
  validation loss:		2.634849E-02
Epoch took 8.448s

Epoch 89 of 100
  training loss:		2.632662E-02
  validation loss:		2.623681E-02
Epoch took 8.777s

Epoch 90 of 100
  training loss:		2.628920E-02
  validation loss:		2.628443E-02
Epoch took 9.218s

Epoch 91 of 100
  training loss:		2.632662E-02
  validation loss:		2.635838E-02
Epoch took 8.486s

Epoch 92 of 100
  training loss:		2.624458E-02
  validation loss:		2.643770E-02
Epoch took 9.224s

Epoch 93 of 100
  training loss:		2.638693E-02
  validation loss:		2.644451E-02
Epoch took 9.595s

Epoch 94 of 100
  training loss:		2.625702E-02
  validation loss:		2.620149E-02
Epoch took 9.620s

Epoch 95 of 100
  training loss:		2.620388E-02
  validation loss:		2.649573E-02
Epoch took 8.030s

Epoch 96 of 100
  training loss:		2.624344E-02
  validation loss:		2.612061E-02
Epoch took 9.208s

Epoch 97 of 100
  training loss:		2.629490E-02
  validation loss:		2.628094E-02
Epoch took 9.096s

Epoch 98 of 100
  training loss:		2.624015E-02
  validation loss:		2.673657E-02
Epoch took 8.604s

Epoch 99 of 100
  training loss:		2.628084E-02
  validation loss:		2.613001E-02
Epoch took 7.786s

Epoch 100 of 100
  training loss:		2.621949E-02
  validation loss:		2.619557E-02
Epoch took 8.833s

Training RMSE: 1.58187671861e-07
Validation RMSE: 1.58638266541e-07
