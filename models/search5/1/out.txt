Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		8.104163E-02
  validation loss:		7.124257E-03
Epoch took 10.076s

Epoch 2 of 100
  training loss:		4.462834E-03
  validation loss:		2.941271E-03
Epoch took 9.949s

Epoch 3 of 100
  training loss:		2.233797E-03
  validation loss:		1.704901E-03
Epoch took 10.367s

Epoch 4 of 100
  training loss:		1.333082E-03
  validation loss:		1.026883E-03
Epoch took 9.798s

Epoch 5 of 100
  training loss:		8.164253E-04
  validation loss:		6.446413E-04
Epoch took 10.150s

Epoch 6 of 100
  training loss:		5.116482E-04
  validation loss:		4.059130E-04
Epoch took 9.584s

Epoch 7 of 100
  training loss:		3.194478E-04
  validation loss:		2.537587E-04
Epoch took 10.318s

Epoch 8 of 100
  training loss:		1.967110E-04
  validation loss:		1.586587E-04
Epoch took 11.205s

Epoch 9 of 100
  training loss:		1.185171E-04
  validation loss:		9.385458E-05
Epoch took 10.312s

Epoch 10 of 100
  training loss:		7.047058E-05
  validation loss:		5.399060E-05
Epoch took 9.443s

Epoch 11 of 100
  training loss:		3.972892E-05
  validation loss:		2.892597E-05
Epoch took 10.354s

Epoch 12 of 100
  training loss:		2.176104E-05
  validation loss:		1.508476E-05
Epoch took 10.008s

Epoch 13 of 100
  training loss:		1.245536E-05
  validation loss:		8.476331E-06
Epoch took 10.163s

Epoch 14 of 100
  training loss:		6.137296E-06
  validation loss:		5.480141E-06
Epoch took 11.093s

Epoch 15 of 100
  training loss:		3.489989E-06
  validation loss:		1.977963E-06
Epoch took 10.120s

Epoch 16 of 100
  training loss:		1.939662E-06
  validation loss:		1.249412E-06
Epoch took 10.055s

Epoch 17 of 100
  training loss:		1.685746E-06
  validation loss:		1.017895E-06
Epoch took 10.522s

Epoch 18 of 100
  training loss:		7.134282E-07
  validation loss:		2.871294E-07
Epoch took 10.862s

Epoch 19 of 100
  training loss:		1.209002E-06
  validation loss:		1.354752E-07
Epoch took 10.456s

Epoch 20 of 100
  training loss:		7.731923E-07
  validation loss:		1.374515E-07
Epoch took 11.041s

Epoch 21 of 100
  training loss:		8.717468E-07
  validation loss:		1.472942E-06
Epoch took 9.391s

Epoch 22 of 100
  training loss:		9.868320E-07
  validation loss:		5.597675E-08
Epoch took 10.936s

Epoch 23 of 100
  training loss:		1.234684E-06
  validation loss:		1.133375E-07
Epoch took 9.155s

Epoch 24 of 100
  training loss:		1.042752E-06
  validation loss:		3.261208E-06
Epoch took 9.799s

Epoch 25 of 100
  training loss:		1.177813E-06
  validation loss:		2.831396E-06
Epoch took 11.879s

Epoch 26 of 100
  training loss:		6.318449E-07
  validation loss:		1.126392E-07
Epoch took 10.743s

Epoch 27 of 100
  training loss:		1.065660E-06
  validation loss:		5.044944E-08
Epoch took 9.936s

Epoch 28 of 100
  training loss:		2.203854E-06
  validation loss:		1.006974E-07
Epoch took 10.530s

Epoch 29 of 100
  training loss:		4.221317E-08
  validation loss:		3.696775E-08
Epoch took 10.076s

Epoch 30 of 100
  training loss:		2.002117E-06
  validation loss:		1.015993E-08
Epoch took 10.724s

Epoch 31 of 100
  training loss:		5.268241E-07
  validation loss:		2.270103E-06
Epoch took 10.404s

Epoch 32 of 100
  training loss:		1.111229E-06
  validation loss:		1.302570E-08
Epoch took 10.574s

Epoch 33 of 100
  training loss:		1.221625E-06
  validation loss:		4.698292E-07
Epoch took 9.969s

Epoch 34 of 100
  training loss:		1.364432E-06
  validation loss:		1.977729E-08
Epoch took 9.232s

Epoch 35 of 100
  training loss:		7.141367E-07
  validation loss:		6.071869E-06
Epoch took 10.119s

Epoch 36 of 100
  training loss:		7.626075E-07
  validation loss:		6.673235E-08
Epoch took 9.688s

Epoch 37 of 100
  training loss:		1.205911E-06
  validation loss:		2.049093E-06
Epoch took 10.892s

Epoch 38 of 100
  training loss:		8.350818E-07
  validation loss:		1.509354E-06
Epoch took 9.866s

Epoch 39 of 100
  training loss:		3.883798E-06
  validation loss:		3.555389E-08
Epoch took 10.193s

Epoch 40 of 100
  training loss:		1.319981E-08
  validation loss:		3.442197E-09
Epoch took 10.525s

Epoch 41 of 100
  training loss:		8.609769E-09
  validation loss:		4.765374E-08
Epoch took 11.185s

Epoch 42 of 100
  training loss:		2.615921E-06
  validation loss:		1.147908E-08
Epoch took 8.995s

Epoch 43 of 100
  training loss:		2.821888E-08
  validation loss:		3.166238E-07
Epoch took 9.280s

Epoch 44 of 100
  training loss:		1.952254E-06
  validation loss:		3.527471E-08
Epoch took 9.330s

Epoch 45 of 100
  training loss:		2.862605E-07
  validation loss:		5.548963E-07
Epoch took 8.784s

Epoch 46 of 100
  training loss:		1.590448E-06
  validation loss:		9.663322E-09
Epoch took 10.219s

Epoch 47 of 100
  training loss:		1.553487E-06
  validation loss:		2.246873E-08
Epoch took 8.791s

Epoch 48 of 100
  training loss:		3.974573E-08
  validation loss:		3.742296E-08
Epoch took 9.656s

Epoch 49 of 100
  training loss:		1.510749E-06
  validation loss:		2.281469E-08
Epoch took 9.937s

Epoch 50 of 100
  training loss:		1.566413E-06
  validation loss:		3.293352E-08
Epoch took 8.764s

Epoch 51 of 100
  training loss:		3.024371E-08
  validation loss:		5.483110E-07
Epoch took 10.125s

Epoch 52 of 100
  training loss:		2.800210E-06
  validation loss:		5.054321E-09
Epoch took 10.699s

Epoch 53 of 100
  training loss:		6.152421E-08
  validation loss:		9.789063E-08
Epoch took 10.857s

Epoch 54 of 100
  training loss:		2.253089E-06
  validation loss:		7.902615E-09
Epoch took 10.284s

Epoch 55 of 100
  training loss:		8.447831E-08
  validation loss:		1.416924E-07
Epoch took 9.528s

Epoch 56 of 100
  training loss:		1.420534E-06
  validation loss:		4.211807E-08
Epoch took 10.518s

Epoch 57 of 100
  training loss:		1.182158E-06
  validation loss:		1.087136E-06
Epoch took 9.936s

Epoch 58 of 100
  training loss:		1.388263E-06
  validation loss:		8.761419E-08
Epoch took 8.978s

Epoch 59 of 100
  training loss:		9.871885E-07
  validation loss:		6.902794E-08
Epoch took 10.125s

Epoch 60 of 100
  training loss:		4.860703E-07
  validation loss:		1.079079E-06
Epoch took 9.317s

Epoch 61 of 100
  training loss:		1.393253E-06
  validation loss:		3.112054E-06
Epoch took 10.409s

Epoch 62 of 100
  training loss:		1.598946E-06
  validation loss:		1.153114E-08
Epoch took 10.365s

Epoch 63 of 100
  training loss:		4.077625E-07
  validation loss:		5.608200E-06
Epoch took 10.654s

Epoch 64 of 100
  training loss:		1.864201E-06
  validation loss:		2.658184E-08
Epoch took 9.459s

Epoch 65 of 100
  training loss:		1.211184E-06
  validation loss:		5.667186E-06
Epoch took 8.808s

Epoch 66 of 100
  training loss:		4.839613E-07
  validation loss:		7.860427E-09
Epoch took 11.178s

Epoch 67 of 100
  training loss:		1.172257E-06
  validation loss:		3.706261E-07
Epoch took 10.127s

Epoch 68 of 100
  training loss:		1.339679E-06
  validation loss:		1.178808E-06
Epoch took 10.348s

Epoch 69 of 100
  training loss:		2.275064E-07
  validation loss:		2.082552E-06
Epoch took 9.397s

Epoch 70 of 100
  training loss:		1.860461E-06
  validation loss:		5.074504E-07
Epoch took 8.066s

Epoch 71 of 100
  training loss:		4.478831E-07
  validation loss:		3.415741E-07
Epoch took 7.853s

Epoch 72 of 100
  training loss:		2.195654E-06
  validation loss:		2.406713E-07
Epoch took 7.929s

Epoch 73 of 100
  training loss:		3.464433E-08
  validation loss:		4.409730E-09
Epoch took 10.374s

Epoch 74 of 100
  training loss:		1.048105E-06
  validation loss:		1.510057E-06
Epoch took 10.035s

Epoch 75 of 100
  training loss:		5.012296E-07
  validation loss:		9.251718E-09
Epoch took 10.632s

Epoch 76 of 100
  training loss:		1.927262E-06
  validation loss:		2.200654E-08
Epoch took 12.469s

Epoch 77 of 100
  training loss:		4.076806E-07
  validation loss:		1.210713E-06
Epoch took 9.349s

Epoch 78 of 100
  training loss:		9.806895E-07
  validation loss:		1.786527E-06
Epoch took 9.684s

Epoch 79 of 100
  training loss:		1.118316E-06
  validation loss:		9.180675E-09
Epoch took 9.723s

Epoch 80 of 100
  training loss:		1.157497E-06
  validation loss:		1.434174E-08
Epoch took 10.172s

Epoch 81 of 100
  training loss:		1.548132E-06
  validation loss:		1.468297E-06
Epoch took 9.983s

Epoch 82 of 100
  training loss:		3.868735E-07
  validation loss:		4.364861E-08
Epoch took 10.895s

Epoch 83 of 100
  training loss:		1.296908E-06
  validation loss:		2.455346E-08
Epoch took 10.353s

Epoch 84 of 100
  training loss:		1.874623E-06
  validation loss:		9.623710E-08
Epoch took 10.353s

Epoch 85 of 100
  training loss:		1.100557E-08
  validation loss:		3.328796E-09
Epoch took 10.578s

Epoch 86 of 100
  training loss:		1.321382E-06
  validation loss:		7.052250E-07
Epoch took 9.624s

Epoch 87 of 100
  training loss:		1.457425E-06
  validation loss:		4.987382E-06
Epoch took 10.670s

Epoch 88 of 100
  training loss:		5.815430E-07
  validation loss:		2.320728E-08
Epoch took 9.252s

Epoch 89 of 100
  training loss:		1.914217E-06
  validation loss:		8.942007E-08
Epoch took 9.892s

Epoch 90 of 100
  training loss:		6.485379E-08
  validation loss:		3.182878E-08
Epoch took 9.919s

Epoch 91 of 100
  training loss:		2.723302E-06
  validation loss:		7.965100E-09
Epoch took 11.531s

Epoch 92 of 100
  training loss:		9.674673E-09
  validation loss:		2.498321E-08
Epoch took 10.464s

Epoch 93 of 100
  training loss:		1.569704E-06
  validation loss:		3.547689E-07
Epoch took 9.981s

Epoch 94 of 100
  training loss:		2.310214E-06
  validation loss:		4.765185E-06
Epoch took 10.767s

Epoch 95 of 100
  training loss:		7.688184E-08
  validation loss:		1.986772E-08
Epoch took 9.985s

Epoch 96 of 100
  training loss:		8.456951E-07
  validation loss:		1.017618E-05
Epoch took 9.451s

Epoch 97 of 100
  training loss:		1.982251E-06
  validation loss:		9.017313E-08
Epoch took 9.858s

Epoch 98 of 100
  training loss:		1.451540E-07
  validation loss:		6.077931E-07
Epoch took 11.342s

Epoch 99 of 100
  training loss:		2.936209E-06
  validation loss:		1.312583E-08
Epoch took 10.620s

Epoch 100 of 100
  training loss:		6.353776E-09
  validation loss:		3.557363E-09
Epoch took 10.069s

Training RMSE: 5.98460477431e-05
Validation RMSE: 5.96387650735e-05
