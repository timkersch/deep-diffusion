Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		6.607029E-02
  validation loss:		5.067835E-03
Epoch took 9.638s

Epoch 2 of 100
  training loss:		2.979890E-03
  validation loss:		1.639093E-03
Epoch took 10.474s

Epoch 3 of 100
  training loss:		1.180525E-03
  validation loss:		7.792595E-04
Epoch took 12.136s

Epoch 4 of 100
  training loss:		5.867742E-04
  validation loss:		4.162127E-04
Epoch took 10.050s

Epoch 5 of 100
  training loss:		3.126413E-04
  validation loss:		2.262935E-04
Epoch took 10.342s

Epoch 6 of 100
  training loss:		1.690218E-04
  validation loss:		1.267965E-04
Epoch took 10.415s

Epoch 7 of 100
  training loss:		9.215894E-05
  validation loss:		6.837794E-05
Epoch took 10.328s

Epoch 8 of 100
  training loss:		4.720725E-05
  validation loss:		3.257907E-05
Epoch took 10.053s

Epoch 9 of 100
  training loss:		2.322887E-05
  validation loss:		1.575590E-05
Epoch took 9.953s

Epoch 10 of 100
  training loss:		1.154325E-05
  validation loss:		7.989792E-06
Epoch took 10.598s

Epoch 11 of 100
  training loss:		5.698577E-06
  validation loss:		4.318596E-06
Epoch took 9.304s

Epoch 12 of 100
  training loss:		2.822264E-06
  validation loss:		2.031621E-06
Epoch took 9.940s

Epoch 13 of 100
  training loss:		1.417551E-06
  validation loss:		9.032231E-07
Epoch took 9.552s

Epoch 14 of 100
  training loss:		7.868612E-07
  validation loss:		9.386861E-07
Epoch took 10.602s

Epoch 15 of 100
  training loss:		7.559178E-07
  validation loss:		3.358128E-07
Epoch took 10.966s

Epoch 16 of 100
  training loss:		5.603824E-06
  validation loss:		6.323872E-07
Epoch took 11.050s

Epoch 17 of 100
  training loss:		2.172336E-07
  validation loss:		1.291645E-06
Epoch took 10.288s

Epoch 18 of 100
  training loss:		4.542476E-06
  validation loss:		2.998880E-08
Epoch took 10.183s

Epoch 19 of 100
  training loss:		5.244502E-06
  validation loss:		1.242797E-06
Epoch took 10.672s

Epoch 20 of 100
  training loss:		1.833348E-06
  validation loss:		6.083705E-06
Epoch took 9.141s

Epoch 21 of 100
  training loss:		2.156442E-06
  validation loss:		3.114120E-07
Epoch took 9.775s

Epoch 22 of 100
  training loss:		4.793869E-06
  validation loss:		5.631821E-08
Epoch took 9.823s

Epoch 23 of 100
  training loss:		3.483092E-06
  validation loss:		5.351129E-06
Epoch took 10.382s

Epoch 24 of 100
  training loss:		3.717800E-06
  validation loss:		1.567997E-08
Epoch took 9.460s

Epoch 25 of 100
  training loss:		4.453293E-06
  validation loss:		3.639121E-07
Epoch took 10.727s

Epoch 26 of 100
  training loss:		5.800571E-06
  validation loss:		6.340202E-07
Epoch took 10.479s

Epoch 27 of 100
  training loss:		2.145512E-07
  validation loss:		3.940786E-08
Epoch took 10.410s

Epoch 28 of 100
  training loss:		3.654198E-06
  validation loss:		5.419280E-06
Epoch took 10.446s

Epoch 29 of 100
  training loss:		9.179873E-06
  validation loss:		8.232943E-09
Epoch took 9.810s

Epoch 30 of 100
  training loss:		1.878819E-07
  validation loss:		3.148688E-06
Epoch took 11.230s

Epoch 31 of 100
  training loss:		3.571528E-06
  validation loss:		3.870330E-07
Epoch took 9.591s

Epoch 32 of 100
  training loss:		5.919674E-06
  validation loss:		1.638342E-06
Epoch took 11.118s

Epoch 33 of 100
  training loss:		2.473580E-06
  validation loss:		7.471092E-09
Epoch took 10.291s

Epoch 34 of 100
  training loss:		6.894935E-06
  validation loss:		5.387872E-07
Epoch took 9.260s

Epoch 35 of 100
  training loss:		5.308960E-07
  validation loss:		5.725160E-07
Epoch took 9.947s

Epoch 36 of 100
  training loss:		5.820054E-06
  validation loss:		3.966433E-06
Epoch took 10.355s

Epoch 37 of 100
  training loss:		6.439878E-07
  validation loss:		9.795392E-08
Epoch took 10.128s

Epoch 38 of 100
  training loss:		4.917232E-06
  validation loss:		4.340580E-07
Epoch took 8.990s

Epoch 39 of 100
  training loss:		4.986523E-06
  validation loss:		1.081491E-07
Epoch took 10.069s

Epoch 40 of 100
  training loss:		6.461226E-06
  validation loss:		1.220641E-07
Epoch took 10.806s

Epoch 41 of 100
  training loss:		1.660081E-07
  validation loss:		3.812612E-06
Epoch took 10.660s

Epoch 42 of 100
  training loss:		3.909181E-06
  validation loss:		1.747750E-07
Epoch took 9.571s

Epoch 43 of 100
  training loss:		6.940993E-06
  validation loss:		9.050022E-09
Epoch took 9.894s

Epoch 44 of 100
  training loss:		5.175220E-08
  validation loss:		2.610806E-08
Epoch took 9.560s

Epoch 45 of 100
  training loss:		6.617782E-06
  validation loss:		4.437166E-08
Epoch took 9.791s

Epoch 46 of 100
  training loss:		2.192736E-06
  validation loss:		7.734554E-07
Epoch took 10.522s

Epoch 47 of 100
  training loss:		4.555352E-06
  validation loss:		7.023555E-07
Epoch took 9.382s

Epoch 48 of 100
  training loss:		3.856703E-06
  validation loss:		1.546263E-06
Epoch took 9.480s

Epoch 49 of 100
  training loss:		1.539411E-06
  validation loss:		6.209497E-06
Epoch took 9.763s

Epoch 50 of 100
  training loss:		6.522220E-06
  validation loss:		2.448921E-07
Epoch took 10.229s

Epoch 51 of 100
  training loss:		3.231077E-06
  validation loss:		1.266520E-06
Epoch took 10.157s

Epoch 52 of 100
  training loss:		3.517776E-06
  validation loss:		3.688769E-05
Epoch took 11.285s

Epoch 53 of 100
  training loss:		1.231126E-06
  validation loss:		1.280912E-07
Epoch took 10.830s

Epoch 54 of 100
  training loss:		4.457178E-06
  validation loss:		1.114293E-06
Epoch took 9.122s

Epoch 55 of 100
  training loss:		2.306390E-06
  validation loss:		2.440049E-06
Epoch took 9.565s

Epoch 56 of 100
  training loss:		2.684163E-06
  validation loss:		1.561896E-06
Epoch took 9.806s

Epoch 57 of 100
  training loss:		4.448318E-06
  validation loss:		1.262992E-08
Epoch took 10.839s

Epoch 58 of 100
  training loss:		4.820528E-06
  validation loss:		6.654804E-07
Epoch took 9.513s

Epoch 59 of 100
  training loss:		1.132918E-07
  validation loss:		1.267218E-07
Epoch took 11.631s

Epoch 60 of 100
  training loss:		6.891119E-06
  validation loss:		5.424203E-09
Epoch took 11.506s

Epoch 61 of 100
  training loss:		3.462116E-08
  validation loss:		3.111265E-07
Epoch took 10.060s

Epoch 62 of 100
  training loss:		4.181378E-06
  validation loss:		1.114491E-07
Epoch took 10.558s

Epoch 63 of 100
  training loss:		3.850715E-06
  validation loss:		1.554907E-06
Epoch took 10.131s

Epoch 64 of 100
  training loss:		2.121196E-06
  validation loss:		1.255640E-05
Epoch took 11.548s

Epoch 65 of 100
  training loss:		8.214713E-06
  validation loss:		7.714452E-09
Epoch took 9.536s

Epoch 66 of 100
  training loss:		9.046018E-08
  validation loss:		8.109269E-07
Epoch took 9.816s

Epoch 67 of 100
  training loss:		6.344713E-06
  validation loss:		1.817456E-08
Epoch took 10.494s

Epoch 68 of 100
  training loss:		1.293851E-06
  validation loss:		1.646415E-06
Epoch took 9.903s

Epoch 69 of 100
  training loss:		3.328699E-06
  validation loss:		3.618222E-07
Epoch took 9.828s

Epoch 70 of 100
  training loss:		4.986794E-06
  validation loss:		6.274280E-08
Epoch took 9.322s

Epoch 71 of 100
  training loss:		2.899217E-06
  validation loss:		4.347633E-06
Epoch took 9.607s

Epoch 72 of 100
  training loss:		2.622868E-06
  validation loss:		4.699599E-07
Epoch took 8.348s

Epoch 73 of 100
  training loss:		3.120141E-06
  validation loss:		2.157062E-06
Epoch took 9.397s

Epoch 74 of 100
  training loss:		2.809871E-06
  validation loss:		4.264918E-07
Epoch took 10.861s

Epoch 75 of 100
  training loss:		2.247154E-06
  validation loss:		8.069847E-07
Epoch took 10.278s

Epoch 76 of 100
  training loss:		6.918712E-06
  validation loss:		7.175799E-08
Epoch took 9.763s

Epoch 77 of 100
  training loss:		4.289770E-08
  validation loss:		2.915365E-07
Epoch took 10.120s

Epoch 78 of 100
  training loss:		5.295276E-06
  validation loss:		1.127723E-08
Epoch took 10.096s

Epoch 79 of 100
  training loss:		5.222208E-06
  validation loss:		2.820678E-06
Epoch took 10.794s

Epoch 80 of 100
  training loss:		2.396113E-07
  validation loss:		1.084075E-06
Epoch took 9.748s

Epoch 81 of 100
  training loss:		3.917868E-06
  validation loss:		6.268337E-06
Epoch took 10.098s

Epoch 82 of 100
  training loss:		1.322398E-06
  validation loss:		2.628903E-05
Epoch took 10.619s

Epoch 83 of 100
  training loss:		3.271303E-06
  validation loss:		1.629532E-05
Epoch took 11.067s

Epoch 84 of 100
  training loss:		9.163530E-06
  validation loss:		1.190421E-08
Epoch took 8.885s

Epoch 85 of 100
  training loss:		1.519613E-08
  validation loss:		2.331783E-08
Epoch took 9.910s

Epoch 86 of 100
  training loss:		6.637458E-06
  validation loss:		1.863639E-08
Epoch took 10.322s

Epoch 87 of 100
  training loss:		1.421826E-07
  validation loss:		1.200559E-06
Epoch took 11.240s

Epoch 88 of 100
  training loss:		6.336312E-06
  validation loss:		6.885289E-09
Epoch took 11.863s

Epoch 89 of 100
  training loss:		1.728203E-06
  validation loss:		4.240093E-05
Epoch took 10.325s

Epoch 90 of 100
  training loss:		5.108867E-06
  validation loss:		3.370223E-06
Epoch took 10.616s

Epoch 91 of 100
  training loss:		3.085447E-07
  validation loss:		3.726592E-06
Epoch took 10.657s

Epoch 92 of 100
  training loss:		3.895281E-06
  validation loss:		1.996906E-07
Epoch took 11.056s

Epoch 93 of 100
  training loss:		3.497445E-06
  validation loss:		5.648806E-06
Epoch took 10.168s

Epoch 94 of 100
  training loss:		4.764309E-06
  validation loss:		7.670740E-06
Epoch took 10.144s

Epoch 95 of 100
  training loss:		1.365599E-06
  validation loss:		5.481719E-08
Epoch took 10.622s

Epoch 96 of 100
  training loss:		5.631308E-06
  validation loss:		6.397696E-08
Epoch took 9.711s

Epoch 97 of 100
  training loss:		3.631565E-07
  validation loss:		2.092171E-06
Epoch took 10.236s

Epoch 98 of 100
  training loss:		3.402233E-06
  validation loss:		1.332568E-06
Epoch took 10.442s

Epoch 99 of 100
  training loss:		3.156088E-06
  validation loss:		3.787055E-07
Epoch took 10.075s

Epoch 100 of 100
  training loss:		3.228508E-06
  validation loss:		4.527581E-07
Epoch took 11.355s

Training RMSE: 0.000675780148986
Validation RMSE: 0.000672817266607
