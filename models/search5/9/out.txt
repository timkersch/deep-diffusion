Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		4.183692E-01
  validation loss:		3.359683E-02
Epoch took 7.416s

Epoch 2 of 100
  training loss:		2.133522E-02
  validation loss:		1.373439E-02
Epoch took 8.000s

Epoch 3 of 100
  training loss:		1.112033E-02
  validation loss:		8.803332E-03
Epoch took 7.908s

Epoch 4 of 100
  training loss:		7.570162E-03
  validation loss:		6.262145E-03
Epoch took 8.632s

Epoch 5 of 100
  training loss:		5.527693E-03
  validation loss:		4.601426E-03
Epoch took 7.520s

Epoch 6 of 100
  training loss:		4.162355E-03
  validation loss:		3.508962E-03
Epoch took 7.538s

Epoch 7 of 100
  training loss:		3.262514E-03
  validation loss:		2.814803E-03
Epoch took 7.846s

Epoch 8 of 100
  training loss:		2.666751E-03
  validation loss:		2.353432E-03
Epoch took 8.999s

Epoch 9 of 100
  training loss:		2.245900E-03
  validation loss:		1.987179E-03
Epoch took 7.854s

Epoch 10 of 100
  training loss:		1.896931E-03
  validation loss:		1.663814E-03
Epoch took 8.196s

Epoch 11 of 100
  training loss:		1.625091E-03
  validation loss:		1.445662E-03
Epoch took 8.855s

Epoch 12 of 100
  training loss:		1.404593E-03
  validation loss:		1.250417E-03
Epoch took 8.110s

Epoch 13 of 100
  training loss:		1.222663E-03
  validation loss:		1.096298E-03
Epoch took 7.785s

Epoch 14 of 100
  training loss:		1.079345E-03
  validation loss:		9.694566E-04
Epoch took 7.780s

Epoch 15 of 100
  training loss:		9.497790E-04
  validation loss:		8.521508E-04
Epoch took 7.775s

Epoch 16 of 100
  training loss:		8.431626E-04
  validation loss:		7.611869E-04
Epoch took 8.036s

Epoch 17 of 100
  training loss:		7.502239E-04
  validation loss:		6.746829E-04
Epoch took 8.222s

Epoch 18 of 100
  training loss:		6.676433E-04
  validation loss:		6.013374E-04
Epoch took 7.987s

Epoch 19 of 100
  training loss:		5.962706E-04
  validation loss:		5.349012E-04
Epoch took 7.259s

Epoch 20 of 100
  training loss:		5.312715E-04
  validation loss:		4.759684E-04
Epoch took 9.385s

Epoch 21 of 100
  training loss:		4.716155E-04
  validation loss:		4.243282E-04
Epoch took 8.188s

Epoch 22 of 100
  training loss:		4.197073E-04
  validation loss:		3.791207E-04
Epoch took 7.447s

Epoch 23 of 100
  training loss:		3.733796E-04
  validation loss:		3.373324E-04
Epoch took 7.573s

Epoch 24 of 100
  training loss:		3.344626E-04
  validation loss:		3.035772E-04
Epoch took 9.305s

Epoch 25 of 100
  training loss:		2.992212E-04
  validation loss:		2.730074E-04
Epoch took 7.925s

Epoch 26 of 100
  training loss:		2.682306E-04
  validation loss:		2.452447E-04
Epoch took 8.207s

Epoch 27 of 100
  training loss:		2.404737E-04
  validation loss:		2.213463E-04
Epoch took 7.788s

Epoch 28 of 100
  training loss:		2.162777E-04
  validation loss:		1.982397E-04
Epoch took 7.489s

Epoch 29 of 100
  training loss:		1.950868E-04
  validation loss:		1.820213E-04
Epoch took 7.036s

Epoch 30 of 100
  training loss:		1.768109E-04
  validation loss:		1.632257E-04
Epoch took 7.930s

Epoch 31 of 100
  training loss:		1.594226E-04
  validation loss:		1.508146E-04
Epoch took 7.846s

Epoch 32 of 100
  training loss:		1.439141E-04
  validation loss:		1.325789E-04
Epoch took 8.150s

Epoch 33 of 100
  training loss:		1.299079E-04
  validation loss:		1.204066E-04
Epoch took 8.121s

Epoch 34 of 100
  training loss:		1.160718E-04
  validation loss:		1.074346E-04
Epoch took 7.113s

Epoch 35 of 100
  training loss:		1.038698E-04
  validation loss:		9.527290E-05
Epoch took 8.438s

Epoch 36 of 100
  training loss:		9.407933E-05
  validation loss:		8.620476E-05
Epoch took 7.600s

Epoch 37 of 100
  training loss:		8.409106E-05
  validation loss:		7.713803E-05
Epoch took 7.725s

Epoch 38 of 100
  training loss:		7.499620E-05
  validation loss:		6.736032E-05
Epoch took 7.553s

Epoch 39 of 100
  training loss:		6.630320E-05
  validation loss:		6.204508E-05
Epoch took 7.826s

Epoch 40 of 100
  training loss:		5.981261E-05
  validation loss:		5.609199E-05
Epoch took 8.326s

Epoch 41 of 100
  training loss:		5.415673E-05
  validation loss:		4.881901E-05
Epoch took 8.226s

Epoch 42 of 100
  training loss:		4.862118E-05
  validation loss:		4.485735E-05
Epoch took 7.560s

Epoch 43 of 100
  training loss:		4.418261E-05
  validation loss:		4.033151E-05
Epoch took 8.155s

Epoch 44 of 100
  training loss:		4.010981E-05
  validation loss:		3.621337E-05
Epoch took 8.382s

Epoch 45 of 100
  training loss:		3.662227E-05
  validation loss:		3.272345E-05
Epoch took 7.203s

Epoch 46 of 100
  training loss:		3.282716E-05
  validation loss:		2.911390E-05
Epoch took 7.626s

Epoch 47 of 100
  training loss:		2.943772E-05
  validation loss:		2.640844E-05
Epoch took 8.062s

Epoch 48 of 100
  training loss:		2.667682E-05
  validation loss:		2.377954E-05
Epoch took 7.937s

Epoch 49 of 100
  training loss:		2.427862E-05
  validation loss:		2.105575E-05
Epoch took 8.242s

Epoch 50 of 100
  training loss:		2.189010E-05
  validation loss:		1.903528E-05
Epoch took 6.917s

Epoch 51 of 100
  training loss:		2.022968E-05
  validation loss:		1.769170E-05
Epoch took 7.914s

Epoch 52 of 100
  training loss:		1.780146E-05
  validation loss:		1.555396E-05
Epoch took 8.791s

Epoch 53 of 100
  training loss:		1.607031E-05
  validation loss:		1.557335E-05
Epoch took 7.744s

Epoch 54 of 100
  training loss:		1.494995E-05
  validation loss:		1.285000E-05
Epoch took 7.989s

Epoch 55 of 100
  training loss:		1.319626E-05
  validation loss:		1.136989E-05
Epoch took 7.698s

Epoch 56 of 100
  training loss:		1.205433E-05
  validation loss:		1.111269E-05
Epoch took 9.511s

Epoch 57 of 100
  training loss:		1.117200E-05
  validation loss:		1.029531E-05
Epoch took 7.593s

Epoch 58 of 100
  training loss:		1.039586E-05
  validation loss:		8.496171E-06
Epoch took 7.717s

Epoch 59 of 100
  training loss:		9.112297E-06
  validation loss:		8.036149E-06
Epoch took 8.842s

Epoch 60 of 100
  training loss:		8.338566E-06
  validation loss:		7.688827E-06
Epoch took 7.982s

Epoch 61 of 100
  training loss:		7.765180E-06
  validation loss:		6.799545E-06
Epoch took 8.474s

Epoch 62 of 100
  training loss:		7.057439E-06
  validation loss:		6.048894E-06
Epoch took 8.285s

Epoch 63 of 100
  training loss:		7.138632E-06
  validation loss:		5.986659E-06
Epoch took 8.171s

Epoch 64 of 100
  training loss:		5.941849E-06
  validation loss:		5.034920E-06
Epoch took 8.324s

Epoch 65 of 100
  training loss:		5.666642E-06
  validation loss:		5.397467E-06
Epoch took 7.854s

Epoch 66 of 100
  training loss:		5.438184E-06
  validation loss:		4.251818E-06
Epoch took 7.953s

Epoch 67 of 100
  training loss:		4.581189E-06
  validation loss:		4.000166E-06
Epoch took 7.798s

Epoch 68 of 100
  training loss:		4.225121E-06
  validation loss:		3.692446E-06
Epoch took 8.350s

Epoch 69 of 100
  training loss:		4.203995E-06
  validation loss:		3.440028E-06
Epoch took 8.367s

Epoch 70 of 100
  training loss:		3.872450E-06
  validation loss:		3.776888E-06
Epoch took 7.337s

Epoch 71 of 100
  training loss:		3.622745E-06
  validation loss:		3.076010E-06
Epoch took 7.108s

Epoch 72 of 100
  training loss:		3.904432E-06
  validation loss:		5.318529E-06
Epoch took 8.302s

Epoch 73 of 100
  training loss:		3.875162E-06
  validation loss:		2.427538E-06
Epoch took 7.719s

Epoch 74 of 100
  training loss:		3.053475E-06
  validation loss:		3.808695E-06
Epoch took 7.267s

Epoch 75 of 100
  training loss:		2.608493E-06
  validation loss:		2.131714E-06
Epoch took 7.565s

Epoch 76 of 100
  training loss:		2.789237E-06
  validation loss:		1.861149E-06
Epoch took 8.489s

Epoch 77 of 100
  training loss:		2.817086E-06
  validation loss:		1.801391E-06
Epoch took 8.310s

Epoch 78 of 100
  training loss:		3.599910E-06
  validation loss:		3.663631E-06
Epoch took 8.235s

Epoch 79 of 100
  training loss:		2.358065E-06
  validation loss:		2.632987E-06
Epoch took 8.720s

Epoch 80 of 100
  training loss:		1.942694E-06
  validation loss:		2.174513E-06
Epoch took 8.142s

Epoch 81 of 100
  training loss:		2.031649E-06
  validation loss:		1.615532E-06
Epoch took 7.587s

Epoch 82 of 100
  training loss:		1.711616E-06
  validation loss:		1.605441E-06
Epoch took 8.286s

Epoch 83 of 100
  training loss:		1.663664E-06
  validation loss:		2.008640E-06
Epoch took 7.830s

Epoch 84 of 100
  training loss:		1.839773E-06
  validation loss:		1.847400E-06
Epoch took 8.015s

Epoch 85 of 100
  training loss:		1.711711E-06
  validation loss:		8.835581E-07
Epoch took 7.600s

Epoch 86 of 100
  training loss:		1.756351E-06
  validation loss:		7.999072E-07
Epoch took 8.180s

Epoch 87 of 100
  training loss:		1.157565E-06
  validation loss:		1.155076E-06
Epoch took 8.687s

Epoch 88 of 100
  training loss:		1.751491E-06
  validation loss:		1.690795E-06
Epoch took 8.148s

Epoch 89 of 100
  training loss:		1.609833E-06
  validation loss:		7.077033E-06
Epoch took 8.510s

Epoch 90 of 100
  training loss:		1.416819E-06
  validation loss:		7.137327E-07
Epoch took 8.006s

Epoch 91 of 100
  training loss:		1.560666E-06
  validation loss:		1.613591E-06
Epoch took 9.532s

Epoch 92 of 100
  training loss:		9.742795E-07
  validation loss:		2.652449E-06
Epoch took 7.310s

Epoch 93 of 100
  training loss:		1.496310E-06
  validation loss:		6.176204E-07
Epoch took 8.463s

Epoch 94 of 100
  training loss:		7.367435E-07
  validation loss:		5.547702E-07
Epoch took 8.427s

Epoch 95 of 100
  training loss:		1.353928E-06
  validation loss:		1.402581E-06
Epoch took 8.665s

Epoch 96 of 100
  training loss:		1.345527E-06
  validation loss:		3.670156E-07
Epoch took 8.711s

Epoch 97 of 100
  training loss:		8.259079E-07
  validation loss:		9.993401E-07
Epoch took 7.937s

Epoch 98 of 100
  training loss:		1.673656E-06
  validation loss:		6.145711E-07
Epoch took 7.645s

Epoch 99 of 100
  training loss:		1.158672E-06
  validation loss:		1.402880E-06
Epoch took 8.588s

Epoch 100 of 100
  training loss:		6.316881E-07
  validation loss:		2.631822E-06
Epoch took 7.805s

Training RMSE: 0.00161609988344
Validation RMSE: 0.00162106851398
