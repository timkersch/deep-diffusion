Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.823495E-02
  validation loss:		3.745073E-03
Epoch took 7.521s

Epoch 2 of 100
  training loss:		2.656360E-03
  validation loss:		1.877989E-03
Epoch took 8.279s

Epoch 3 of 100
  training loss:		1.459472E-03
  validation loss:		1.102889E-03
Epoch took 7.385s

Epoch 4 of 100
  training loss:		8.871166E-04
  validation loss:		6.917999E-04
Epoch took 8.111s

Epoch 5 of 100
  training loss:		5.696306E-04
  validation loss:		4.603029E-04
Epoch took 8.061s

Epoch 6 of 100
  training loss:		3.846222E-04
  validation loss:		3.174216E-04
Epoch took 7.166s

Epoch 7 of 100
  training loss:		2.717951E-04
  validation loss:		2.246879E-04
Epoch took 8.059s

Epoch 8 of 100
  training loss:		1.968531E-04
  validation loss:		1.671529E-04
Epoch took 9.001s

Epoch 9 of 100
  training loss:		1.423986E-04
  validation loss:		1.201728E-04
Epoch took 8.426s

Epoch 10 of 100
  training loss:		1.054387E-04
  validation loss:		9.488474E-05
Epoch took 8.150s

Epoch 11 of 100
  training loss:		8.158137E-05
  validation loss:		7.275041E-05
Epoch took 7.579s

Epoch 12 of 100
  training loss:		6.253606E-05
  validation loss:		5.177160E-05
Epoch took 7.974s

Epoch 13 of 100
  training loss:		4.917205E-05
  validation loss:		4.479271E-05
Epoch took 8.452s

Epoch 14 of 100
  training loss:		3.837856E-05
  validation loss:		3.461233E-05
Epoch took 8.039s

Epoch 15 of 100
  training loss:		3.077378E-05
  validation loss:		2.524181E-05
Epoch took 8.415s

Epoch 16 of 100
  training loss:		2.624966E-05
  validation loss:		2.102326E-05
Epoch took 7.216s

Epoch 17 of 100
  training loss:		2.085495E-05
  validation loss:		1.624167E-05
Epoch took 7.832s

Epoch 18 of 100
  training loss:		1.740168E-05
  validation loss:		1.504159E-05
Epoch took 7.512s

Epoch 19 of 100
  training loss:		1.387127E-05
  validation loss:		1.153662E-05
Epoch took 8.546s

Epoch 20 of 100
  training loss:		1.166688E-05
  validation loss:		1.123953E-05
Epoch took 8.180s

Epoch 21 of 100
  training loss:		9.690436E-06
  validation loss:		7.712496E-06
Epoch took 8.461s

Epoch 22 of 100
  training loss:		8.069684E-06
  validation loss:		6.363633E-06
Epoch took 8.413s

Epoch 23 of 100
  training loss:		6.953627E-06
  validation loss:		5.355512E-06
Epoch took 9.011s

Epoch 24 of 100
  training loss:		6.764774E-06
  validation loss:		4.325794E-06
Epoch took 9.058s

Epoch 25 of 100
  training loss:		4.879786E-06
  validation loss:		4.455851E-06
Epoch took 8.655s

Epoch 26 of 100
  training loss:		4.390106E-06
  validation loss:		3.033796E-06
Epoch took 7.651s

Epoch 27 of 100
  training loss:		3.900878E-06
  validation loss:		6.800296E-06
Epoch took 7.915s

Epoch 28 of 100
  training loss:		4.131963E-06
  validation loss:		2.985061E-06
Epoch took 8.640s

Epoch 29 of 100
  training loss:		4.404202E-06
  validation loss:		2.066604E-06
Epoch took 7.693s

Epoch 30 of 100
  training loss:		2.917577E-06
  validation loss:		2.053887E-06
Epoch took 7.936s

Epoch 31 of 100
  training loss:		2.148849E-06
  validation loss:		1.722095E-06
Epoch took 8.643s

Epoch 32 of 100
  training loss:		1.980402E-06
  validation loss:		1.386406E-06
Epoch took 8.609s

Epoch 33 of 100
  training loss:		2.105447E-06
  validation loss:		1.658473E-06
Epoch took 7.921s

Epoch 34 of 100
  training loss:		1.959683E-06
  validation loss:		1.780790E-06
Epoch took 7.790s

Epoch 35 of 100
  training loss:		1.483640E-06
  validation loss:		1.504514E-06
Epoch took 8.274s

Epoch 36 of 100
  training loss:		1.691338E-06
  validation loss:		9.350331E-07
Epoch took 7.925s

Epoch 37 of 100
  training loss:		3.390606E-06
  validation loss:		6.389068E-06
Epoch took 7.380s

Epoch 38 of 100
  training loss:		1.792130E-06
  validation loss:		1.496730E-06
Epoch took 8.293s

Epoch 39 of 100
  training loss:		1.620736E-06
  validation loss:		1.527818E-06
Epoch took 9.212s

Epoch 40 of 100
  training loss:		3.670391E-06
  validation loss:		3.210871E-07
Epoch took 7.899s

Epoch 41 of 100
  training loss:		1.209230E-06
  validation loss:		7.884939E-07
Epoch took 8.253s

Epoch 42 of 100
  training loss:		7.142274E-07
  validation loss:		2.469816E-07
Epoch took 8.284s

Epoch 43 of 100
  training loss:		1.408786E-06
  validation loss:		2.666539E-07
Epoch took 8.292s

Epoch 44 of 100
  training loss:		2.057038E-06
  validation loss:		7.322428E-07
Epoch took 7.985s

Epoch 45 of 100
  training loss:		6.558296E-07
  validation loss:		5.730938E-07
Epoch took 7.885s

Epoch 46 of 100
  training loss:		2.459234E-06
  validation loss:		1.355750E-06
Epoch took 7.798s

Epoch 47 of 100
  training loss:		2.840438E-06
  validation loss:		3.428886E-07
Epoch took 7.842s

Epoch 48 of 100
  training loss:		1.160890E-06
  validation loss:		7.095854E-07
Epoch took 7.774s

Epoch 49 of 100
  training loss:		4.424464E-06
  validation loss:		9.892565E-08
Epoch took 8.470s

Epoch 50 of 100
  training loss:		2.199579E-07
  validation loss:		4.556379E-07
Epoch took 7.512s

Epoch 51 of 100
  training loss:		9.523527E-07
  validation loss:		2.448899E-05
Epoch took 8.548s

Epoch 52 of 100
  training loss:		1.268870E-06
  validation loss:		6.421127E-08
Epoch took 8.279s

Epoch 53 of 100
  training loss:		7.026339E-06
  validation loss:		1.789491E-07
Epoch took 8.357s

Epoch 54 of 100
  training loss:		9.595925E-08
  validation loss:		9.070146E-08
Epoch took 7.887s

Epoch 55 of 100
  training loss:		8.555869E-08
  validation loss:		1.594497E-07
Epoch took 8.138s

Epoch 56 of 100
  training loss:		3.212890E-06
  validation loss:		7.255715E-06
Epoch took 8.396s

Epoch 57 of 100
  training loss:		6.934777E-07
  validation loss:		4.186434E-08
Epoch took 8.095s

Epoch 58 of 100
  training loss:		2.090085E-07
  validation loss:		3.470088E-07
Epoch took 8.307s

Epoch 59 of 100
  training loss:		3.416016E-06
  validation loss:		7.942274E-06
Epoch took 7.895s

Epoch 60 of 100
  training loss:		2.018745E-06
  validation loss:		1.183026E-07
Epoch took 8.077s

Epoch 61 of 100
  training loss:		2.291808E-07
  validation loss:		8.405706E-08
Epoch took 8.405s

Epoch 62 of 100
  training loss:		5.168951E-06
  validation loss:		2.154332E-06
Epoch took 7.800s

Epoch 63 of 100
  training loss:		2.796749E-07
  validation loss:		1.226444E-08
Epoch took 8.264s

Epoch 64 of 100
  training loss:		8.954490E-08
  validation loss:		2.794779E-07
Epoch took 7.694s

Epoch 65 of 100
  training loss:		7.744220E-06
  validation loss:		8.120028E-08
Epoch took 7.744s

Epoch 66 of 100
  training loss:		2.778346E-08
  validation loss:		2.669490E-08
Epoch took 8.024s

Epoch 67 of 100
  training loss:		4.609668E-08
  validation loss:		3.463067E-08
Epoch took 7.236s

Epoch 68 of 100
  training loss:		2.239757E-07
  validation loss:		2.586045E-06
Epoch took 7.673s

Epoch 69 of 100
  training loss:		3.092140E-06
  validation loss:		1.009733E-07
Epoch took 7.538s

Epoch 70 of 100
  training loss:		1.085129E-06
  validation loss:		4.010683E-07
Epoch took 7.378s

Epoch 71 of 100
  training loss:		2.282112E-06
  validation loss:		1.553606E-06
Epoch took 8.818s

Epoch 72 of 100
  training loss:		6.875638E-07
  validation loss:		5.467061E-07
Epoch took 7.873s

Epoch 73 of 100
  training loss:		2.157084E-06
  validation loss:		9.986999E-06
Epoch took 8.063s

Epoch 74 of 100
  training loss:		4.266950E-06
  validation loss:		7.614746E-08
Epoch took 8.131s

Epoch 75 of 100
  training loss:		1.776637E-08
  validation loss:		1.805249E-08
Epoch took 8.041s

Epoch 76 of 100
  training loss:		6.000974E-06
  validation loss:		4.909483E-06
Epoch took 8.253s

Epoch 77 of 100
  training loss:		1.912149E-06
  validation loss:		6.427342E-09
Epoch took 9.293s

Epoch 78 of 100
  training loss:		6.891480E-09
  validation loss:		3.018348E-09
Epoch took 7.963s

Epoch 79 of 100
  training loss:		9.546129E-08
  validation loss:		1.578722E-06
Epoch took 8.401s

Epoch 80 of 100
  training loss:		1.251868E-06
  validation loss:		6.729850E-06
Epoch took 8.203s

Epoch 81 of 100
  training loss:		7.330060E-06
  validation loss:		2.938943E-08
Epoch took 7.578s

Epoch 82 of 100
  training loss:		6.520992E-08
  validation loss:		9.410956E-09
Epoch took 8.895s

Epoch 83 of 100
  training loss:		1.756974E-08
  validation loss:		5.573201E-08
Epoch took 8.070s

Epoch 84 of 100
  training loss:		1.332135E-06
  validation loss:		2.299114E-06
Epoch took 8.016s

Epoch 85 of 100
  training loss:		3.613064E-06
  validation loss:		1.351407E-08
Epoch took 7.540s

Epoch 86 of 100
  training loss:		1.222469E-08
  validation loss:		7.601267E-09
Epoch took 8.184s

Epoch 87 of 100
  training loss:		5.396581E-06
  validation loss:		1.573709E-06
Epoch took 8.406s

Epoch 88 of 100
  training loss:		6.934975E-07
  validation loss:		2.831969E-09
Epoch took 8.215s

Epoch 89 of 100
  training loss:		3.743305E-08
  validation loss:		1.694962E-07
Epoch took 7.330s

Epoch 90 of 100
  training loss:		1.655948E-06
  validation loss:		1.527995E-05
Epoch took 7.944s

Epoch 91 of 100
  training loss:		2.311881E-06
  validation loss:		1.019844E-06
Epoch took 8.227s

Epoch 92 of 100
  training loss:		1.066835E-06
  validation loss:		3.982761E-06
Epoch took 8.449s

Epoch 93 of 100
  training loss:		8.126201E-06
  validation loss:		5.907331E-07
Epoch took 7.569s

Epoch 94 of 100
  training loss:		3.987616E-08
  validation loss:		2.617596E-09
Epoch took 7.142s

Epoch 95 of 100
  training loss:		2.618937E-09
  validation loss:		1.645602E-09
Epoch took 8.229s

Epoch 96 of 100
  training loss:		2.247029E-08
  validation loss:		4.755856E-08
Epoch took 8.443s

Epoch 97 of 100
  training loss:		3.942382E-06
  validation loss:		5.807773E-07
Epoch took 8.109s

Epoch 98 of 100
  training loss:		9.601318E-07
  validation loss:		3.297955E-06
Epoch took 8.288s

Epoch 99 of 100
  training loss:		1.634054E-06
  validation loss:		7.803296E-08
Epoch took 8.616s

Epoch 100 of 100
  training loss:		7.268029E-07
  validation loss:		1.686750E-06
Epoch took 8.981s

Training RMSE: 0.0013045523557
Validation RMSE: 0.00129868095447
