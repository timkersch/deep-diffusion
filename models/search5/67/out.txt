Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		9.349510E-02
  validation loss:		5.592860E-02
Epoch took 8.154s

Epoch 2 of 100
  training loss:		5.094324E-02
  validation loss:		4.411360E-02
Epoch took 8.694s

Epoch 3 of 100
  training loss:		4.276240E-02
  validation loss:		3.881208E-02
Epoch took 8.572s

Epoch 4 of 100
  training loss:		3.854563E-02
  validation loss:		3.609959E-02
Epoch took 8.838s

Epoch 5 of 100
  training loss:		3.620421E-02
  validation loss:		3.409401E-02
Epoch took 8.395s

Epoch 6 of 100
  training loss:		3.436845E-02
  validation loss:		3.221111E-02
Epoch took 8.164s

Epoch 7 of 100
  training loss:		3.319830E-02
  validation loss:		3.113243E-02
Epoch took 7.180s

Epoch 8 of 100
  training loss:		3.227643E-02
  validation loss:		3.334591E-02
Epoch took 8.766s

Epoch 9 of 100
  training loss:		3.138264E-02
  validation loss:		2.948578E-02
Epoch took 8.384s

Epoch 10 of 100
  training loss:		3.080595E-02
  validation loss:		2.946250E-02
Epoch took 8.776s

Epoch 11 of 100
  training loss:		3.013836E-02
  validation loss:		2.878903E-02
Epoch took 8.218s

Epoch 12 of 100
  training loss:		2.964131E-02
  validation loss:		2.931145E-02
Epoch took 8.349s

Epoch 13 of 100
  training loss:		2.954935E-02
  validation loss:		3.140479E-02
Epoch took 7.829s

Epoch 14 of 100
  training loss:		2.984678E-02
  validation loss:		2.886759E-02
Epoch took 8.214s

Epoch 15 of 100
  training loss:		2.890398E-02
  validation loss:		2.829955E-02
Epoch took 8.138s

Epoch 16 of 100
  training loss:		2.878371E-02
  validation loss:		2.936996E-02
Epoch took 8.734s

Epoch 17 of 100
  training loss:		2.853562E-02
  validation loss:		2.834855E-02
Epoch took 9.058s

Epoch 18 of 100
  training loss:		2.832442E-02
  validation loss:		2.771745E-02
Epoch took 7.847s

Epoch 19 of 100
  training loss:		2.853563E-02
  validation loss:		2.767556E-02
Epoch took 8.520s

Epoch 20 of 100
  training loss:		2.865567E-02
  validation loss:		2.768721E-02
Epoch took 7.805s

Epoch 21 of 100
  training loss:		2.828890E-02
  validation loss:		2.768261E-02
Epoch took 8.263s

Epoch 22 of 100
  training loss:		2.790710E-02
  validation loss:		2.846542E-02
Epoch took 8.532s

Epoch 23 of 100
  training loss:		2.802219E-02
  validation loss:		2.702623E-02
Epoch took 8.201s

Epoch 24 of 100
  training loss:		2.765029E-02
  validation loss:		2.747787E-02
Epoch took 8.642s

Epoch 25 of 100
  training loss:		2.760012E-02
  validation loss:		2.876481E-02
Epoch took 9.114s

Epoch 26 of 100
  training loss:		2.768416E-02
  validation loss:		2.702659E-02
Epoch took 7.844s

Epoch 27 of 100
  training loss:		2.747955E-02
  validation loss:		2.680912E-02
Epoch took 8.771s

Epoch 28 of 100
  training loss:		2.765459E-02
  validation loss:		2.705005E-02
Epoch took 8.307s

Epoch 29 of 100
  training loss:		2.788740E-02
  validation loss:		2.722131E-02
Epoch took 8.292s

Epoch 30 of 100
  training loss:		2.802681E-02
  validation loss:		2.725358E-02
Epoch took 9.618s

Epoch 31 of 100
  training loss:		2.733577E-02
  validation loss:		3.041408E-02
Epoch took 9.316s

Epoch 32 of 100
  training loss:		2.771824E-02
  validation loss:		2.850231E-02
Epoch took 9.147s

Epoch 33 of 100
  training loss:		2.754558E-02
  validation loss:		2.799901E-02
Epoch took 8.672s

Epoch 34 of 100
  training loss:		2.738046E-02
  validation loss:		2.661873E-02
Epoch took 8.960s

Epoch 35 of 100
  training loss:		2.777513E-02
  validation loss:		2.781378E-02
Epoch took 7.835s

Epoch 36 of 100
  training loss:		2.742926E-02
  validation loss:		2.717173E-02
Epoch took 9.076s

Epoch 37 of 100
  training loss:		2.709547E-02
  validation loss:		2.689728E-02
Epoch took 8.782s

Epoch 38 of 100
  training loss:		2.740093E-02
  validation loss:		2.674355E-02
Epoch took 8.719s

Epoch 39 of 100
  training loss:		2.727761E-02
  validation loss:		2.712976E-02
Epoch took 9.242s

Epoch 40 of 100
  training loss:		2.736286E-02
  validation loss:		2.778028E-02
Epoch took 7.908s

Early stopping, val-loss increased over the last 10 epochs from 0.0274777596669 to 0.0277070493186
Training RMSE: 1.61713768558e-07
Validation RMSE: 1.61758517127e-07
