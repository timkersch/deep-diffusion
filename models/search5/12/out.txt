Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		8.650376E-02
  validation loss:		1.771421E-03
Epoch took 6.987s

Epoch 2 of 100
  training loss:		1.099806E-03
  validation loss:		6.132587E-04
Epoch took 8.245s

Epoch 3 of 100
  training loss:		4.221460E-04
  validation loss:		2.610389E-04
Epoch took 7.700s

Epoch 4 of 100
  training loss:		1.873782E-04
  validation loss:		1.202379E-04
Epoch took 7.583s

Epoch 5 of 100
  training loss:		9.701299E-05
  validation loss:		7.010866E-05
Epoch took 7.874s

Epoch 6 of 100
  training loss:		5.884205E-05
  validation loss:		4.465142E-05
Epoch took 8.901s

Epoch 7 of 100
  training loss:		3.902182E-05
  validation loss:		3.065754E-05
Epoch took 7.661s

Epoch 8 of 100
  training loss:		2.752413E-05
  validation loss:		2.255695E-05
Epoch took 8.025s

Epoch 9 of 100
  training loss:		2.032570E-05
  validation loss:		1.775196E-05
Epoch took 7.565s

Epoch 10 of 100
  training loss:		1.606564E-05
  validation loss:		1.409734E-05
Epoch took 7.449s

Epoch 11 of 100
  training loss:		1.275496E-05
  validation loss:		1.110742E-05
Epoch took 7.905s

Epoch 12 of 100
  training loss:		1.025506E-05
  validation loss:		9.606769E-06
Epoch took 8.220s

Epoch 13 of 100
  training loss:		8.576355E-06
  validation loss:		7.545359E-06
Epoch took 7.940s

Epoch 14 of 100
  training loss:		6.933609E-06
  validation loss:		6.209016E-06
Epoch took 7.755s

Epoch 15 of 100
  training loss:		5.856895E-06
  validation loss:		5.429046E-06
Epoch took 8.603s

Epoch 16 of 100
  training loss:		5.075997E-06
  validation loss:		4.447065E-06
Epoch took 8.004s

Epoch 17 of 100
  training loss:		4.186680E-06
  validation loss:		3.970285E-06
Epoch took 8.404s

Epoch 18 of 100
  training loss:		3.518856E-06
  validation loss:		3.403936E-06
Epoch took 8.123s

Epoch 19 of 100
  training loss:		3.081545E-06
  validation loss:		2.993820E-06
Epoch took 7.961s

Epoch 20 of 100
  training loss:		2.564970E-06
  validation loss:		2.447212E-06
Epoch took 8.238s

Epoch 21 of 100
  training loss:		2.074359E-06
  validation loss:		1.800580E-06
Epoch took 8.221s

Epoch 22 of 100
  training loss:		1.762029E-06
  validation loss:		1.582996E-06
Epoch took 7.732s

Epoch 23 of 100
  training loss:		1.440336E-06
  validation loss:		1.635773E-06
Epoch took 7.104s

Epoch 24 of 100
  training loss:		1.265456E-06
  validation loss:		1.084639E-06
Epoch took 9.732s

Epoch 25 of 100
  training loss:		1.116044E-06
  validation loss:		9.870502E-07
Epoch took 7.918s

Epoch 26 of 100
  training loss:		9.817607E-07
  validation loss:		8.674135E-07
Epoch took 8.945s

Epoch 27 of 100
  training loss:		8.420372E-07
  validation loss:		6.336610E-07
Epoch took 8.241s

Epoch 28 of 100
  training loss:		6.895748E-07
  validation loss:		5.827199E-07
Epoch took 7.235s

Epoch 29 of 100
  training loss:		6.426052E-07
  validation loss:		6.849205E-07
Epoch took 6.878s

Epoch 30 of 100
  training loss:		5.080873E-07
  validation loss:		1.237328E-06
Epoch took 7.980s

Epoch 31 of 100
  training loss:		4.868575E-07
  validation loss:		3.429403E-07
Epoch took 8.396s

Epoch 32 of 100
  training loss:		4.546331E-07
  validation loss:		6.685605E-07
Epoch took 8.248s

Epoch 33 of 100
  training loss:		7.421213E-07
  validation loss:		2.039287E-06
Epoch took 7.641s

Epoch 34 of 100
  training loss:		9.507613E-06
  validation loss:		2.024568E-06
Epoch took 7.905s

Epoch 35 of 100
  training loss:		6.438562E-06
  validation loss:		3.116135E-05
Epoch took 7.138s

Epoch 36 of 100
  training loss:		3.846171E-05
  validation loss:		1.066028E-04
Epoch took 7.813s

Epoch 37 of 100
  training loss:		6.723101E-05
  validation loss:		1.034541E-05
Epoch took 7.329s

Epoch 38 of 100
  training loss:		5.272500E-05
  validation loss:		6.894318E-07
Epoch took 7.568s

Epoch 39 of 100
  training loss:		9.160115E-05
  validation loss:		2.975940E-05
Epoch took 8.015s

Epoch 40 of 100
  training loss:		1.154557E-05
  validation loss:		1.118733E-06
Epoch took 7.605s

Epoch 41 of 100
  training loss:		4.184476E-06
  validation loss:		9.033575E-07
Epoch took 8.496s

Epoch 42 of 100
  training loss:		2.334603E-04
  validation loss:		3.705792E-06
Epoch took 7.722s

Epoch 43 of 100
  training loss:		1.612947E-06
  validation loss:		1.236921E-06
Epoch took 7.643s

Epoch 44 of 100
  training loss:		1.518272E-06
  validation loss:		2.485947E-07
Epoch took 8.851s

Epoch 45 of 100
  training loss:		1.145299E-06
  validation loss:		4.586993E-06
Epoch took 8.935s

Epoch 46 of 100
  training loss:		1.381985E-04
  validation loss:		1.154509E-06
Epoch took 8.060s

Epoch 47 of 100
  training loss:		3.491442E-06
  validation loss:		7.118046E-06
Epoch took 7.478s

Epoch 48 of 100
  training loss:		1.473962E-05
  validation loss:		3.773450E-06
Epoch took 7.958s

Epoch 49 of 100
  training loss:		1.237139E-04
  validation loss:		2.918074E-06
Epoch took 8.104s

Epoch 50 of 100
  training loss:		8.567900E-06
  validation loss:		3.054504E-06
Epoch took 7.991s

Epoch 51 of 100
  training loss:		7.385270E-05
  validation loss:		4.165310E-05
Epoch took 8.019s

Epoch 52 of 100
  training loss:		1.070587E-05
  validation loss:		1.079117E-06
Epoch took 8.941s

Epoch 53 of 100
  training loss:		7.298459E-05
  validation loss:		7.810141E-05
Epoch took 8.087s

Epoch 54 of 100
  training loss:		2.651343E-05
  validation loss:		1.956005E-06
Epoch took 9.134s

Epoch 55 of 100
  training loss:		4.880170E-05
  validation loss:		2.071258E-06
Epoch took 8.371s

Epoch 56 of 100
  training loss:		4.792104E-07
  validation loss:		1.700498E-07
Epoch took 7.643s

Epoch 57 of 100
  training loss:		5.325221E-05
  validation loss:		1.834376E-05
Epoch took 7.497s

Epoch 58 of 100
  training loss:		1.140231E-04
  validation loss:		5.832431E-06
Epoch took 7.939s

Epoch 59 of 100
  training loss:		1.811017E-06
  validation loss:		3.063542E-07
Epoch took 7.802s

Epoch 60 of 100
  training loss:		5.055874E-06
  validation loss:		4.202452E-05
Epoch took 7.884s

Epoch 61 of 100
  training loss:		1.665667E-04
  validation loss:		4.485567E-06
Epoch took 7.874s

Epoch 62 of 100
  training loss:		1.427994E-06
  validation loss:		2.506431E-06
Epoch took 7.691s

Epoch 63 of 100
  training loss:		7.241862E-07
  validation loss:		3.551889E-07
Epoch took 7.728s

Epoch 64 of 100
  training loss:		2.597585E-07
  validation loss:		1.323921E-07
Epoch took 8.169s

Epoch 65 of 100
  training loss:		4.075700E-05
  validation loss:		1.533097E-05
Epoch took 7.431s

Epoch 66 of 100
  training loss:		2.782328E-06
  validation loss:		8.548270E-07
Epoch took 7.991s

Epoch 67 of 100
  training loss:		9.218018E-05
  validation loss:		2.554727E-05
Epoch took 7.335s

Epoch 68 of 100
  training loss:		3.288751E-06
  validation loss:		2.226059E-07
Epoch took 7.750s

Epoch 69 of 100
  training loss:		1.943862E-06
  validation loss:		3.232703E-06
Epoch took 7.637s

Epoch 70 of 100
  training loss:		1.091809E-04
  validation loss:		1.718304E-05
Epoch took 8.085s

Epoch 71 of 100
  training loss:		6.378991E-06
  validation loss:		2.047055E-06
Epoch took 7.203s

Epoch 72 of 100
  training loss:		2.699215E-06
  validation loss:		2.011879E-07
Epoch took 8.398s

Epoch 73 of 100
  training loss:		3.415753E-05
  validation loss:		8.210427E-05
Epoch took 7.764s

Epoch 74 of 100
  training loss:		1.698952E-05
  validation loss:		1.579049E-07
Epoch took 7.562s

Epoch 75 of 100
  training loss:		1.113614E-05
  validation loss:		5.830420E-05
Epoch took 8.198s

Epoch 76 of 100
  training loss:		2.697335E-05
  validation loss:		6.155324E-06
Epoch took 8.106s

Epoch 77 of 100
  training loss:		3.622108E-05
  validation loss:		4.366510E-06
Epoch took 6.865s

Epoch 78 of 100
  training loss:		1.510730E-06
  validation loss:		1.965150E-05
Epoch took 6.933s

Epoch 79 of 100
  training loss:		1.879290E-05
  validation loss:		1.604952E-06
Epoch took 7.548s

Epoch 80 of 100
  training loss:		2.120828E-04
  validation loss:		4.202473E-06
Epoch took 7.537s

Epoch 81 of 100
  training loss:		1.348634E-06
  validation loss:		7.932147E-07
Epoch took 8.063s

Epoch 82 of 100
  training loss:		4.946239E-07
  validation loss:		2.262961E-07
Epoch took 7.940s

Epoch 83 of 100
  training loss:		2.831094E-07
  validation loss:		1.788853E-07
Epoch took 7.728s

Epoch 84 of 100
  training loss:		1.469901E-07
  validation loss:		6.481826E-08
Epoch took 8.320s

Epoch 85 of 100
  training loss:		7.226119E-08
  validation loss:		4.392520E-08
Epoch took 7.932s

Epoch 86 of 100
  training loss:		1.193587E-07
  validation loss:		5.005837E-08
Epoch took 8.310s

Epoch 87 of 100
  training loss:		3.172159E-05
  validation loss:		6.961670E-05
Epoch took 8.602s

Epoch 88 of 100
  training loss:		1.088288E-05
  validation loss:		2.078754E-07
Epoch took 7.980s

Epoch 89 of 100
  training loss:		5.936636E-07
  validation loss:		2.463285E-06
Epoch took 8.154s

Epoch 90 of 100
  training loss:		4.534588E-05
  validation loss:		1.367890E-06
Epoch took 7.472s

Epoch 91 of 100
  training loss:		3.482578E-07
  validation loss:		1.486315E-07
Epoch took 8.289s

Epoch 92 of 100
  training loss:		1.113369E-06
  validation loss:		4.614310E-06
Epoch took 8.113s

Epoch 93 of 100
  training loss:		7.177627E-05
  validation loss:		8.575822E-06
Epoch took 8.505s

Epoch 94 of 100
  training loss:		1.150071E-06
  validation loss:		4.899767E-07
Epoch took 8.841s

Epoch 95 of 100
  training loss:		1.283041E-07
  validation loss:		3.072944E-08
Epoch took 9.558s

Epoch 96 of 100
  training loss:		1.307837E-07
  validation loss:		1.206161E-07
Epoch took 7.643s

Epoch 97 of 100
  training loss:		1.000962E-06
  validation loss:		2.644895E-05
Epoch took 7.921s

Epoch 98 of 100
  training loss:		3.883675E-05
  validation loss:		8.405454E-06
Epoch took 8.375s

Epoch 99 of 100
  training loss:		1.123050E-05
  validation loss:		6.754247E-06
Epoch took 8.454s

Epoch 100 of 100
  training loss:		1.056899E-06
  validation loss:		4.413618E-08
Epoch took 9.264s

Training RMSE: 0.000214418467982
Validation RMSE: 0.000210334435055
