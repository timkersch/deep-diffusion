Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		9.080180E-02
  validation loss:		6.079753E-02
Epoch took 7.987s

Epoch 2 of 100
  training loss:		5.476421E-02
  validation loss:		4.791357E-02
Epoch took 7.327s

Epoch 3 of 100
  training loss:		4.577255E-02
  validation loss:		4.255804E-02
Epoch took 7.693s

Epoch 4 of 100
  training loss:		4.052787E-02
  validation loss:		3.894901E-02
Epoch took 7.415s

Epoch 5 of 100
  training loss:		3.765778E-02
  validation loss:		3.611017E-02
Epoch took 7.464s

Epoch 6 of 100
  training loss:		3.558113E-02
  validation loss:		3.489972E-02
Epoch took 9.035s

Epoch 7 of 100
  training loss:		3.378646E-02
  validation loss:		3.264555E-02
Epoch took 7.237s

Epoch 8 of 100
  training loss:		3.307401E-02
  validation loss:		3.130848E-02
Epoch took 7.075s

Epoch 9 of 100
  training loss:		3.148064E-02
  validation loss:		3.065368E-02
Epoch took 7.739s

Epoch 10 of 100
  training loss:		3.094927E-02
  validation loss:		3.048747E-02
Epoch took 8.312s

Epoch 11 of 100
  training loss:		3.029970E-02
  validation loss:		3.134672E-02
Epoch took 9.154s

Epoch 12 of 100
  training loss:		2.992647E-02
  validation loss:		2.939644E-02
Epoch took 8.293s

Epoch 13 of 100
  training loss:		2.982515E-02
  validation loss:		2.923492E-02
Epoch took 7.717s

Epoch 14 of 100
  training loss:		2.926522E-02
  validation loss:		2.980702E-02
Epoch took 7.905s

Epoch 15 of 100
  training loss:		2.898318E-02
  validation loss:		2.808799E-02
Epoch took 8.329s

Epoch 16 of 100
  training loss:		2.870479E-02
  validation loss:		2.818100E-02
Epoch took 8.720s

Epoch 17 of 100
  training loss:		2.881724E-02
  validation loss:		2.903148E-02
Epoch took 8.346s

Epoch 18 of 100
  training loss:		2.821742E-02
  validation loss:		2.839774E-02
Epoch took 8.522s

Epoch 19 of 100
  training loss:		2.835196E-02
  validation loss:		2.816118E-02
Epoch took 7.675s

Epoch 20 of 100
  training loss:		2.810073E-02
  validation loss:		2.877437E-02
Epoch took 7.745s

Epoch 21 of 100
  training loss:		2.787979E-02
  validation loss:		2.816180E-02
Epoch took 8.312s

Epoch 22 of 100
  training loss:		2.789898E-02
  validation loss:		2.827666E-02
Epoch took 7.514s

Epoch 23 of 100
  training loss:		2.765952E-02
  validation loss:		2.905738E-02
Epoch took 7.964s

Epoch 24 of 100
  training loss:		2.772651E-02
  validation loss:		2.732792E-02
Epoch took 8.240s

Epoch 25 of 100
  training loss:		2.765570E-02
  validation loss:		2.692016E-02
Epoch took 8.150s

Epoch 26 of 100
  training loss:		2.752200E-02
  validation loss:		2.695335E-02
Epoch took 7.915s

Epoch 27 of 100
  training loss:		2.736692E-02
  validation loss:		2.749000E-02
Epoch took 8.027s

Epoch 28 of 100
  training loss:		2.728596E-02
  validation loss:		2.702959E-02
Epoch took 7.684s

Epoch 29 of 100
  training loss:		2.748063E-02
  validation loss:		2.853538E-02
Epoch took 8.871s

Epoch 30 of 100
  training loss:		2.737637E-02
  validation loss:		2.854350E-02
Epoch took 8.511s

Epoch 31 of 100
  training loss:		2.740367E-02
  validation loss:		2.653823E-02
Epoch took 8.178s

Epoch 32 of 100
  training loss:		2.708997E-02
  validation loss:		2.740814E-02
Epoch took 8.540s

Epoch 33 of 100
  training loss:		2.729805E-02
  validation loss:		2.739286E-02
Epoch took 7.949s

Epoch 34 of 100
  training loss:		2.752373E-02
  validation loss:		2.715982E-02
Epoch took 7.235s

Epoch 35 of 100
  training loss:		2.694793E-02
  validation loss:		2.663775E-02
Epoch took 8.164s

Epoch 36 of 100
  training loss:		2.719815E-02
  validation loss:		2.655358E-02
Epoch took 7.907s

Epoch 37 of 100
  training loss:		2.696158E-02
  validation loss:		3.064987E-02
Epoch took 7.979s

Epoch 38 of 100
  training loss:		2.714752E-02
  validation loss:		2.709367E-02
Epoch took 7.305s

Epoch 39 of 100
  training loss:		2.709840E-02
  validation loss:		2.697646E-02
Epoch took 7.446s

Epoch 40 of 100
  training loss:		2.712854E-02
  validation loss:		2.777445E-02
Epoch took 7.408s

Epoch 41 of 100
  training loss:		2.700380E-02
  validation loss:		2.663279E-02
Epoch took 7.560s

Epoch 42 of 100
  training loss:		2.678592E-02
  validation loss:		2.675339E-02
Epoch took 7.715s

Epoch 43 of 100
  training loss:		2.682521E-02
  validation loss:		2.767313E-02
Epoch took 7.255s

Epoch 44 of 100
  training loss:		2.680701E-02
  validation loss:		2.686758E-02
Epoch took 7.886s

Epoch 45 of 100
  training loss:		2.687763E-02
  validation loss:		2.704318E-02
Epoch took 7.876s

Epoch 46 of 100
  training loss:		2.713546E-02
  validation loss:		2.697793E-02
Epoch took 7.732s

Epoch 47 of 100
  training loss:		2.679094E-02
  validation loss:		2.626695E-02
Epoch took 7.661s

Epoch 48 of 100
  training loss:		2.704619E-02
  validation loss:		2.721955E-02
Epoch took 8.670s

Epoch 49 of 100
  training loss:		2.677369E-02
  validation loss:		2.871463E-02
Epoch took 8.280s

Epoch 50 of 100
  training loss:		2.681266E-02
  validation loss:		2.682768E-02
Epoch took 8.602s

Epoch 51 of 100
  training loss:		2.678294E-02
  validation loss:		2.718853E-02
Epoch took 7.651s

Epoch 52 of 100
  training loss:		2.679128E-02
  validation loss:		2.696041E-02
Epoch took 8.427s

Epoch 53 of 100
  training loss:		2.673170E-02
  validation loss:		2.826504E-02
Epoch took 8.346s

Epoch 54 of 100
  training loss:		2.676715E-02
  validation loss:		2.770288E-02
Epoch took 7.469s

Epoch 55 of 100
  training loss:		2.682938E-02
  validation loss:		2.707871E-02
Epoch took 7.864s

Epoch 56 of 100
  training loss:		2.708944E-02
  validation loss:		2.711382E-02
Epoch took 8.351s

Epoch 57 of 100
  training loss:		2.712515E-02
  validation loss:		2.655178E-02
Epoch took 7.437s

Epoch 58 of 100
  training loss:		2.657405E-02
  validation loss:		2.675343E-02
Epoch took 8.830s

Epoch 59 of 100
  training loss:		2.675501E-02
  validation loss:		2.647021E-02
Epoch took 7.855s

Epoch 60 of 100
  training loss:		2.678428E-02
  validation loss:		2.706209E-02
Epoch took 8.167s

Early stopping, val-loss increased over the last 10 epochs from 0.0270976812976 to 0.0271146923511
Training RMSE: 1.59551860559e-07
Validation RMSE: 1.60263675466e-07
