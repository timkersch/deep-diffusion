Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		9.829195E-03
  validation loss:		4.181641E-04
Epoch took 8.176s

Epoch 2 of 100
  training loss:		2.373021E-04
  validation loss:		1.411134E-04
Epoch took 8.643s

Epoch 3 of 100
  training loss:		7.904865E-05
  validation loss:		4.703310E-05
Epoch took 8.153s

Epoch 4 of 100
  training loss:		3.491961E-05
  validation loss:		2.194040E-05
Epoch took 8.933s

Epoch 5 of 100
  training loss:		1.720267E-05
  validation loss:		1.102517E-05
Epoch took 8.016s

Epoch 6 of 100
  training loss:		1.369706E-05
  validation loss:		1.353694E-05
Epoch took 8.478s

Epoch 7 of 100
  training loss:		1.195043E-05
  validation loss:		1.011075E-05
Epoch took 7.816s

Epoch 8 of 100
  training loss:		9.690779E-06
  validation loss:		5.759408E-06
Epoch took 7.628s

Epoch 9 of 100
  training loss:		1.173804E-05
  validation loss:		4.774232E-06
Epoch took 9.282s

Epoch 10 of 100
  training loss:		6.520545E-06
  validation loss:		2.582247E-05
Epoch took 8.349s

Epoch 11 of 100
  training loss:		1.590756E-05
  validation loss:		2.514641E-06
Epoch took 8.571s

Epoch 12 of 100
  training loss:		1.459629E-05
  validation loss:		3.526745E-07
Epoch took 8.141s

Epoch 13 of 100
  training loss:		7.281236E-05
  validation loss:		9.625664E-05
Epoch took 8.085s

Epoch 14 of 100
  training loss:		1.327395E-05
  validation loss:		3.129717E-06
Epoch took 10.441s

Epoch 15 of 100
  training loss:		2.409434E-06
  validation loss:		9.282305E-07
Epoch took 9.327s

Epoch 16 of 100
  training loss:		2.501440E-04
  validation loss:		3.441766E-06
Epoch took 9.255s

Epoch 17 of 100
  training loss:		2.343659E-06
  validation loss:		5.823454E-07
Epoch took 8.800s

Epoch 18 of 100
  training loss:		1.461718E-06
  validation loss:		7.656630E-07
Epoch took 8.364s

Epoch 19 of 100
  training loss:		3.269947E-07
  validation loss:		1.407987E-07
Epoch took 8.904s

Epoch 20 of 100
  training loss:		1.254052E-05
  validation loss:		2.169509E-07
Epoch took 7.575s

Epoch 21 of 100
  training loss:		6.959538E-05
  validation loss:		4.909268E-07
Epoch took 8.621s

Epoch 22 of 100
  training loss:		9.331985E-06
  validation loss:		5.905599E-06
Epoch took 8.735s

Epoch 23 of 100
  training loss:		1.249137E-04
  validation loss:		2.361283E-05
Epoch took 8.599s

Epoch 24 of 100
  training loss:		2.910260E-06
  validation loss:		3.862031E-06
Epoch took 8.040s

Epoch 25 of 100
  training loss:		7.704813E-05
  validation loss:		1.014791E-04
Epoch took 8.532s

Epoch 26 of 100
  training loss:		1.039769E-05
  validation loss:		3.179131E-07
Epoch took 8.752s

Epoch 27 of 100
  training loss:		1.460869E-06
  validation loss:		1.647410E-07
Epoch took 8.835s

Epoch 28 of 100
  training loss:		6.303999E-05
  validation loss:		4.075489E-06
Epoch took 8.845s

Epoch 29 of 100
  training loss:		5.402199E-06
  validation loss:		9.465618E-07
Epoch took 8.984s

Epoch 30 of 100
  training loss:		7.834369E-05
  validation loss:		6.239667E-06
Epoch took 8.772s

Epoch 31 of 100
  training loss:		1.148515E-06
  validation loss:		1.797540E-07
Epoch took 9.791s

Epoch 32 of 100
  training loss:		2.510313E-05
  validation loss:		2.538741E-04
Epoch took 9.296s

Epoch 33 of 100
  training loss:		4.152863E-05
  validation loss:		2.378701E-07
Epoch took 8.524s

Epoch 34 of 100
  training loss:		2.955339E-06
  validation loss:		5.429967E-07
Epoch took 9.199s

Epoch 35 of 100
  training loss:		1.366918E-04
  validation loss:		5.014745E-06
Epoch took 8.262s

Epoch 36 of 100
  training loss:		1.853828E-06
  validation loss:		5.028747E-07
Epoch took 9.282s

Epoch 37 of 100
  training loss:		8.038425E-07
  validation loss:		6.906132E-07
Epoch took 8.925s

Epoch 38 of 100
  training loss:		6.972663E-07
  validation loss:		2.342666E-06
Epoch took 8.159s

Epoch 39 of 100
  training loss:		2.712008E-05
  validation loss:		1.423166E-04
Epoch took 8.243s

Epoch 40 of 100
  training loss:		6.294175E-06
  validation loss:		3.013706E-05
Epoch took 8.164s

Epoch 41 of 100
  training loss:		6.834695E-05
  validation loss:		2.593514E-06
Epoch took 8.839s

Epoch 42 of 100
  training loss:		9.838664E-07
  validation loss:		1.514121E-06
Epoch took 8.052s

Epoch 43 of 100
  training loss:		5.071803E-05
  validation loss:		1.544450E-04
Epoch took 9.023s

Epoch 44 of 100
  training loss:		2.951803E-05
  validation loss:		8.405300E-08
Epoch took 8.547s

Epoch 45 of 100
  training loss:		7.078059E-08
  validation loss:		2.549366E-08
Epoch took 8.387s

Epoch 46 of 100
  training loss:		2.633406E-05
  validation loss:		7.989790E-05
Epoch took 10.618s

Epoch 47 of 100
  training loss:		1.145707E-05
  validation loss:		4.970645E-06
Epoch took 9.243s

Epoch 48 of 100
  training loss:		3.582798E-05
  validation loss:		6.164366E-05
Epoch took 8.626s

Epoch 49 of 100
  training loss:		1.097340E-05
  validation loss:		3.232635E-07
Epoch took 9.576s

Epoch 50 of 100
  training loss:		3.010221E-06
  validation loss:		6.052136E-06
Epoch took 9.078s

Epoch 51 of 100
  training loss:		6.298697E-05
  validation loss:		1.774892E-07
Epoch took 8.918s

Epoch 52 of 100
  training loss:		1.208981E-07
  validation loss:		2.409458E-08
Epoch took 9.609s

Epoch 53 of 100
  training loss:		2.997895E-05
  validation loss:		5.019445E-05
Epoch took 8.968s

Epoch 54 of 100
  training loss:		3.468915E-06
  validation loss:		1.198312E-06
Epoch took 8.501s

Epoch 55 of 100
  training loss:		2.362706E-05
  validation loss:		1.080032E-06
Epoch took 9.285s

Epoch 56 of 100
  training loss:		1.880558E-05
  validation loss:		1.487854E-05
Epoch took 8.704s

Epoch 57 of 100
  training loss:		2.977242E-05
  validation loss:		9.633295E-08
Epoch took 8.091s

Epoch 58 of 100
  training loss:		8.333660E-08
  validation loss:		9.428478E-09
Epoch took 8.328s

Epoch 59 of 100
  training loss:		4.955985E-05
  validation loss:		2.171755E-04
Epoch took 9.773s

Epoch 60 of 100
  training loss:		3.208261E-05
  validation loss:		1.069329E-07
Epoch took 8.484s

Epoch 61 of 100
  training loss:		8.567740E-08
  validation loss:		1.675062E-08
Epoch took 9.423s

Epoch 62 of 100
  training loss:		3.300348E-08
  validation loss:		1.635885E-08
Epoch took 8.128s

Epoch 63 of 100
  training loss:		2.316693E-05
  validation loss:		4.725023E-06
Epoch took 8.890s

Epoch 64 of 100
  training loss:		1.653989E-06
  validation loss:		1.017659E-05
Epoch took 8.826s

Epoch 65 of 100
  training loss:		3.273422E-05
  validation loss:		3.584051E-06
Epoch took 8.737s

Epoch 66 of 100
  training loss:		1.492104E-06
  validation loss:		3.722600E-06
Epoch took 8.369s

Epoch 67 of 100
  training loss:		2.180719E-05
  validation loss:		1.469066E-04
Epoch took 8.749s

Epoch 68 of 100
  training loss:		2.105399E-05
  validation loss:		6.683588E-08
Epoch took 9.172s

Epoch 69 of 100
  training loss:		3.774617E-08
  validation loss:		1.266337E-08
Epoch took 8.713s

Epoch 70 of 100
  training loss:		4.821612E-05
  validation loss:		2.392514E-04
Epoch took 8.649s

Epoch 71 of 100
  training loss:		3.267618E-05
  validation loss:		4.187914E-07
Epoch took 10.624s

Epoch 72 of 100
  training loss:		1.858251E-07
  validation loss:		7.103803E-08
Epoch took 7.873s

Epoch 73 of 100
  training loss:		3.250626E-08
  validation loss:		1.711739E-08
Epoch took 7.956s

Epoch 74 of 100
  training loss:		4.185088E-07
  validation loss:		3.088423E-06
Epoch took 8.220s

Epoch 75 of 100
  training loss:		4.631381E-05
  validation loss:		3.189937E-06
Epoch took 8.144s

Epoch 76 of 100
  training loss:		7.997166E-07
  validation loss:		1.125008E-07
Epoch took 8.652s

Epoch 77 of 100
  training loss:		1.742144E-07
  validation loss:		4.525066E-07
Epoch took 9.740s

Epoch 78 of 100
  training loss:		2.380147E-05
  validation loss:		1.351558E-05
Epoch took 8.771s

Epoch 79 of 100
  training loss:		2.788203E-06
  validation loss:		4.663100E-08
Epoch took 8.356s

Epoch 80 of 100
  training loss:		1.771026E-07
  validation loss:		2.470416E-07
Epoch took 8.590s

Epoch 81 of 100
  training loss:		3.362165E-05
  validation loss:		4.448490E-07
Epoch took 9.463s

Epoch 82 of 100
  training loss:		8.208919E-08
  validation loss:		3.371805E-08
Epoch took 8.838s

Epoch 83 of 100
  training loss:		4.187153E-07
  validation loss:		2.735376E-06
Epoch took 8.428s

Epoch 84 of 100
  training loss:		3.351920E-05
  validation loss:		1.618302E-05
Epoch took 8.925s

Epoch 85 of 100
  training loss:		2.966229E-06
  validation loss:		4.504199E-08
Epoch took 9.185s

Epoch 86 of 100
  training loss:		3.204594E-08
  validation loss:		3.193523E-07
Epoch took 7.870s

Epoch 87 of 100
  training loss:		2.247652E-05
  validation loss:		5.002087E-05
Epoch took 8.098s

Epoch 88 of 100
  training loss:		1.394725E-05
  validation loss:		5.296384E-08
Epoch took 9.753s

Epoch 89 of 100
  training loss:		1.915926E-08
  validation loss:		7.517444E-10
Epoch took 8.995s

Epoch 90 of 100
  training loss:		1.726661E-09
  validation loss:		5.167186E-09
Epoch took 7.434s

Epoch 91 of 100
  training loss:		3.140971E-05
  validation loss:		1.010842E-06
Epoch took 9.055s

Epoch 92 of 100
  training loss:		3.503557E-07
  validation loss:		7.958455E-08
Epoch took 7.927s

Epoch 93 of 100
  training loss:		3.494754E-07
  validation loss:		2.018484E-07
Epoch took 8.181s

Epoch 94 of 100
  training loss:		1.292213E-05
  validation loss:		1.034582E-06
Epoch took 8.556s

Epoch 95 of 100
  training loss:		2.776747E-06
  validation loss:		1.805397E-06
Epoch took 9.426s

Epoch 96 of 100
  training loss:		1.080502E-05
  validation loss:		1.052209E-07
Epoch took 7.823s

Epoch 97 of 100
  training loss:		1.026247E-05
  validation loss:		3.794553E-06
Epoch took 8.698s

Epoch 98 of 100
  training loss:		1.662043E-06
  validation loss:		1.065165E-07
Epoch took 8.921s

Epoch 99 of 100
  training loss:		7.440293E-06
  validation loss:		4.948041E-06
Epoch took 8.774s

Epoch 100 of 100
  training loss:		4.803661E-06
  validation loss:		2.382590E-05
Epoch took 8.543s

Training RMSE: 0.00485448329075
Validation RMSE: 0.00488093947134
