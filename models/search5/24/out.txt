Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		4.091527E-02
  validation loss:		1.093480E-03
Epoch took 8.988s

Epoch 2 of 100
  training loss:		5.690452E-04
  validation loss:		2.670308E-04
Epoch took 8.151s

Epoch 3 of 100
  training loss:		1.708037E-04
  validation loss:		1.082924E-04
Epoch took 8.022s

Epoch 4 of 100
  training loss:		7.234268E-05
  validation loss:		5.051599E-05
Epoch took 7.589s

Epoch 5 of 100
  training loss:		3.721053E-05
  validation loss:		2.891773E-05
Epoch took 7.691s

Epoch 6 of 100
  training loss:		2.236946E-05
  validation loss:		1.785386E-05
Epoch took 7.922s

Epoch 7 of 100
  training loss:		1.536794E-05
  validation loss:		1.409464E-05
Epoch took 7.613s

Epoch 8 of 100
  training loss:		1.071325E-05
  validation loss:		9.259414E-06
Epoch took 7.725s

Epoch 9 of 100
  training loss:		8.252896E-06
  validation loss:		7.339605E-06
Epoch took 7.992s

Epoch 10 of 100
  training loss:		6.090919E-06
  validation loss:		4.889582E-06
Epoch took 8.978s

Epoch 11 of 100
  training loss:		4.663583E-06
  validation loss:		6.022833E-06
Epoch took 7.412s

Epoch 12 of 100
  training loss:		3.991984E-06
  validation loss:		3.114517E-06
Epoch took 7.206s

Epoch 13 of 100
  training loss:		2.922063E-06
  validation loss:		2.274917E-06
Epoch took 9.492s

Epoch 14 of 100
  training loss:		2.390416E-06
  validation loss:		2.306360E-06
Epoch took 8.164s

Epoch 15 of 100
  training loss:		1.840854E-06
  validation loss:		1.375769E-06
Epoch took 7.840s

Epoch 16 of 100
  training loss:		1.655329E-06
  validation loss:		3.285843E-06
Epoch took 9.014s

Epoch 17 of 100
  training loss:		1.782647E-06
  validation loss:		1.247025E-06
Epoch took 8.343s

Epoch 18 of 100
  training loss:		9.036628E-07
  validation loss:		8.544798E-07
Epoch took 8.531s

Epoch 19 of 100
  training loss:		1.370389E-06
  validation loss:		1.702637E-06
Epoch took 8.135s

Epoch 20 of 100
  training loss:		1.265690E-06
  validation loss:		1.045907E-06
Epoch took 8.881s

Epoch 21 of 100
  training loss:		2.056167E-05
  validation loss:		1.279777E-04
Epoch took 8.225s

Epoch 22 of 100
  training loss:		7.726422E-06
  validation loss:		4.399659E-06
Epoch took 7.448s

Epoch 23 of 100
  training loss:		2.027855E-04
  validation loss:		4.224161E-06
Epoch took 8.575s

Epoch 24 of 100
  training loss:		1.895948E-06
  validation loss:		4.534276E-06
Epoch took 8.523s

Epoch 25 of 100
  training loss:		1.214098E-06
  validation loss:		2.156268E-07
Epoch took 7.855s

Early stopping, val-loss increased over the last 5 epochs from 1.62717838267e-06 to 2.8270279977e-05
Training RMSE: 0.00102360855548
Validation RMSE: 0.00102556732446
