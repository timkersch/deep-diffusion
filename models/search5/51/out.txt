Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		6.652466E-02
  validation loss:		4.399242E-02
Epoch took 10.414s

Epoch 2 of 100
  training loss:		4.147376E-02
  validation loss:		3.840101E-02
Epoch took 10.261s

Epoch 3 of 100
  training loss:		3.606860E-02
  validation loss:		3.311218E-02
Epoch took 10.302s

Epoch 4 of 100
  training loss:		3.363523E-02
  validation loss:		3.855214E-02
Epoch took 9.989s

Epoch 5 of 100
  training loss:		3.247117E-02
  validation loss:		3.219997E-02
Epoch took 10.532s

Epoch 6 of 100
  training loss:		3.178630E-02
  validation loss:		2.997366E-02
Epoch took 9.658s

Epoch 7 of 100
  training loss:		3.045265E-02
  validation loss:		3.553849E-02
Epoch took 10.757s

Epoch 8 of 100
  training loss:		2.997373E-02
  validation loss:		2.889544E-02
Epoch took 10.106s

Epoch 9 of 100
  training loss:		2.944811E-02
  validation loss:		3.029484E-02
Epoch took 10.025s

Epoch 10 of 100
  training loss:		2.907459E-02
  validation loss:		2.948545E-02
Epoch took 10.866s

Epoch 11 of 100
  training loss:		2.878289E-02
  validation loss:		2.907563E-02
Epoch took 9.612s

Epoch 12 of 100
  training loss:		2.846864E-02
  validation loss:		2.976234E-02
Epoch took 10.805s

Epoch 13 of 100
  training loss:		2.845575E-02
  validation loss:		2.895147E-02
Epoch took 11.590s

Epoch 14 of 100
  training loss:		2.815629E-02
  validation loss:		2.850604E-02
Epoch took 11.099s

Epoch 15 of 100
  training loss:		2.808526E-02
  validation loss:		2.798902E-02
Epoch took 10.346s

Epoch 16 of 100
  training loss:		2.819384E-02
  validation loss:		2.805027E-02
Epoch took 11.112s

Epoch 17 of 100
  training loss:		2.786023E-02
  validation loss:		2.893884E-02
Epoch took 9.180s

Epoch 18 of 100
  training loss:		2.788825E-02
  validation loss:		2.863538E-02
Epoch took 10.963s

Epoch 19 of 100
  training loss:		2.781752E-02
  validation loss:		2.790382E-02
Epoch took 10.633s

Epoch 20 of 100
  training loss:		2.799076E-02
  validation loss:		2.995005E-02
Epoch took 10.563s

Epoch 21 of 100
  training loss:		2.781960E-02
  validation loss:		2.692896E-02
Epoch took 10.150s

Epoch 22 of 100
  training loss:		2.756454E-02
  validation loss:		2.709280E-02
Epoch took 10.335s

Epoch 23 of 100
  training loss:		2.777065E-02
  validation loss:		2.733558E-02
Epoch took 10.091s

Epoch 24 of 100
  training loss:		2.776666E-02
  validation loss:		2.837840E-02
Epoch took 10.799s

Epoch 25 of 100
  training loss:		2.740485E-02
  validation loss:		2.876850E-02
Epoch took 10.139s

Epoch 26 of 100
  training loss:		2.762116E-02
  validation loss:		2.932042E-02
Epoch took 9.896s

Epoch 27 of 100
  training loss:		2.752591E-02
  validation loss:		2.744042E-02
Epoch took 9.825s

Epoch 28 of 100
  training loss:		2.750229E-02
  validation loss:		2.678004E-02
Epoch took 10.829s

Epoch 29 of 100
  training loss:		2.732832E-02
  validation loss:		2.737115E-02
Epoch took 10.138s

Epoch 30 of 100
  training loss:		2.735258E-02
  validation loss:		2.805434E-02
Epoch took 9.967s

Early stopping, val-loss increased over the last 5 epochs from 0.027700848452 to 0.0277932730853
Training RMSE: 1.66735456313e-07
Validation RMSE: 1.66212993905e-07
