Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 100
  training loss:		1.139024E-02
  validation loss:		4.011308E-04
Epoch took 11.310s

Epoch 2 of 100
  training loss:		3.114224E-04
  validation loss:		6.736358E-05
Epoch took 11.233s

Epoch 3 of 100
  training loss:		1.510528E-04
  validation loss:		1.503267E-04
Epoch took 9.571s

Epoch 4 of 100
  training loss:		1.615428E-05
  validation loss:		9.296887E-06
Epoch took 10.917s

Epoch 5 of 100
  training loss:		4.080681E-05
  validation loss:		3.709543E-06
Epoch took 10.917s

Epoch 6 of 100
  training loss:		5.285060E-05
  validation loss:		1.626019E-05
Epoch took 10.200s

Epoch 7 of 100
  training loss:		1.247464E-04
  validation loss:		7.465413E-06
Epoch took 11.882s

Epoch 8 of 100
  training loss:		7.832515E-06
  validation loss:		5.062349E-05
Epoch took 11.538s

Epoch 9 of 100
  training loss:		1.173552E-04
  validation loss:		6.317251E-06
Epoch took 10.391s

Epoch 10 of 100
  training loss:		3.147567E-05
  validation loss:		4.461595E-05
Epoch took 9.155s

Epoch 11 of 100
  training loss:		1.401194E-04
  validation loss:		2.145920E-06
Epoch took 9.898s

Epoch 12 of 100
  training loss:		4.505879E-05
  validation loss:		1.525682E-04
Epoch took 10.496s

Epoch 13 of 100
  training loss:		1.166246E-04
  validation loss:		7.305385E-06
Epoch took 10.798s

Epoch 14 of 100
  training loss:		1.660999E-05
  validation loss:		3.282276E-05
Epoch took 10.833s

Epoch 15 of 100
  training loss:		7.540386E-05
  validation loss:		1.604421E-05
Epoch took 11.019s

Epoch 16 of 100
  training loss:		9.769955E-05
  validation loss:		1.492532E-06
Epoch took 10.138s

Epoch 17 of 100
  training loss:		1.597853E-05
  validation loss:		1.475013E-04
Epoch took 10.332s

Epoch 18 of 100
  training loss:		5.735655E-05
  validation loss:		2.077947E-06
Epoch took 10.536s

Epoch 19 of 100
  training loss:		4.469593E-05
  validation loss:		2.379130E-05
Epoch took 10.266s

Epoch 20 of 100
  training loss:		6.843504E-05
  validation loss:		1.203742E-06
Epoch took 8.066s

Epoch 21 of 100
  training loss:		9.559048E-05
  validation loss:		4.100923E-05
Epoch took 9.061s

Epoch 22 of 100
  training loss:		5.806022E-06
  validation loss:		4.226947E-06
Epoch took 11.515s

Epoch 23 of 100
  training loss:		7.908183E-05
  validation loss:		4.800916E-06
Epoch took 9.903s

Epoch 24 of 100
  training loss:		6.398586E-06
  validation loss:		7.291570E-06
Epoch took 10.724s

Epoch 25 of 100
  training loss:		1.040915E-04
  validation loss:		2.403322E-06
Epoch took 11.380s

Epoch 26 of 100
  training loss:		5.251142E-06
  validation loss:		3.172259E-06
Epoch took 11.052s

Epoch 27 of 100
  training loss:		7.047919E-05
  validation loss:		5.972027E-06
Epoch took 11.674s

Epoch 28 of 100
  training loss:		2.625294E-06
  validation loss:		3.637972E-07
Epoch took 10.238s

Epoch 29 of 100
  training loss:		3.697272E-05
  validation loss:		1.548369E-05
Epoch took 7.678s

Epoch 30 of 100
  training loss:		3.417303E-05
  validation loss:		9.690471E-05
Epoch took 7.752s

Epoch 31 of 100
  training loss:		9.645080E-06
  validation loss:		7.351822E-06
Epoch took 10.841s

Epoch 32 of 100
  training loss:		4.488670E-05
  validation loss:		9.646812E-07
Epoch took 9.643s

Epoch 33 of 100
  training loss:		2.769938E-05
  validation loss:		9.253851E-05
Epoch took 9.283s

Epoch 34 of 100
  training loss:		2.135951E-05
  validation loss:		2.795597E-06
Epoch took 10.502s

Epoch 35 of 100
  training loss:		2.696084E-05
  validation loss:		6.871753E-05
Epoch took 10.450s

Epoch 36 of 100
  training loss:		1.051503E-05
  validation loss:		1.013887E-05
Epoch took 9.844s

Epoch 37 of 100
  training loss:		3.884465E-05
  validation loss:		1.421624E-05
Epoch took 9.509s

Epoch 38 of 100
  training loss:		2.122668E-05
  validation loss:		4.503195E-07
Epoch took 9.361s

Epoch 39 of 100
  training loss:		3.417024E-05
  validation loss:		2.391891E-05
Epoch took 10.183s

Epoch 40 of 100
  training loss:		5.071594E-06
  validation loss:		1.505901E-06
Epoch took 9.800s

Epoch 41 of 100
  training loss:		2.400636E-05
  validation loss:		2.950330E-06
Epoch took 11.522s

Epoch 42 of 100
  training loss:		1.777002E-05
  validation loss:		1.923545E-05
Epoch took 10.477s

Epoch 43 of 100
  training loss:		2.789880E-05
  validation loss:		3.408146E-06
Epoch took 10.210s

Epoch 44 of 100
  training loss:		1.235058E-06
  validation loss:		1.642084E-06
Epoch took 10.383s

Epoch 45 of 100
  training loss:		3.334858E-05
  validation loss:		1.710752E-06
Epoch took 9.246s

Epoch 46 of 100
  training loss:		1.515224E-06
  validation loss:		4.167383E-06
Epoch took 7.751s

Epoch 47 of 100
  training loss:		2.748377E-05
  validation loss:		5.244976E-06
Epoch took 7.748s

Epoch 48 of 100
  training loss:		2.755210E-06
  validation loss:		2.884911E-06
Epoch took 9.446s

Epoch 49 of 100
  training loss:		2.720878E-05
  validation loss:		2.367391E-07
Epoch took 9.583s

Epoch 50 of 100
  training loss:		9.614304E-07
  validation loss:		6.670872E-06
Epoch took 9.544s

Epoch 51 of 100
  training loss:		2.923299E-05
  validation loss:		1.874022E-07
Epoch took 11.425s

Epoch 52 of 100
  training loss:		1.155815E-06
  validation loss:		1.962838E-05
Epoch took 10.134s

Epoch 53 of 100
  training loss:		1.302678E-05
  validation loss:		7.301830E-06
Epoch took 10.402s

Epoch 54 of 100
  training loss:		1.595000E-05
  validation loss:		3.055071E-06
Epoch took 9.713s

Epoch 55 of 100
  training loss:		9.040002E-06
  validation loss:		1.047320E-04
Epoch took 10.433s

Epoch 56 of 100
  training loss:		1.403897E-05
  validation loss:		1.245219E-07
Epoch took 10.720s

Epoch 57 of 100
  training loss:		1.868787E-06
  validation loss:		1.754815E-05
Epoch took 10.847s

Epoch 58 of 100
  training loss:		1.441268E-05
  validation loss:		2.723385E-07
Epoch took 9.258s

Epoch 59 of 100
  training loss:		1.497363E-05
  validation loss:		4.456913E-05
Epoch took 10.165s

Epoch 60 of 100
  training loss:		2.307122E-06
  validation loss:		4.332464E-08
Epoch took 9.447s

Epoch 61 of 100
  training loss:		1.430786E-05
  validation loss:		4.970647E-06
Epoch took 10.397s

Epoch 62 of 100
  training loss:		8.574862E-07
  validation loss:		4.145927E-06
Epoch took 10.123s

Epoch 63 of 100
  training loss:		8.984708E-06
  validation loss:		5.364326E-07
Epoch took 10.125s

Epoch 64 of 100
  training loss:		1.286619E-05
  validation loss:		8.652575E-06
Epoch took 10.029s

Epoch 65 of 100
  training loss:		9.807675E-07
  validation loss:		7.455004E-07
Epoch took 10.317s

Epoch 66 of 100
  training loss:		1.398650E-05
  validation loss:		6.332413E-07
Epoch took 10.970s

Epoch 67 of 100
  training loss:		4.036391E-07
  validation loss:		7.443495E-07
Epoch took 9.749s

Epoch 68 of 100
  training loss:		9.661212E-06
  validation loss:		1.312600E-06
Epoch took 9.426s

Epoch 69 of 100
  training loss:		8.361817E-07
  validation loss:		1.403041E-06
Epoch took 9.513s

Epoch 70 of 100
  training loss:		8.555746E-06
  validation loss:		5.020853E-06
Epoch took 11.045s

Epoch 71 of 100
  training loss:		3.871488E-06
  validation loss:		1.103427E-06
Epoch took 10.903s

Epoch 72 of 100
  training loss:		1.008837E-05
  validation loss:		1.701116E-06
Epoch took 9.209s

Epoch 73 of 100
  training loss:		3.178816E-07
  validation loss:		1.174927E-07
Epoch took 9.660s

Epoch 74 of 100
  training loss:		7.018094E-06
  validation loss:		5.040697E-07
Epoch took 9.711s

Epoch 75 of 100
  training loss:		2.477402E-06
  validation loss:		9.703690E-06
Epoch took 9.205s

Epoch 76 of 100
  training loss:		7.637101E-06
  validation loss:		4.825968E-08
Epoch took 9.842s

Epoch 77 of 100
  training loss:		5.470576E-06
  validation loss:		1.440694E-05
Epoch took 9.557s

Epoch 78 of 100
  training loss:		1.268133E-06
  validation loss:		1.989402E-07
Epoch took 10.597s

Epoch 79 of 100
  training loss:		6.541450E-06
  validation loss:		3.117865E-06
Epoch took 9.694s

Epoch 80 of 100
  training loss:		1.034080E-06
  validation loss:		5.261890E-07
Epoch took 9.044s

Epoch 81 of 100
  training loss:		6.014660E-06
  validation loss:		3.220621E-06
Epoch took 11.355s

Epoch 82 of 100
  training loss:		5.488448E-07
  validation loss:		1.192164E-07
Epoch took 11.041s

Epoch 83 of 100
  training loss:		4.910990E-06
  validation loss:		3.370958E-07
Epoch took 10.385s

Epoch 84 of 100
  training loss:		5.175812E-07
  validation loss:		3.118840E-06
Epoch took 10.125s

Epoch 85 of 100
  training loss:		4.014324E-06
  validation loss:		6.622317E-07
Epoch took 9.775s

Epoch 86 of 100
  training loss:		5.231932E-06
  validation loss:		3.403243E-06
Epoch took 10.364s

Epoch 87 of 100
  training loss:		6.497338E-07
  validation loss:		7.543648E-07
Epoch took 10.402s

Epoch 88 of 100
  training loss:		5.918170E-06
  validation loss:		1.179353E-07
Epoch took 10.265s

Epoch 89 of 100
  training loss:		7.708421E-08
  validation loss:		9.592398E-08
Epoch took 10.378s

Epoch 90 of 100
  training loss:		3.636857E-06
  validation loss:		4.195176E-07
Epoch took 10.177s

Epoch 91 of 100
  training loss:		6.072880E-07
  validation loss:		2.221167E-06
Epoch took 10.326s

Epoch 92 of 100
  training loss:		3.674867E-06
  validation loss:		4.770555E-07
Epoch took 10.701s

Epoch 93 of 100
  training loss:		1.293503E-07
  validation loss:		1.041253E-07
Epoch took 11.421s

Epoch 94 of 100
  training loss:		6.266778E-06
  validation loss:		1.240033E-07
Epoch took 10.941s

Epoch 95 of 100
  training loss:		3.167915E-07
  validation loss:		1.268328E-06
Epoch took 10.078s

Epoch 96 of 100
  training loss:		1.089573E-06
  validation loss:		1.621431E-06
Epoch took 11.096s

Epoch 97 of 100
  training loss:		1.853449E-06
  validation loss:		9.367093E-07
Epoch took 11.187s

Epoch 98 of 100
  training loss:		2.447844E-06
  validation loss:		1.165892E-07
Epoch took 10.153s

Epoch 99 of 100
  training loss:		3.373399E-07
  validation loss:		4.011132E-06
Epoch took 9.321s

Epoch 100 of 100
  training loss:		2.514576E-06
  validation loss:		1.601319E-07
Epoch took 11.632s

Training RMSE: 0.000402638622017
Validation RMSE: 0.0004002611805
