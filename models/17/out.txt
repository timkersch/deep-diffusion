Epoch 1 of 300
  example target:		3.083971E-02
  example prediction:		1.969501E-01
  training loss:		9.403830E-02
  validation loss:		8.069827E-02

Epoch 2 of 300
  example target:		2.984942E-02
  example prediction:		1.638970E-01
  training loss:		6.827713E-02
  validation loss:		5.139091E-02

Epoch 3 of 300
  example target:		7.253521E-01
  example prediction:		5.158731E-01
  training loss:		3.544203E-02
  validation loss:		2.075468E-02

Epoch 4 of 300
  example target:		1.000000E+00
  example prediction:		6.753524E-01
  training loss:		1.319022E-02
  validation loss:		7.834619E-03

Epoch 5 of 300
  example target:		6.137065E-02
  example prediction:		6.822337E-02
  training loss:		5.836221E-03
  validation loss:		4.615993E-03

Epoch 6 of 300
  example target:		3.982057E-02
  example prediction:		5.676139E-02
  training loss:		4.228687E-03
  validation loss:		3.942612E-03

Epoch 7 of 300
  example target:		3.831306E-02
  example prediction:		6.568902E-02
  training loss:		3.894660E-03
  validation loss:		3.748124E-03

Epoch 8 of 300
  example target:		1.304502E-01
  example prediction:		4.720493E-02
  training loss:		3.747724E-03
  validation loss:		3.597259E-03

Epoch 9 of 300
  example target:		4.026011E-02
  example prediction:		4.993834E-02
  training loss:		3.572202E-03
  validation loss:		3.443087E-03

Epoch 10 of 300
  example target:		1.886472E-02
  example prediction:		4.709380E-02
  training loss:		3.407718E-03
  validation loss:		3.262280E-03

Epoch 11 of 300
  example target:		3.372446E-01
  example prediction:		2.669528E-01
  training loss:		3.170054E-03
  validation loss:		3.035084E-03

Epoch 12 of 300
  example target:		6.270856E-01
  example prediction:		6.789567E-01
  training loss:		2.907796E-03
  validation loss:		2.779940E-03

Epoch 13 of 300
  example target:		2.187258E-02
  example prediction:		6.286236E-02
  training loss:		2.646479E-03
  validation loss:		2.571089E-03

Epoch 14 of 300
  example target:		2.187258E-02
  example prediction:		4.747832E-02
  training loss:		2.414083E-03
  validation loss:		2.404270E-03

Epoch 15 of 300
  example target:		7.612945E-02
  example prediction:		7.355682E-02
  training loss:		2.235793E-03
  validation loss:		2.175287E-03

Epoch 16 of 300
  example target:		3.372446E-01
  example prediction:		2.550129E-01
  training loss:		2.086006E-03
  validation loss:		2.050112E-03

Epoch 17 of 300
  example target:		1.886472E-02
  example prediction:		4.620384E-02
  training loss:		1.989091E-03
  validation loss:		1.944662E-03

Epoch 18 of 300
  example target:		3.982057E-02
  example prediction:		2.997437E-02
  training loss:		1.860978E-03
  validation loss:		1.864012E-03

Epoch 19 of 300
  example target:		6.402986E-01
  example prediction:		6.597482E-01
  training loss:		1.789302E-03
  validation loss:		1.768926E-03

Epoch 20 of 300
  example target:		1.645437E-02
  example prediction:		3.683499E-02
  training loss:		1.653800E-03
  validation loss:		1.623476E-03

Epoch 21 of 300
  example target:		1.071292E-01
  example prediction:		5.727422E-02
  training loss:		1.513095E-03
  validation loss:		1.498149E-03

Epoch 22 of 300
  example target:		6.077772E-02
  example prediction:		1.876492E-02
  training loss:		1.300088E-03
  validation loss:		1.250368E-03

Epoch 23 of 300
  example target:		5.847623E-02
  example prediction:		2.758142E-02
  training loss:		1.129909E-03
  validation loss:		1.066218E-03

Epoch 24 of 300
  example target:		8.434618E-01
  example prediction:		8.379663E-01
  training loss:		9.701209E-04
  validation loss:		9.374757E-04

Epoch 25 of 300
  example target:		3.083971E-02
  example prediction:		4.402294E-02
  training loss:		8.446020E-04
  validation loss:		8.158577E-04

Epoch 26 of 300
  example target:		2.112001E-02
  example prediction:		3.665441E-02
  training loss:		7.451333E-04
  validation loss:		7.431644E-04

Epoch 27 of 300
  example target:		3.016191E-01
  example prediction:		2.771625E-01
  training loss:		6.745089E-04
  validation loss:		6.765503E-04

Epoch 28 of 300
  example target:		3.083971E-02
  example prediction:		4.415594E-02
  training loss:		6.150015E-04
  validation loss:		6.247403E-04

Epoch 29 of 300
  example target:		6.964043E-02
  example prediction:		6.117579E-02
  training loss:		5.600462E-04
  validation loss:		5.578394E-04

Epoch 30 of 300
  example target:		5.004843E-02
  example prediction:		4.254564E-02
  training loss:		5.101281E-04
  validation loss:		5.148116E-04

Epoch 31 of 300
  example target:		3.372446E-01
  example prediction:		3.305808E-01
  training loss:		4.670757E-04
  validation loss:		5.018757E-04

Epoch 32 of 300
  example target:		3.016191E-01
  example prediction:		2.897054E-01
  training loss:		4.300212E-04
  validation loss:		4.266301E-04

Epoch 33 of 300
  example target:		3.083971E-02
  example prediction:		3.507748E-02
  training loss:		4.015838E-04
  validation loss:		3.925179E-04

Epoch 34 of 300
  example target:		3.372446E-01
  example prediction:		3.337022E-01
  training loss:		3.776186E-04
  validation loss:		3.747877E-04

Epoch 35 of 300
  example target:		1.414259E-01
  example prediction:		1.405763E-01
  training loss:		3.520264E-04
  validation loss:		3.396551E-04

Epoch 36 of 300
  example target:		3.831306E-02
  example prediction:		6.684725E-02
  training loss:		3.253244E-04
  validation loss:		3.193789E-04

Epoch 37 of 300
  example target:		6.449202E-01
  example prediction:		6.344169E-01
  training loss:		3.095314E-04
  validation loss:		3.047761E-04

Epoch 38 of 300
  example target:		2.983466E-01
  example prediction:		3.175299E-01
  training loss:		2.913333E-04
  validation loss:		2.816161E-04

Epoch 39 of 300
  example target:		2.785667E-02
  example prediction:		2.455275E-02
  training loss:		2.766923E-04
  validation loss:		2.661244E-04

Epoch 40 of 300
  example target:		1.645437E-02
  example prediction:		3.292438E-02
  training loss:		2.656772E-04
  validation loss:		2.683169E-04

Epoch 41 of 300
  example target:		2.983466E-01
  example prediction:		3.215919E-01
  training loss:		2.558366E-04
  validation loss:		2.645798E-04

Epoch 42 of 300
  example target:		2.506635E-02
  example prediction:		2.125554E-02
  training loss:		2.457967E-04
  validation loss:		2.421322E-04

Epoch 43 of 300
  example target:		6.137065E-02
  example prediction:		4.100719E-02
  training loss:		2.334649E-04
  validation loss:		2.683998E-04

Epoch 44 of 300
  example target:		7.253521E-01
  example prediction:		7.303200E-01
  training loss:		2.281244E-04
  validation loss:		2.184738E-04

Epoch 45 of 300
  example target:		5.004843E-02
  example prediction:		4.353743E-02
  training loss:		2.202242E-04
  validation loss:		2.692322E-04

Epoch 46 of 300
  example target:		1.958275E-02
  example prediction:		3.543162E-02
  training loss:		2.217386E-04
  validation loss:		2.061039E-04

Epoch 47 of 300
  example target:		1.403356E-02
  example prediction:		9.231751E-03
  training loss:		2.036179E-04
  validation loss:		1.945259E-04

Epoch 48 of 300
  example target:		1.414259E-01
  example prediction:		1.268663E-01
  training loss:		1.992963E-04
  validation loss:		1.937935E-04

Epoch 49 of 300
  example target:		1.645437E-02
  example prediction:		3.014046E-02
  training loss:		1.920701E-04
  validation loss:		1.878775E-04

Epoch 50 of 300
  example target:		3.372446E-01
  example prediction:		3.400780E-01
  training loss:		2.006154E-04
  validation loss:		1.796582E-04

Epoch 51 of 300
  example target:		2.112001E-02
  example prediction:		2.656495E-02
  training loss:		1.939637E-04
  validation loss:		1.821638E-04

Epoch 52 of 300
  example target:		2.457999E-01
  example prediction:		2.367091E-01
  training loss:		1.858568E-04
  validation loss:		1.696543E-04

Epoch 53 of 300
  example target:		5.004843E-02
  example prediction:		5.323090E-02
  training loss:		1.749558E-04
  validation loss:		1.664905E-04

Epoch 54 of 300
  example target:		7.612945E-02
  example prediction:		8.269246E-02
  training loss:		1.734058E-04
  validation loss:		1.730377E-04

Epoch 55 of 300
  example target:		1.645437E-02
  example prediction:		2.799138E-02
  training loss:		1.702600E-04
  validation loss:		1.597498E-04

Epoch 56 of 300
  example target:		2.983466E-01
  example prediction:		3.089880E-01
  training loss:		1.710468E-04
  validation loss:		1.637554E-04

Epoch 57 of 300
  example target:		1.403356E-02
  example prediction:		7.491667E-03
  training loss:		1.641744E-04
  validation loss:		1.532580E-04

Epoch 58 of 300
  example target:		1.000000E+00
  example prediction:		9.993864E-01
  training loss:		1.630219E-04
  validation loss:		1.651996E-04

Epoch 59 of 300
  example target:		2.785667E-02
  example prediction:		3.104062E-02
  training loss:		1.639781E-04
  validation loss:		1.526735E-04

Epoch 60 of 300
  example target:		1.702205E-02
  example prediction:		3.443785E-02
  training loss:		1.592761E-04
  validation loss:		1.459532E-04

Epoch 61 of 300
  example target:		8.434618E-01
  example prediction:		8.504168E-01
  training loss:		1.530946E-04
  validation loss:		1.580297E-04

Epoch 62 of 300
  example target:		1.886472E-02
  example prediction:		1.586198E-02
  training loss:		1.500206E-04
  validation loss:		1.388786E-04

Epoch 63 of 300
  example target:		2.735347E-03
  example prediction:		1.252298E-02
  training loss:		1.440294E-04
  validation loss:		1.376164E-04

Epoch 64 of 300
  example target:		7.433516E-01
  example prediction:		7.488998E-01
  training loss:		1.489239E-04
  validation loss:		1.345114E-04

Epoch 65 of 300
  example target:		1.958275E-02
  example prediction:		3.142902E-02
  training loss:		1.389657E-04
  validation loss:		1.426819E-04

Epoch 66 of 300
  example target:		1.958275E-02
  example prediction:		3.687351E-02
  training loss:		1.389662E-04
  validation loss:		1.315962E-04

Epoch 67 of 300
  example target:		8.434618E-01
  example prediction:		8.507879E-01
  training loss:		1.407113E-04
  validation loss:		1.500918E-04

Epoch 68 of 300
  example target:		5.847623E-02
  example prediction:		6.158658E-02
  training loss:		1.378099E-04
  validation loss:		1.445831E-04

Epoch 69 of 300
  example target:		7.433516E-01
  example prediction:		7.544554E-01
  training loss:		1.312897E-04
  validation loss:		1.575309E-04

Epoch 70 of 300
  example target:		0.000000E+00
  example prediction:		3.609397E-03
  training loss:		1.307614E-04
  validation loss:		1.191359E-04

Epoch 71 of 300
  example target:		6.964043E-02
  example prediction:		5.121663E-02
  training loss:		1.263449E-04
  validation loss:		1.284909E-04

Epoch 72 of 300
  example target:		2.785667E-02
  example prediction:		3.394246E-02
  training loss:		1.280597E-04
  validation loss:		1.324325E-04

Epoch 73 of 300
  example target:		6.137065E-02
  example prediction:		5.509965E-02
  training loss:		1.232476E-04
  validation loss:		1.261374E-04

Epoch 74 of 300
  example target:		2.187258E-02
  example prediction:		2.503950E-02
  training loss:		1.206548E-04
  validation loss:		1.614914E-04

Epoch 75 of 300
  example target:		3.016191E-01
  example prediction:		3.025604E-01
  training loss:		1.163660E-04
  validation loss:		1.062402E-04

Epoch 76 of 300
  example target:		1.702205E-02
  example prediction:		3.298835E-02
  training loss:		1.196255E-04
  validation loss:		1.046752E-04

Epoch 77 of 300
  example target:		3.297330E-01
  example prediction:		3.230771E-01
  training loss:		1.106149E-04
  validation loss:		1.060819E-04

Epoch 78 of 300
  example target:		1.403356E-02
  example prediction:		1.197054E-02
  training loss:		1.096310E-04
  validation loss:		1.092160E-04

Epoch 79 of 300
  example target:		8.434618E-01
  example prediction:		8.437633E-01
  training loss:		1.102064E-04
  validation loss:		9.944212E-05

Epoch 80 of 300
  example target:		2.785667E-02
  example prediction:		2.893676E-02
  training loss:		1.038662E-04
  validation loss:		9.669019E-05

Epoch 81 of 300
  example target:		1.886472E-02
  example prediction:		1.298072E-02
  training loss:		1.030768E-04
  validation loss:		9.751111E-05

Epoch 82 of 300
  example target:		6.137065E-02
  example prediction:		5.116831E-02
  training loss:		1.064527E-04
  validation loss:		9.605177E-05

Epoch 83 of 300
  example target:		2.187258E-02
  example prediction:		3.059532E-02
  training loss:		1.021154E-04
  validation loss:		9.156964E-05

Epoch 84 of 300
  example target:		2.984942E-02
  example prediction:		3.812230E-02
  training loss:		1.033501E-04
  validation loss:		8.991412E-05

Epoch 85 of 300
  example target:		6.964043E-02
  example prediction:		5.661116E-02
  training loss:		9.792196E-05
  validation loss:		8.806064E-05

Epoch 86 of 300
  example target:		7.612945E-02
  example prediction:		8.240763E-02
  training loss:		9.918180E-05
  validation loss:		1.125480E-04

Epoch 87 of 300
  example target:		1.071292E-01
  example prediction:		1.019738E-01
  training loss:		9.448701E-05
  validation loss:		9.143476E-05

Epoch 88 of 300
  example target:		2.319687E-01
  example prediction:		2.371444E-01
  training loss:		9.190424E-05
  validation loss:		8.719716E-05

Epoch 89 of 300
  example target:		0.000000E+00
  example prediction:		4.215749E-03
  training loss:		9.021354E-05
  validation loss:		8.413020E-05

Epoch 90 of 300
  example target:		1.403356E-02
  example prediction:		1.258073E-02
  training loss:		8.595797E-05
  validation loss:		9.050002E-05

Epoch 91 of 300
  example target:		1.000000E+00
  example prediction:		9.997297E-01
  training loss:		9.026900E-05
  validation loss:		7.896852E-05

Epoch 92 of 300
  example target:		3.016191E-01
  example prediction:		3.083991E-01
  training loss:		8.731827E-05
  validation loss:		1.011041E-04

Epoch 93 of 300
  example target:		9.711442E-01
  example prediction:		9.647478E-01
  training loss:		8.987059E-05
  validation loss:		9.810163E-05

Epoch 94 of 300
  example target:		1.071292E-01
  example prediction:		1.032739E-01
  training loss:		8.365019E-05
  validation loss:		8.070808E-05

Epoch 95 of 300
  example target:		4.026011E-02
  example prediction:		4.172386E-02
  training loss:		8.127251E-05
  validation loss:		7.599595E-05

Epoch 96 of 300
  example target:		2.984942E-02
  example prediction:		3.661629E-02
  training loss:		7.919510E-05
  validation loss:		7.205894E-05

Epoch 97 of 300
  example target:		9.711442E-01
  example prediction:		9.657662E-01
  training loss:		8.270064E-05
  validation loss:		8.328430E-05

Epoch 98 of 300
  example target:		1.414259E-01
  example prediction:		1.263207E-01
  training loss:		7.789315E-05
  validation loss:		6.959889E-05

Epoch 99 of 300
  example target:		9.711442E-01
  example prediction:		9.682981E-01
  training loss:		7.627546E-05
  validation loss:		6.836573E-05

Epoch 100 of 300
  example target:		5.004843E-02
  example prediction:		4.254005E-02
  training loss:		7.972019E-05
  validation loss:		1.225870E-04

Epoch 101 of 300
  example target:		6.137065E-02
  example prediction:		5.328662E-02
  training loss:		7.649734E-05
  validation loss:		6.891288E-05

Epoch 102 of 300
  example target:		5.004843E-02
  example prediction:		4.727298E-02
  training loss:		7.197314E-05
  validation loss:		7.237402E-05

Epoch 103 of 300
  example target:		2.983466E-01
  example prediction:		2.968988E-01
  training loss:		6.989416E-05
  validation loss:		6.415284E-05

Epoch 104 of 300
  example target:		1.000000E+00
  example prediction:		9.969601E-01
  training loss:		7.012165E-05
  validation loss:		7.197693E-05

Epoch 105 of 300
  example target:		2.319687E-01
  example prediction:		2.364051E-01
  training loss:		6.980162E-05
  validation loss:		7.524027E-05

Epoch 106 of 300
  example target:		7.433516E-01
  example prediction:		7.406768E-01
  training loss:		6.816436E-05
  validation loss:		9.801560E-05

Epoch 107 of 300
  example target:		1.414259E-01
  example prediction:		1.331155E-01
  training loss:		6.727969E-05
  validation loss:		9.617155E-05

Epoch 108 of 300
  example target:		1.071292E-01
  example prediction:		1.049615E-01
  training loss:		6.573507E-05
  validation loss:		6.509194E-05

Epoch 109 of 300
  example target:		2.785667E-02
  example prediction:		2.851707E-02
  training loss:		6.588307E-05
  validation loss:		6.248557E-05

Epoch 110 of 300
  example target:		1.958275E-02
  example prediction:		2.558188E-02
  training loss:		6.184911E-05
  validation loss:		5.772544E-05

Epoch 111 of 300
  example target:		2.187258E-02
  example prediction:		3.248291E-02
  training loss:		6.259434E-05
  validation loss:		6.686365E-05

Epoch 112 of 300
  example target:		3.297330E-01
  example prediction:		3.240720E-01
  training loss:		6.544548E-05
  validation loss:		5.698213E-05

Epoch 113 of 300
  example target:		0.000000E+00
  example prediction:		1.118524E-03
  training loss:		6.046614E-05
  validation loss:		5.433560E-05

Epoch 114 of 300
  example target:		5.847623E-02
  example prediction:		5.570465E-02
  training loss:		5.776254E-05
  validation loss:		5.408867E-05

Epoch 115 of 300
  example target:		2.735347E-03
  example prediction:		1.234853E-02
  training loss:		5.850805E-05
  validation loss:		6.111099E-05

Epoch 116 of 300
  example target:		2.506635E-02
  example prediction:		1.254920E-02
  training loss:		5.670303E-05
  validation loss:		5.115044E-05

Epoch 117 of 300
  example target:		1.403356E-02
  example prediction:		1.137834E-02
  training loss:		5.487099E-05
  validation loss:		5.018332E-05

Epoch 118 of 300
  example target:		2.457999E-01
  example prediction:		2.510418E-01
  training loss:		5.668906E-05
  validation loss:		6.571153E-05

Epoch 119 of 300
  example target:		3.083971E-02
  example prediction:		3.298608E-02
  training loss:		5.771921E-05
  validation loss:		6.847408E-05

Epoch 120 of 300
  example target:		3.297330E-01
  example prediction:		3.265311E-01
  training loss:		5.467480E-05
  validation loss:		4.794633E-05

Epoch 121 of 300
  example target:		2.319687E-01
  example prediction:		2.379598E-01
  training loss:		5.793645E-05
  validation loss:		5.289231E-05

Epoch 122 of 300
  example target:		7.433516E-01
  example prediction:		7.454486E-01
  training loss:		5.409796E-05
  validation loss:		4.628588E-05

Epoch 123 of 300
  example target:		4.026011E-02
  example prediction:		4.389822E-02
  training loss:		4.957253E-05
  validation loss:		4.571429E-05

Epoch 124 of 300
  example target:		3.016191E-01
  example prediction:		3.003207E-01
  training loss:		4.910528E-05
  validation loss:		5.741676E-05

Epoch 125 of 300
  example target:		6.270856E-01
  example prediction:		6.273935E-01
  training loss:		5.147661E-05
  validation loss:		4.469136E-05

Epoch 126 of 300
  example target:		9.711442E-01
  example prediction:		9.684589E-01
  training loss:		5.034513E-05
  validation loss:		4.328202E-05

Epoch 127 of 300
  example target:		1.702205E-02
  example prediction:		3.264518E-02
  training loss:		4.776543E-05
  validation loss:		4.840844E-05

Epoch 128 of 300
  example target:		6.270856E-01
  example prediction:		6.283778E-01
  training loss:		4.837658E-05
  validation loss:		4.150411E-05

Epoch 129 of 300
  example target:		1.645437E-02
  example prediction:		2.116853E-02
  training loss:		4.693060E-05
  validation loss:		4.201227E-05

Epoch 130 of 300
  example target:		3.982057E-02
  example prediction:		3.542900E-02
  training loss:		4.730673E-05
  validation loss:		4.394634E-05

Epoch 131 of 300
  example target:		6.077772E-02
  example prediction:		4.694961E-02
  training loss:		4.388961E-05
  validation loss:		4.810283E-05

Epoch 132 of 300
  example target:		3.372446E-01
  example prediction:		3.359821E-01
  training loss:		4.389518E-05
  validation loss:		3.896280E-05

Epoch 133 of 300
  example target:		2.187258E-02
  example prediction:		2.575085E-02
  training loss:		4.609500E-05
  validation loss:		4.219070E-05

Epoch 134 of 300
  example target:		9.711442E-01
  example prediction:		9.731726E-01
  training loss:		4.380399E-05
  validation loss:		6.883904E-05

Epoch 135 of 300
  example target:		6.077772E-02
  example prediction:		4.296799E-02
  training loss:		4.459566E-05
  validation loss:		3.936850E-05

Epoch 136 of 300
  example target:		2.785667E-02
  example prediction:		3.324995E-02
  training loss:		4.195343E-05
  validation loss:		4.137831E-05

Epoch 137 of 300
  example target:		1.702205E-02
  example prediction:		3.281081E-02
  training loss:		4.121066E-05
  validation loss:		4.723595E-05

Epoch 138 of 300
  example target:		6.270856E-01
  example prediction:		6.274262E-01
  training loss:		4.305942E-05
  validation loss:		3.595069E-05

Epoch 139 of 300
  example target:		2.984942E-02
  example prediction:		3.242553E-02
  training loss:		4.454596E-05
  validation loss:		3.500926E-05

Epoch 140 of 300
  example target:		1.886472E-02
  example prediction:		1.198199E-02
  training loss:		3.789433E-05
  validation loss:		3.433814E-05

Epoch 141 of 300
  example target:		6.270856E-01
  example prediction:		6.275581E-01
  training loss:		3.845612E-05
  validation loss:		3.490565E-05

Epoch 142 of 300
  example target:		4.026011E-02
  example prediction:		4.218548E-02
  training loss:		3.774747E-05
  validation loss:		3.355744E-05

Epoch 143 of 300
  example target:		1.304502E-01
  example prediction:		1.263558E-01
  training loss:		3.740311E-05
  validation loss:		3.396719E-05

Epoch 144 of 300
  example target:		3.083971E-02
  example prediction:		2.910969E-02
  training loss:		3.584547E-05
  validation loss:		3.291618E-05

Epoch 145 of 300
  example target:		7.253521E-01
  example prediction:		7.227466E-01
  training loss:		3.547412E-05
  validation loss:		5.004912E-05

Epoch 146 of 300
  example target:		3.372446E-01
  example prediction:		3.383255E-01
  training loss:		3.578459E-05
  validation loss:		3.507105E-05

Epoch 147 of 300
  example target:		1.304502E-01
  example prediction:		1.281293E-01
  training loss:		3.676022E-05
  validation loss:		3.793106E-05

Epoch 148 of 300
  example target:		7.433516E-01
  example prediction:		7.443321E-01
  training loss:		3.303354E-05
  validation loss:		2.986333E-05

Epoch 149 of 300
  example target:		4.026011E-02
  example prediction:		3.751658E-02
  training loss:		3.805430E-05
  validation loss:		5.156801E-05

Epoch 150 of 300
  example target:		6.964043E-02
  example prediction:		6.491965E-02
  training loss:		3.432578E-05
  validation loss:		2.962753E-05

Epoch 151 of 300
  example target:		2.506635E-02
  example prediction:		1.399168E-02
  training loss:		3.359833E-05
  validation loss:		3.167641E-05

Epoch 152 of 300
  example target:		2.457999E-01
  example prediction:		2.457161E-01
  training loss:		3.809701E-05
  validation loss:		3.178834E-05

Epoch 153 of 300
  example target:		2.984942E-02
  example prediction:		3.023376E-02
  training loss:		3.271214E-05
  validation loss:		2.806035E-05

Epoch 154 of 300
  example target:		1.304502E-01
  example prediction:		1.257641E-01
  training loss:		2.995506E-05
  validation loss:		2.726353E-05

Epoch 155 of 300
  example target:		6.077772E-02
  example prediction:		4.819823E-02
  training loss:		3.078244E-05
  validation loss:		2.696863E-05

Epoch 156 of 300
  example target:		2.735347E-03
  example prediction:		6.487563E-03
  training loss:		3.035818E-05
  validation loss:		2.640543E-05

Epoch 157 of 300
  example target:		1.000000E+00
  example prediction:		1.003797E+00
  training loss:		3.032389E-05
  validation loss:		3.669417E-05

Epoch 158 of 300
  example target:		6.964043E-02
  example prediction:		6.794439E-02
  training loss:		3.021100E-05
  validation loss:		2.779241E-05

Epoch 159 of 300
  example target:		7.433516E-01
  example prediction:		7.438589E-01
  training loss:		3.022872E-05
  validation loss:		2.557634E-05

Epoch 160 of 300
  example target:		1.958275E-02
  example prediction:		2.355556E-02
  training loss:		2.770085E-05
  validation loss:		2.480084E-05

Epoch 161 of 300
  example target:		2.983466E-01
  example prediction:		2.934656E-01
  training loss:		2.740972E-05
  validation loss:		2.422956E-05

Epoch 162 of 300
  example target:		6.137065E-02
  example prediction:		5.655672E-02
  training loss:		2.673504E-05
  validation loss:		3.204205E-05

Epoch 163 of 300
  example target:		1.645437E-02
  example prediction:		1.873151E-02
  training loss:		2.821899E-05
  validation loss:		2.589305E-05

Epoch 164 of 300
  example target:		4.026011E-02
  example prediction:		4.223352E-02
  training loss:		2.831511E-05
  validation loss:		2.316842E-05

Epoch 165 of 300
  example target:		2.187258E-02
  example prediction:		2.910525E-02
  training loss:		2.670166E-05
  validation loss:		3.107634E-05

Epoch 166 of 300
  example target:		2.506635E-02
  example prediction:		1.666666E-02
  training loss:		2.786075E-05
  validation loss:		2.255977E-05

Epoch 167 of 300
  example target:		7.253521E-01
  example prediction:		7.238715E-01
  training loss:		2.709690E-05
  validation loss:		2.900283E-05

Epoch 168 of 300
  example target:		6.964043E-02
  example prediction:		6.629004E-02
  training loss:		2.723722E-05
  validation loss:		2.223224E-05

Epoch 169 of 300
  example target:		2.319687E-01
  example prediction:		2.387581E-01
  training loss:		2.526921E-05
  validation loss:		2.416229E-05

Epoch 170 of 300
  example target:		2.319687E-01
  example prediction:		2.407597E-01
  training loss:		2.432020E-05
  validation loss:		2.145595E-05

Epoch 171 of 300
  example target:		3.083971E-02
  example prediction:		2.974093E-02
  training loss:		2.458545E-05
  validation loss:		2.183660E-05

Epoch 172 of 300
  example target:		5.004843E-02
  example prediction:		4.974210E-02
  training loss:		2.632731E-05
  validation loss:		2.051154E-05

Epoch 173 of 300
  example target:		2.319687E-01
  example prediction:		2.365561E-01
  training loss:		2.370915E-05
  validation loss:		3.326909E-05

Epoch 174 of 300
  example target:		9.711442E-01
  example prediction:		9.698572E-01
  training loss:		2.401305E-05
  validation loss:		1.994479E-05

Epoch 175 of 300
  example target:		2.735347E-03
  example prediction:		5.033361E-03
  training loss:		2.334774E-05
  validation loss:		1.943242E-05

Epoch 176 of 300
  example target:		3.982057E-02
  example prediction:		3.655485E-02
  training loss:		2.218116E-05
  validation loss:		1.922760E-05

Epoch 177 of 300
  example target:		1.000000E+00
  example prediction:		1.001714E+00
  training loss:		2.334366E-05
  validation loss:		2.042853E-05

Epoch 178 of 300
  example target:		7.253521E-01
  example prediction:		7.267797E-01
  training loss:		2.632540E-05
  validation loss:		1.887201E-05

Epoch 179 of 300
  example target:		0.000000E+00
  example prediction:		-1.131250E-03
  training loss:		2.195454E-05
  validation loss:		1.836062E-05

Epoch 180 of 300
  example target:		2.457999E-01
  example prediction:		2.485451E-01
  training loss:		2.030840E-05
  validation loss:		1.912887E-05

Epoch 181 of 300
  example target:		1.886472E-02
  example prediction:		1.200567E-02
  training loss:		2.187954E-05
  validation loss:		1.902497E-05

Epoch 182 of 300
  example target:		1.645437E-02
  example prediction:		1.857156E-02
  training loss:		2.167609E-05
  validation loss:		1.932322E-05

Epoch 183 of 300
  example target:		0.000000E+00
  example prediction:		-4.964928E-03
  training loss:		2.182914E-05
  validation loss:		3.161820E-05

Epoch 184 of 300
  example target:		1.403356E-02
  example prediction:		1.275022E-02
  training loss:		2.098010E-05
  validation loss:		1.721164E-05

Epoch 185 of 300
  example target:		6.077772E-02
  example prediction:		5.478270E-02
  training loss:		2.041626E-05
  validation loss:		2.994620E-05

Epoch 186 of 300
  example target:		6.137065E-02
  example prediction:		5.845163E-02
  training loss:		2.031069E-05
  validation loss:		1.955409E-05

Epoch 187 of 300
  example target:		1.414259E-01
  example prediction:		1.359131E-01
  training loss:		1.958260E-05
  validation loss:		1.853712E-05

Epoch 188 of 300
  example target:		5.847623E-02
  example prediction:		5.564546E-02
  training loss:		1.917367E-05
  validation loss:		1.841048E-05

Epoch 189 of 300
  example target:		2.319687E-01
  example prediction:		2.409818E-01
  training loss:		1.752663E-05
  validation loss:		1.704701E-05

Epoch 190 of 300
  example target:		3.372446E-01
  example prediction:		3.356739E-01
  training loss:		2.152556E-05
  validation loss:		1.582312E-05

Epoch 191 of 300
  example target:		6.402986E-01
  example prediction:		6.416058E-01
  training loss:		1.852362E-05
  validation loss:		1.864761E-05

Epoch 192 of 300
  example target:		2.983466E-01
  example prediction:		2.955213E-01
  training loss:		1.788467E-05
  validation loss:		2.091701E-05

Epoch 193 of 300
  example target:		2.506635E-02
  example prediction:		2.135277E-02
  training loss:		1.829607E-05
  validation loss:		2.027663E-05

Epoch 194 of 300
  example target:		3.831306E-02
  example prediction:		4.744975E-02
  training loss:		1.844124E-05
  validation loss:		1.924045E-05

Epoch 195 of 300
  example target:		2.457999E-01
  example prediction:		2.497677E-01
  training loss:		1.757435E-05
  validation loss:		1.969175E-05

Epoch 196 of 300
  example target:		5.847623E-02
  example prediction:		5.850620E-02
  training loss:		1.910036E-05
  validation loss:		1.552587E-05

Epoch 197 of 300
  example target:		3.083971E-02
  example prediction:		2.837532E-02
  training loss:		2.152173E-05
  validation loss:		1.990280E-05

Epoch 198 of 300
  example target:		1.645437E-02
  example prediction:		2.049689E-02
  training loss:		1.717185E-05
  validation loss:		1.622199E-05

Epoch 199 of 300
  example target:		1.000000E+00
  example prediction:		1.001409E+00
  training loss:		1.677033E-05
  validation loss:		1.380042E-05

Epoch 200 of 300
  example target:		6.077772E-02
  example prediction:		5.525865E-02
  training loss:		1.562422E-05
  validation loss:		2.130434E-05

Epoch 201 of 300
  example target:		5.847623E-02
  example prediction:		5.498047E-02
  training loss:		1.768340E-05
  validation loss:		1.913403E-05

Epoch 202 of 300
  example target:		1.414259E-01
  example prediction:		1.334345E-01
  training loss:		1.652537E-05
  validation loss:		1.592551E-05

Epoch 203 of 300
  example target:		6.077772E-02
  example prediction:		5.391672E-02
  training loss:		1.670009E-05
  validation loss:		1.461122E-05

Epoch 204 of 300
  example target:		6.077772E-02
  example prediction:		5.281204E-02
  training loss:		1.669911E-05
  validation loss:		1.290531E-05

Epoch 205 of 300
  example target:		6.270856E-01
  example prediction:		6.276489E-01
  training loss:		1.576022E-05
  validation loss:		1.555470E-05

Epoch 206 of 300
  example target:		3.831306E-02
  example prediction:		4.873584E-02
  training loss:		1.640862E-05
  validation loss:		1.253422E-05

Epoch 207 of 300
  example target:		2.785667E-02
  example prediction:		2.524692E-02
  training loss:		1.515334E-05
  validation loss:		3.205807E-05

Epoch 208 of 300
  example target:		6.077772E-02
  example prediction:		5.277424E-02
  training loss:		1.649116E-05
  validation loss:		1.225657E-05

Epoch 209 of 300
  example target:		6.402986E-01
  example prediction:		6.410623E-01
  training loss:		1.455340E-05
  validation loss:		1.322343E-05

Epoch 210 of 300
  example target:		9.711442E-01
  example prediction:		9.693139E-01
  training loss:		1.505596E-05
  validation loss:		1.199016E-05

Epoch 211 of 300
  example target:		1.645437E-02
  example prediction:		1.477246E-02
  training loss:		1.479665E-05
  validation loss:		2.571110E-05

Epoch 212 of 300
  example target:		3.831306E-02
  example prediction:		4.447346E-02
  training loss:		1.469680E-05
  validation loss:		2.505450E-05

Epoch 213 of 300
  example target:		6.137065E-02
  example prediction:		5.925966E-02
  training loss:		1.547364E-05
  validation loss:		1.476414E-05

Epoch 214 of 300
  example target:		6.964043E-02
  example prediction:		6.838275E-02
  training loss:		1.385105E-05
  validation loss:		1.247749E-05

Epoch 215 of 300
  example target:		5.847623E-02
  example prediction:		5.780435E-02
  training loss:		1.475437E-05
  validation loss:		1.130208E-05

Epoch 216 of 300
  example target:		3.831306E-02
  example prediction:		4.802105E-02
  training loss:		1.297993E-05
  validation loss:		1.098018E-05

Epoch 217 of 300
  example target:		5.004843E-02
  example prediction:		4.997114E-02
  training loss:		1.305825E-05
  validation loss:		1.085026E-05

Epoch 218 of 300
  example target:		9.711442E-01
  example prediction:		9.654172E-01
  training loss:		1.425620E-05
  validation loss:		3.514109E-05

Epoch 219 of 300
  example target:		7.612945E-02
  example prediction:		7.258588E-02
  training loss:		1.451119E-05
  validation loss:		1.271511E-05

Epoch 220 of 300
  example target:		1.304502E-01
  example prediction:		1.256058E-01
  training loss:		1.260854E-05
  validation loss:		1.333173E-05

Epoch 221 of 300
  example target:		1.886472E-02
  example prediction:		1.810274E-02
  training loss:		1.288206E-05
  validation loss:		2.359792E-05

Epoch 222 of 300
  example target:		6.964043E-02
  example prediction:		7.023972E-02
  training loss:		1.353292E-05
  validation loss:		1.030162E-05

Epoch 223 of 300
  example target:		6.964043E-02
  example prediction:		7.152954E-02
  training loss:		1.285014E-05
  validation loss:		1.279425E-05

Epoch 224 of 300
  example target:		5.004843E-02
  example prediction:		4.973485E-02
  training loss:		1.274462E-05
  validation loss:		1.025645E-05

Epoch 225 of 300
  example target:		2.785667E-02
  example prediction:		3.052260E-02
  training loss:		1.142693E-05
  validation loss:		1.096916E-05

Epoch 226 of 300
  example target:		2.983466E-01
  example prediction:		2.924568E-01
  training loss:		1.210493E-05
  validation loss:		1.033175E-05

Epoch 227 of 300
  example target:		9.711442E-01
  example prediction:		9.708279E-01
  training loss:		1.172490E-05
  validation loss:		1.177584E-05

Epoch 228 of 300
  example target:		2.983466E-01
  example prediction:		2.923809E-01
  training loss:		1.392496E-05
  validation loss:		9.872891E-06

Epoch 229 of 300
  example target:		3.372446E-01
  example prediction:		3.333863E-01
  training loss:		1.453924E-05
  validation loss:		1.686778E-05

Epoch 230 of 300
  example target:		3.297330E-01
  example prediction:		3.250687E-01
  training loss:		1.155746E-05
  validation loss:		1.332347E-05

Epoch 231 of 300
  example target:		1.958275E-02
  example prediction:		2.066227E-02
  training loss:		1.197864E-05
  validation loss:		1.177103E-05

Epoch 232 of 300
  example target:		5.004843E-02
  example prediction:		4.851130E-02
  training loss:		1.153699E-05
  validation loss:		1.153895E-05

Epoch 233 of 300
  example target:		6.137065E-02
  example prediction:		6.278055E-02
  training loss:		1.211289E-05
  validation loss:		9.720327E-06

Epoch 234 of 300
  example target:		0.000000E+00
  example prediction:		-2.814443E-03
  training loss:		1.175312E-05
  validation loss:		1.341658E-05

Epoch 235 of 300
  example target:		5.847623E-02
  example prediction:		6.161292E-02
  training loss:		1.182159E-05
  validation loss:		2.121304E-05

Epoch 236 of 300
  example target:		2.984942E-02
  example prediction:		2.567839E-02
  training loss:		1.074798E-05
  validation loss:		1.302174E-05

Epoch 237 of 300
  example target:		1.071292E-01
  example prediction:		1.059148E-01
  training loss:		1.128613E-05
  validation loss:		1.439866E-05

Epoch 238 of 300
  example target:		6.270856E-01
  example prediction:		6.267033E-01
  training loss:		1.121526E-05
  validation loss:		1.364506E-05

Epoch 239 of 300
  example target:		2.506635E-02
  example prediction:		2.208527E-02
  training loss:		1.265990E-05
  validation loss:		8.575497E-06

Epoch 240 of 300
  example target:		2.983466E-01
  example prediction:		2.944625E-01
  training loss:		1.256841E-05
  validation loss:		9.040941E-06

Epoch 241 of 300
  example target:		1.000000E+00
  example prediction:		1.000332E+00
  training loss:		1.013840E-05
  validation loss:		8.436911E-06

Epoch 242 of 300
  example target:		7.433516E-01
  example prediction:		7.416182E-01
  training loss:		1.092342E-05
  validation loss:		1.021500E-05

Epoch 243 of 300
  example target:		3.083971E-02
  example prediction:		3.092805E-02
  training loss:		1.011412E-05
  validation loss:		7.915620E-06

Epoch 244 of 300
  example target:		1.645437E-02
  example prediction:		1.310454E-02
  training loss:		1.018064E-05
  validation loss:		2.843955E-05

Epoch 245 of 300
  example target:		2.457999E-01
  example prediction:		2.476593E-01
  training loss:		1.122481E-05
  validation loss:		7.889503E-06

Epoch 246 of 300
  example target:		3.982057E-02
  example prediction:		3.671304E-02
  training loss:		1.062579E-05
  validation loss:		7.702839E-06

Epoch 247 of 300
  example target:		4.026011E-02
  example prediction:		4.121363E-02
  training loss:		1.110943E-05
  validation loss:		7.514478E-06

Epoch 248 of 300
  example target:		6.964043E-02
  example prediction:		6.872967E-02
  training loss:		9.574479E-06
  validation loss:		1.003241E-05

Epoch 249 of 300
  example target:		3.083971E-02
  example prediction:		2.939178E-02
  training loss:		1.241526E-05
  validation loss:		8.491476E-06

Epoch 250 of 300
  example target:		1.403356E-02
  example prediction:		1.585757E-02
  training loss:		9.685975E-06
  validation loss:		1.085282E-05

Epoch 251 of 300
  example target:		2.735347E-03
  example prediction:		9.501217E-04
  training loss:		9.806360E-06
  validation loss:		8.136391E-06

Epoch 252 of 300
  example target:		4.026011E-02
  example prediction:		4.223547E-02
  training loss:		1.031161E-05
  validation loss:		8.582255E-06

Epoch 253 of 300
  example target:		5.847623E-02
  example prediction:		5.902128E-02
  training loss:		8.594337E-06
  validation loss:		7.754422E-06

Epoch 254 of 300
  example target:		8.434618E-01
  example prediction:		8.410209E-01
  training loss:		1.225146E-05
  validation loss:		1.052817E-05

Epoch 255 of 300
  example target:		2.187258E-02
  example prediction:		2.520323E-02
  training loss:		9.526811E-06
  validation loss:		7.691093E-06

Epoch 256 of 300
  example target:		1.886472E-02
  example prediction:		1.903770E-02
  training loss:		1.149636E-05
  validation loss:		2.214129E-05

Epoch 257 of 300
  example target:		2.735347E-03
  example prediction:		2.255604E-03
  training loss:		1.029388E-05
  validation loss:		6.772846E-06

Epoch 258 of 300
  example target:		1.414259E-01
  example prediction:		1.417578E-01
  training loss:		1.123392E-05
  validation loss:		2.519207E-05

Epoch 259 of 300
  example target:		8.434618E-01
  example prediction:		8.425104E-01
  training loss:		8.448012E-06
  validation loss:		6.609969E-06

Epoch 260 of 300
  example target:		9.711442E-01
  example prediction:		9.704082E-01
  training loss:		8.217946E-06
  validation loss:		6.518578E-06

Epoch 261 of 300
  example target:		8.434618E-01
  example prediction:		8.410177E-01
  training loss:		8.332624E-06
  validation loss:		7.519943E-06

Epoch 262 of 300
  example target:		6.964043E-02
  example prediction:		7.051691E-02
  training loss:		8.355756E-06
  validation loss:		6.381026E-06

Epoch 263 of 300
  example target:		3.083971E-02
  example prediction:		2.803603E-02
  training loss:		8.226994E-06
  validation loss:		1.267430E-05

Epoch 264 of 300
  example target:		6.964043E-02
  example prediction:		6.658308E-02
  training loss:		9.714731E-06
  validation loss:		2.325295E-05

Epoch 265 of 300
  example target:		3.372446E-01
  example prediction:		3.340774E-01
  training loss:		8.916520E-06
  validation loss:		1.176883E-05

Epoch 266 of 300
  example target:		1.645437E-02
  example prediction:		1.293268E-02
  training loss:		8.776518E-06
  validation loss:		2.452229E-05

Epoch 267 of 300
  example target:		2.983466E-01
  example prediction:		2.957320E-01
  training loss:		8.943841E-06
  validation loss:		8.999521E-06

Epoch 268 of 300
  example target:		1.645437E-02
  example prediction:		1.642983E-02
  training loss:		7.299579E-06
  validation loss:		6.321967E-06

Epoch 269 of 300
  example target:		1.702205E-02
  example prediction:		2.146033E-02
  training loss:		9.059793E-06
  validation loss:		6.260399E-06

Epoch 270 of 300
  example target:		2.735347E-03
  example prediction:		1.917005E-03
  training loss:		8.733409E-06
  validation loss:		5.898600E-06

Epoch 271 of 300
  example target:		3.831306E-02
  example prediction:		4.781252E-02
  training loss:		1.057854E-05
  validation loss:		1.422125E-05

Epoch 272 of 300
  example target:		5.847623E-02
  example prediction:		5.735443E-02
  training loss:		9.630319E-06
  validation loss:		6.432783E-06

Epoch 273 of 300
  example target:		3.831306E-02
  example prediction:		4.134158E-02
  training loss:		7.735318E-06
  validation loss:		1.527845E-05

Epoch 274 of 300
  example target:		1.886472E-02
  example prediction:		1.573317E-02
  training loss:		8.548389E-06
  validation loss:		5.657932E-06

Epoch 275 of 300
  example target:		3.831306E-02
  example prediction:		4.857996E-02
  training loss:		8.012310E-06
  validation loss:		2.004178E-05

Epoch 276 of 300
  example target:		3.982057E-02
  example prediction:		3.527274E-02
  training loss:		7.488432E-06
  validation loss:		6.482491E-06

Epoch 277 of 300
  example target:		3.831306E-02
  example prediction:		4.671718E-02
  training loss:		7.968171E-06
  validation loss:		1.018458E-05

Epoch 278 of 300
  example target:		2.319687E-01
  example prediction:		2.363247E-01
  training loss:		8.353222E-06
  validation loss:		6.519290E-06

Epoch 279 of 300
  example target:		5.004843E-02
  example prediction:		4.867994E-02
  training loss:		7.155930E-06
  validation loss:		7.561358E-06

Epoch 280 of 300
  example target:		2.112001E-02
  example prediction:		2.536417E-02
  training loss:		7.407929E-06
  validation loss:		6.712840E-06

Epoch 281 of 300
  example target:		5.004843E-02
  example prediction:		5.227017E-02
  training loss:		9.089953E-06
  validation loss:		9.201399E-06

Epoch 282 of 300
  example target:		6.137065E-02
  example prediction:		6.489647E-02
  training loss:		9.348549E-06
  validation loss:		1.119172E-05

Epoch 283 of 300
  example target:		7.612945E-02
  example prediction:		7.272353E-02
  training loss:		7.418553E-06
  validation loss:		8.012402E-06

Epoch 284 of 300
  example target:		2.506635E-02
  example prediction:		2.364861E-02
  training loss:		7.451842E-06
  validation loss:		5.808103E-06

Epoch 285 of 300
  example target:		7.253521E-01
  example prediction:		7.250234E-01
  training loss:		7.430457E-06
  validation loss:		6.253959E-06

Epoch 286 of 300
  example target:		1.304502E-01
  example prediction:		1.272827E-01
  training loss:		7.652760E-06
  validation loss:		5.805577E-06

Epoch 287 of 300
  example target:		8.434618E-01
  example prediction:		8.423158E-01
  training loss:		7.570707E-06
  validation loss:		4.984325E-06

Epoch 288 of 300
  example target:		1.702205E-02
  example prediction:		1.949963E-02
  training loss:		6.620267E-06
  validation loss:		5.538295E-06

Epoch 289 of 300
  example target:		6.077772E-02
  example prediction:		5.514164E-02
  training loss:		6.834431E-06
  validation loss:		7.440607E-06

Epoch 290 of 300
  example target:		2.112001E-02
  example prediction:		2.270650E-02
  training loss:		6.184014E-06
  validation loss:		6.408668E-06

Epoch 291 of 300
  example target:		7.612945E-02
  example prediction:		7.534359E-02
  training loss:		9.307020E-06
  validation loss:		5.372571E-06

Epoch 292 of 300
  example target:		1.304502E-01
  example prediction:		1.247191E-01
  training loss:		6.715419E-06
  validation loss:		1.764506E-05

Epoch 293 of 300
  example target:		2.319687E-01
  example prediction:		2.375736E-01
  training loss:		8.021609E-06
  validation loss:		4.815655E-06

Epoch 294 of 300
  example target:		2.112001E-02
  example prediction:		2.384871E-02
  training loss:		6.689930E-06
  validation loss:		4.647190E-06

Epoch 295 of 300
  example target:		1.958275E-02
  example prediction:		2.137933E-02
  training loss:		7.071214E-06
  validation loss:		5.090852E-06

Epoch 296 of 300
  example target:		6.964043E-02
  example prediction:		7.065671E-02
  training loss:		8.582330E-06
  validation loss:		4.684309E-06

Epoch 297 of 300
  example target:		8.434618E-01
  example prediction:		8.419499E-01
  training loss:		6.399994E-06
  validation loss:		4.881696E-06

Epoch 298 of 300
  example target:		3.982057E-02
  example prediction:		3.771073E-02
  training loss:		6.268039E-06
  validation loss:		6.502213E-06

Epoch 299 of 300
  example target:		3.831306E-02
  example prediction:		4.162663E-02
  training loss:		6.614653E-06
  validation loss:		7.927473E-06

Epoch 300 of 300
  example target:		6.449202E-01
  example prediction:		6.452533E-01
  training loss:		6.240067E-06
  validation loss:		4.393978E-06

Test-set, Scaled RMSE: 0.00213152529599
Test-set, Original RMSE: 1.98341230158e-09
