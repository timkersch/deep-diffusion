Training network with 75120 training samples and 14085 validation samples
Epoch 1 of 200
  training loss:		1.061195E-01
  validation loss:		5.513680E-02
Epoch took 8.392s

Epoch 2 of 200
  training loss:		4.645775E-02
  validation loss:		4.539021E-02
Epoch took 8.275s

Epoch 3 of 200
  training loss:		3.909967E-02
  validation loss:		3.671283E-02
Epoch took 9.288s

Epoch 4 of 200
  training loss:		3.545091E-02
  validation loss:		3.411359E-02
Epoch took 8.475s

Epoch 5 of 200
  training loss:		3.382386E-02
  validation loss:		3.453863E-02
Epoch took 8.856s

Epoch 6 of 200
  training loss:		3.244765E-02
  validation loss:		3.237546E-02
Epoch took 8.889s

Epoch 7 of 200
  training loss:		3.126410E-02
  validation loss:		3.080970E-02
Epoch took 8.340s

Epoch 8 of 200
  training loss:		3.100594E-02
  validation loss:		3.092225E-02
Epoch took 9.199s

Epoch 9 of 200
  training loss:		2.974328E-02
  validation loss:		3.244771E-02
Epoch took 8.578s

Epoch 10 of 200
  training loss:		3.010975E-02
  validation loss:		2.994356E-02
Epoch took 8.196s

Epoch 11 of 200
  training loss:		2.944966E-02
  validation loss:		3.224027E-02
Epoch took 8.957s

Epoch 12 of 200
  training loss:		2.932314E-02
  validation loss:		2.870524E-02
Epoch took 9.032s

Epoch 13 of 200
  training loss:		2.881231E-02
  validation loss:		2.881880E-02
Epoch took 8.566s

Epoch 14 of 200
  training loss:		2.902535E-02
  validation loss:		2.844684E-02
Epoch took 7.823s

Epoch 15 of 200
  training loss:		2.860702E-02
  validation loss:		2.909426E-02
Epoch took 7.832s

Epoch 16 of 200
  training loss:		2.877665E-02
  validation loss:		2.716268E-02
Epoch took 8.402s

Epoch 17 of 200
  training loss:		2.841929E-02
  validation loss:		2.719199E-02
Epoch took 9.548s

Epoch 18 of 200
  training loss:		2.802007E-02
  validation loss:		2.713980E-02
Epoch took 8.257s

Epoch 19 of 200
  training loss:		2.853141E-02
  validation loss:		2.719469E-02
Epoch took 10.129s

Epoch 20 of 200
  training loss:		2.769719E-02
  validation loss:		2.780613E-02
Epoch took 8.731s

Epoch 21 of 200
  training loss:		2.812096E-02
  validation loss:		2.867118E-02
Epoch took 9.869s

Epoch 22 of 200
  training loss:		2.805724E-02
  validation loss:		2.818527E-02
Epoch took 7.489s

Epoch 23 of 200
  training loss:		2.779423E-02
  validation loss:		2.845399E-02
Epoch took 6.981s

Epoch 24 of 200
  training loss:		2.774538E-02
  validation loss:		2.707665E-02
Epoch took 7.844s

Epoch 25 of 200
  training loss:		2.755193E-02
  validation loss:		2.839271E-02
Epoch took 7.078s

Epoch 26 of 200
  training loss:		2.757454E-02
  validation loss:		2.751123E-02
Epoch took 9.197s

Epoch 27 of 200
  training loss:		2.748801E-02
  validation loss:		2.707934E-02
Epoch took 8.915s

Epoch 28 of 200
  training loss:		2.761238E-02
  validation loss:		2.726221E-02
Epoch took 9.724s

Epoch 29 of 200
  training loss:		2.737990E-02
  validation loss:		2.721097E-02
Epoch took 9.029s

Epoch 30 of 200
  training loss:		2.760459E-02
  validation loss:		2.705371E-02
Epoch took 8.380s

Epoch 31 of 200
  training loss:		2.745230E-02
  validation loss:		2.708274E-02
Epoch took 7.992s

Epoch 32 of 200
  training loss:		2.752109E-02
  validation loss:		2.780603E-02
Epoch took 7.759s

Epoch 33 of 200
  training loss:		2.756316E-02
  validation loss:		2.774107E-02
Epoch took 9.327s

Epoch 34 of 200
  training loss:		2.744734E-02
  validation loss:		2.728512E-02
Epoch took 8.264s

Epoch 35 of 200
  training loss:		2.714624E-02
  validation loss:		2.684679E-02
Epoch took 8.457s

Epoch 36 of 200
  training loss:		2.718443E-02
  validation loss:		2.688768E-02
Epoch took 8.521s

Epoch 37 of 200
  training loss:		2.713070E-02
  validation loss:		2.857994E-02
Epoch took 9.844s

Epoch 38 of 200
  training loss:		2.738397E-02
  validation loss:		2.672443E-02
Epoch took 9.705s

Epoch 39 of 200
  training loss:		2.730853E-02
  validation loss:		2.722687E-02
Epoch took 8.048s

Epoch 40 of 200
  training loss:		2.731796E-02
  validation loss:		2.705951E-02
Epoch took 8.322s

Epoch 41 of 200
  training loss:		2.736443E-02
  validation loss:		2.762628E-02
Epoch took 8.733s

Epoch 42 of 200
  training loss:		2.692543E-02
  validation loss:		2.681803E-02
Epoch took 7.561s

Epoch 43 of 200
  training loss:		2.687540E-02
  validation loss:		2.741229E-02
Epoch took 8.288s

Epoch 44 of 200
  training loss:		2.704058E-02
  validation loss:		2.670683E-02
Epoch took 8.181s

Epoch 45 of 200
  training loss:		2.700740E-02
  validation loss:		2.748042E-02
Epoch took 8.498s

Epoch 46 of 200
  training loss:		2.706594E-02
  validation loss:		2.708827E-02
Epoch took 8.660s

Epoch 47 of 200
  training loss:		2.691744E-02
  validation loss:		2.721945E-02
Epoch took 8.900s

Epoch 48 of 200
  training loss:		2.706359E-02
  validation loss:		2.671007E-02
Epoch took 9.697s

Epoch 49 of 200
  training loss:		2.676403E-02
  validation loss:		2.707778E-02
Epoch took 7.609s

Epoch 50 of 200
  training loss:		2.684858E-02
  validation loss:		2.673078E-02
Epoch took 8.529s

Epoch 51 of 200
  training loss:		2.694517E-02
  validation loss:		2.696233E-02
Epoch took 9.328s

Epoch 52 of 200
  training loss:		2.682582E-02
  validation loss:		2.654776E-02
Epoch took 9.386s

Epoch 53 of 200
  training loss:		2.686455E-02
  validation loss:		2.790306E-02
Epoch took 8.790s

Epoch 54 of 200
  training loss:		2.666023E-02
  validation loss:		2.649558E-02
Epoch took 9.633s

Epoch 55 of 200
  training loss:		2.665164E-02
  validation loss:		2.655244E-02
Epoch took 9.052s

Epoch 56 of 200
  training loss:		2.683905E-02
  validation loss:		2.728373E-02
Epoch took 7.940s

Epoch 57 of 200
  training loss:		2.676814E-02
  validation loss:		2.634510E-02
Epoch took 9.135s

Epoch 58 of 200
  training loss:		2.660716E-02
  validation loss:		2.690254E-02
Epoch took 8.060s

Epoch 59 of 200
  training loss:		2.672606E-02
  validation loss:		2.716456E-02
Epoch took 8.767s

Epoch 60 of 200
  training loss:		2.673235E-02
  validation loss:		2.660693E-02
Epoch took 8.471s

Epoch 61 of 200
  training loss:		2.693859E-02
  validation loss:		2.669303E-02
Epoch took 8.158s

Epoch 62 of 200
  training loss:		2.659707E-02
  validation loss:		2.690156E-02
Epoch took 8.328s

Epoch 63 of 200
  training loss:		2.662849E-02
  validation loss:		2.644625E-02
Epoch took 8.532s

Epoch 64 of 200
  training loss:		2.658740E-02
  validation loss:		2.640567E-02
Epoch took 8.022s

Epoch 65 of 200
  training loss:		2.668861E-02
  validation loss:		2.705447E-02
Epoch took 9.265s

Epoch 66 of 200
  training loss:		2.663592E-02
  validation loss:		2.648288E-02
Epoch took 9.450s

Epoch 67 of 200
  training loss:		2.654330E-02
  validation loss:		2.628843E-02
Epoch took 8.331s

Epoch 68 of 200
  training loss:		2.653955E-02
  validation loss:		2.670672E-02
Epoch took 8.692s

Epoch 69 of 200
  training loss:		2.661674E-02
  validation loss:		2.642051E-02
Epoch took 8.938s

Epoch 70 of 200
  training loss:		2.656979E-02
  validation loss:		2.630294E-02
Epoch took 9.035s

Epoch 71 of 200
  training loss:		2.648453E-02
  validation loss:		2.680444E-02
Epoch took 7.660s

Epoch 72 of 200
  training loss:		2.657820E-02
  validation loss:		2.657734E-02
Epoch took 7.835s

Epoch 73 of 200
  training loss:		2.657246E-02
  validation loss:		2.630397E-02
Epoch took 8.670s

Epoch 74 of 200
  training loss:		2.651665E-02
  validation loss:		2.683119E-02
Epoch took 7.695s

Epoch 75 of 200
  training loss:		2.659744E-02
  validation loss:		2.637113E-02
Epoch took 7.960s

Epoch 76 of 200
  training loss:		2.638271E-02
  validation loss:		2.688270E-02
Epoch took 8.229s

Epoch 77 of 200
  training loss:		2.657171E-02
  validation loss:		2.624738E-02
Epoch took 7.484s

Epoch 78 of 200
  training loss:		2.643998E-02
  validation loss:		2.655932E-02
Epoch took 8.987s

Epoch 79 of 200
  training loss:		2.642725E-02
  validation loss:		2.646349E-02
Epoch took 8.694s

Epoch 80 of 200
  training loss:		2.642664E-02
  validation loss:		2.681415E-02
Epoch took 8.930s

Early stopping, val-loss increased over the last 10 epochs from 0.0265702456637 to 0.0265855124798
Training RMSE: 1.58728629893e-07
Validation RMSE: 1.58978755831e-07
Test RMSE: 1.59932736443e-07
Test MSE: 2.55784801862e-14
Test MAE: 9.14779544781e-08
Test R2: 0.732170865178 

