Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.619837E-01
  validation loss:		8.020723E-03
Epoch took 13.780s

Epoch 2 of 100
  training loss:		2.764011E-02
  validation loss:		6.303186E-03
Epoch took 13.682s

Epoch 3 of 100
  training loss:		1.890035E-02
  validation loss:		2.838849E-03
Epoch took 13.674s

Epoch 4 of 100
  training loss:		1.527159E-02
  validation loss:		2.626546E-03
Epoch took 13.715s

Epoch 5 of 100
  training loss:		1.326082E-02
  validation loss:		2.240840E-03
Epoch took 13.685s

Epoch 6 of 100
  training loss:		1.148209E-02
  validation loss:		3.084393E-03
Epoch took 13.681s

Epoch 7 of 100
  training loss:		1.019699E-02
  validation loss:		1.760461E-03
Epoch took 13.704s

Epoch 8 of 100
  training loss:		8.851326E-03
  validation loss:		1.748452E-03
Epoch took 13.691s

Epoch 9 of 100
  training loss:		7.988661E-03
  validation loss:		1.214266E-03
Epoch took 13.678s

Epoch 10 of 100
  training loss:		7.348507E-03
  validation loss:		1.844673E-03
Epoch took 13.677s

Epoch 11 of 100
  training loss:		6.546414E-03
  validation loss:		1.197286E-03
Epoch took 13.712s

Epoch 12 of 100
  training loss:		5.983818E-03
  validation loss:		1.433471E-03
Epoch took 13.693s

Epoch 13 of 100
  training loss:		5.835090E-03
  validation loss:		1.241747E-03
Epoch took 13.670s

Epoch 14 of 100
  training loss:		5.508758E-03
  validation loss:		1.023965E-03
Epoch took 13.675s

Epoch 15 of 100
  training loss:		5.042282E-03
  validation loss:		9.352013E-04
Epoch took 13.673s

Epoch 16 of 100
  training loss:		4.744689E-03
  validation loss:		1.072638E-03
Epoch took 13.686s

Epoch 17 of 100
  training loss:		4.220562E-03
  validation loss:		9.695945E-04
Epoch took 13.702s

Epoch 18 of 100
  training loss:		3.914896E-03
  validation loss:		8.242401E-04
Epoch took 13.695s

Epoch 19 of 100
  training loss:		3.853170E-03
  validation loss:		8.020890E-04
Epoch took 13.686s

Epoch 20 of 100
  training loss:		3.351884E-03
  validation loss:		9.033999E-04
Epoch took 13.687s

Epoch 21 of 100
  training loss:		3.223226E-03
  validation loss:		7.852273E-04
Epoch took 13.663s

Epoch 22 of 100
  training loss:		3.193344E-03
  validation loss:		5.408160E-04
Epoch took 13.683s

Epoch 23 of 100
  training loss:		2.911078E-03
  validation loss:		4.320916E-04
Epoch took 13.710s

Epoch 24 of 100
  training loss:		2.748703E-03
  validation loss:		6.328453E-04
Epoch took 13.731s

Epoch 25 of 100
  training loss:		2.654694E-03
  validation loss:		6.167937E-04
Epoch took 13.709s

Epoch 26 of 100
  training loss:		2.554669E-03
  validation loss:		5.085952E-04
Epoch took 13.704s

Epoch 27 of 100
  training loss:		2.303677E-03
  validation loss:		2.937652E-04
Epoch took 13.712s

Epoch 28 of 100
  training loss:		2.204798E-03
  validation loss:		4.765433E-04
Epoch took 13.699s

Epoch 29 of 100
  training loss:		2.125286E-03
  validation loss:		5.295221E-04
Epoch took 13.704s

Epoch 30 of 100
  training loss:		2.107187E-03
  validation loss:		4.429995E-04
Epoch took 13.723s

Epoch 31 of 100
  training loss:		2.007379E-03
  validation loss:		4.375187E-04
Epoch took 13.699s

Epoch 32 of 100
  training loss:		1.899988E-03
  validation loss:		5.247641E-04
Epoch took 13.703s

Epoch 33 of 100
  training loss:		1.785213E-03
  validation loss:		5.514134E-04
Epoch took 13.681s

Epoch 34 of 100
  training loss:		1.708487E-03
  validation loss:		3.383707E-04
Epoch took 13.689s

Epoch 35 of 100
  training loss:		1.641021E-03
  validation loss:		4.164536E-04
Epoch took 13.696s

Epoch 36 of 100
  training loss:		1.614398E-03
  validation loss:		3.693655E-04
Epoch took 13.706s

Epoch 37 of 100
  training loss:		1.581417E-03
  validation loss:		3.266423E-04
Epoch took 13.708s

Epoch 38 of 100
  training loss:		1.508714E-03
  validation loss:		3.767421E-04
Epoch took 13.684s

Epoch 39 of 100
  training loss:		1.422339E-03
  validation loss:		3.601643E-04
Epoch took 13.660s

Epoch 40 of 100
  training loss:		1.378323E-03
  validation loss:		2.471130E-04
Epoch took 13.672s

Epoch 41 of 100
  training loss:		1.339661E-03
  validation loss:		2.243592E-04
Epoch took 13.674s

Epoch 42 of 100
  training loss:		1.334928E-03
  validation loss:		3.449397E-04
Epoch took 13.715s

Epoch 43 of 100
  training loss:		1.221673E-03
  validation loss:		3.679612E-04
Epoch took 13.703s

Epoch 44 of 100
  training loss:		1.222173E-03
  validation loss:		3.295558E-04
Epoch took 13.686s

Epoch 45 of 100
  training loss:		1.260260E-03
  validation loss:		2.138157E-04
Epoch took 13.695s

Epoch 46 of 100
  training loss:		1.159343E-03
  validation loss:		2.583111E-04
Epoch took 13.694s

Epoch 47 of 100
  training loss:		1.154744E-03
  validation loss:		3.319041E-04
Epoch took 13.698s

Epoch 48 of 100
  training loss:		1.075577E-03
  validation loss:		2.796019E-04
Epoch took 13.691s

Epoch 49 of 100
  training loss:		1.064532E-03
  validation loss:		2.253737E-04
Epoch took 13.697s

Epoch 50 of 100
  training loss:		1.033781E-03
  validation loss:		4.203596E-04
Epoch took 13.673s

Epoch 51 of 100
  training loss:		1.017956E-03
  validation loss:		2.138066E-04
Epoch took 13.689s

Epoch 52 of 100
  training loss:		9.033503E-04
  validation loss:		2.223937E-04
Epoch took 13.705s

Epoch 53 of 100
  training loss:		9.859857E-04
  validation loss:		2.328613E-04
Epoch took 13.697s

Epoch 54 of 100
  training loss:		8.982078E-04
  validation loss:		1.945392E-04
Epoch took 13.691s

Epoch 55 of 100
  training loss:		8.664952E-04
  validation loss:		1.327471E-04
Epoch took 13.701s

Epoch 56 of 100
  training loss:		8.594059E-04
  validation loss:		3.370253E-04
Epoch took 13.681s

Epoch 57 of 100
  training loss:		8.778903E-04
  validation loss:		3.111821E-04
Epoch took 13.667s

Epoch 58 of 100
  training loss:		8.154629E-04
  validation loss:		4.298847E-04
Epoch took 13.675s

Epoch 59 of 100
  training loss:		7.929437E-04
  validation loss:		1.796374E-04
Epoch took 13.695s

Epoch 60 of 100
  training loss:		8.170820E-04
  validation loss:		2.165789E-04
Epoch took 13.730s

Epoch 61 of 100
  training loss:		7.850703E-04
  validation loss:		2.325677E-04
Epoch took 13.736s

Epoch 62 of 100
  training loss:		7.553119E-04
  validation loss:		2.777447E-04
Epoch took 13.668s

Epoch 63 of 100
  training loss:		7.289050E-04
  validation loss:		1.521765E-04
Epoch took 13.679s

Epoch 64 of 100
  training loss:		7.372246E-04
  validation loss:		1.559656E-04
Epoch took 13.692s

Epoch 65 of 100
  training loss:		7.022904E-04
  validation loss:		1.763056E-04
Epoch took 13.692s

Epoch 66 of 100
  training loss:		6.788966E-04
  validation loss:		2.524216E-04
Epoch took 13.663s

Epoch 67 of 100
  training loss:		6.594934E-04
  validation loss:		1.579485E-04
Epoch took 13.692s

Epoch 68 of 100
  training loss:		6.334689E-04
  validation loss:		2.019563E-04
Epoch took 13.713s

Epoch 69 of 100
  training loss:		6.421362E-04
  validation loss:		1.884137E-04
Epoch took 13.686s

Epoch 70 of 100
  training loss:		6.359416E-04
  validation loss:		1.698843E-04
Epoch took 13.711s

Epoch 71 of 100
  training loss:		6.056220E-04
  validation loss:		1.314843E-04
Epoch took 13.713s

Epoch 72 of 100
  training loss:		6.040255E-04
  validation loss:		1.491319E-04
Epoch took 13.702s

Epoch 73 of 100
  training loss:		6.062365E-04
  validation loss:		1.250228E-04
Epoch took 13.673s

Epoch 74 of 100
  training loss:		5.629752E-04
  validation loss:		1.262382E-04
Epoch took 13.685s

Epoch 75 of 100
  training loss:		5.721240E-04
  validation loss:		2.155071E-04
Epoch took 13.817s

Epoch 76 of 100
  training loss:		5.615179E-04
  validation loss:		1.872764E-04
Epoch took 13.976s

Epoch 77 of 100
  training loss:		5.649018E-04
  validation loss:		1.033661E-04
Epoch took 14.010s

Epoch 78 of 100
  training loss:		5.367142E-04
  validation loss:		1.595227E-04
Epoch took 13.957s

Epoch 79 of 100
  training loss:		5.558392E-04
  validation loss:		2.302604E-04
Epoch took 14.069s

Epoch 80 of 100
  training loss:		5.262392E-04
  validation loss:		9.391616E-05
Epoch took 13.949s

Epoch 81 of 100
  training loss:		4.971700E-04
  validation loss:		1.028989E-04
Epoch took 14.046s

Epoch 82 of 100
  training loss:		5.103326E-04
  validation loss:		1.808717E-04
Epoch took 13.968s

Epoch 83 of 100
  training loss:		5.115952E-04
  validation loss:		1.284969E-04
Epoch took 14.115s

Epoch 84 of 100
  training loss:		5.031134E-04
  validation loss:		1.265041E-04
Epoch took 13.942s

Epoch 85 of 100
  training loss:		4.832514E-04
  validation loss:		1.229967E-04
Epoch took 13.834s

Epoch 86 of 100
  training loss:		4.800693E-04
  validation loss:		1.503557E-04
Epoch took 13.707s

Epoch 87 of 100
  training loss:		4.526737E-04
  validation loss:		7.350145E-05
Epoch took 13.643s

Epoch 88 of 100
  training loss:		4.376837E-04
  validation loss:		1.615679E-04
Epoch took 13.667s

Epoch 89 of 100
  training loss:		4.462720E-04
  validation loss:		1.993466E-04
Epoch took 13.641s

Epoch 90 of 100
  training loss:		4.633163E-04
  validation loss:		9.201990E-05
Epoch took 13.688s

Epoch 91 of 100
  training loss:		4.412025E-04
  validation loss:		9.530417E-05
Epoch took 13.677s

Epoch 92 of 100
  training loss:		4.190358E-04
  validation loss:		9.938350E-05
Epoch took 13.685s

Epoch 93 of 100
  training loss:		4.006359E-04
  validation loss:		1.385370E-04
Epoch took 13.675s

Epoch 94 of 100
  training loss:		4.137503E-04
  validation loss:		8.464876E-05
Epoch took 13.664s

Epoch 95 of 100
  training loss:		4.030668E-04
  validation loss:		1.107952E-04
Epoch took 13.682s

Epoch 96 of 100
  training loss:		4.238372E-04
  validation loss:		9.584270E-05
Epoch took 13.660s

Epoch 97 of 100
  training loss:		3.951687E-04
  validation loss:		1.319268E-04
Epoch took 13.644s

Epoch 98 of 100
  training loss:		3.897680E-04
  validation loss:		9.150957E-05
Epoch took 13.653s

Epoch 99 of 100
  training loss:		4.087497E-04
  validation loss:		9.918205E-05
Epoch took 13.653s

Epoch 100 of 100
  training loss:		3.895350E-04
  validation loss:		9.693382E-05
Epoch took 13.666s

Training RMSE: 9.54822894645e-09
Validation RMSE: 9.65580005934e-09
