Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		1.778259E-01
  validation loss:		2.109193E-02
Epoch took 13.704s

Epoch 2 of 100
  training loss:		4.681424E-02
  validation loss:		6.361070E-03
Epoch took 13.734s

Epoch 3 of 100
  training loss:		3.159184E-02
  validation loss:		6.242037E-03
Epoch took 13.722s

Epoch 4 of 100
  training loss:		2.532072E-02
  validation loss:		4.157630E-03
Epoch took 13.707s

Epoch 5 of 100
  training loss:		2.195478E-02
  validation loss:		5.387379E-03
Epoch took 13.709s

Epoch 6 of 100
  training loss:		1.849408E-02
  validation loss:		2.207799E-03
Epoch took 13.691s

Epoch 7 of 100
  training loss:		1.603920E-02
  validation loss:		3.579735E-03
Epoch took 13.698s

Epoch 8 of 100
  training loss:		1.473678E-02
  validation loss:		2.848715E-03
Epoch took 13.716s

Epoch 9 of 100
  training loss:		1.331306E-02
  validation loss:		2.207930E-03
Epoch took 13.716s

Epoch 10 of 100
  training loss:		1.218481E-02
  validation loss:		2.593804E-03
Epoch took 13.727s

Epoch 11 of 100
  training loss:		1.143507E-02
  validation loss:		1.831401E-03
Epoch took 13.719s

Epoch 12 of 100
  training loss:		1.077962E-02
  validation loss:		1.670725E-03
Epoch took 13.713s

Epoch 13 of 100
  training loss:		9.828482E-03
  validation loss:		1.401969E-03
Epoch took 13.714s

Epoch 14 of 100
  training loss:		8.837867E-03
  validation loss:		1.336883E-03
Epoch took 13.734s

Epoch 15 of 100
  training loss:		8.547128E-03
  validation loss:		2.020897E-03
Epoch took 13.711s

Epoch 16 of 100
  training loss:		7.943463E-03
  validation loss:		1.432647E-03
Epoch took 13.731s

Epoch 17 of 100
  training loss:		7.720024E-03
  validation loss:		1.464430E-03
Epoch took 13.717s

Epoch 18 of 100
  training loss:		7.266486E-03
  validation loss:		1.388652E-03
Epoch took 13.738s

Epoch 19 of 100
  training loss:		6.907322E-03
  validation loss:		1.162620E-03
Epoch took 13.711s

Epoch 20 of 100
  training loss:		6.326556E-03
  validation loss:		1.378274E-03
Epoch took 13.727s

Epoch 21 of 100
  training loss:		6.230254E-03
  validation loss:		8.990420E-04
Epoch took 13.723s

Epoch 22 of 100
  training loss:		5.848179E-03
  validation loss:		1.390435E-03
Epoch took 13.738s

Epoch 23 of 100
  training loss:		5.525889E-03
  validation loss:		1.024577E-03
Epoch took 13.697s

Epoch 24 of 100
  training loss:		5.403812E-03
  validation loss:		1.246042E-03
Epoch took 13.721s

Epoch 25 of 100
  training loss:		5.116827E-03
  validation loss:		8.069496E-04
Epoch took 13.674s

Epoch 26 of 100
  training loss:		4.989505E-03
  validation loss:		1.015655E-03
Epoch took 13.704s

Epoch 27 of 100
  training loss:		4.427579E-03
  validation loss:		8.566670E-04
Epoch took 13.726s

Epoch 28 of 100
  training loss:		4.691555E-03
  validation loss:		8.705354E-04
Epoch took 13.726s

Epoch 29 of 100
  training loss:		4.430465E-03
  validation loss:		8.589373E-04
Epoch took 13.752s

Epoch 30 of 100
  training loss:		4.090980E-03
  validation loss:		8.567272E-04
Epoch took 13.718s

Epoch 31 of 100
  training loss:		4.027999E-03
  validation loss:		9.175569E-04
Epoch took 13.693s

Epoch 32 of 100
  training loss:		3.835975E-03
  validation loss:		1.147922E-03
Epoch took 13.875s

Epoch 33 of 100
  training loss:		3.775158E-03
  validation loss:		9.331527E-04
Epoch took 13.896s

Epoch 34 of 100
  training loss:		3.590481E-03
  validation loss:		6.015804E-04
Epoch took 13.908s

Epoch 35 of 100
  training loss:		3.370250E-03
  validation loss:		7.926304E-04
Epoch took 13.740s

Epoch 36 of 100
  training loss:		3.395160E-03
  validation loss:		6.725513E-04
Epoch took 13.694s

Epoch 37 of 100
  training loss:		3.343045E-03
  validation loss:		7.295265E-04
Epoch took 13.701s

Epoch 38 of 100
  training loss:		3.163174E-03
  validation loss:		6.411679E-04
Epoch took 13.738s

Epoch 39 of 100
  training loss:		3.106063E-03
  validation loss:		8.881014E-04
Epoch took 13.688s

Epoch 40 of 100
  training loss:		3.121127E-03
  validation loss:		5.135216E-04
Epoch took 13.684s

Epoch 41 of 100
  training loss:		2.746226E-03
  validation loss:		4.882034E-04
Epoch took 13.648s

Epoch 42 of 100
  training loss:		2.708637E-03
  validation loss:		4.676119E-04
Epoch took 13.709s

Epoch 43 of 100
  training loss:		2.823443E-03
  validation loss:		6.288212E-04
Epoch took 13.679s

Epoch 44 of 100
  training loss:		2.697482E-03
  validation loss:		7.236581E-04
Epoch took 13.694s

Epoch 45 of 100
  training loss:		2.638759E-03
  validation loss:		4.288370E-04
Epoch took 13.687s

Epoch 46 of 100
  training loss:		2.438960E-03
  validation loss:		7.969700E-04
Epoch took 13.715s

Epoch 47 of 100
  training loss:		2.466618E-03
  validation loss:		3.947863E-04
Epoch took 13.669s

Epoch 48 of 100
  training loss:		2.554820E-03
  validation loss:		6.781179E-04
Epoch took 13.694s

Epoch 49 of 100
  training loss:		2.386056E-03
  validation loss:		5.157594E-04
Epoch took 13.685s

Epoch 50 of 100
  training loss:		2.281456E-03
  validation loss:		3.260820E-04
Epoch took 13.681s

Epoch 51 of 100
  training loss:		2.353349E-03
  validation loss:		4.867175E-04
Epoch took 13.668s

Epoch 52 of 100
  training loss:		2.167023E-03
  validation loss:		4.468805E-04
Epoch took 13.750s

Epoch 53 of 100
  training loss:		2.101322E-03
  validation loss:		5.370043E-04
Epoch took 13.686s

Epoch 54 of 100
  training loss:		2.095343E-03
  validation loss:		4.836161E-04
Epoch took 13.730s

Epoch 55 of 100
  training loss:		1.984134E-03
  validation loss:		3.853005E-04
Epoch took 13.711s

Epoch 56 of 100
  training loss:		2.081452E-03
  validation loss:		4.944636E-04
Epoch took 13.701s

Epoch 57 of 100
  training loss:		1.988104E-03
  validation loss:		4.039329E-04
Epoch took 13.657s

Epoch 58 of 100
  training loss:		1.882828E-03
  validation loss:		4.568764E-04
Epoch took 13.700s

Epoch 59 of 100
  training loss:		1.912637E-03
  validation loss:		4.946244E-04
Epoch took 13.705s

Epoch 60 of 100
  training loss:		1.835408E-03
  validation loss:		6.873709E-04
Epoch took 13.699s

Epoch 61 of 100
  training loss:		1.827420E-03
  validation loss:		4.849899E-04
Epoch took 13.688s

Epoch 62 of 100
  training loss:		1.718622E-03
  validation loss:		3.149137E-04
Epoch took 13.708s

Epoch 63 of 100
  training loss:		1.673292E-03
  validation loss:		2.879006E-04
Epoch took 13.703s

Epoch 64 of 100
  training loss:		1.692246E-03
  validation loss:		6.720217E-04
Epoch took 13.693s

Epoch 65 of 100
  training loss:		1.706428E-03
  validation loss:		4.046886E-04
Epoch took 13.692s

Epoch 66 of 100
  training loss:		1.599059E-03
  validation loss:		3.462793E-04
Epoch took 13.729s

Epoch 67 of 100
  training loss:		1.627079E-03
  validation loss:		4.423476E-04
Epoch took 13.717s

Epoch 68 of 100
  training loss:		1.588366E-03
  validation loss:		3.548800E-04
Epoch took 13.728s

Epoch 69 of 100
  training loss:		1.563080E-03
  validation loss:		3.890226E-04
Epoch took 13.702s

Epoch 70 of 100
  training loss:		1.477069E-03
  validation loss:		4.551321E-04
Epoch took 13.677s

Epoch 71 of 100
  training loss:		1.510919E-03
  validation loss:		2.707367E-04
Epoch took 13.660s

Epoch 72 of 100
  training loss:		1.450448E-03
  validation loss:		3.290437E-04
Epoch took 13.706s

Epoch 73 of 100
  training loss:		1.442778E-03
  validation loss:		2.666105E-04
Epoch took 13.688s

Epoch 74 of 100
  training loss:		1.395494E-03
  validation loss:		4.207070E-04
Epoch took 13.685s

Epoch 75 of 100
  training loss:		1.398789E-03
  validation loss:		3.178139E-04
Epoch took 13.668s

Epoch 76 of 100
  training loss:		1.306252E-03
  validation loss:		3.927475E-04
Epoch took 13.722s

Epoch 77 of 100
  training loss:		1.350479E-03
  validation loss:		3.742900E-04
Epoch took 13.698s

Epoch 78 of 100
  training loss:		1.316317E-03
  validation loss:		2.512866E-04
Epoch took 13.705s

Epoch 79 of 100
  training loss:		1.317771E-03
  validation loss:		3.899724E-04
Epoch took 13.681s

Epoch 80 of 100
  training loss:		1.268434E-03
  validation loss:		3.852894E-04
Epoch took 13.691s

Epoch 81 of 100
  training loss:		1.213999E-03
  validation loss:		6.749660E-04
Epoch took 13.694s

Epoch 82 of 100
  training loss:		1.234923E-03
  validation loss:		2.054503E-04
Epoch took 13.728s

Epoch 83 of 100
  training loss:		1.205956E-03
  validation loss:		3.296012E-04
Epoch took 13.714s

Epoch 84 of 100
  training loss:		1.165115E-03
  validation loss:		2.001419E-04
Epoch took 13.700s

Epoch 85 of 100
  training loss:		1.164909E-03
  validation loss:		2.395082E-04
Epoch took 13.693s

Epoch 86 of 100
  training loss:		1.144349E-03
  validation loss:		2.245318E-04
Epoch took 13.728s

Epoch 87 of 100
  training loss:		1.109201E-03
  validation loss:		3.007616E-04
Epoch took 13.680s

Epoch 88 of 100
  training loss:		1.129863E-03
  validation loss:		3.267706E-04
Epoch took 13.725s

Epoch 89 of 100
  training loss:		1.121051E-03
  validation loss:		2.499030E-04
Epoch took 13.696s

Epoch 90 of 100
  training loss:		1.126024E-03
  validation loss:		2.544785E-04
Epoch took 13.752s

Epoch 91 of 100
  training loss:		1.093114E-03
  validation loss:		2.624207E-04
Epoch took 13.734s

Epoch 92 of 100
  training loss:		1.065428E-03
  validation loss:		3.317542E-04
Epoch took 13.738s

Epoch 93 of 100
  training loss:		1.082777E-03
  validation loss:		1.813642E-04
Epoch took 13.697s

Epoch 94 of 100
  training loss:		1.048199E-03
  validation loss:		3.311204E-04
Epoch took 13.712s

Epoch 95 of 100
  training loss:		1.031734E-03
  validation loss:		2.303251E-04
Epoch took 13.704s

Epoch 96 of 100
  training loss:		1.013084E-03
  validation loss:		1.699577E-04
Epoch took 13.711s

Epoch 97 of 100
  training loss:		9.770388E-04
  validation loss:		2.347672E-04
Epoch took 13.694s

Epoch 98 of 100
  training loss:		9.962741E-04
  validation loss:		2.030648E-04
Epoch took 13.675s

Epoch 99 of 100
  training loss:		1.007550E-03
  validation loss:		1.735243E-04
Epoch took 13.721s

Epoch 100 of 100
  training loss:		9.889699E-04
  validation loss:		1.723811E-04
Epoch took 13.696s

Training RMSE: 1.28298554085e-08
Validation RMSE: 1.28673891204e-08
