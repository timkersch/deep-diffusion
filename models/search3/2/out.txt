Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		3.334350E-01
  validation loss:		2.547880E-02
Epoch took 13.638s

Epoch 2 of 100
  training loss:		4.520658E-02
  validation loss:		8.924069E-03
Epoch took 13.662s

Epoch 3 of 100
  training loss:		2.545227E-02
  validation loss:		6.617092E-03
Epoch took 13.645s

Epoch 4 of 100
  training loss:		1.914379E-02
  validation loss:		6.360627E-03
Epoch took 13.644s

Epoch 5 of 100
  training loss:		1.590737E-02
  validation loss:		4.016093E-03
Epoch took 13.653s

Epoch 6 of 100
  training loss:		1.400868E-02
  validation loss:		3.383674E-03
Epoch took 13.646s

Epoch 7 of 100
  training loss:		1.198416E-02
  validation loss:		3.394873E-03
Epoch took 13.653s

Epoch 8 of 100
  training loss:		1.059888E-02
  validation loss:		2.534102E-03
Epoch took 13.611s

Epoch 9 of 100
  training loss:		9.683924E-03
  validation loss:		2.122112E-03
Epoch took 13.653s

Epoch 10 of 100
  training loss:		8.423489E-03
  validation loss:		1.669699E-03
Epoch took 13.644s

Epoch 11 of 100
  training loss:		7.784030E-03
  validation loss:		2.143961E-03
Epoch took 13.614s

Epoch 12 of 100
  training loss:		7.748342E-03
  validation loss:		1.626344E-03
Epoch took 13.601s

Epoch 13 of 100
  training loss:		6.665966E-03
  validation loss:		2.067591E-03
Epoch took 13.593s

Epoch 14 of 100
  training loss:		6.539439E-03
  validation loss:		1.825066E-03
Epoch took 13.631s

Epoch 15 of 100
  training loss:		5.496669E-03
  validation loss:		1.708672E-03
Epoch took 13.695s

Epoch 16 of 100
  training loss:		5.361822E-03
  validation loss:		1.433390E-03
Epoch took 13.625s

Epoch 17 of 100
  training loss:		5.235750E-03
  validation loss:		9.479784E-04
Epoch took 13.615s

Epoch 18 of 100
  training loss:		4.607491E-03
  validation loss:		1.598314E-03
Epoch took 13.622s

Epoch 19 of 100
  training loss:		4.304884E-03
  validation loss:		1.257751E-03
Epoch took 13.655s

Epoch 20 of 100
  training loss:		4.123125E-03
  validation loss:		9.511372E-04
Epoch took 13.642s

Epoch 21 of 100
  training loss:		3.927659E-03
  validation loss:		8.217411E-04
Epoch took 13.661s

Epoch 22 of 100
  training loss:		3.690470E-03
  validation loss:		1.430729E-03
Epoch took 13.636s

Epoch 23 of 100
  training loss:		3.627818E-03
  validation loss:		1.042665E-03
Epoch took 13.659s

Epoch 24 of 100
  training loss:		3.434003E-03
  validation loss:		9.628222E-04
Epoch took 13.623s

Epoch 25 of 100
  training loss:		3.282366E-03
  validation loss:		5.658334E-04
Epoch took 13.645s

Epoch 26 of 100
  training loss:		3.026426E-03
  validation loss:		7.669468E-04
Epoch took 13.628s

Epoch 27 of 100
  training loss:		2.989951E-03
  validation loss:		7.624122E-04
Epoch took 13.628s

Epoch 28 of 100
  training loss:		2.714124E-03
  validation loss:		6.730044E-04
Epoch took 13.651s

Epoch 29 of 100
  training loss:		2.789507E-03
  validation loss:		6.441979E-04
Epoch took 13.645s

Epoch 30 of 100
  training loss:		2.670640E-03
  validation loss:		7.783631E-04
Epoch took 13.603s

Epoch 31 of 100
  training loss:		2.455562E-03
  validation loss:		5.991530E-04
Epoch took 13.626s

Epoch 32 of 100
  training loss:		2.343682E-03
  validation loss:		5.048976E-04
Epoch took 13.617s

Epoch 33 of 100
  training loss:		2.181518E-03
  validation loss:		6.791554E-04
Epoch took 13.632s

Epoch 34 of 100
  training loss:		2.196944E-03
  validation loss:		4.481137E-04
Epoch took 13.628s

Epoch 35 of 100
  training loss:		2.032077E-03
  validation loss:		5.422637E-04
Epoch took 13.652s

Epoch 36 of 100
  training loss:		2.052841E-03
  validation loss:		4.091353E-04
Epoch took 13.631s

Epoch 37 of 100
  training loss:		1.970146E-03
  validation loss:		3.637743E-04
Epoch took 13.632s

Epoch 38 of 100
  training loss:		1.934739E-03
  validation loss:		3.986427E-04
Epoch took 13.640s

Epoch 39 of 100
  training loss:		1.785438E-03
  validation loss:		4.770139E-04
Epoch took 13.654s

Epoch 40 of 100
  training loss:		1.729989E-03
  validation loss:		3.367881E-04
Epoch took 13.636s

Epoch 41 of 100
  training loss:		1.696584E-03
  validation loss:		5.270331E-04
Epoch took 13.628s

Epoch 42 of 100
  training loss:		1.635559E-03
  validation loss:		3.528472E-04
Epoch took 13.632s

Epoch 43 of 100
  training loss:		1.550459E-03
  validation loss:		4.779260E-04
Epoch took 13.628s

Epoch 44 of 100
  training loss:		1.579173E-03
  validation loss:		5.790369E-04
Epoch took 13.628s

Epoch 45 of 100
  training loss:		1.477729E-03
  validation loss:		3.792975E-04
Epoch took 13.676s

Epoch 46 of 100
  training loss:		1.425504E-03
  validation loss:		3.971671E-04
Epoch took 13.682s

Epoch 47 of 100
  training loss:		1.364716E-03
  validation loss:		3.001409E-04
Epoch took 13.646s

Epoch 48 of 100
  training loss:		1.388976E-03
  validation loss:		3.671288E-04
Epoch took 13.729s

Epoch 49 of 100
  training loss:		1.311943E-03
  validation loss:		3.204029E-04
Epoch took 13.823s

Epoch 50 of 100
  training loss:		1.284881E-03
  validation loss:		3.722400E-04
Epoch took 13.789s

Epoch 51 of 100
  training loss:		1.300575E-03
  validation loss:		4.141662E-04
Epoch took 13.876s

Epoch 52 of 100
  training loss:		1.207289E-03
  validation loss:		3.333847E-04
Epoch took 13.850s

Epoch 53 of 100
  training loss:		1.186511E-03
  validation loss:		2.971097E-04
Epoch took 13.859s

Epoch 54 of 100
  training loss:		1.122391E-03
  validation loss:		2.240826E-04
Epoch took 13.775s

Epoch 55 of 100
  training loss:		1.161986E-03
  validation loss:		2.803470E-04
Epoch took 13.844s

Epoch 56 of 100
  training loss:		1.051175E-03
  validation loss:		2.508927E-04
Epoch took 13.873s

Epoch 57 of 100
  training loss:		1.067247E-03
  validation loss:		2.547755E-04
Epoch took 13.946s

Epoch 58 of 100
  training loss:		1.056597E-03
  validation loss:		3.595994E-04
Epoch took 13.875s

Epoch 59 of 100
  training loss:		1.059181E-03
  validation loss:		2.723127E-04
Epoch took 13.974s

Epoch 60 of 100
  training loss:		1.011224E-03
  validation loss:		1.885388E-04
Epoch took 13.978s

Epoch 61 of 100
  training loss:		9.630396E-04
  validation loss:		2.750115E-04
Epoch took 14.026s

Epoch 62 of 100
  training loss:		9.474590E-04
  validation loss:		2.291875E-04
Epoch took 13.851s

Epoch 63 of 100
  training loss:		9.486184E-04
  validation loss:		3.954700E-04
Epoch took 13.980s

Epoch 64 of 100
  training loss:		8.919196E-04
  validation loss:		3.052214E-04
Epoch took 13.860s

Epoch 65 of 100
  training loss:		8.636852E-04
  validation loss:		1.890206E-04
Epoch took 13.860s

Epoch 66 of 100
  training loss:		8.763327E-04
  validation loss:		3.126132E-04
Epoch took 13.848s

Epoch 67 of 100
  training loss:		8.526979E-04
  validation loss:		1.816070E-04
Epoch took 13.838s

Epoch 68 of 100
  training loss:		8.120108E-04
  validation loss:		2.128791E-04
Epoch took 13.832s

Epoch 69 of 100
  training loss:		8.656312E-04
  validation loss:		1.935246E-04
Epoch took 13.829s

Epoch 70 of 100
  training loss:		8.010122E-04
  validation loss:		2.103786E-04
Epoch took 13.838s

Epoch 71 of 100
  training loss:		7.636313E-04
  validation loss:		1.183452E-04
Epoch took 13.830s

Epoch 72 of 100
  training loss:		7.555581E-04
  validation loss:		1.845541E-04
Epoch took 13.856s

Epoch 73 of 100
  training loss:		7.572424E-04
  validation loss:		1.276101E-04
Epoch took 13.857s

Epoch 74 of 100
  training loss:		7.394744E-04
  validation loss:		2.973250E-04
Epoch took 13.835s

Epoch 75 of 100
  training loss:		7.114174E-04
  validation loss:		1.300787E-04
Epoch took 13.858s

Epoch 76 of 100
  training loss:		7.356738E-04
  validation loss:		1.872127E-04
Epoch took 13.840s

Epoch 77 of 100
  training loss:		7.289066E-04
  validation loss:		1.763515E-04
Epoch took 13.852s

Epoch 78 of 100
  training loss:		7.077561E-04
  validation loss:		1.492832E-04
Epoch took 13.846s

Epoch 79 of 100
  training loss:		6.554518E-04
  validation loss:		1.748820E-04
Epoch took 13.851s

Epoch 80 of 100
  training loss:		6.419614E-04
  validation loss:		1.273920E-04
Epoch took 13.842s

Epoch 81 of 100
  training loss:		7.084377E-04
  validation loss:		1.630738E-04
Epoch took 13.848s

Epoch 82 of 100
  training loss:		6.851904E-04
  validation loss:		1.549696E-04
Epoch took 13.837s

Epoch 83 of 100
  training loss:		6.188587E-04
  validation loss:		1.249997E-04
Epoch took 13.850s

Epoch 84 of 100
  training loss:		6.070631E-04
  validation loss:		9.831237E-05
Epoch took 13.839s

Epoch 85 of 100
  training loss:		5.601522E-04
  validation loss:		1.164366E-04
Epoch took 13.849s

Epoch 86 of 100
  training loss:		5.719020E-04
  validation loss:		2.561276E-04
Epoch took 13.837s

Epoch 87 of 100
  training loss:		5.643755E-04
  validation loss:		1.024465E-04
Epoch took 13.855s

Epoch 88 of 100
  training loss:		5.854341E-04
  validation loss:		1.385471E-04
Epoch took 13.874s

Epoch 89 of 100
  training loss:		5.740540E-04
  validation loss:		1.225043E-04
Epoch took 14.326s

Epoch 90 of 100
  training loss:		5.442732E-04
  validation loss:		8.621313E-05
Epoch took 13.955s

Epoch 91 of 100
  training loss:		5.237081E-04
  validation loss:		1.494696E-04
Epoch took 14.022s

Epoch 92 of 100
  training loss:		5.420878E-04
  validation loss:		1.051169E-04
Epoch took 13.937s

Epoch 93 of 100
  training loss:		4.971494E-04
  validation loss:		1.353786E-04
Epoch took 13.913s

Epoch 94 of 100
  training loss:		5.303990E-04
  validation loss:		1.809854E-04
Epoch took 13.921s

Epoch 95 of 100
  training loss:		5.261407E-04
  validation loss:		1.377696E-04
Epoch took 13.955s

Epoch 96 of 100
  training loss:		5.150386E-04
  validation loss:		1.076505E-04
Epoch took 13.923s

Epoch 97 of 100
  training loss:		4.922724E-04
  validation loss:		1.458578E-04
Epoch took 13.903s

Epoch 98 of 100
  training loss:		4.916350E-04
  validation loss:		8.055729E-05
Epoch took 13.997s

Epoch 99 of 100
  training loss:		5.164772E-04
  validation loss:		1.702338E-04
Epoch took 13.675s

Epoch 100 of 100
  training loss:		4.660386E-04
  validation loss:		9.647686E-05
Epoch took 13.629s

Training RMSE: 9.498984578e-09
Validation RMSE: 9.62490041919e-09
