Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 500
  training loss:		8.734567E-02
  validation loss:		7.918169E-02

Epoch 2 of 500
  training loss:		7.038124E-02
  validation loss:		6.116551E-02

Epoch 3 of 500
  training loss:		5.063095E-02
  validation loss:		4.001753E-02

Epoch 4 of 500
  training loss:		3.004991E-02
  validation loss:		2.145454E-02

Epoch 5 of 500
  training loss:		1.542359E-02
  validation loss:		1.122605E-02

Epoch 6 of 500
  training loss:		9.291307E-03
  validation loss:		8.169909E-03

Epoch 7 of 500
  training loss:		7.678761E-03
  validation loss:		7.267504E-03

Epoch 8 of 500
  training loss:		6.959578E-03
  validation loss:		6.686541E-03

Epoch 9 of 500
  training loss:		6.398856E-03
  validation loss:		6.189442E-03

Epoch 10 of 500
  training loss:		5.877745E-03
  validation loss:		5.591742E-03

Epoch 11 of 500
  training loss:		5.380358E-03
  validation loss:		5.109949E-03

Epoch 12 of 500
  training loss:		4.923640E-03
  validation loss:		4.698438E-03

Epoch 13 of 500
  training loss:		4.482509E-03
  validation loss:		4.256527E-03

Epoch 14 of 500
  training loss:		4.084001E-03
  validation loss:		3.924854E-03

Epoch 15 of 500
  training loss:		3.718397E-03
  validation loss:		3.525219E-03

Epoch 16 of 500
  training loss:		3.399857E-03
  validation loss:		3.218043E-03

Epoch 17 of 500
  training loss:		3.107341E-03
  validation loss:		2.948650E-03

Epoch 18 of 500
  training loss:		2.853536E-03
  validation loss:		2.732693E-03

Epoch 19 of 500
  training loss:		2.629644E-03
  validation loss:		2.503094E-03

Epoch 20 of 500
  training loss:		2.435595E-03
  validation loss:		2.324386E-03

Epoch 21 of 500
  training loss:		2.269809E-03
  validation loss:		2.173546E-03

Epoch 22 of 500
  training loss:		2.130140E-03
  validation loss:		2.042117E-03

Epoch 23 of 500
  training loss:		2.009724E-03
  validation loss:		1.956807E-03

Epoch 24 of 500
  training loss:		1.903836E-03
  validation loss:		1.847893E-03

Epoch 25 of 500
  training loss:		1.820532E-03
  validation loss:		1.754723E-03

Epoch 26 of 500
  training loss:		1.744103E-03
  validation loss:		1.685116E-03

Epoch 27 of 500
  training loss:		1.681544E-03
  validation loss:		1.627209E-03

Epoch 28 of 500
  training loss:		1.621632E-03
  validation loss:		1.571528E-03

Epoch 29 of 500
  training loss:		1.568506E-03
  validation loss:		1.525304E-03

Epoch 30 of 500
  training loss:		1.519714E-03
  validation loss:		1.530232E-03

Epoch 31 of 500
  training loss:		1.470110E-03
  validation loss:		1.449884E-03

Epoch 32 of 500
  training loss:		1.397625E-03
  validation loss:		1.377836E-03

Epoch 33 of 500
  training loss:		1.276004E-03
  validation loss:		1.185199E-03

Epoch 34 of 500
  training loss:		1.110296E-03
  validation loss:		9.990710E-04

Epoch 35 of 500
  training loss:		9.331638E-04
  validation loss:		8.322710E-04

Epoch 36 of 500
  training loss:		7.825473E-04
  validation loss:		7.306796E-04

Epoch 37 of 500
  training loss:		6.619469E-04
  validation loss:		6.197627E-04

Epoch 38 of 500
  training loss:		5.716533E-04
  validation loss:		5.126110E-04

Epoch 39 of 500
  training loss:		4.991390E-04
  validation loss:		4.492006E-04

Epoch 40 of 500
  training loss:		4.385408E-04
  validation loss:		3.989544E-04

Epoch 41 of 500
  training loss:		3.894451E-04
  validation loss:		3.532279E-04

Epoch 42 of 500
  training loss:		3.500551E-04
  validation loss:		3.207196E-04

Epoch 43 of 500
  training loss:		3.149571E-04
  validation loss:		2.888861E-04

Epoch 44 of 500
  training loss:		2.851260E-04
  validation loss:		2.618089E-04

Epoch 45 of 500
  training loss:		2.608136E-04
  validation loss:		2.463046E-04

Epoch 46 of 500
  training loss:		2.370008E-04
  validation loss:		2.196541E-04

Epoch 47 of 500
  training loss:		2.199424E-04
  validation loss:		2.094492E-04

Epoch 48 of 500
  training loss:		1.999209E-04
  validation loss:		1.892253E-04

Epoch 49 of 500
  training loss:		1.861331E-04
  validation loss:		1.727809E-04

Epoch 50 of 500
  training loss:		1.725792E-04
  validation loss:		1.609741E-04

Epoch 51 of 500
  training loss:		1.599672E-04
  validation loss:		1.510694E-04

Epoch 52 of 500
  training loss:		1.501647E-04
  validation loss:		1.428232E-04

Epoch 53 of 500
  training loss:		1.405907E-04
  validation loss:		1.327279E-04

Epoch 54 of 500
  training loss:		1.316323E-04
  validation loss:		1.257826E-04

Epoch 55 of 500
  training loss:		1.240793E-04
  validation loss:		1.166402E-04

Epoch 56 of 500
  training loss:		1.168560E-04
  validation loss:		1.099338E-04

Epoch 57 of 500
  training loss:		1.109989E-04
  validation loss:		1.039417E-04

Epoch 58 of 500
  training loss:		1.042054E-04
  validation loss:		1.013794E-04

Epoch 59 of 500
  training loss:		9.914165E-05
  validation loss:		9.300435E-05

Epoch 60 of 500
  training loss:		9.380177E-05
  validation loss:		9.187948E-05

Epoch 61 of 500
  training loss:		8.971386E-05
  validation loss:		8.934711E-05

Epoch 62 of 500
  training loss:		8.487795E-05
  validation loss:		8.027500E-05

Epoch 63 of 500
  training loss:		8.114300E-05
  validation loss:		9.497916E-05

Epoch 64 of 500
  training loss:		7.725135E-05
  validation loss:		7.382343E-05

Epoch 65 of 500
  training loss:		7.396652E-05
  validation loss:		7.529484E-05

Epoch 66 of 500
  training loss:		7.100175E-05
  validation loss:		7.078185E-05

Epoch 67 of 500
  training loss:		6.781823E-05
  validation loss:		6.706012E-05

Epoch 68 of 500
  training loss:		6.496009E-05
  validation loss:		6.084627E-05

Epoch 69 of 500
  training loss:		6.272183E-05
  validation loss:		5.896975E-05

Epoch 70 of 500
  training loss:		6.010325E-05
  validation loss:		5.704504E-05

Epoch 71 of 500
  training loss:		5.741905E-05
  validation loss:		6.111526E-05

Epoch 72 of 500
  training loss:		5.585743E-05
  validation loss:		5.331136E-05

Epoch 73 of 500
  training loss:		5.345848E-05
  validation loss:		4.991957E-05

Epoch 74 of 500
  training loss:		5.168337E-05
  validation loss:		5.236330E-05

Epoch 75 of 500
  training loss:		5.003471E-05
  validation loss:		4.729228E-05

Epoch 76 of 500
  training loss:		4.838928E-05
  validation loss:		4.501563E-05

Epoch 77 of 500
  training loss:		4.666032E-05
  validation loss:		4.411752E-05

Epoch 78 of 500
  training loss:		4.553263E-05
  validation loss:		4.262808E-05

Epoch 79 of 500
  training loss:		4.394200E-05
  validation loss:		4.324373E-05

Epoch 80 of 500
  training loss:		4.292838E-05
  validation loss:		3.981892E-05

Epoch 81 of 500
  training loss:		4.137878E-05
  validation loss:		4.429422E-05

Epoch 82 of 500
  training loss:		4.017905E-05
  validation loss:		4.542252E-05

Epoch 83 of 500
  training loss:		3.924702E-05
  validation loss:		3.811461E-05

Epoch 84 of 500
  training loss:		3.808347E-05
  validation loss:		3.635427E-05

Epoch 85 of 500
  training loss:		3.686275E-05
  validation loss:		3.607856E-05

Epoch 86 of 500
  training loss:		3.612943E-05
  validation loss:		3.436661E-05

Epoch 87 of 500
  training loss:		3.521669E-05
  validation loss:		3.300373E-05

Epoch 88 of 500
  training loss:		3.418551E-05
  validation loss:		3.342793E-05

Epoch 89 of 500
  training loss:		3.334481E-05
  validation loss:		3.098607E-05

Epoch 90 of 500
  training loss:		3.240817E-05
  validation loss:		3.071760E-05

Epoch 91 of 500
  training loss:		3.180027E-05
  validation loss:		3.071633E-05

Epoch 92 of 500
  training loss:		3.114400E-05
  validation loss:		2.859069E-05

Epoch 93 of 500
  training loss:		3.012827E-05
  validation loss:		2.951208E-05

Epoch 94 of 500
  training loss:		2.920935E-05
  validation loss:		2.717319E-05

Epoch 95 of 500
  training loss:		2.841231E-05
  validation loss:		2.747483E-05

Epoch 96 of 500
  training loss:		2.795217E-05
  validation loss:		2.980074E-05

Epoch 97 of 500
  training loss:		2.698557E-05
  validation loss:		2.600542E-05

Epoch 98 of 500
  training loss:		2.651196E-05
  validation loss:		2.530962E-05

Epoch 99 of 500
  training loss:		2.584529E-05
  validation loss:		2.412876E-05

Epoch 100 of 500
  training loss:		2.574849E-05
  validation loss:		2.858648E-05

Epoch 101 of 500
  training loss:		2.483363E-05
  validation loss:		2.816194E-05

Epoch 102 of 500
  training loss:		2.417704E-05
  validation loss:		2.437444E-05

Epoch 103 of 500
  training loss:		2.388613E-05
  validation loss:		2.214238E-05

Epoch 104 of 500
  training loss:		2.317280E-05
  validation loss:		2.151483E-05

Epoch 105 of 500
  training loss:		2.286701E-05
  validation loss:		3.093027E-05

Epoch 106 of 500
  training loss:		2.216567E-05
  validation loss:		2.071392E-05

Epoch 107 of 500
  training loss:		2.171528E-05
  validation loss:		2.072462E-05

Epoch 108 of 500
  training loss:		2.112779E-05
  validation loss:		2.034854E-05

Epoch 109 of 500
  training loss:		2.076971E-05
  validation loss:		2.287830E-05

Epoch 110 of 500
  training loss:		2.039915E-05
  validation loss:		1.892112E-05

Epoch 111 of 500
  training loss:		1.989745E-05
  validation loss:		1.921939E-05

Epoch 112 of 500
  training loss:		1.958782E-05
  validation loss:		1.831671E-05

Epoch 113 of 500
  training loss:		1.911237E-05
  validation loss:		1.797733E-05

Epoch 114 of 500
  training loss:		1.893001E-05
  validation loss:		1.729058E-05

Epoch 115 of 500
  training loss:		1.845297E-05
  validation loss:		1.880440E-05

Epoch 116 of 500
  training loss:		1.804098E-05
  validation loss:		1.664768E-05

Epoch 117 of 500
  training loss:		1.801376E-05
  validation loss:		2.160353E-05

Epoch 118 of 500
  training loss:		1.762126E-05
  validation loss:		1.721118E-05

Epoch 119 of 500
  training loss:		1.734719E-05
  validation loss:		1.629014E-05

Epoch 120 of 500
  training loss:		1.704009E-05
  validation loss:		1.649211E-05

Epoch 121 of 500
  training loss:		1.663773E-05
  validation loss:		1.865577E-05

Epoch 122 of 500
  training loss:		1.625556E-05
  validation loss:		1.895561E-05

Epoch 123 of 500
  training loss:		1.630619E-05
  validation loss:		1.483387E-05

Epoch 124 of 500
  training loss:		1.576225E-05
  validation loss:		1.458496E-05

Epoch 125 of 500
  training loss:		1.553434E-05
  validation loss:		1.701613E-05

Epoch 126 of 500
  training loss:		1.537224E-05
  validation loss:		1.414601E-05

Epoch 127 of 500
  training loss:		1.499760E-05
  validation loss:		1.412016E-05

Epoch 128 of 500
  training loss:		1.481613E-05
  validation loss:		1.394663E-05

Epoch 129 of 500
  training loss:		1.441616E-05
  validation loss:		1.320324E-05

Epoch 130 of 500
  training loss:		1.405265E-05
  validation loss:		1.382643E-05

Epoch 131 of 500
  training loss:		1.403850E-05
  validation loss:		1.277453E-05

Epoch 132 of 500
  training loss:		1.389731E-05
  validation loss:		1.299271E-05

Epoch 133 of 500
  training loss:		1.365795E-05
  validation loss:		1.323930E-05

Epoch 134 of 500
  training loss:		1.349139E-05
  validation loss:		1.393260E-05

Epoch 135 of 500
  training loss:		1.308365E-05
  validation loss:		1.566409E-05

Epoch 136 of 500
  training loss:		1.309815E-05
  validation loss:		1.182773E-05

Epoch 137 of 500
  training loss:		1.252264E-05
  validation loss:		1.175506E-05

Epoch 138 of 500
  training loss:		1.253964E-05
  validation loss:		1.211249E-05

Epoch 139 of 500
  training loss:		1.234962E-05
  validation loss:		1.125689E-05

Epoch 140 of 500
  training loss:		1.208587E-05
  validation loss:		1.227036E-05

Epoch 141 of 500
  training loss:		1.207329E-05
  validation loss:		1.103836E-05

Epoch 142 of 500
  training loss:		1.185925E-05
  validation loss:		1.164187E-05

Epoch 143 of 500
  training loss:		1.147640E-05
  validation loss:		1.081494E-05

Epoch 144 of 500
  training loss:		1.153301E-05
  validation loss:		1.076315E-05

Epoch 145 of 500
  training loss:		1.114149E-05
  validation loss:		1.040374E-05

Epoch 146 of 500
  training loss:		1.115628E-05
  validation loss:		1.046604E-05

Epoch 147 of 500
  training loss:		1.091105E-05
  validation loss:		9.903201E-06

Epoch 148 of 500
  training loss:		1.072524E-05
  validation loss:		9.817677E-06

Epoch 149 of 500
  training loss:		1.068177E-05
  validation loss:		1.030095E-05

Epoch 150 of 500
  training loss:		1.034515E-05
  validation loss:		9.883503E-06

Epoch 151 of 500
  training loss:		1.024167E-05
  validation loss:		9.331944E-06

Epoch 152 of 500
  training loss:		1.002723E-05
  validation loss:		1.073421E-05

Epoch 153 of 500
  training loss:		9.957876E-06
  validation loss:		1.153853E-05

Epoch 154 of 500
  training loss:		9.808016E-06
  validation loss:		9.435192E-06

Epoch 155 of 500
  training loss:		9.762620E-06
  validation loss:		9.590138E-06

Epoch 156 of 500
  training loss:		9.565111E-06
  validation loss:		8.726121E-06

Epoch 157 of 500
  training loss:		9.267441E-06
  validation loss:		9.059288E-06

Epoch 158 of 500
  training loss:		9.361796E-06
  validation loss:		9.090632E-06

Epoch 159 of 500
  training loss:		8.995322E-06
  validation loss:		8.782879E-06

Epoch 160 of 500
  training loss:		8.975557E-06
  validation loss:		8.754980E-06

Epoch 161 of 500
  training loss:		8.697867E-06
  validation loss:		8.125442E-06

Epoch 162 of 500
  training loss:		8.751045E-06
  validation loss:		7.964386E-06

Epoch 163 of 500
  training loss:		8.658614E-06
  validation loss:		9.012085E-06

Epoch 164 of 500
  training loss:		8.384909E-06
  validation loss:		8.163585E-06

Epoch 165 of 500
  training loss:		8.436283E-06
  validation loss:		7.614862E-06

Epoch 166 of 500
  training loss:		8.278824E-06
  validation loss:		7.631917E-06

Epoch 167 of 500
  training loss:		7.962481E-06
  validation loss:		7.306517E-06

Epoch 168 of 500
  training loss:		8.091547E-06
  validation loss:		7.573384E-06

Epoch 169 of 500
  training loss:		7.972915E-06
  validation loss:		7.914445E-06

Epoch 170 of 500
  training loss:		7.800298E-06
  validation loss:		7.276968E-06

Epoch 171 of 500
  training loss:		7.781544E-06
  validation loss:		6.975416E-06

Epoch 172 of 500
  training loss:		7.553774E-06
  validation loss:		6.975950E-06

Epoch 173 of 500
  training loss:		7.491204E-06
  validation loss:		8.989877E-06

Epoch 174 of 500
  training loss:		7.316357E-06
  validation loss:		6.683641E-06

Epoch 175 of 500
  training loss:		7.276966E-06
  validation loss:		1.314120E-05

Epoch 176 of 500
  training loss:		7.080052E-06
  validation loss:		6.404776E-06

Epoch 177 of 500
  training loss:		7.109577E-06
  validation loss:		1.216147E-05

Epoch 178 of 500
  training loss:		6.938857E-06
  validation loss:		6.394974E-06

Epoch 179 of 500
  training loss:		6.893014E-06
  validation loss:		6.757852E-06

Epoch 180 of 500
  training loss:		6.740461E-06
  validation loss:		6.446530E-06

Epoch 181 of 500
  training loss:		6.634770E-06
  validation loss:		6.007024E-06

Epoch 182 of 500
  training loss:		6.561229E-06
  validation loss:		6.092795E-06

Epoch 183 of 500
  training loss:		6.439173E-06
  validation loss:		5.948205E-06

Epoch 184 of 500
  training loss:		6.340324E-06
  validation loss:		6.218091E-06

Epoch 185 of 500
  training loss:		6.369344E-06
  validation loss:		5.908182E-06

Epoch 186 of 500
  training loss:		6.290324E-06
  validation loss:		6.117155E-06

Epoch 187 of 500
  training loss:		5.994226E-06
  validation loss:		5.595778E-06

Epoch 188 of 500
  training loss:		6.132504E-06
  validation loss:		6.315744E-06

Epoch 189 of 500
  training loss:		6.102753E-06
  validation loss:		5.803260E-06

Epoch 190 of 500
  training loss:		5.824469E-06
  validation loss:		6.105223E-06

Epoch 191 of 500
  training loss:		5.800412E-06
  validation loss:		7.361179E-06

Epoch 192 of 500
  training loss:		5.605075E-06
  validation loss:		5.541042E-06

Epoch 193 of 500
  training loss:		5.626434E-06
  validation loss:		5.579170E-06

Epoch 194 of 500
  training loss:		5.472576E-06
  validation loss:		5.672285E-06

Epoch 195 of 500
  training loss:		5.523829E-06
  validation loss:		4.990282E-06

Epoch 196 of 500
  training loss:		5.394357E-06
  validation loss:		4.820010E-06

Epoch 197 of 500
  training loss:		5.397018E-06
  validation loss:		5.052100E-06

Epoch 198 of 500
  training loss:		5.385912E-06
  validation loss:		5.328897E-06

Epoch 199 of 500
  training loss:		5.180558E-06
  validation loss:		4.915335E-06

Epoch 200 of 500
  training loss:		5.170478E-06
  validation loss:		6.850066E-06

Epoch 201 of 500
  training loss:		5.026161E-06
  validation loss:		4.703521E-06

Epoch 202 of 500
  training loss:		5.005695E-06
  validation loss:		4.476106E-06

Epoch 203 of 500
  training loss:		4.901003E-06
  validation loss:		4.766625E-06

Epoch 204 of 500
  training loss:		4.856363E-06
  validation loss:		8.788339E-06

Epoch 205 of 500
  training loss:		4.791158E-06
  validation loss:		6.495921E-06

Epoch 206 of 500
  training loss:		4.767281E-06
  validation loss:		4.277541E-06

Epoch 207 of 500
  training loss:		4.640731E-06
  validation loss:		4.729262E-06

Epoch 208 of 500
  training loss:		4.634940E-06
  validation loss:		4.116031E-06

Epoch 209 of 500
  training loss:		4.492003E-06
  validation loss:		5.736288E-06

Epoch 210 of 500
  training loss:		4.528543E-06
  validation loss:		3.977180E-06

Epoch 211 of 500
  training loss:		4.424571E-06
  validation loss:		4.222197E-06

Epoch 212 of 500
  training loss:		4.346433E-06
  validation loss:		3.839637E-06

Epoch 213 of 500
  training loss:		4.280251E-06
  validation loss:		3.819421E-06

Epoch 214 of 500
  training loss:		4.216055E-06
  validation loss:		3.818247E-06

Epoch 215 of 500
  training loss:		4.170809E-06
  validation loss:		3.742152E-06

Epoch 216 of 500
  training loss:		4.125580E-06
  validation loss:		3.802336E-06

Epoch 217 of 500
  training loss:		4.074349E-06
  validation loss:		3.804740E-06

Epoch 218 of 500
  training loss:		4.027177E-06
  validation loss:		4.386286E-06

Epoch 219 of 500
  training loss:		3.961966E-06
  validation loss:		4.283255E-06

Epoch 220 of 500
  training loss:		3.922162E-06
  validation loss:		3.451710E-06

Epoch 221 of 500
  training loss:		3.853535E-06
  validation loss:		3.538258E-06

Epoch 222 of 500
  training loss:		3.977127E-06
  validation loss:		3.889069E-06

Epoch 223 of 500
  training loss:		3.729226E-06
  validation loss:		3.467004E-06

Epoch 224 of 500
  training loss:		3.766144E-06
  validation loss:		3.561622E-06

Epoch 225 of 500
  training loss:		3.730785E-06
  validation loss:		3.963455E-06

Epoch 226 of 500
  training loss:		3.550866E-06
  validation loss:		3.413365E-06

Epoch 227 of 500
  training loss:		3.506404E-06
  validation loss:		3.432502E-06

Epoch 228 of 500
  training loss:		3.563813E-06
  validation loss:		3.137748E-06

Epoch 229 of 500
  training loss:		3.483774E-06
  validation loss:		4.294331E-06

Epoch 230 of 500
  training loss:		3.480568E-06
  validation loss:		3.033633E-06

Epoch 231 of 500
  training loss:		3.350228E-06
  validation loss:		2.977765E-06

Epoch 232 of 500
  training loss:		3.414801E-06
  validation loss:		2.913319E-06

Epoch 233 of 500
  training loss:		3.212550E-06
  validation loss:		3.243726E-06

Epoch 234 of 500
  training loss:		3.289087E-06
  validation loss:		2.843329E-06

Epoch 235 of 500
  training loss:		3.221984E-06
  validation loss:		2.847775E-06

Epoch 236 of 500
  training loss:		3.195639E-06
  validation loss:		3.649805E-06

Epoch 237 of 500
  training loss:		3.207349E-06
  validation loss:		3.287952E-06

Epoch 238 of 500
  training loss:		3.117609E-06
  validation loss:		2.723962E-06

Epoch 239 of 500
  training loss:		3.158207E-06
  validation loss:		3.270866E-06

Epoch 240 of 500
  training loss:		2.998581E-06
  validation loss:		2.765559E-06

Epoch 241 of 500
  training loss:		3.036191E-06
  validation loss:		2.637155E-06

Epoch 242 of 500
  training loss:		2.981130E-06
  validation loss:		2.557786E-06

Epoch 243 of 500
  training loss:		2.970806E-06
  validation loss:		3.186076E-06

Epoch 244 of 500
  training loss:		2.876518E-06
  validation loss:		5.165368E-06

Epoch 245 of 500
  training loss:		2.805635E-06
  validation loss:		2.572717E-06

Epoch 246 of 500
  training loss:		2.826436E-06
  validation loss:		2.435987E-06

Epoch 247 of 500
  training loss:		2.838819E-06
  validation loss:		4.506515E-06

Epoch 248 of 500
  training loss:		2.706550E-06
  validation loss:		2.557752E-06

Epoch 249 of 500
  training loss:		2.699482E-06
  validation loss:		2.327825E-06

Epoch 250 of 500
  training loss:		2.679752E-06
  validation loss:		2.619964E-06

Epoch 251 of 500
  training loss:		2.656635E-06
  validation loss:		2.904198E-06

Epoch 252 of 500
  training loss:		2.627587E-06
  validation loss:		2.319558E-06

Epoch 253 of 500
  training loss:		2.558662E-06
  validation loss:		2.640240E-06

Epoch 254 of 500
  training loss:		2.585241E-06
  validation loss:		2.714354E-06

Epoch 255 of 500
  training loss:		2.541488E-06
  validation loss:		2.205265E-06

Epoch 256 of 500
  training loss:		2.422246E-06
  validation loss:		2.160145E-06

Epoch 257 of 500
  training loss:		2.469227E-06
  validation loss:		2.184086E-06

Epoch 258 of 500
  training loss:		2.404471E-06
  validation loss:		2.101149E-06

Epoch 259 of 500
  training loss:		2.425439E-06
  validation loss:		3.039973E-06

Epoch 260 of 500
  training loss:		2.414838E-06
  validation loss:		2.893858E-06

Epoch 261 of 500
  training loss:		2.355816E-06
  validation loss:		2.805249E-06

Epoch 262 of 500
  training loss:		2.330500E-06
  validation loss:		2.164934E-06

Epoch 263 of 500
  training loss:		2.298131E-06
  validation loss:		2.411329E-06

Epoch 264 of 500
  training loss:		2.238719E-06
  validation loss:		3.163801E-06

Epoch 265 of 500
  training loss:		2.215899E-06
  validation loss:		2.868785E-06

Epoch 266 of 500
  training loss:		2.229077E-06
  validation loss:		2.453723E-06

Epoch 267 of 500
  training loss:		2.158259E-06
  validation loss:		1.952483E-06

Epoch 268 of 500
  training loss:		2.145039E-06
  validation loss:		1.936242E-06

Epoch 269 of 500
  training loss:		2.130776E-06
  validation loss:		3.862983E-06

Epoch 270 of 500
  training loss:		2.130684E-06
  validation loss:		2.000807E-06

Epoch 271 of 500
  training loss:		2.080768E-06
  validation loss:		1.808291E-06

Epoch 272 of 500
  training loss:		2.027282E-06
  validation loss:		1.729476E-06

Epoch 273 of 500
  training loss:		2.036000E-06
  validation loss:		1.950667E-06

Epoch 274 of 500
  training loss:		1.967406E-06
  validation loss:		2.702823E-06

Epoch 275 of 500
  training loss:		1.983115E-06
  validation loss:		1.859040E-06

Epoch 276 of 500
  training loss:		1.959335E-06
  validation loss:		1.808646E-06

Epoch 277 of 500
  training loss:		1.867046E-06
  validation loss:		2.192246E-06

Epoch 278 of 500
  training loss:		1.928063E-06
  validation loss:		2.290048E-06

Epoch 279 of 500
  training loss:		1.877511E-06
  validation loss:		1.583135E-06

Epoch 280 of 500
  training loss:		1.853501E-06
  validation loss:		1.768134E-06

Epoch 281 of 500
  training loss:		1.860824E-06
  validation loss:		1.966588E-06

Epoch 282 of 500
  training loss:		1.853339E-06
  validation loss:		1.589667E-06

Epoch 283 of 500
  training loss:		1.791096E-06
  validation loss:		1.590921E-06

Epoch 284 of 500
  training loss:		1.781937E-06
  validation loss:		1.757766E-06

Epoch 285 of 500
  training loss:		1.757991E-06
  validation loss:		1.602355E-06

Epoch 286 of 500
  training loss:		1.737243E-06
  validation loss:		1.733073E-06

Epoch 287 of 500
  training loss:		1.770737E-06
  validation loss:		1.911328E-06

Epoch 288 of 500
  training loss:		1.681381E-06
  validation loss:		1.627076E-06

Epoch 289 of 500
  training loss:		1.665288E-06
  validation loss:		1.443216E-06

Epoch 290 of 500
  training loss:		1.654509E-06
  validation loss:		1.375753E-06

Epoch 291 of 500
  training loss:		1.644807E-06
  validation loss:		1.447405E-06

Epoch 292 of 500
  training loss:		1.639541E-06
  validation loss:		3.728031E-06

Epoch 293 of 500
  training loss:		1.622875E-06
  validation loss:		1.396149E-06

Epoch 294 of 500
  training loss:		1.585571E-06
  validation loss:		1.371310E-06

Epoch 295 of 500
  training loss:		1.531062E-06
  validation loss:		1.581385E-06

Epoch 296 of 500
  training loss:		1.638284E-06
  validation loss:		2.860080E-06

Epoch 297 of 500
  training loss:		1.527344E-06
  validation loss:		1.267314E-06

Epoch 298 of 500
  training loss:		1.526546E-06
  validation loss:		1.596192E-06

Epoch 299 of 500
  training loss:		1.534849E-06
  validation loss:		1.838352E-06

Epoch 300 of 500
  training loss:		1.476238E-06
  validation loss:		1.357213E-06

Epoch 301 of 500
  training loss:		1.466277E-06
  validation loss:		1.255179E-06

Epoch 302 of 500
  training loss:		1.475691E-06
  validation loss:		1.638591E-06

Epoch 303 of 500
  training loss:		1.416635E-06
  validation loss:		1.800058E-06

Epoch 304 of 500
  training loss:		1.419193E-06
  validation loss:		1.552488E-06

Epoch 305 of 500
  training loss:		1.464408E-06
  validation loss:		1.202092E-06

Epoch 306 of 500
  training loss:		1.410838E-06
  validation loss:		1.167276E-06

Epoch 307 of 500
  training loss:		1.346279E-06
  validation loss:		1.181734E-06

Epoch 308 of 500
  training loss:		1.364279E-06
  validation loss:		1.181908E-06

Epoch 309 of 500
  training loss:		1.360614E-06
  validation loss:		1.176170E-06

Epoch 310 of 500
  training loss:		1.356512E-06
  validation loss:		1.164150E-06

Epoch 311 of 500
  training loss:		1.337000E-06
  validation loss:		1.085838E-06

Epoch 312 of 500
  training loss:		1.281072E-06
  validation loss:		1.076315E-06

Epoch 313 of 500
  training loss:		1.334528E-06
  validation loss:		1.411713E-06

Epoch 314 of 500
  training loss:		1.334491E-06
  validation loss:		1.048595E-06

Epoch 315 of 500
  training loss:		1.292518E-06
  validation loss:		1.034606E-06

Epoch 316 of 500
  training loss:		1.276635E-06
  validation loss:		1.030616E-06

Epoch 317 of 500
  training loss:		1.257027E-06
  validation loss:		1.066230E-06

Epoch 318 of 500
  training loss:		1.263625E-06
  validation loss:		1.624836E-06

Epoch 319 of 500
  training loss:		1.235381E-06
  validation loss:		1.078805E-06

Epoch 320 of 500
  training loss:		1.212490E-06
  validation loss:		1.460381E-06

Epoch 321 of 500
  training loss:		1.222616E-06
  validation loss:		9.656309E-07

Epoch 322 of 500
  training loss:		1.197407E-06
  validation loss:		2.330482E-06

Epoch 323 of 500
  training loss:		1.222601E-06
  validation loss:		1.855692E-06

Epoch 324 of 500
  training loss:		1.161823E-06
  validation loss:		9.435454E-07

Epoch 325 of 500
  training loss:		1.150136E-06
  validation loss:		9.943133E-07

Epoch 326 of 500
  training loss:		1.153443E-06
  validation loss:		1.309921E-06

Epoch 327 of 500
  training loss:		1.114995E-06
  validation loss:		1.170583E-06

Epoch 328 of 500
  training loss:		1.144920E-06
  validation loss:		1.807200E-06

Epoch 329 of 500
  training loss:		1.120897E-06
  validation loss:		1.112376E-06

Epoch 330 of 500
  training loss:		1.090852E-06
  validation loss:		1.081313E-06

Early stopping, val-loss increased over the last 15 epochs from 0.00033525529829 to 0.000350363996111
Training RMSE: 1.02176611532e-09
Validation RMSE: 1.03457502319e-09
