Training network with 45280 training samples and 8490 validation samples
Epoch 1 of 100
  training loss:		4.167410E-02
  validation loss:		4.546152E-03
Epoch took 13.796s

Epoch 2 of 100
  training loss:		8.907643E-03
  validation loss:		2.439245E-03
Epoch took 13.949s

Epoch 3 of 100
  training loss:		5.845952E-03
  validation loss:		1.686847E-03
Epoch took 13.956s

Epoch 4 of 100
  training loss:		3.823345E-03
  validation loss:		2.036832E-03
Epoch took 13.941s

Epoch 5 of 100
  training loss:		2.951846E-03
  validation loss:		1.795888E-03
Epoch took 14.004s

Epoch 6 of 100
  training loss:		2.501030E-03
  validation loss:		8.908067E-04
Epoch took 13.868s

Epoch 7 of 100
  training loss:		2.161414E-03
  validation loss:		5.613251E-04
Epoch took 14.091s

Epoch 8 of 100
  training loss:		1.891552E-03
  validation loss:		6.722694E-04
Epoch took 14.300s

Epoch 9 of 100
  training loss:		1.654961E-03
  validation loss:		6.016053E-04
Epoch took 14.140s

Epoch 10 of 100
  training loss:		1.470126E-03
  validation loss:		4.294669E-04
Epoch took 13.999s

Epoch 11 of 100
  training loss:		1.301501E-03
  validation loss:		6.521184E-04
Epoch took 13.965s

Epoch 12 of 100
  training loss:		1.178933E-03
  validation loss:		4.148126E-04
Epoch took 13.870s

Epoch 13 of 100
  training loss:		1.046497E-03
  validation loss:		3.087138E-04
Epoch took 13.913s

Epoch 14 of 100
  training loss:		8.969707E-04
  validation loss:		2.548359E-04
Epoch took 13.831s

Epoch 15 of 100
  training loss:		8.201785E-04
  validation loss:		3.193430E-04
Epoch took 13.929s

Epoch 16 of 100
  training loss:		7.911156E-04
  validation loss:		3.082413E-04
Epoch took 13.850s

Epoch 17 of 100
  training loss:		6.408995E-04
  validation loss:		4.380385E-04
Epoch took 13.919s

Epoch 18 of 100
  training loss:		6.374393E-04
  validation loss:		3.538182E-04
Epoch took 13.842s

Epoch 19 of 100
  training loss:		5.912533E-04
  validation loss:		2.000716E-04
Epoch took 13.937s

Epoch 20 of 100
  training loss:		5.345259E-04
  validation loss:		4.771918E-04
Epoch took 13.884s

Epoch 21 of 100
  training loss:		5.377114E-04
  validation loss:		3.558565E-04
Epoch took 13.925s

Epoch 22 of 100
  training loss:		4.702750E-04
  validation loss:		1.871397E-04
Epoch took 13.887s

Epoch 23 of 100
  training loss:		4.270399E-04
  validation loss:		1.687807E-04
Epoch took 13.935s

Epoch 24 of 100
  training loss:		4.137076E-04
  validation loss:		1.999477E-04
Epoch took 13.897s

Epoch 25 of 100
  training loss:		3.889270E-04
  validation loss:		1.202313E-04
Epoch took 13.939s

Epoch 26 of 100
  training loss:		3.772475E-04
  validation loss:		1.036957E-04
Epoch took 13.882s

Epoch 27 of 100
  training loss:		3.943788E-04
  validation loss:		1.717761E-04
Epoch took 13.916s

Epoch 28 of 100
  training loss:		3.128543E-04
  validation loss:		1.801876E-04
Epoch took 13.883s

Epoch 29 of 100
  training loss:		2.656286E-04
  validation loss:		3.572241E-04
Epoch took 13.935s

Epoch 30 of 100
  training loss:		2.548837E-04
  validation loss:		1.173556E-04
Epoch took 13.868s

Epoch 31 of 100
  training loss:		3.279589E-04
  validation loss:		1.078298E-04
Epoch took 13.920s

Epoch 32 of 100
  training loss:		2.725600E-04
  validation loss:		1.455689E-04
Epoch took 13.879s

Epoch 33 of 100
  training loss:		2.315594E-04
  validation loss:		9.992953E-05
Epoch took 13.945s

Epoch 34 of 100
  training loss:		1.970339E-04
  validation loss:		1.331878E-04
Epoch took 13.877s

Epoch 35 of 100
  training loss:		2.202243E-04
  validation loss:		9.185756E-05
Epoch took 13.917s

Epoch 36 of 100
  training loss:		1.973925E-04
  validation loss:		7.355464E-05
Epoch took 13.867s

Epoch 37 of 100
  training loss:		2.000601E-04
  validation loss:		1.454435E-04
Epoch took 13.921s

Epoch 38 of 100
  training loss:		1.663262E-04
  validation loss:		1.221965E-04
Epoch took 13.863s

Epoch 39 of 100
  training loss:		1.722874E-04
  validation loss:		8.993876E-05
Epoch took 13.914s

Epoch 40 of 100
  training loss:		1.865628E-04
  validation loss:		6.107309E-05
Epoch took 13.862s

Epoch 41 of 100
  training loss:		1.481909E-04
  validation loss:		7.022448E-05
Epoch took 13.922s

Epoch 42 of 100
  training loss:		1.423030E-04
  validation loss:		4.884960E-05
Epoch took 13.890s

Epoch 43 of 100
  training loss:		1.708571E-04
  validation loss:		9.317374E-05
Epoch took 13.920s

Epoch 44 of 100
  training loss:		1.223528E-04
  validation loss:		5.940509E-05
Epoch took 13.888s

Epoch 45 of 100
  training loss:		1.316897E-04
  validation loss:		4.947734E-05
Epoch took 13.983s

Epoch 46 of 100
  training loss:		1.426917E-04
  validation loss:		6.107267E-05
Epoch took 13.694s

Epoch 47 of 100
  training loss:		1.061028E-04
  validation loss:		2.973946E-05
Epoch took 13.931s

Epoch 48 of 100
  training loss:		1.399685E-04
  validation loss:		1.359586E-04
Epoch took 13.878s

Epoch 49 of 100
  training loss:		1.371240E-04
  validation loss:		1.038544E-04
Epoch took 13.898s

Epoch 50 of 100
  training loss:		9.603218E-05
  validation loss:		3.699875E-05
Epoch took 13.912s

Epoch 51 of 100
  training loss:		9.975934E-05
  validation loss:		3.969945E-05
Epoch took 13.909s

Epoch 52 of 100
  training loss:		1.040185E-04
  validation loss:		1.334803E-04
Epoch took 13.909s

Epoch 53 of 100
  training loss:		1.160010E-04
  validation loss:		2.263577E-04
Epoch took 14.013s

Epoch 54 of 100
  training loss:		9.260218E-05
  validation loss:		3.011379E-05
Epoch took 13.930s

Epoch 55 of 100
  training loss:		1.115061E-04
  validation loss:		4.078229E-05
Epoch took 13.914s

Epoch 56 of 100
  training loss:		1.079208E-04
  validation loss:		6.790074E-05
Epoch took 13.684s

Epoch 57 of 100
  training loss:		8.595493E-05
  validation loss:		3.689618E-05
Epoch took 13.673s

Epoch 58 of 100
  training loss:		7.101128E-05
  validation loss:		6.700352E-05
Epoch took 13.647s

Epoch 59 of 100
  training loss:		8.061343E-05
  validation loss:		7.582954E-05
Epoch took 13.701s

Epoch 60 of 100
  training loss:		8.543823E-05
  validation loss:		1.793121E-04
Epoch took 13.589s

Epoch 61 of 100
  training loss:		8.085366E-05
  validation loss:		1.435464E-04
Epoch took 13.674s

Epoch 62 of 100
  training loss:		8.844407E-05
  validation loss:		3.027976E-05
Epoch took 13.625s

Epoch 63 of 100
  training loss:		6.777214E-05
  validation loss:		1.309533E-04
Epoch took 13.693s

Epoch 64 of 100
  training loss:		6.520554E-05
  validation loss:		3.473666E-05
Epoch took 13.640s

Epoch 65 of 100
  training loss:		6.256285E-05
  validation loss:		3.858212E-05
Epoch took 13.685s

Epoch 66 of 100
  training loss:		8.240844E-05
  validation loss:		8.997375E-05
Epoch took 13.621s

Epoch 67 of 100
  training loss:		7.156251E-05
  validation loss:		7.424161E-05
Epoch took 13.691s

Epoch 68 of 100
  training loss:		6.506362E-05
  validation loss:		5.613769E-05
Epoch took 13.680s

Epoch 69 of 100
  training loss:		7.634188E-05
  validation loss:		2.852634E-05
Epoch took 13.691s

Epoch 70 of 100
  training loss:		5.459503E-05
  validation loss:		2.633444E-05
Epoch took 13.641s

Epoch 71 of 100
  training loss:		5.626702E-05
  validation loss:		2.976191E-05
Epoch took 13.667s

Epoch 72 of 100
  training loss:		6.346461E-05
  validation loss:		6.473250E-05
Epoch took 13.660s

Epoch 73 of 100
  training loss:		5.830414E-05
  validation loss:		4.991534E-05
Epoch took 13.678s

Epoch 74 of 100
  training loss:		5.580127E-05
  validation loss:		2.652017E-05
Epoch took 13.645s

Epoch 75 of 100
  training loss:		6.004421E-05
  validation loss:		3.700619E-05
Epoch took 13.671s

Epoch 76 of 100
  training loss:		5.822081E-05
  validation loss:		9.751345E-05
Epoch took 13.647s

Epoch 77 of 100
  training loss:		6.090824E-05
  validation loss:		8.823358E-05
Epoch took 13.696s

Epoch 78 of 100
  training loss:		7.093634E-05
  validation loss:		4.113723E-05
Epoch took 13.638s

Epoch 79 of 100
  training loss:		4.537454E-05
  validation loss:		1.823140E-05
Epoch took 13.685s

Epoch 80 of 100
  training loss:		5.430316E-05
  validation loss:		1.310210E-05
Epoch took 13.621s

Epoch 81 of 100
  training loss:		4.278905E-05
  validation loss:		5.750161E-05
Epoch took 13.708s

Epoch 82 of 100
  training loss:		4.287560E-05
  validation loss:		1.474811E-05
Epoch took 13.624s

Epoch 83 of 100
  training loss:		4.236836E-05
  validation loss:		2.552544E-05
Epoch took 13.689s

Epoch 84 of 100
  training loss:		5.188945E-05
  validation loss:		1.989978E-05
Epoch took 13.659s

Epoch 85 of 100
  training loss:		4.370399E-05
  validation loss:		2.557964E-05
Epoch took 13.687s

Epoch 86 of 100
  training loss:		5.095348E-05
  validation loss:		3.122892E-05
Epoch took 13.654s

Epoch 87 of 100
  training loss:		4.401045E-05
  validation loss:		7.022237E-05
Epoch took 13.708s

Epoch 88 of 100
  training loss:		4.939092E-05
  validation loss:		3.122625E-05
Epoch took 13.636s

Epoch 89 of 100
  training loss:		4.437294E-05
  validation loss:		6.469616E-05
Epoch took 13.659s

Epoch 90 of 100
  training loss:		7.006561E-05
  validation loss:		2.013982E-05
Epoch took 13.650s

Epoch 91 of 100
  training loss:		3.699256E-05
  validation loss:		1.759506E-05
Epoch took 13.679s

Epoch 92 of 100
  training loss:		3.892387E-05
  validation loss:		8.772296E-06
Epoch took 13.646s

Epoch 93 of 100
  training loss:		4.689255E-05
  validation loss:		1.830872E-05
Epoch took 13.678s

Epoch 94 of 100
  training loss:		3.734949E-05
  validation loss:		9.238010E-06
Epoch took 13.631s

Epoch 95 of 100
  training loss:		3.436416E-05
  validation loss:		2.901185E-05
Epoch took 13.661s

Epoch 96 of 100
  training loss:		3.898921E-05
  validation loss:		7.215340E-05
Epoch took 13.639s

Epoch 97 of 100
  training loss:		3.859869E-05
  validation loss:		1.972123E-05
Epoch took 13.676s

Epoch 98 of 100
  training loss:		4.600150E-05
  validation loss:		2.376374E-05
Epoch took 13.631s

Epoch 99 of 100
  training loss:		3.698807E-05
  validation loss:		1.584251E-05
Epoch took 13.715s

Epoch 100 of 100
  training loss:		3.191749E-05
  validation loss:		1.077707E-05
Epoch took 13.637s

Training RMSE: 3.25527284011e-09
Validation RMSE: 3.21759156899e-09
